{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.vasilyev\\Anaconda3\\lib\\site-packages\\gym\\envs\\registration.py:505: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1` with the environment ID `CartPole-v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\alexander.vasilyev\\pomdp-baselines-main\\utils\\logger.py:9: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.10 it will stop working\n",
      "  from collections import OrderedDict, Set\n",
      "C:\\Users\\alexander.vasilyev\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchkit.pytorch_utils as ptu\n",
    "import torchsde\n",
    "from torch.nn import functional as F\n",
    "import random as rnd\n",
    "import copy as cp\n",
    "# import environments\n",
    "import envs.pomdp\n",
    "import pdb\n",
    "# import recurrent model-free RL (separate architecture)\n",
    "from policies.models.policy_rnn import ModelFreeOffPolicy_Separate_RNN as Policy_RNN\n",
    "from policies.models.policy_rnn_shared import ModelFreeOffPolicy_Shared_RNN as Policy_Shared_RNN\n",
    "from policies.models.policy_mlp import ModelFreeOffPolicy_MLP as Policy_MLP\n",
    "from tqdm import tqdm\n",
    "# import the replay buffer\n",
    "from buffers.seq_replay_buffer_vanilla import SeqReplayBuffer\n",
    "from buffers.simple_replay_buffer import SimpleReplayBuffer \n",
    "from utils import helpers as utl\n",
    "from typing import Sequence\n",
    "from read_ini import read_ini\n",
    "conf =read_ini(\"C:/Users/alexander.vasilyev/pomdp-baselines-main/configfile.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a POMDP environment: Pendulum-V (only observe the velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelFreeOffPolicy_Separate_RNN(\n",
      "  (critic): Critic_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_shortcut_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=2, out_features=48, bias=True)\n",
      "    )\n",
      "    (qf1): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf2): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (critic_target): Critic_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_shortcut_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=2, out_features=48, bias=True)\n",
      "    )\n",
      "    (qf1): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf2): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (actor): Actor_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (policy): DeterministicPolicy(\n",
      "      (fc0): Linear(in_features=104, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (actor_target): Actor_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (policy): DeterministicPolicy(\n",
      "      (fc0): Linear(in_features=104, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "total env episodes 2505 total env steps 501000\n"
     ]
    }
   ],
   "source": [
    "cuda_id = 0  # -1 if using cpu\n",
    "ptu.set_gpu_mode(torch.cuda.is_available() and cuda_id >= 0, cuda_id)\n",
    "\n",
    "env = gym.make(conf[\"env_name\"])\n",
    "max_trajectory_len = env._max_episode_steps\n",
    "act_dim = env.action_space.shape[0]\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "shared = False\n",
    "markov = False\n",
    "\n",
    "if markov:\n",
    "    agent = Policy_MLP(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=act_dim,\n",
    "        algo_name=conf[\"algo_name\"],\n",
    "        dqn_layers=[128, 128],\n",
    "        policy_layers=[128, 128],\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        tau=5e-3,\n",
    "    ).to(ptu.device)\n",
    "    encoder=\"Nan\"\n",
    "else:\n",
    "    if shared:\n",
    "        agent = Policy_Shared_RNN(\n",
    "            obs_dim=obs_dim,\n",
    "            action_dim=act_dim,\n",
    "            encoder=conf[\"encoder\"],\n",
    "            algo_name=conf[\"algo_name\"],\n",
    "            action_embedding_size=int(conf[\"action_embedding_size\"]),\n",
    "            observ_embedding_size=int(conf[\"observ_embedding_size\"]),\n",
    "            reward_embedding_size=int(conf[\"reward_embedding_size\"]),\n",
    "            rnn_hidden_size=int(conf[\"hidden_size\"]),\n",
    "            dqn_layers=[128, 128],\n",
    "            policy_layers=[128, 128],\n",
    "            lr=float(conf[\"lr\"]),\n",
    "            gamma=0.9,\n",
    "            tau=0.005,\n",
    "            embed=True,\n",
    "        ).to(ptu.device)\n",
    "    else: \n",
    "        agent = Policy_RNN(\n",
    "            obs_dim=obs_dim,\n",
    "            action_dim=act_dim,\n",
    "            encoder=conf[\"encoder\"],\n",
    "            algo_name=conf[\"algo_name\"],\n",
    "            action_embedding_size=int(conf[\"action_embedding_size\"]),\n",
    "            observ_embedding_size=int(conf[\"observ_embedding_size\"]),\n",
    "            reward_embedding_size=int(conf[\"reward_embedding_size\"]),\n",
    "            rnn_hidden_size=int(conf[\"hidden_size\"]),\n",
    "            dqn_layers=[128, 128],\n",
    "            policy_layers=[128, 128],\n",
    "            lr=float(conf[\"lr\"]),\n",
    "            gamma=0.9,\n",
    "            tau=0.005,\n",
    "            radii=40,\n",
    "            embed=True,\n",
    "            activation = conf[\"activation\"],\n",
    "        ).to(ptu.device)\n",
    "    \n",
    "print(agent)\n",
    "lr=float(conf[\"lr\"])\n",
    "encoder=conf[\"encoder\"]\n",
    "num_updates_per_iter = int(conf[\"num_updates_per_iter\"])  # training frequency\n",
    "sampled_seq_len = int(conf[\"sampled_seq_len\"])  # context length\n",
    "buffer_size = int(float(conf[\"buffer_size\"]))\n",
    "batch_size = int(conf[\"batch_size\"])\n",
    "dropout_rate=float(conf[\"dropout_rate\"])\n",
    "num_iters = int(conf[\"num_iters\"])\n",
    "num_init_rollouts_pool = int(conf[\"num_init_rollouts_pool\"])\n",
    "num_rollouts_per_iter = int(conf[\"num_rollouts_per_iter\"])\n",
    "total_rollouts = num_init_rollouts_pool + num_iters * num_rollouts_per_iter\n",
    "n_env_steps_total = max_trajectory_len * total_rollouts\n",
    "_n_env_steps_total = 0\n",
    "print(\"total env episodes\", total_rollouts, \"total env steps\", n_env_steps_total)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a recurent model-free RL agent: separate architecture, `lstm` encoder, `oar` policy input space, `td3` RL algorithm (context length set later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define other training parameters such as context length and training frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define key functions: collect rollouts and policy update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ncde_row(obs, next_obs, prev_action, action, prev_reward, reward, steps,init):\n",
    "    \n",
    "    if init:\n",
    "        obs_row= obs\n",
    "        rew_row = prev_reward\n",
    "        act_row = prev_action\n",
    "    else:\n",
    "        obs_row=torch.cat((obs, next_obs),0)\n",
    "        rew_row=torch.cat((prev_reward, reward),0)\n",
    "        act_row=torch.cat((prev_action, action),0)\n",
    " \n",
    "    if shared: \n",
    "        obs_row=agent.observ_embedder(obs_row)\n",
    "        rew_row=agent.reward_embedder(rew_row)\n",
    "        act_row=agent.action_embedder(act_row)\n",
    "    else: \n",
    "        obs_row=agent.actor.observ_embedder(obs_row)\n",
    "        rew_row=agent.actor.reward_embedder(rew_row)\n",
    "        act_row=agent.actor.action_embedder(act_row)\n",
    "    \n",
    "    if init:\n",
    "        time_tensor=torch.tensor([[steps]]).to(ptu.device)\n",
    "    else:\n",
    "        time_tensor=torch.tensor([[steps],[steps+1]]).to(ptu.device)\n",
    "\n",
    "    ncde_row=torch.cat((time_tensor,act_row,obs_row,rew_row),1)\n",
    "    ncde_row=ncde_row[None,:]\n",
    "    \n",
    "    return ncde_row\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_rollouts(\n",
    "    num_rollouts, random_actions=False, deterministic=True, train_mode=True\n",
    "):\n",
    "    \"\"\"collect num_rollouts of trajectories in task and save into policy buffer\n",
    "    :param\n",
    "        random_actions: whether to use policy to sample actions, or randomly sample action space\n",
    "        deterministic: deterministic action selection?\n",
    "        train_mode: whether to train (stored to buffer) or test\n",
    "    \"\"\"\n",
    "    if not train_mode:\n",
    "        assert random_actions == False and deterministic == True\n",
    "\n",
    "    total_steps = 0\n",
    "    total_rewards = 0.0\n",
    "    trewards =[]\n",
    "    for idx in range(num_rollouts):\n",
    "        steps = 0\n",
    "        rewards = 0.0\n",
    "        energy = 0.0\n",
    "        print(env.reset())\n",
    "        obs = ptu.from_numpy(env.reset())\n",
    "        obs = obs.reshape(1, obs.shape[-1])\n",
    "        done_rollout = False\n",
    "        init=True\n",
    "        # get hidden state at timestep=0, None for mlp\n",
    "        \n",
    "        if not markov:\n",
    "            action, reward, internal_state = agent.get_initial_info()\n",
    "\n",
    "            if encoder == \"ncde\":\n",
    "                internal_state= None\n",
    "                ncde_row= create_ncde_row(obs, obs, action, action, reward, reward, steps,init)\n",
    "                prev_action= action.clone()\n",
    "                prev_reward= reward.clone()\n",
    "                next_obs= obs.clone()\n",
    "        \n",
    "        \n",
    "        if train_mode:\n",
    "            # temporary storage\n",
    "            obs_list, act_list, rew_list, next_obs_list, term_list = (\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "            )\n",
    "                           \n",
    "\n",
    "        while not done_rollout:\n",
    "            if markov: \n",
    "                action = agent.act(obs=obs, deterministic=deterministic)[0]\n",
    "            else:\n",
    "                if encoder == \"ncde\":\n",
    "                    (action,_,_,_), internal_state= agent.ncde_act(ncde_row=ncde_row, prev_internal_state=internal_state, obs=obs,  deterministic=deterministic)\n",
    "                else:\n",
    "                    (action, _, _, _), internal_state = agent.act(\n",
    "                        prev_internal_state=internal_state,\n",
    "                        prev_action=action,\n",
    "                        reward=reward,\n",
    "                        obs=obs,\n",
    "                        deterministic=deterministic,\n",
    "                    )\n",
    "            # observe reward and next obs (B=1, dim)\n",
    "            #pdb.set_trace()\n",
    "        \n",
    "            #print(torch.norm(internal_state))\n",
    "            next_obs, reward, done, info = utl.env_step(env, action.squeeze(dim=0))\n",
    "            done_rollout = False if ptu.get_numpy(done[0][0]) == 0.0 else True\n",
    "            init=False\n",
    "            \n",
    "            if not markov:\n",
    "                if encoder == \"ncde\":\n",
    "   \n",
    "                    ncde_row= create_ncde_row(obs, next_obs, prev_action, action, prev_reward, reward, steps,init)\n",
    "            \n",
    "            #switch on/off dropouts\n",
    "            #drop_trigger=rnd.uniform(0,1)\n",
    "            #if drop_trigger<dropout_rate:\n",
    "            #    next_obs=cp.deepcopy(obs)\n",
    "            # update statistics\n",
    "           \n",
    "            rewards += reward.item()\n",
    "            energy += action*action\n",
    "           \n",
    "            # early stopping env: such as rmdp, pomdp, generalize tasks. term ignores timeout\n",
    "            term = (\n",
    "                False\n",
    "                if \"TimeLimit.truncated\" in info or steps >= max_trajectory_len\n",
    "                else done_rollout\n",
    "            )\n",
    "\n",
    "            if train_mode:\n",
    "                # append tensors to temporary storage\n",
    "                obs_list.append(obs)  # (1, dim)\n",
    "                act_list.append(action)  # (1, dim)\n",
    "                rew_list.append(reward)  # (1, dim)\n",
    "                term_list.append(term)  # bool\n",
    "                next_obs_list.append(next_obs)  # (1, dim)\n",
    "            steps += 1\n",
    "            # set: obs <- next_obs\n",
    "            obs = next_obs.clone()\n",
    "            prev_reward= reward.clone()\n",
    "            prev_action= action.clone()\n",
    "        if train_mode:\n",
    "            # add collected sequence to buffer\n",
    "            policy_storage.add_episode(\n",
    "                observations=ptu.get_numpy(torch.cat(obs_list, dim=0)),  # (L, dim)\n",
    "                actions=ptu.get_numpy(torch.cat(act_list, dim=0)),  # (L, dim)\n",
    "                rewards=ptu.get_numpy(torch.cat(rew_list, dim=0)),  # (L, dim)\n",
    "                terminals=np.array(term_list).reshape(-1, 1),  # (L, 1)\n",
    "                next_observations=ptu.get_numpy(\n",
    "                    torch.cat(next_obs_list, dim=0)\n",
    "                ),  # (L, dim)\n",
    "            )\n",
    "        print(\n",
    "            \"Mode:\",\n",
    "            \"Train\" if train_mode else \"Test\",\n",
    "            \"env_steps\",\n",
    "            steps,\n",
    "            \"total rewards\",\n",
    "            rewards,\n",
    "            \"total energy\",\n",
    "            energy,\n",
    "        )\n",
    "        total_steps += steps\n",
    "        total_rewards += rewards\n",
    "        trewards.append(rewards)\n",
    "    if train_mode:\n",
    "        return total_steps\n",
    "    else:\n",
    "        return total_rewards / num_rollouts, np.std(trewards)\n",
    "\n",
    "\n",
    "def update(num_updates, factor):\n",
    "    rl_losses_agg = {}\n",
    "    # print(num_updates)\n",
    "    for update in tqdm(range(num_updates), leave=True):\n",
    "        # sample random RL batch: in transitions\n",
    "        batch = ptu.np_to_pytorch_batch(policy_storage.random_episodes(batch_size))\n",
    "        # RL update\n",
    "        \n",
    "        rl_losses = agent.update(batch, factor)\n",
    "\n",
    "        for k, v in rl_losses.items():\n",
    "            if update == 0:  # first iterate - create list\n",
    "                rl_losses_agg[k] = [v]\n",
    "            else:  # append values\n",
    "                rl_losses_agg[k].append(v)\n",
    "    # statistics\n",
    "    for k in rl_losses_agg:\n",
    "        rl_losses_agg[k] = np.mean(rl_losses_agg[k])\n",
    "    return rl_losses_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the agent: only costs < 20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer RAM usage: 0.02 GB\n",
      "[-0.9953948]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.vasilyev\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Train env_steps 200 total rewards -1570.046748161316 total energy tensor([[6.6871e-05]])\n",
      "[0.23094335]\n",
      "Mode: Train env_steps 200 total rewards -957.7108780145645 total energy tensor([[0.0007]])\n",
      "[-0.55273527]\n",
      "Mode: Train env_steps 200 total rewards -1391.0569982528687 total energy tensor([[0.0003]])\n",
      "[-0.8675668]\n",
      "Mode: Train env_steps 200 total rewards -1191.461077928543 total energy tensor([[0.0004]])\n",
      "[-0.3151585]\n",
      "Mode: Train env_steps 200 total rewards -1307.7665836811066 total energy tensor([[0.0004]])\n",
      "[0.05086967]\n",
      "Mode: Train env_steps 200 total rewards -1831.725305557251 total energy tensor([[3.5283e-05]])\n",
      "[0.80072767]\n",
      "Mode: Train env_steps 200 total rewards -1324.2787919044495 total energy tensor([[0.0003]])\n",
      "[-0.27755544]\n",
      "Mode: Train env_steps 200 total rewards -630.769354712218 total energy tensor([[0.0002]])\n",
      "[0.56966573]\n",
      "Mode: Train env_steps 200 total rewards -1451.595944404602 total energy tensor([[0.0002]])\n",
      "[0.3534958]\n",
      "Mode: Train env_steps 200 total rewards -970.4422736763954 total energy tensor([[0.0006]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\alexander.vasilyev\\pomdp-baselines-main\\torchkit\\pytorch_utils.py:73: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if v.dtype == np.bool:\n",
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6530923]\n",
      "Mode: Train env_steps 200 total rewards -1292.5857775211334 total energy tensor([[186.6316]])\n",
      "[-0.07260388]\n",
      "Mode: Train env_steps 200 total rewards -1534.510039806366 total energy tensor([[188.9306]])\n",
      "[-0.264491]\n",
      "Mode: Train env_steps 200 total rewards -1468.8469953536987 total energy tensor([[191.1458]])\n",
      "[-0.20494787]\n",
      "Mode: Train env_steps 200 total rewards -1610.4021558761597 total energy tensor([[192.5283]])\n",
      "[-0.79145616]\n",
      "Mode: Train env_steps 200 total rewards -1419.9829085469246 total energy tensor([[190.8808]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1764962]\n",
      "Mode: Train env_steps 200 total rewards -1600.8015027046204 total energy tensor([[32.5889]])\n",
      "[0.3663391]\n",
      "Mode: Train env_steps 200 total rewards -1683.8662447929382 total energy tensor([[29.5105]])\n",
      "[0.2694646]\n",
      "Mode: Train env_steps 200 total rewards -1397.6177160441875 total energy tensor([[65.6285]])\n",
      "[-0.55143595]\n",
      "Mode: Train env_steps 200 total rewards -1400.397753417492 total energy tensor([[65.9454]])\n",
      "[-0.8337831]\n",
      "Mode: Train env_steps 200 total rewards -1566.1663113832474 total energy tensor([[34.1099]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35029215]\n",
      "Mode: Train env_steps 200 total rewards -1250.751866042614 total energy tensor([[150.8866]])\n",
      "[0.5181941]\n",
      "Mode: Train env_steps 200 total rewards -1526.6400017738342 total energy tensor([[172.9350]])\n",
      "[-0.28004476]\n",
      "Mode: Train env_steps 200 total rewards -1616.065242946148 total energy tensor([[172.1550]])\n",
      "[0.35532135]\n",
      "Mode: Train env_steps 200 total rewards -1528.3379611968994 total energy tensor([[176.6349]])\n",
      "[-0.6493892]\n",
      "Mode: Train env_steps 200 total rewards -1606.5569690465927 total energy tensor([[171.7289]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6333513]\n",
      "Mode: Test env_steps 200 total rewards -1591.1226505019004 total energy tensor([[193.2074]])\n",
      "[-0.6520536]\n",
      "Mode: Test env_steps 200 total rewards -1194.9621276855469 total energy tensor([[150.1358]])\n",
      "[-0.6058455]\n",
      "Mode: Test env_steps 200 total rewards -1308.9288175106049 total energy tensor([[156.8155]])\n",
      "[-0.3227725]\n",
      "Mode: Test env_steps 200 total rewards -1632.9329324960709 total energy tensor([[195.0854]])\n",
      "[-0.7857761]\n",
      "Mode: Test env_steps 200 total rewards -1357.5720357894897 total energy tensor([[161.8741]])\n",
      "[-0.5482783]\n",
      "Mode: Test env_steps 200 total rewards -1516.1718697547913 total energy tensor([[185.9533]])\n",
      "[-0.3075142]\n",
      "Mode: Test env_steps 200 total rewards -1668.3143776655197 total energy tensor([[196.3662]])\n",
      "[0.00319802]\n",
      "Mode: Test env_steps 200 total rewards -1196.0265407562256 total energy tensor([[150.9898]])\n",
      "[-0.43020102]\n",
      "Mode: Test env_steps 200 total rewards -1660.0613567829132 total energy tensor([[195.8461]])\n",
      "[0.35809192]\n",
      "Mode: Test env_steps 200 total rewards -1182.723680138588 total energy tensor([[150.9797]])\n",
      "5000 -1430.881638908165\n",
      "[0.9663308]\n",
      "Mode: Train env_steps 200 total rewards -1646.4559853076935 total energy tensor([[196.2601]])\n",
      "[-0.2520168]\n",
      "Mode: Train env_steps 200 total rewards -1619.9906240701675 total energy tensor([[195.0994]])\n",
      "[-0.33643895]\n",
      "Mode: Train env_steps 200 total rewards -1522.9166278839111 total energy tensor([[170.0881]])\n",
      "[-0.6554067]\n",
      "Mode: Train env_steps 200 total rewards -1652.1654697656631 total energy tensor([[195.4865]])\n",
      "[0.5898754]\n",
      "Mode: Train env_steps 200 total rewards -1239.8700284957886 total energy tensor([[152.7382]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80033517]\n",
      "Mode: Train env_steps 200 total rewards -1660.9731088876724 total energy tensor([[197.6273]])\n",
      "[-0.6060469]\n",
      "Mode: Train env_steps 200 total rewards -1613.774273097515 total energy tensor([[196.2608]])\n",
      "[0.40612775]\n",
      "Mode: Train env_steps 200 total rewards -1311.463769197464 total energy tensor([[155.8935]])\n",
      "[-0.13136658]\n",
      "Mode: Train env_steps 200 total rewards -1680.4451575279236 total energy tensor([[198.2163]])\n",
      "[0.10135972]\n",
      "Mode: Train env_steps 200 total rewards -1349.4951484203339 total energy tensor([[160.0383]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01462566]\n",
      "Mode: Train env_steps 200 total rewards -1608.5683520082384 total energy tensor([[196.2491]])\n",
      "[0.58045775]\n",
      "Mode: Train env_steps 200 total rewards -1663.5084693431854 total energy tensor([[196.8876]])\n",
      "[-0.78630817]\n",
      "Mode: Train env_steps 200 total rewards -1658.2521106600761 total energy tensor([[197.8923]])\n",
      "[0.80784464]\n",
      "Mode: Train env_steps 200 total rewards -1656.1515065729618 total energy tensor([[198.2703]])\n",
      "[0.47359356]\n",
      "Mode: Train env_steps 200 total rewards -1627.8462223410606 total energy tensor([[197.1793]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77472633]\n",
      "Mode: Train env_steps 200 total rewards -1653.83756005764 total energy tensor([[197.5097]])\n",
      "[-0.6253975]\n",
      "Mode: Train env_steps 200 total rewards -1201.3327702730894 total energy tensor([[124.5586]])\n",
      "[-0.51630944]\n",
      "Mode: Train env_steps 200 total rewards -1458.6578917503357 total energy tensor([[151.4948]])\n",
      "[-0.81158847]\n",
      "Mode: Train env_steps 200 total rewards -1492.6535477638245 total energy tensor([[146.1502]])\n",
      "[-0.79867697]\n",
      "Mode: Train env_steps 200 total rewards -1502.6089973449707 total energy tensor([[191.3912]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98014677]\n",
      "Mode: Train env_steps 200 total rewards -1314.1471347212791 total energy tensor([[129.9218]])\n",
      "[-0.16630927]\n",
      "Mode: Train env_steps 200 total rewards -1642.1675062775612 total energy tensor([[196.4019]])\n",
      "[0.49864072]\n",
      "Mode: Train env_steps 200 total rewards -1621.7061980701983 total energy tensor([[197.3051]])\n",
      "[-0.52736425]\n",
      "Mode: Train env_steps 200 total rewards -1523.3434495925903 total energy tensor([[185.2525]])\n",
      "[-0.7763645]\n",
      "Mode: Train env_steps 200 total rewards -1467.2688605338335 total energy tensor([[193.0328]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39615124]\n",
      "Mode: Test env_steps 200 total rewards -1620.969302892685 total energy tensor([[195.7810]])\n",
      "[-0.3135149]\n",
      "Mode: Test env_steps 200 total rewards -1389.6021480560303 total energy tensor([[139.4613]])\n",
      "[0.80440015]\n",
      "Mode: Test env_steps 200 total rewards -1530.8164944648743 total energy tensor([[178.2107]])\n",
      "[-0.17901708]\n",
      "Mode: Test env_steps 200 total rewards -1603.2320405766368 total energy tensor([[196.9255]])\n",
      "[0.57314587]\n",
      "Mode: Test env_steps 200 total rewards -1654.0726263523102 total energy tensor([[198.7420]])\n",
      "[-0.19431175]\n",
      "Mode: Test env_steps 200 total rewards -1540.9245352745056 total energy tensor([[175.3083]])\n",
      "[-0.574566]\n",
      "Mode: Test env_steps 200 total rewards -1493.801738023758 total energy tensor([[151.4586]])\n",
      "[-0.13677183]\n",
      "Mode: Test env_steps 200 total rewards -1532.7721481323242 total energy tensor([[178.3710]])\n",
      "[0.3072443]\n",
      "Mode: Test env_steps 200 total rewards -1103.506862707436 total energy tensor([[143.3534]])\n",
      "[-0.06332374]\n",
      "Mode: Test env_steps 200 total rewards -1599.7130071520805 total energy tensor([[195.2243]])\n",
      "10000 -1506.941090363264\n",
      "[-0.971661]\n",
      "Mode: Train env_steps 200 total rewards -1214.7075645327568 total energy tensor([[135.5865]])\n",
      "[-0.8724579]\n",
      "Mode: Train env_steps 200 total rewards -1389.185245513916 total energy tensor([[139.4428]])\n",
      "[0.0594844]\n",
      "Mode: Train env_steps 200 total rewards -1265.0857129693031 total energy tensor([[137.4011]])\n",
      "[-0.9918277]\n",
      "Mode: Train env_steps 200 total rewards -1526.53981924057 total energy tensor([[181.8960]])\n",
      "[0.9072699]\n",
      "Mode: Train env_steps 200 total rewards -1389.4804567098618 total energy tensor([[139.4477]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17232378]\n",
      "Mode: Train env_steps 200 total rewards -1214.0089320540428 total energy tensor([[148.9593]])\n",
      "[-0.74649876]\n",
      "Mode: Train env_steps 200 total rewards -1237.4409682750702 total energy tensor([[152.2354]])\n",
      "[-0.6065079]\n",
      "Mode: Train env_steps 200 total rewards -1595.222753237933 total energy tensor([[195.8528]])\n",
      "[0.07025519]\n",
      "Mode: Train env_steps 200 total rewards -1667.9964027404785 total energy tensor([[198.5607]])\n",
      "[-0.33184913]\n",
      "Mode: Train env_steps 200 total rewards -1612.9413672685623 total energy tensor([[196.7578]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.73481977]\n",
      "Mode: Train env_steps 200 total rewards -1641.7465392947197 total energy tensor([[197.6133]])\n",
      "[-0.9958827]\n",
      "Mode: Train env_steps 200 total rewards -1511.5794820785522 total energy tensor([[182.6547]])\n",
      "[0.64565325]\n",
      "Mode: Train env_steps 200 total rewards -1565.0847837924957 total energy tensor([[194.2355]])\n",
      "[0.8217423]\n",
      "Mode: Train env_steps 200 total rewards -1199.872122168541 total energy tensor([[157.0074]])\n",
      "[0.9914251]\n",
      "Mode: Train env_steps 200 total rewards -1676.6251014471054 total energy tensor([[197.4674]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54054445]\n",
      "Mode: Train env_steps 200 total rewards -1614.507150888443 total energy tensor([[196.8488]])\n",
      "[-0.7627825]\n",
      "Mode: Train env_steps 200 total rewards -1209.9574131071568 total energy tensor([[141.3745]])\n",
      "[-0.42021376]\n",
      "Mode: Train env_steps 200 total rewards -1362.4289116859436 total energy tensor([[154.1973]])\n",
      "[-0.74000233]\n",
      "Mode: Train env_steps 200 total rewards -1510.93989944458 total energy tensor([[176.5977]])\n",
      "[-0.0577843]\n",
      "Mode: Train env_steps 200 total rewards -1377.1131842136383 total energy tensor([[156.1472]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9887144]\n",
      "Mode: Train env_steps 200 total rewards -1075.496035888791 total energy tensor([[136.3950]])\n",
      "[-0.46115187]\n",
      "Mode: Train env_steps 200 total rewards -1557.528829306364 total energy tensor([[194.4334]])\n",
      "[0.4036603]\n",
      "Mode: Train env_steps 200 total rewards -1331.8211908340454 total energy tensor([[150.6517]])\n",
      "[0.74670345]\n",
      "Mode: Train env_steps 200 total rewards -1169.6124024391174 total energy tensor([[139.5017]])\n",
      "[0.9532278]\n",
      "Mode: Train env_steps 200 total rewards -1653.5644142627716 total energy tensor([[198.1378]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48841473]\n",
      "Mode: Test env_steps 200 total rewards -1269.8523055315018 total energy tensor([[152.9609]])\n",
      "[-0.26954827]\n",
      "Mode: Test env_steps 200 total rewards -1619.4166123569012 total energy tensor([[197.2328]])\n",
      "[0.763569]\n",
      "Mode: Test env_steps 200 total rewards -1453.3111608028412 total energy tensor([[152.2433]])\n",
      "[-0.4140864]\n",
      "Mode: Test env_steps 200 total rewards -1406.0227522850037 total energy tensor([[162.9699]])\n",
      "[0.9197889]\n",
      "Mode: Test env_steps 200 total rewards -1382.1915171146393 total energy tensor([[153.0947]])\n",
      "[-0.46773684]\n",
      "Mode: Test env_steps 200 total rewards -1455.5512926578522 total energy tensor([[152.2543]])\n",
      "[0.74880385]\n",
      "Mode: Test env_steps 200 total rewards -1668.4558839797974 total energy tensor([[198.2076]])\n",
      "[0.30016196]\n",
      "Mode: Test env_steps 200 total rewards -1464.3541204929352 total energy tensor([[150.9615]])\n",
      "[-0.8093361]\n",
      "Mode: Test env_steps 200 total rewards -1351.3670094013214 total energy tensor([[155.4343]])\n",
      "[-0.82784605]\n",
      "Mode: Test env_steps 200 total rewards -979.1886621117592 total energy tensor([[145.9336]])\n",
      "15000 -1404.9711316734551\n",
      "[-0.5330307]\n",
      "Mode: Train env_steps 200 total rewards -1662.6915264129639 total energy tensor([[198.1042]])\n",
      "[-0.01074553]\n",
      "Mode: Train env_steps 200 total rewards -1064.0077313184738 total energy tensor([[149.0996]])\n",
      "[-0.2431869]\n",
      "Mode: Train env_steps 200 total rewards -1469.844259262085 total energy tensor([[151.3853]])\n",
      "[-0.96953166]\n",
      "Mode: Train env_steps 200 total rewards -1447.2057275772095 total energy tensor([[166.6521]])\n",
      "[0.07457551]\n",
      "Mode: Train env_steps 200 total rewards -1496.2610275745392 total energy tensor([[155.9470]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37617218]\n",
      "Mode: Train env_steps 200 total rewards -1634.2962954193354 total energy tensor([[197.8594]])\n",
      "[0.90931964]\n",
      "Mode: Train env_steps 200 total rewards -1643.6109041571617 total energy tensor([[197.0889]])\n",
      "[-0.595823]\n",
      "Mode: Train env_steps 200 total rewards -1479.6533434391022 total energy tensor([[146.7735]])\n",
      "[-0.2559869]\n",
      "Mode: Train env_steps 200 total rewards -1666.2955662608147 total energy tensor([[198.2735]])\n",
      "[0.6660296]\n",
      "Mode: Train env_steps 200 total rewards -1651.054469794035 total energy tensor([[198.2557]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.71436155]\n",
      "Mode: Train env_steps 200 total rewards -1179.3437259793282 total energy tensor([[140.6127]])\n",
      "[-0.05427961]\n",
      "Mode: Train env_steps 200 total rewards -1687.7663143873215 total energy tensor([[198.5286]])\n",
      "[0.7248283]\n",
      "Mode: Train env_steps 200 total rewards -1430.7561786174774 total energy tensor([[135.3645]])\n",
      "[0.5194244]\n",
      "Mode: Train env_steps 200 total rewards -1514.8557510375977 total energy tensor([[160.6187]])\n",
      "[-0.14715646]\n",
      "Mode: Train env_steps 200 total rewards -1359.7426879405975 total energy tensor([[138.4543]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8151505]\n",
      "Mode: Train env_steps 200 total rewards -1475.5719527453184 total energy tensor([[185.4223]])\n",
      "[-0.08570853]\n",
      "Mode: Train env_steps 200 total rewards -1488.0073370933533 total energy tensor([[133.5710]])\n",
      "[0.39713612]\n",
      "Mode: Train env_steps 200 total rewards -1582.1451513171196 total energy tensor([[197.0900]])\n",
      "[-0.20184551]\n",
      "Mode: Train env_steps 200 total rewards -1414.223392009735 total energy tensor([[138.5287]])\n",
      "[0.4304767]\n",
      "Mode: Train env_steps 200 total rewards -1555.7878007888794 total energy tensor([[124.2379]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13090466]\n",
      "Mode: Train env_steps 200 total rewards -1489.2742176055908 total energy tensor([[130.6584]])\n",
      "[-0.8263749]\n",
      "Mode: Train env_steps 200 total rewards -1470.3203933238983 total energy tensor([[136.7842]])\n",
      "[0.49241814]\n",
      "Mode: Train env_steps 200 total rewards -1422.9390943050385 total energy tensor([[140.4934]])\n",
      "[0.19625297]\n",
      "Mode: Train env_steps 200 total rewards -1393.7790410518646 total energy tensor([[140.6498]])\n",
      "[-0.15007113]\n",
      "Mode: Train env_steps 200 total rewards -1659.266262292862 total energy tensor([[198.4531]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42558375]\n",
      "Mode: Test env_steps 200 total rewards -1567.8286480903625 total energy tensor([[73.0550]])\n",
      "[0.7135994]\n",
      "Mode: Test env_steps 200 total rewards -1634.1204015016556 total energy tensor([[198.4404]])\n",
      "[-0.70155895]\n",
      "Mode: Test env_steps 200 total rewards -1639.7544022649527 total energy tensor([[198.3839]])\n",
      "[0.557777]\n",
      "Mode: Test env_steps 200 total rewards -1529.8269958496094 total energy tensor([[85.1752]])\n",
      "[0.9978542]\n",
      "Mode: Test env_steps 200 total rewards -1561.2494359016418 total energy tensor([[98.0612]])\n",
      "[-0.89666015]\n",
      "Mode: Test env_steps 200 total rewards -1665.5139396190643 total energy tensor([[198.6536]])\n",
      "[-0.57927865]\n",
      "Mode: Test env_steps 200 total rewards -1063.539028301835 total energy tensor([[132.1996]])\n",
      "[0.5347754]\n",
      "Mode: Test env_steps 200 total rewards -1560.529513835907 total energy tensor([[82.0869]])\n",
      "[0.90398246]\n",
      "Mode: Test env_steps 200 total rewards -1591.4141974300146 total energy tensor([[195.6168]])\n",
      "[0.21964037]\n",
      "Mode: Test env_steps 200 total rewards -1558.6401076316833 total energy tensor([[82.5429]])\n",
      "20000 -1537.2416670426726\n",
      "[0.42828256]\n",
      "Mode: Train env_steps 200 total rewards -1538.6900925636292 total energy tensor([[94.7995]])\n",
      "[0.56822366]\n",
      "Mode: Train env_steps 200 total rewards -1214.5204889178276 total energy tensor([[139.6053]])\n",
      "[0.80535316]\n",
      "Mode: Train env_steps 200 total rewards -1410.2827064990997 total energy tensor([[122.6733]])\n",
      "[0.57245594]\n",
      "Mode: Train env_steps 200 total rewards -1657.8377511501312 total energy tensor([[198.6494]])\n",
      "[0.5752235]\n",
      "Mode: Train env_steps 200 total rewards -1584.6601781845093 total energy tensor([[71.6786]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8161433]\n",
      "Mode: Train env_steps 200 total rewards -1080.7843383550644 total energy tensor([[147.7792]])\n",
      "[-0.09066819]\n",
      "Mode: Train env_steps 200 total rewards -1559.360613822937 total energy tensor([[133.6475]])\n",
      "[0.43093368]\n",
      "Mode: Train env_steps 200 total rewards -965.4346897006035 total energy tensor([[143.3597]])\n",
      "[0.16481566]\n",
      "Mode: Train env_steps 200 total rewards -1416.1400382518768 total energy tensor([[155.6147]])\n",
      "[0.6171744]\n",
      "Mode: Train env_steps 200 total rewards -1606.4332913160324 total energy tensor([[198.4424]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5234953]\n",
      "Mode: Train env_steps 200 total rewards -1292.640330672264 total energy tensor([[148.4431]])\n",
      "[-0.16127905]\n",
      "Mode: Train env_steps 200 total rewards -1596.9458253830671 total energy tensor([[196.0781]])\n",
      "[-0.7692602]\n",
      "Mode: Train env_steps 200 total rewards -1529.7884430885315 total energy tensor([[150.1188]])\n",
      "[-0.1513886]\n",
      "Mode: Train env_steps 200 total rewards -1632.9202704429626 total energy tensor([[196.0091]])\n",
      "[-0.5706148]\n",
      "Mode: Train env_steps 200 total rewards -1402.2752766609192 total energy tensor([[144.2415]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03332519]\n",
      "Mode: Train env_steps 200 total rewards -1443.4753391742706 total energy tensor([[128.4075]])\n",
      "[-0.02085755]\n",
      "Mode: Train env_steps 200 total rewards -1558.9102549552917 total energy tensor([[93.1461]])\n",
      "[-0.6067226]\n",
      "Mode: Train env_steps 200 total rewards -1556.263222694397 total energy tensor([[96.5679]])\n",
      "[-0.77872485]\n",
      "Mode: Train env_steps 200 total rewards -1667.9735379219055 total energy tensor([[198.5100]])\n",
      "[-0.40144232]\n",
      "Mode: Train env_steps 200 total rewards -1540.8821258544922 total energy tensor([[110.4952]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00286688]\n",
      "Mode: Train env_steps 200 total rewards -1527.4438523948193 total energy tensor([[187.0760]])\n",
      "[-0.5593529]\n",
      "Mode: Train env_steps 200 total rewards -1575.0267701148987 total energy tensor([[82.5706]])\n",
      "[-0.6983604]\n",
      "Mode: Train env_steps 200 total rewards -1643.8118959516287 total energy tensor([[198.6110]])\n",
      "[-0.5896251]\n",
      "Mode: Train env_steps 200 total rewards -1626.9395961761475 total energy tensor([[197.4593]])\n",
      "[0.5009804]\n",
      "Mode: Train env_steps 200 total rewards -1557.5580531656742 total energy tensor([[194.6254]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28020445]\n",
      "Mode: Test env_steps 200 total rewards -1654.2448801994324 total energy tensor([[196.2813]])\n",
      "[-0.4166649]\n",
      "Mode: Test env_steps 200 total rewards -1617.466546535492 total energy tensor([[196.2079]])\n",
      "[0.8640165]\n",
      "Mode: Test env_steps 200 total rewards -1434.6545827388763 total energy tensor([[106.0474]])\n",
      "[0.24295908]\n",
      "Mode: Test env_steps 200 total rewards -1206.4899674654007 total energy tensor([[137.7142]])\n",
      "[-0.03731411]\n",
      "Mode: Test env_steps 200 total rewards -1654.763708114624 total energy tensor([[197.9906]])\n",
      "[0.6838145]\n",
      "Mode: Test env_steps 200 total rewards -1527.341768503189 total energy tensor([[186.2759]])\n",
      "[-0.29936093]\n",
      "Mode: Test env_steps 200 total rewards -1636.3502083793283 total energy tensor([[198.6444]])\n",
      "[0.15354222]\n",
      "Mode: Test env_steps 200 total rewards -1654.4954957962036 total energy tensor([[198.1322]])\n",
      "[0.73334736]\n",
      "Mode: Test env_steps 200 total rewards -1575.605411529541 total energy tensor([[64.4815]])\n",
      "[-0.69080186]\n",
      "Mode: Test env_steps 200 total rewards -1487.9219551086426 total energy tensor([[109.5502]])\n",
      "25000 -1544.933452437073\n",
      "[-0.26630896]\n",
      "Mode: Train env_steps 200 total rewards -1606.9573862552643 total energy tensor([[196.7328]])\n",
      "[-0.78817284]\n",
      "Mode: Train env_steps 200 total rewards -1527.1796257942915 total energy tensor([[184.1534]])\n",
      "[-0.4105977]\n",
      "Mode: Train env_steps 200 total rewards -1262.758405327797 total energy tensor([[136.9827]])\n",
      "[-0.02971515]\n",
      "Mode: Train env_steps 200 total rewards -1521.3809663951397 total energy tensor([[186.3389]])\n",
      "[-0.25308445]\n",
      "Mode: Train env_steps 200 total rewards -1622.5379999428988 total energy tensor([[196.7901]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3856272]\n",
      "Mode: Train env_steps 200 total rewards -1546.932912349701 total energy tensor([[188.3894]])\n",
      "[0.94032335]\n",
      "Mode: Train env_steps 200 total rewards -1675.012769460678 total energy tensor([[198.1418]])\n",
      "[-0.4005443]\n",
      "Mode: Train env_steps 200 total rewards -1658.2944753170013 total energy tensor([[197.0316]])\n",
      "[-0.31921673]\n",
      "Mode: Train env_steps 200 total rewards -1626.9029843956232 total energy tensor([[196.9459]])\n",
      "[0.49886644]\n",
      "Mode: Train env_steps 200 total rewards -1275.4114274978638 total energy tensor([[143.1814]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42943108]\n",
      "Mode: Train env_steps 200 total rewards -1595.5994859337807 total energy tensor([[198.6341]])\n",
      "[0.9833914]\n",
      "Mode: Train env_steps 200 total rewards -1525.3437778949738 total energy tensor([[95.0001]])\n",
      "[0.8769261]\n",
      "Mode: Train env_steps 200 total rewards -1554.9462280273438 total energy tensor([[195.2823]])\n",
      "[0.6121928]\n",
      "Mode: Train env_steps 200 total rewards -1476.8272704705596 total energy tensor([[177.8099]])\n",
      "[0.01624557]\n",
      "Mode: Train env_steps 200 total rewards -1552.7641406059265 total energy tensor([[91.8775]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9911597]\n",
      "Mode: Train env_steps 200 total rewards -1666.1428331136703 total energy tensor([[197.5646]])\n",
      "[-0.77911377]\n",
      "Mode: Train env_steps 200 total rewards -1372.383288860321 total energy tensor([[132.8015]])\n",
      "[-0.767282]\n",
      "Mode: Train env_steps 200 total rewards -1564.9293203353882 total energy tensor([[66.3673]])\n",
      "[0.01610684]\n",
      "Mode: Train env_steps 200 total rewards -1252.9928743839264 total energy tensor([[144.9239]])\n",
      "[0.5204888]\n",
      "Mode: Train env_steps 200 total rewards -1558.5962917804718 total energy tensor([[83.0015]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09807338]\n",
      "Mode: Train env_steps 200 total rewards -1492.746832370758 total energy tensor([[85.9857]])\n",
      "[0.66831607]\n",
      "Mode: Train env_steps 200 total rewards -1614.2336931228638 total energy tensor([[62.0060]])\n",
      "[-0.0147096]\n",
      "Mode: Train env_steps 200 total rewards -1596.6573104858398 total energy tensor([[75.6174]])\n",
      "[0.41357175]\n",
      "Mode: Train env_steps 200 total rewards -1631.9696106910706 total energy tensor([[60.3110]])\n",
      "[0.51490605]\n",
      "Mode: Train env_steps 200 total rewards -1523.1902776136994 total energy tensor([[181.4191]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9041246]\n",
      "Mode: Test env_steps 200 total rewards -1538.6188448369503 total energy tensor([[183.8882]])\n",
      "[0.8792343]\n",
      "Mode: Test env_steps 200 total rewards -1568.6687900424004 total energy tensor([[194.0315]])\n",
      "[-0.28801107]\n",
      "Mode: Test env_steps 200 total rewards -1566.1728739738464 total energy tensor([[70.7321]])\n",
      "[0.5481155]\n",
      "Mode: Test env_steps 200 total rewards -1578.2023842334747 total energy tensor([[61.8641]])\n",
      "[0.61569566]\n",
      "Mode: Test env_steps 200 total rewards -1598.832320690155 total energy tensor([[56.3246]])\n",
      "[-0.18144964]\n",
      "Mode: Test env_steps 200 total rewards -1638.2242119461298 total energy tensor([[198.4756]])\n",
      "[-0.628173]\n",
      "Mode: Test env_steps 200 total rewards -1566.9826867580414 total energy tensor([[73.2172]])\n",
      "[0.8194282]\n",
      "Mode: Test env_steps 200 total rewards -1567.5499427318573 total energy tensor([[74.4501]])\n",
      "[0.04724132]\n",
      "Mode: Test env_steps 200 total rewards -1597.5296577364206 total energy tensor([[194.7876]])\n",
      "[-0.7446099]\n",
      "Mode: Test env_steps 200 total rewards -1580.6126117706299 total energy tensor([[65.0844]])\n",
      "30000 -1580.1394324719906\n",
      "[0.28454995]\n",
      "Mode: Train env_steps 200 total rewards -1590.1974551081657 total energy tensor([[197.7517]])\n",
      "[0.9743081]\n",
      "Mode: Train env_steps 200 total rewards -1213.84916472435 total energy tensor([[141.8741]])\n",
      "[0.14820904]\n",
      "Mode: Train env_steps 200 total rewards -1538.6337905228138 total energy tensor([[188.0868]])\n",
      "[-0.73818785]\n",
      "Mode: Train env_steps 200 total rewards -1518.4228067994118 total energy tensor([[190.2238]])\n",
      "[-0.8110257]\n",
      "Mode: Train env_steps 200 total rewards -1666.977681517601 total energy tensor([[197.4434]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78177166]\n",
      "Mode: Train env_steps 200 total rewards -1677.0982981920242 total energy tensor([[198.0173]])\n",
      "[0.78418964]\n",
      "Mode: Train env_steps 200 total rewards -1613.225326538086 total energy tensor([[197.1135]])\n",
      "[-0.37393293]\n",
      "Mode: Train env_steps 200 total rewards -1665.9088027477264 total energy tensor([[198.6102]])\n",
      "[0.9030602]\n",
      "Mode: Train env_steps 200 total rewards -1633.8494119644165 total energy tensor([[195.1508]])\n",
      "[0.38347748]\n",
      "Mode: Train env_steps 200 total rewards -1633.9721720293164 total energy tensor([[198.3760]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98839873]\n",
      "Mode: Train env_steps 200 total rewards -1536.892957881093 total energy tensor([[184.3905]])\n",
      "[-0.50369275]\n",
      "Mode: Train env_steps 200 total rewards -1656.8013538122177 total energy tensor([[195.7839]])\n",
      "[0.685719]\n",
      "Mode: Train env_steps 200 total rewards -1542.6366267204285 total energy tensor([[77.0677]])\n",
      "[-0.09537721]\n",
      "Mode: Train env_steps 200 total rewards -1549.907109260559 total energy tensor([[64.6136]])\n",
      "[0.43800482]\n",
      "Mode: Train env_steps 200 total rewards -1559.1318809986115 total energy tensor([[74.7681]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07768435]\n",
      "Mode: Train env_steps 200 total rewards -1576.957466519052 total energy tensor([[191.1309]])\n",
      "[0.6870245]\n",
      "Mode: Train env_steps 200 total rewards -1446.5269658714533 total energy tensor([[188.1698]])\n",
      "[-0.4399454]\n",
      "Mode: Train env_steps 200 total rewards -1443.4274179935455 total energy tensor([[107.8594]])\n",
      "[-0.4271126]\n",
      "Mode: Train env_steps 200 total rewards -1540.1446581482887 total energy tensor([[186.7363]])\n",
      "[-0.24506393]\n",
      "Mode: Train env_steps 200 total rewards -1233.103278875351 total energy tensor([[136.1985]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6138394]\n",
      "Mode: Train env_steps 200 total rewards -1538.0764315128326 total energy tensor([[187.1974]])\n",
      "[0.73856425]\n",
      "Mode: Train env_steps 200 total rewards -1608.9769699424505 total energy tensor([[194.1974]])\n",
      "[0.96653694]\n",
      "Mode: Train env_steps 200 total rewards -1501.3057940006256 total energy tensor([[92.7151]])\n",
      "[0.20950511]\n",
      "Mode: Train env_steps 200 total rewards -1588.48961353302 total energy tensor([[71.8891]])\n",
      "[0.78311414]\n",
      "Mode: Train env_steps 200 total rewards -1521.0589163303375 total energy tensor([[87.0455]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86083174]\n",
      "Mode: Test env_steps 200 total rewards -1138.145599424839 total energy tensor([[142.1244]])\n",
      "[-0.21929088]\n",
      "Mode: Test env_steps 200 total rewards -1526.717734694481 total energy tensor([[186.8364]])\n",
      "[0.04066423]\n",
      "Mode: Test env_steps 200 total rewards -1519.0925006866455 total energy tensor([[86.6124]])\n",
      "[-0.18057357]\n",
      "Mode: Test env_steps 200 total rewards -1561.6529450416565 total energy tensor([[66.4409]])\n",
      "[-0.6196866]\n",
      "Mode: Test env_steps 200 total rewards -1639.9495553076267 total energy tensor([[197.2361]])\n",
      "[-0.01935134]\n",
      "Mode: Test env_steps 200 total rewards -1682.577967762947 total energy tensor([[197.4857]])\n",
      "[-0.81951576]\n",
      "Mode: Test env_steps 200 total rewards -1451.250117778778 total energy tensor([[101.2914]])\n",
      "[0.14069992]\n",
      "Mode: Test env_steps 200 total rewards -1667.3141859173775 total energy tensor([[197.1916]])\n",
      "[0.8340039]\n",
      "Mode: Test env_steps 200 total rewards -1550.492149591446 total energy tensor([[83.7120]])\n",
      "[-0.6181782]\n",
      "Mode: Test env_steps 200 total rewards -1520.3227301239967 total energy tensor([[185.1936]])\n",
      "35000 -1525.7515486329794\n",
      "[0.35853785]\n",
      "Mode: Train env_steps 200 total rewards -1394.5510931015015 total energy tensor([[114.0160]])\n",
      "[0.971549]\n",
      "Mode: Train env_steps 200 total rewards -1525.7540400028229 total energy tensor([[80.0580]])\n",
      "[-0.797024]\n",
      "Mode: Train env_steps 200 total rewards -1444.3241834640503 total energy tensor([[103.2342]])\n",
      "[-0.37978297]\n",
      "Mode: Train env_steps 200 total rewards -1558.3190469741821 total energy tensor([[69.9277]])\n",
      "[0.04315944]\n",
      "Mode: Train env_steps 200 total rewards -1556.0629215240479 total energy tensor([[77.3099]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.50178194]\n",
      "Mode: Train env_steps 200 total rewards -1467.551929473877 total energy tensor([[94.0385]])\n",
      "[-0.7382835]\n",
      "Mode: Train env_steps 200 total rewards -1594.0507360696793 total energy tensor([[195.8488]])\n",
      "[-0.44977418]\n",
      "Mode: Train env_steps 200 total rewards -1550.3143310546875 total energy tensor([[60.0260]])\n",
      "[-0.26234254]\n",
      "Mode: Train env_steps 200 total rewards -1457.4538180828094 total energy tensor([[93.7283]])\n",
      "[-0.00073658]\n",
      "Mode: Train env_steps 200 total rewards -1577.5200691223145 total energy tensor([[44.5420]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.71542245]\n",
      "Mode: Train env_steps 200 total rewards -1628.273680984974 total energy tensor([[195.7780]])\n",
      "[-0.21030797]\n",
      "Mode: Train env_steps 200 total rewards -1602.5666335001588 total energy tensor([[193.5739]])\n",
      "[-0.29530412]\n",
      "Mode: Train env_steps 200 total rewards -1569.7064616680145 total energy tensor([[77.7686]])\n",
      "[-0.31945997]\n",
      "Mode: Train env_steps 200 total rewards -1615.371975660324 total energy tensor([[63.2749]])\n",
      "[0.11686933]\n",
      "Mode: Train env_steps 200 total rewards -1621.8095072507858 total energy tensor([[194.6989]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0744771]\n",
      "Mode: Train env_steps 200 total rewards -1665.2580088973045 total energy tensor([[195.7099]])\n",
      "[-0.25206596]\n",
      "Mode: Train env_steps 200 total rewards -1661.1759624481201 total energy tensor([[52.3083]])\n",
      "[-0.49207267]\n",
      "Mode: Train env_steps 200 total rewards -1578.6862310767174 total energy tensor([[194.9039]])\n",
      "[0.34677988]\n",
      "Mode: Train env_steps 200 total rewards -1655.0898675322533 total energy tensor([[196.2579]])\n",
      "[-0.11770602]\n",
      "Mode: Train env_steps 200 total rewards -1516.942458416801 total energy tensor([[184.1013]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14238742]\n",
      "Mode: Train env_steps 200 total rewards -1605.4306151866913 total energy tensor([[63.2817]])\n",
      "[0.71031463]\n",
      "Mode: Train env_steps 200 total rewards -1609.5142112970352 total energy tensor([[194.7559]])\n",
      "[-0.6437919]\n",
      "Mode: Train env_steps 200 total rewards -1541.2529227733612 total energy tensor([[80.5865]])\n",
      "[-0.95838463]\n",
      "Mode: Train env_steps 200 total rewards -1675.9044024944305 total energy tensor([[196.3216]])\n",
      "[0.05139745]\n",
      "Mode: Train env_steps 200 total rewards -1652.5183579921722 total energy tensor([[194.0399]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32022843]\n",
      "Mode: Test env_steps 200 total rewards -1510.6155930012465 total energy tensor([[182.9736]])\n",
      "[0.32866827]\n",
      "Mode: Test env_steps 200 total rewards -1652.738576889038 total energy tensor([[65.3328]])\n",
      "[-0.6168631]\n",
      "Mode: Test env_steps 200 total rewards -1636.9810824394226 total energy tensor([[57.6448]])\n",
      "[-0.2969561]\n",
      "Mode: Test env_steps 200 total rewards -1510.8492833152413 total energy tensor([[183.0417]])\n",
      "[0.5312137]\n",
      "Mode: Test env_steps 200 total rewards -1534.1398755088449 total energy tensor([[186.1725]])\n",
      "[0.9907319]\n",
      "Mode: Test env_steps 200 total rewards -1609.7903053760529 total energy tensor([[67.6147]])\n",
      "[0.53764963]\n",
      "Mode: Test env_steps 200 total rewards -1670.6935804486275 total energy tensor([[195.9480]])\n",
      "[-0.9268973]\n",
      "Mode: Test env_steps 200 total rewards -1577.40600335598 total energy tensor([[193.7935]])\n",
      "[-0.9119654]\n",
      "Mode: Test env_steps 200 total rewards -1513.5578916370869 total energy tensor([[186.4083]])\n",
      "[0.8969308]\n",
      "Mode: Test env_steps 200 total rewards -1480.637073636055 total energy tensor([[88.5903]])\n",
      "40000 -1569.7409265607596\n",
      "[0.21099316]\n",
      "Mode: Train env_steps 200 total rewards -1400.729786515236 total energy tensor([[103.8312]])\n",
      "[0.64865744]\n",
      "Mode: Train env_steps 200 total rewards -1408.978219985962 total energy tensor([[106.4883]])\n",
      "[0.7140208]\n",
      "Mode: Train env_steps 200 total rewards -1652.4050440192223 total energy tensor([[194.3906]])\n",
      "[0.08546674]\n",
      "Mode: Train env_steps 200 total rewards -1587.9703810214996 total energy tensor([[76.3908]])\n",
      "[0.95305943]\n",
      "Mode: Train env_steps 200 total rewards -1394.2060267925262 total energy tensor([[106.1615]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7604878]\n",
      "Mode: Train env_steps 200 total rewards -1579.1261259913445 total energy tensor([[194.6868]])\n",
      "[-0.45766824]\n",
      "Mode: Train env_steps 200 total rewards -1613.8917970657349 total energy tensor([[69.8297]])\n",
      "[0.0834824]\n",
      "Mode: Train env_steps 200 total rewards -1444.5593945384026 total energy tensor([[188.8951]])\n",
      "[0.25564077]\n",
      "Mode: Train env_steps 200 total rewards -1340.9362207651138 total energy tensor([[108.4004]])\n",
      "[0.9119577]\n",
      "Mode: Train env_steps 200 total rewards -1478.4973535574973 total energy tensor([[180.5653]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92196524]\n",
      "Mode: Train env_steps 200 total rewards -1668.163999080658 total energy tensor([[62.5322]])\n",
      "[0.19608125]\n",
      "Mode: Train env_steps 200 total rewards -1593.779424905777 total energy tensor([[195.2221]])\n",
      "[0.15918088]\n",
      "Mode: Train env_steps 200 total rewards -1656.6155819892883 total energy tensor([[194.9942]])\n",
      "[0.6085662]\n",
      "Mode: Train env_steps 200 total rewards -1620.6108357906342 total energy tensor([[64.2308]])\n",
      "[0.7116061]\n",
      "Mode: Train env_steps 200 total rewards -1621.5095901489258 total energy tensor([[63.3021]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17186277]\n",
      "Mode: Train env_steps 200 total rewards -1668.4364300966263 total energy tensor([[194.9217]])\n",
      "[0.16300094]\n",
      "Mode: Train env_steps 200 total rewards -1603.677565574646 total energy tensor([[39.5139]])\n",
      "[0.5302293]\n",
      "Mode: Train env_steps 200 total rewards -1594.3652205467224 total energy tensor([[62.0642]])\n",
      "[-0.00993345]\n",
      "Mode: Train env_steps 200 total rewards -1346.1165645122528 total energy tensor([[114.5300]])\n",
      "[0.7921494]\n",
      "Mode: Train env_steps 200 total rewards -1612.7005462646484 total energy tensor([[194.1106]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41017175]\n",
      "Mode: Train env_steps 200 total rewards -1333.436641216278 total energy tensor([[105.1053]])\n",
      "[0.03047838]\n",
      "Mode: Train env_steps 200 total rewards -1667.2355709075928 total energy tensor([[56.1662]])\n",
      "[-0.6458577]\n",
      "Mode: Train env_steps 200 total rewards -1666.8576021194458 total energy tensor([[25.7870]])\n",
      "[0.5924374]\n",
      "Mode: Train env_steps 200 total rewards -1572.1946957707405 total energy tensor([[193.1846]])\n",
      "[-0.89234066]\n",
      "Mode: Train env_steps 200 total rewards -1665.9401906728745 total energy tensor([[195.4449]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16717616]\n",
      "Mode: Test env_steps 200 total rewards -1573.7785866074264 total energy tensor([[189.2971]])\n",
      "[-0.9155397]\n",
      "Mode: Test env_steps 200 total rewards -1681.8886089324951 total energy tensor([[54.2924]])\n",
      "[-0.53353405]\n",
      "Mode: Test env_steps 200 total rewards -1553.869773864746 total energy tensor([[73.8809]])\n",
      "[0.41180164]\n",
      "Mode: Test env_steps 200 total rewards -1628.4180827140808 total energy tensor([[72.7449]])\n",
      "[-0.8308327]\n",
      "Mode: Test env_steps 200 total rewards -1634.6750683784485 total energy tensor([[193.9831]])\n",
      "[-0.11169599]\n",
      "Mode: Test env_steps 200 total rewards -1498.3706794083118 total energy tensor([[189.6122]])\n",
      "[0.57232463]\n",
      "Mode: Test env_steps 200 total rewards -1482.0015869289637 total energy tensor([[185.0787]])\n",
      "[0.12168721]\n",
      "Mode: Test env_steps 200 total rewards -1698.9203486442566 total energy tensor([[50.3731]])\n",
      "[0.500965]\n",
      "Mode: Test env_steps 200 total rewards -1675.7787318229675 total energy tensor([[52.0103]])\n",
      "[-0.35898104]\n",
      "Mode: Test env_steps 200 total rewards -1526.1883342266083 total energy tensor([[186.7825]])\n",
      "45000 -1595.3889801528305\n",
      "[-0.99652666]\n",
      "Mode: Train env_steps 200 total rewards -1626.6399946212769 total energy tensor([[60.5029]])\n",
      "[0.44125482]\n",
      "Mode: Train env_steps 200 total rewards -1620.3568353652954 total energy tensor([[194.2969]])\n",
      "[0.51524824]\n",
      "Mode: Train env_steps 200 total rewards -1625.3537318706512 total energy tensor([[79.2872]])\n",
      "[0.7127021]\n",
      "Mode: Train env_steps 200 total rewards -1594.7992165088654 total energy tensor([[64.2595]])\n",
      "[0.95375544]\n",
      "Mode: Train env_steps 200 total rewards -1650.0189583301544 total energy tensor([[43.7720]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06440759]\n",
      "Mode: Train env_steps 200 total rewards -1691.2927770614624 total energy tensor([[41.1887]])\n",
      "[0.60449374]\n",
      "Mode: Train env_steps 200 total rewards -1707.6846237182617 total energy tensor([[58.2235]])\n",
      "[0.37062517]\n",
      "Mode: Train env_steps 200 total rewards -1619.4498482495546 total energy tensor([[192.5240]])\n",
      "[-0.7068939]\n",
      "Mode: Train env_steps 200 total rewards -1585.6861808300018 total energy tensor([[53.7800]])\n",
      "[0.9677356]\n",
      "Mode: Train env_steps 200 total rewards -1405.1172180771828 total energy tensor([[91.8519]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9001299]\n",
      "Mode: Train env_steps 200 total rewards -1056.3923988938332 total energy tensor([[148.0976]])\n",
      "[-0.6300965]\n",
      "Mode: Train env_steps 200 total rewards -1674.1579232215881 total energy tensor([[31.0141]])\n",
      "[-0.9563492]\n",
      "Mode: Train env_steps 200 total rewards -1422.1583080291748 total energy tensor([[99.6314]])\n",
      "[0.25112376]\n",
      "Mode: Train env_steps 200 total rewards -1716.022476196289 total energy tensor([[40.0985]])\n",
      "[-0.08224306]\n",
      "Mode: Train env_steps 200 total rewards -1669.0797238349915 total energy tensor([[31.3427]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.729684]\n",
      "Mode: Train env_steps 200 total rewards -1633.0251210331917 total energy tensor([[194.2790]])\n",
      "[0.89577436]\n",
      "Mode: Train env_steps 200 total rewards -1621.000871539116 total energy tensor([[195.0227]])\n",
      "[-0.5460177]\n",
      "Mode: Train env_steps 200 total rewards -1683.6660652160645 total energy tensor([[34.0116]])\n",
      "[-0.40112153]\n",
      "Mode: Train env_steps 200 total rewards -1639.0385568141937 total energy tensor([[42.5042]])\n",
      "[0.78051084]\n",
      "Mode: Train env_steps 200 total rewards -1665.379689693451 total energy tensor([[56.6720]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77455986]\n",
      "Mode: Train env_steps 200 total rewards -1654.9873324632645 total energy tensor([[195.5092]])\n",
      "[0.85356635]\n",
      "Mode: Train env_steps 200 total rewards -1309.2330137193203 total energy tensor([[180.7879]])\n",
      "[0.83300614]\n",
      "Mode: Train env_steps 200 total rewards -1689.8930764198303 total energy tensor([[49.0804]])\n",
      "[-0.8250804]\n",
      "Mode: Train env_steps 200 total rewards -1685.4378414154053 total energy tensor([[43.4415]])\n",
      "[0.49016246]\n",
      "Mode: Train env_steps 200 total rewards -1642.4514565467834 total energy tensor([[37.4679]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1223444]\n",
      "Mode: Test env_steps 200 total rewards -1579.9248823523521 total energy tensor([[194.2448]])\n",
      "[0.3327098]\n",
      "Mode: Test env_steps 200 total rewards -1423.4867486953735 total energy tensor([[90.3284]])\n",
      "[0.4081422]\n",
      "Mode: Test env_steps 200 total rewards -1678.514533996582 total energy tensor([[29.7779]])\n",
      "[0.47170335]\n",
      "Mode: Test env_steps 200 total rewards -1604.3147026896477 total energy tensor([[191.2507]])\n",
      "[0.60834527]\n",
      "Mode: Test env_steps 200 total rewards -1291.0842655301094 total energy tensor([[121.4019]])\n",
      "[0.21077521]\n",
      "Mode: Test env_steps 200 total rewards -1674.8185262680054 total energy tensor([[40.6972]])\n",
      "[-0.51829267]\n",
      "Mode: Test env_steps 200 total rewards -1563.1054992740974 total energy tensor([[183.9795]])\n",
      "[-0.31083503]\n",
      "Mode: Test env_steps 200 total rewards -1592.0992609411478 total energy tensor([[189.0142]])\n",
      "[-0.71145093]\n",
      "Mode: Test env_steps 200 total rewards -1595.5530056804419 total energy tensor([[189.3321]])\n",
      "[0.05401254]\n",
      "Mode: Test env_steps 200 total rewards -1597.1090137399733 total energy tensor([[190.2141]])\n",
      "50000 -1560.0010439167731\n",
      "[0.156821]\n",
      "Mode: Train env_steps 200 total rewards -1592.76972803846 total energy tensor([[189.0545]])\n",
      "[-0.79773074]\n",
      "Mode: Train env_steps 200 total rewards -1200.6541563272476 total energy tensor([[135.4979]])\n",
      "[0.09571017]\n",
      "Mode: Train env_steps 200 total rewards -1087.1326820403337 total energy tensor([[144.7080]])\n",
      "[0.6943778]\n",
      "Mode: Train env_steps 200 total rewards -1214.1343334913254 total energy tensor([[136.1286]])\n",
      "[0.29202324]\n",
      "Mode: Train env_steps 200 total rewards -1593.3272136449814 total energy tensor([[194.3702]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5854127]\n",
      "Mode: Train env_steps 200 total rewards -1583.44686293602 total energy tensor([[70.1755]])\n",
      "[-0.6974719]\n",
      "Mode: Train env_steps 200 total rewards -1667.3865213394165 total energy tensor([[44.0689]])\n",
      "[-0.2546401]\n",
      "Mode: Train env_steps 200 total rewards -1636.7618379592896 total energy tensor([[194.0117]])\n",
      "[-0.668793]\n",
      "Mode: Train env_steps 200 total rewards -1885.0502462387085 total energy tensor([[7.6050]])\n",
      "[-0.87510073]\n",
      "Mode: Train env_steps 200 total rewards -1656.449196100235 total energy tensor([[44.4823]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6822606]\n",
      "Mode: Train env_steps 200 total rewards -1819.9157400131226 total energy tensor([[23.3850]])\n",
      "[0.7113764]\n",
      "Mode: Train env_steps 200 total rewards -1491.9267012758646 total energy tensor([[179.3622]])\n",
      "[-0.32501483]\n",
      "Mode: Train env_steps 200 total rewards -1824.9155082702637 total energy tensor([[22.5575]])\n",
      "[-0.55657095]\n",
      "Mode: Train env_steps 200 total rewards -1812.111951828003 total energy tensor([[24.0580]])\n",
      "[0.22458622]\n",
      "Mode: Train env_steps 200 total rewards -982.9758528359234 total energy tensor([[139.6841]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0731152]\n",
      "Mode: Train env_steps 200 total rewards -1620.6231931447983 total energy tensor([[193.6174]])\n",
      "[-0.12252534]\n",
      "Mode: Train env_steps 200 total rewards -1495.3533511161804 total energy tensor([[84.6856]])\n",
      "[-0.29123566]\n",
      "Mode: Train env_steps 200 total rewards -1641.0524389743805 total energy tensor([[56.9331]])\n",
      "[0.22165692]\n",
      "Mode: Train env_steps 200 total rewards -1671.130244731903 total energy tensor([[50.2812]])\n",
      "[0.19810908]\n",
      "Mode: Train env_steps 200 total rewards -1609.5299289226532 total energy tensor([[52.3996]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5086107]\n",
      "Mode: Train env_steps 200 total rewards -1607.3831570148468 total energy tensor([[194.7872]])\n",
      "[0.8787966]\n",
      "Mode: Train env_steps 200 total rewards -1601.194265127182 total energy tensor([[194.7004]])\n",
      "[-0.34772396]\n",
      "Mode: Train env_steps 200 total rewards -1654.4138612747192 total energy tensor([[43.0734]])\n",
      "[-0.83238935]\n",
      "Mode: Train env_steps 200 total rewards -1530.4530726969242 total energy tensor([[193.8298]])\n",
      "[0.05377831]\n",
      "Mode: Train env_steps 200 total rewards -1600.3593474626541 total energy tensor([[196.0466]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46875778]\n",
      "Mode: Test env_steps 200 total rewards -1584.4975094795227 total energy tensor([[194.8398]])\n",
      "[0.504076]\n",
      "Mode: Test env_steps 200 total rewards -1823.854320526123 total energy tensor([[19.8178]])\n",
      "[-0.9881905]\n",
      "Mode: Test env_steps 200 total rewards -1608.7427068725228 total energy tensor([[192.1341]])\n",
      "[-0.08301151]\n",
      "Mode: Test env_steps 200 total rewards -1647.3805426359177 total energy tensor([[195.5636]])\n",
      "[0.79744524]\n",
      "Mode: Test env_steps 200 total rewards -1800.287379026413 total energy tensor([[25.9233]])\n",
      "[0.03490247]\n",
      "Mode: Test env_steps 200 total rewards -1619.5075914859772 total energy tensor([[195.2230]])\n",
      "[-0.62203115]\n",
      "Mode: Test env_steps 200 total rewards -1444.5266513675451 total energy tensor([[78.7277]])\n",
      "[0.7895025]\n",
      "Mode: Test env_steps 200 total rewards -1830.6364574432373 total energy tensor([[19.1559]])\n",
      "[0.3234702]\n",
      "Mode: Test env_steps 200 total rewards -1833.4406414031982 total energy tensor([[18.7744]])\n",
      "[0.47509104]\n",
      "Mode: Test env_steps 200 total rewards -1789.1169548034668 total energy tensor([[26.9691]])\n",
      "55000 -1698.1990755043923\n",
      "[0.55202395]\n",
      "Mode: Train env_steps 200 total rewards -1634.3852626681328 total energy tensor([[193.8186]])\n",
      "[-0.193075]\n",
      "Mode: Train env_steps 200 total rewards -1397.1630074381828 total energy tensor([[78.5832]])\n",
      "[0.75546664]\n",
      "Mode: Train env_steps 200 total rewards -1647.887498497963 total energy tensor([[47.7754]])\n",
      "[-0.52368844]\n",
      "Mode: Train env_steps 200 total rewards -1756.6891264915466 total energy tensor([[27.2164]])\n",
      "[0.39598444]\n",
      "Mode: Train env_steps 200 total rewards -1529.3844201266766 total energy tensor([[65.1208]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69633764]\n",
      "Mode: Train env_steps 200 total rewards -1632.4247923493385 total energy tensor([[194.8286]])\n",
      "[0.48209375]\n",
      "Mode: Train env_steps 200 total rewards -1609.7964743673801 total energy tensor([[193.2607]])\n",
      "[0.05331245]\n",
      "Mode: Train env_steps 200 total rewards -1620.095106601715 total energy tensor([[194.8000]])\n",
      "[0.49878687]\n",
      "Mode: Train env_steps 200 total rewards -1354.8252039551735 total energy tensor([[95.5533]])\n",
      "[-0.7167795]\n",
      "Mode: Train env_steps 200 total rewards -1358.4039742946625 total energy tensor([[97.0968]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33223662]\n",
      "Mode: Train env_steps 200 total rewards -1770.8598327636719 total energy tensor([[33.0842]])\n",
      "[0.01462712]\n",
      "Mode: Train env_steps 200 total rewards -1767.0859746932983 total energy tensor([[33.4133]])\n",
      "[-0.6380066]\n",
      "Mode: Train env_steps 200 total rewards -1684.7176451683044 total energy tensor([[47.2758]])\n",
      "[0.8698973]\n",
      "Mode: Train env_steps 200 total rewards -1616.973767787218 total energy tensor([[192.9667]])\n",
      "[-0.3768421]\n",
      "Mode: Train env_steps 200 total rewards -1315.3319036066532 total energy tensor([[100.1502]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5701734]\n",
      "Mode: Train env_steps 200 total rewards -1349.1200025081635 total energy tensor([[108.2283]])\n",
      "[0.15862091]\n",
      "Mode: Train env_steps 200 total rewards -1710.4111304283142 total energy tensor([[65.0868]])\n",
      "[-0.46276015]\n",
      "Mode: Train env_steps 200 total rewards -1347.804084122181 total energy tensor([[105.1673]])\n",
      "[-0.37799639]\n",
      "Mode: Train env_steps 200 total rewards -1691.9818835258484 total energy tensor([[65.4073]])\n",
      "[0.6018948]\n",
      "Mode: Train env_steps 200 total rewards -1655.8716275691986 total energy tensor([[55.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09544797]\n",
      "Mode: Train env_steps 200 total rewards -1590.8307898044586 total energy tensor([[67.8591]])\n",
      "[0.04072836]\n",
      "Mode: Train env_steps 200 total rewards -1702.439917087555 total energy tensor([[63.0846]])\n",
      "[0.6152258]\n",
      "Mode: Train env_steps 200 total rewards -1638.5157856941223 total energy tensor([[66.0274]])\n",
      "[0.77479225]\n",
      "Mode: Train env_steps 200 total rewards -1654.2056589126587 total energy tensor([[59.3478]])\n",
      "[-0.774808]\n",
      "Mode: Train env_steps 200 total rewards -1639.8225647211075 total energy tensor([[196.1670]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.550654]\n",
      "Mode: Test env_steps 200 total rewards -1632.5505658984184 total energy tensor([[196.1122]])\n",
      "[0.33426756]\n",
      "Mode: Test env_steps 200 total rewards -1640.0777430534363 total energy tensor([[97.7466]])\n",
      "[0.74770755]\n",
      "Mode: Test env_steps 200 total rewards -1602.5761993527412 total energy tensor([[193.7422]])\n",
      "[0.04347856]\n",
      "Mode: Test env_steps 200 total rewards -1616.450223684311 total energy tensor([[194.9149]])\n",
      "[0.72895294]\n",
      "Mode: Test env_steps 200 total rewards -1479.6839179992676 total energy tensor([[93.8003]])\n",
      "[-0.01300442]\n",
      "Mode: Test env_steps 200 total rewards -1661.6184539794922 total energy tensor([[85.6207]])\n",
      "[0.5897035]\n",
      "Mode: Test env_steps 200 total rewards -1609.5104128420353 total energy tensor([[194.5585]])\n",
      "[-0.96830285]\n",
      "Mode: Test env_steps 200 total rewards -1604.642042040825 total energy tensor([[195.8362]])\n",
      "[-0.38008136]\n",
      "Mode: Test env_steps 200 total rewards -1609.8624830543995 total energy tensor([[194.6049]])\n",
      "[0.6921164]\n",
      "Mode: Test env_steps 200 total rewards -1620.9836193323135 total energy tensor([[195.5162]])\n",
      "60000 -1607.795566123724\n",
      "[0.45206755]\n",
      "Mode: Train env_steps 200 total rewards -1659.6550545692444 total energy tensor([[82.9259]])\n",
      "[0.78771895]\n",
      "Mode: Train env_steps 200 total rewards -1651.6455507278442 total energy tensor([[86.0657]])\n",
      "[0.66869795]\n",
      "Mode: Train env_steps 200 total rewards -1591.998547717929 total energy tensor([[191.5148]])\n",
      "[0.6232049]\n",
      "Mode: Train env_steps 200 total rewards -1650.1921515464783 total energy tensor([[72.9182]])\n",
      "[-0.9488602]\n",
      "Mode: Train env_steps 200 total rewards -1630.4883633255959 total energy tensor([[196.1221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30903223]\n",
      "Mode: Train env_steps 200 total rewards -1644.8102760314941 total energy tensor([[74.6857]])\n",
      "[-0.8410392]\n",
      "Mode: Train env_steps 200 total rewards -1649.6223759651184 total energy tensor([[80.3789]])\n",
      "[0.14574796]\n",
      "Mode: Train env_steps 200 total rewards -1440.22034740448 total energy tensor([[87.7947]])\n",
      "[0.95562637]\n",
      "Mode: Train env_steps 200 total rewards -1547.3802765607834 total energy tensor([[74.1869]])\n",
      "[-0.8777626]\n",
      "Mode: Train env_steps 200 total rewards -1664.8195586204529 total energy tensor([[82.9085]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6516067]\n",
      "Mode: Train env_steps 200 total rewards -1581.9441286325455 total energy tensor([[193.8000]])\n",
      "[0.10912076]\n",
      "Mode: Train env_steps 200 total rewards -1361.2573273293674 total energy tensor([[80.8048]])\n",
      "[-0.6901746]\n",
      "Mode: Train env_steps 200 total rewards -1410.4016721099615 total energy tensor([[80.6738]])\n",
      "[-0.89467865]\n",
      "Mode: Train env_steps 200 total rewards -1615.7254301309586 total energy tensor([[74.1830]])\n",
      "[-0.18132144]\n",
      "Mode: Train env_steps 200 total rewards -1503.882519185543 total energy tensor([[94.3181]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03463117]\n",
      "Mode: Train env_steps 200 total rewards -1633.6318111419678 total energy tensor([[106.4915]])\n",
      "[-0.5153198]\n",
      "Mode: Train env_steps 200 total rewards -1594.7650051116943 total energy tensor([[84.5545]])\n",
      "[-0.9826992]\n",
      "Mode: Train env_steps 200 total rewards -1460.9887673556805 total energy tensor([[86.3018]])\n",
      "[-0.97442544]\n",
      "Mode: Train env_steps 200 total rewards -1607.4467515945435 total energy tensor([[93.1253]])\n",
      "[-0.27220896]\n",
      "Mode: Train env_steps 200 total rewards -1558.3924369812012 total energy tensor([[89.2143]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4222285]\n",
      "Mode: Train env_steps 200 total rewards -1624.5237407684326 total energy tensor([[98.5379]])\n",
      "[0.811511]\n",
      "Mode: Train env_steps 200 total rewards -1597.2973566055298 total energy tensor([[82.2272]])\n",
      "[-0.34454414]\n",
      "Mode: Train env_steps 200 total rewards -1642.3529019355774 total energy tensor([[82.2458]])\n",
      "[0.9071565]\n",
      "Mode: Train env_steps 200 total rewards -1589.4341990947723 total energy tensor([[195.8329]])\n",
      "[-0.3341271]\n",
      "Mode: Train env_steps 200 total rewards -1610.7263560295105 total energy tensor([[85.9358]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70715976]\n",
      "Mode: Test env_steps 200 total rewards -1637.9475450515747 total energy tensor([[65.3919]])\n",
      "[0.03008457]\n",
      "Mode: Test env_steps 200 total rewards -1731.3461918830872 total energy tensor([[48.2275]])\n",
      "[-0.1031899]\n",
      "Mode: Test env_steps 200 total rewards -1748.4599895477295 total energy tensor([[42.8678]])\n",
      "[-0.5299616]\n",
      "Mode: Test env_steps 200 total rewards -1523.1367873549461 total energy tensor([[79.1802]])\n",
      "[0.851049]\n",
      "Mode: Test env_steps 200 total rewards -1699.987479686737 total energy tensor([[52.8388]])\n",
      "[-0.9926609]\n",
      "Mode: Test env_steps 200 total rewards -1453.1793761614827 total energy tensor([[178.7810]])\n",
      "[-0.5599699]\n",
      "Mode: Test env_steps 200 total rewards -1726.2101726531982 total energy tensor([[52.6123]])\n",
      "[-0.2900973]\n",
      "Mode: Test env_steps 200 total rewards -1449.424358390388 total energy tensor([[178.3882]])\n",
      "[-0.86072546]\n",
      "Mode: Test env_steps 200 total rewards -1597.9247645139694 total energy tensor([[193.5329]])\n",
      "[-0.3095105]\n",
      "Mode: Test env_steps 200 total rewards -1513.992068350315 total energy tensor([[82.7280]])\n",
      "65000 -1608.1608733593428\n",
      "[-0.4044391]\n",
      "Mode: Train env_steps 200 total rewards -1417.2964036390185 total energy tensor([[177.9825]])\n",
      "[-0.07592779]\n",
      "Mode: Train env_steps 200 total rewards -1646.708215713501 total energy tensor([[65.0051]])\n",
      "[-0.9636359]\n",
      "Mode: Train env_steps 200 total rewards -1613.3589693307877 total energy tensor([[194.6273]])\n",
      "[-0.12591796]\n",
      "Mode: Train env_steps 200 total rewards -1714.3880405426025 total energy tensor([[54.0160]])\n",
      "[-0.74192685]\n",
      "Mode: Train env_steps 200 total rewards -1631.953949213028 total energy tensor([[196.5090]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.787288]\n",
      "Mode: Train env_steps 200 total rewards -1593.3203605413437 total energy tensor([[193.0768]])\n",
      "[0.414992]\n",
      "Mode: Train env_steps 200 total rewards -1508.0718590319157 total energy tensor([[75.2038]])\n",
      "[-0.44351465]\n",
      "Mode: Train env_steps 200 total rewards -1474.8787258923985 total energy tensor([[182.0700]])\n",
      "[0.07820436]\n",
      "Mode: Train env_steps 200 total rewards -1713.4329409599304 total energy tensor([[54.0892]])\n",
      "[0.5500865]\n",
      "Mode: Train env_steps 200 total rewards -1695.3232307434082 total energy tensor([[61.4909]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8944704]\n",
      "Mode: Train env_steps 200 total rewards -1700.7670259475708 total energy tensor([[50.2467]])\n",
      "[0.54702365]\n",
      "Mode: Train env_steps 200 total rewards -1710.6825976371765 total energy tensor([[51.7049]])\n",
      "[0.02678511]\n",
      "Mode: Train env_steps 200 total rewards -1607.3395950198174 total energy tensor([[195.5958]])\n",
      "[0.27205148]\n",
      "Mode: Train env_steps 200 total rewards -1601.761302947998 total energy tensor([[193.8580]])\n",
      "[-0.5262914]\n",
      "Mode: Train env_steps 200 total rewards -1460.9085397273302 total energy tensor([[181.7179]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03578115]\n",
      "Mode: Train env_steps 200 total rewards -1586.1897550225258 total energy tensor([[64.8554]])\n",
      "[-0.5623715]\n",
      "Mode: Train env_steps 200 total rewards -1724.0892629623413 total energy tensor([[48.0666]])\n",
      "[0.6938758]\n",
      "Mode: Train env_steps 200 total rewards -1472.3700282871723 total energy tensor([[184.7775]])\n",
      "[0.52514625]\n",
      "Mode: Train env_steps 200 total rewards -1539.173571832478 total energy tensor([[190.4605]])\n",
      "[-0.46686026]\n",
      "Mode: Train env_steps 200 total rewards -1728.4771728515625 total energy tensor([[49.2389]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8415514]\n",
      "Mode: Train env_steps 200 total rewards -1633.254353404045 total energy tensor([[63.2391]])\n",
      "[0.58323896]\n",
      "Mode: Train env_steps 200 total rewards -1713.3117513656616 total energy tensor([[51.0812]])\n",
      "[-0.67703277]\n",
      "Mode: Train env_steps 200 total rewards -1619.2791438102722 total energy tensor([[58.7090]])\n",
      "[-0.08574792]\n",
      "Mode: Train env_steps 200 total rewards -1716.010380744934 total energy tensor([[44.8460]])\n",
      "[0.81193876]\n",
      "Mode: Train env_steps 200 total rewards -1705.95649766922 total energy tensor([[50.3375]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6620881]\n",
      "Mode: Test env_steps 200 total rewards -1560.9280462265015 total energy tensor([[139.1454]])\n",
      "[0.18290345]\n",
      "Mode: Test env_steps 200 total rewards -1553.1022672653198 total energy tensor([[162.1688]])\n",
      "[0.4500277]\n",
      "Mode: Test env_steps 200 total rewards -1522.6399215459824 total energy tensor([[125.3753]])\n",
      "[0.42057994]\n",
      "Mode: Test env_steps 200 total rewards -1552.6692271232605 total energy tensor([[156.7016]])\n",
      "[0.5254828]\n",
      "Mode: Test env_steps 200 total rewards -1559.9755783081055 total energy tensor([[157.4952]])\n",
      "[0.2352983]\n",
      "Mode: Test env_steps 200 total rewards -1555.959430217743 total energy tensor([[151.3822]])\n",
      "[-0.0284138]\n",
      "Mode: Test env_steps 200 total rewards -1556.314401626587 total energy tensor([[157.8692]])\n",
      "[0.41490945]\n",
      "Mode: Test env_steps 200 total rewards -1569.5314273834229 total energy tensor([[138.7800]])\n",
      "[0.077962]\n",
      "Mode: Test env_steps 200 total rewards -1398.1983751654625 total energy tensor([[168.3565]])\n",
      "[0.02914812]\n",
      "Mode: Test env_steps 200 total rewards -1506.63210105896 total energy tensor([[140.5726]])\n",
      "70000 -1533.5950775921344\n",
      "[0.87633234]\n",
      "Mode: Train env_steps 200 total rewards -1386.5737527906895 total energy tensor([[140.1379]])\n",
      "[-0.5071911]\n",
      "Mode: Train env_steps 200 total rewards -1565.9114561080933 total energy tensor([[154.7692]])\n",
      "[0.8458921]\n",
      "Mode: Train env_steps 200 total rewards -1559.0114483833313 total energy tensor([[150.3152]])\n",
      "[0.23643637]\n",
      "Mode: Train env_steps 200 total rewards -1155.5387272671796 total energy tensor([[147.4278]])\n",
      "[0.335568]\n",
      "Mode: Train env_steps 200 total rewards -1438.7499465346336 total energy tensor([[141.5240]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22750166]\n",
      "Mode: Train env_steps 200 total rewards -1547.7877908349037 total energy tensor([[85.2063]])\n",
      "[0.42275462]\n",
      "Mode: Train env_steps 200 total rewards -1611.501389503479 total energy tensor([[82.8174]])\n",
      "[-0.9557459]\n",
      "Mode: Train env_steps 200 total rewards -1512.9494349062443 total energy tensor([[89.7545]])\n",
      "[-0.57517624]\n",
      "Mode: Train env_steps 200 total rewards -1591.3576270341873 total energy tensor([[80.3172]])\n",
      "[0.54676175]\n",
      "Mode: Train env_steps 200 total rewards -1634.6058411598206 total energy tensor([[85.9669]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6140936]\n",
      "Mode: Train env_steps 200 total rewards -1566.6392159461975 total energy tensor([[150.4255]])\n",
      "[0.37899303]\n",
      "Mode: Train env_steps 200 total rewards -1646.8272805213928 total energy tensor([[81.8440]])\n",
      "[0.8606809]\n",
      "Mode: Train env_steps 200 total rewards -1602.6575255393982 total energy tensor([[88.7259]])\n",
      "[0.79236317]\n",
      "Mode: Train env_steps 200 total rewards -1461.5854959487915 total energy tensor([[92.6372]])\n",
      "[-0.88463914]\n",
      "Mode: Train env_steps 200 total rewards -1643.166953086853 total energy tensor([[88.6237]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5306472]\n",
      "Mode: Train env_steps 200 total rewards -1672.1634747982025 total energy tensor([[78.0532]])\n",
      "[-0.8201518]\n",
      "Mode: Train env_steps 200 total rewards -1591.9881069660187 total energy tensor([[81.2227]])\n",
      "[0.80450684]\n",
      "Mode: Train env_steps 200 total rewards -1613.4856977462769 total energy tensor([[86.1031]])\n",
      "[0.17303765]\n",
      "Mode: Train env_steps 200 total rewards -1715.3398094177246 total energy tensor([[71.5259]])\n",
      "[0.00684795]\n",
      "Mode: Train env_steps 200 total rewards -1564.7174018621445 total energy tensor([[96.1895]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4422191]\n",
      "Mode: Train env_steps 200 total rewards -1559.1270747184753 total energy tensor([[159.0582]])\n",
      "[-0.2842852]\n",
      "Mode: Train env_steps 200 total rewards -1420.047536343336 total energy tensor([[113.8246]])\n",
      "[0.6380656]\n",
      "Mode: Train env_steps 200 total rewards -1515.2517154216766 total energy tensor([[121.5393]])\n",
      "[0.00264126]\n",
      "Mode: Train env_steps 200 total rewards -1561.0247211456299 total energy tensor([[142.2950]])\n",
      "[0.28496984]\n",
      "Mode: Train env_steps 200 total rewards -1435.4040464758873 total energy tensor([[134.9995]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11630165]\n",
      "Mode: Test env_steps 200 total rewards -1527.3876283168793 total energy tensor([[90.4501]])\n",
      "[0.70453745]\n",
      "Mode: Test env_steps 200 total rewards -1548.1414861679077 total energy tensor([[157.4411]])\n",
      "[-0.9907088]\n",
      "Mode: Test env_steps 200 total rewards -1402.1187587156892 total energy tensor([[97.3325]])\n",
      "[0.07741516]\n",
      "Mode: Test env_steps 200 total rewards -1497.3092843741179 total energy tensor([[92.5131]])\n",
      "[-0.07382564]\n",
      "Mode: Test env_steps 200 total rewards -1549.5579028129578 total energy tensor([[94.4515]])\n",
      "[-0.34076357]\n",
      "Mode: Test env_steps 200 total rewards -1531.874415397644 total energy tensor([[89.8156]])\n",
      "[-0.16845556]\n",
      "Mode: Test env_steps 200 total rewards -1545.5387465953827 total energy tensor([[94.9194]])\n",
      "[-0.44482863]\n",
      "Mode: Test env_steps 200 total rewards -1591.8530492782593 total energy tensor([[96.1435]])\n",
      "[-0.08654437]\n",
      "Mode: Test env_steps 200 total rewards -1559.1194298267365 total energy tensor([[98.6438]])\n",
      "[0.89867496]\n",
      "Mode: Test env_steps 200 total rewards -1568.6410286426544 total energy tensor([[89.5821]])\n",
      "75000 -1532.1541730128229\n",
      "[0.20820588]\n",
      "Mode: Train env_steps 200 total rewards -1572.1214270591736 total energy tensor([[91.9530]])\n",
      "[-0.2615918]\n",
      "Mode: Train env_steps 200 total rewards -1562.6275081634521 total energy tensor([[88.6475]])\n",
      "[-0.66113645]\n",
      "Mode: Train env_steps 200 total rewards -1626.0095796585083 total energy tensor([[94.6337]])\n",
      "[-0.35418537]\n",
      "Mode: Train env_steps 200 total rewards -1632.2982289791107 total energy tensor([[88.0287]])\n",
      "[0.32622927]\n",
      "Mode: Train env_steps 200 total rewards -1611.7761862277985 total energy tensor([[90.8123]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6256927]\n",
      "Mode: Train env_steps 200 total rewards -1543.669192314148 total energy tensor([[164.3165]])\n",
      "[0.82685316]\n",
      "Mode: Train env_steps 200 total rewards -1578.2432923316956 total energy tensor([[129.6329]])\n",
      "[-0.22095078]\n",
      "Mode: Train env_steps 200 total rewards -1545.3031549453735 total energy tensor([[164.2805]])\n",
      "[-0.86788595]\n",
      "Mode: Train env_steps 200 total rewards -1563.4958243370056 total energy tensor([[120.0171]])\n",
      "[-0.6441611]\n",
      "Mode: Train env_steps 200 total rewards -1479.88571703434 total energy tensor([[115.9088]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14008373]\n",
      "Mode: Train env_steps 200 total rewards -1513.5860463380814 total energy tensor([[104.2343]])\n",
      "[0.39136463]\n",
      "Mode: Train env_steps 200 total rewards -1420.5328387245536 total energy tensor([[104.6859]])\n",
      "[0.43990052]\n",
      "Mode: Train env_steps 200 total rewards -1483.1774477660656 total energy tensor([[102.8100]])\n",
      "[-0.47017533]\n",
      "Mode: Train env_steps 200 total rewards -1583.2634210586548 total energy tensor([[103.2964]])\n",
      "[0.80963]\n",
      "Mode: Train env_steps 200 total rewards -1588.6852054595947 total energy tensor([[102.5749]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8737793]\n",
      "Mode: Train env_steps 200 total rewards -1645.4140055179596 total energy tensor([[84.0544]])\n",
      "[0.7377348]\n",
      "Mode: Train env_steps 200 total rewards -1442.603831321001 total energy tensor([[101.3466]])\n",
      "[0.9033939]\n",
      "Mode: Train env_steps 200 total rewards -1625.0628118515015 total energy tensor([[83.5649]])\n",
      "[-0.6569545]\n",
      "Mode: Train env_steps 200 total rewards -1617.6705622673035 total energy tensor([[90.5013]])\n",
      "[0.08451119]\n",
      "Mode: Train env_steps 200 total rewards -1548.4744095802307 total energy tensor([[160.7316]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7758857]\n",
      "Mode: Train env_steps 200 total rewards -1440.641111150384 total energy tensor([[109.9077]])\n",
      "[0.12277982]\n",
      "Mode: Train env_steps 200 total rewards -1637.146668434143 total energy tensor([[91.7303]])\n",
      "[0.65058875]\n",
      "Mode: Train env_steps 200 total rewards -1489.6669749617577 total energy tensor([[108.5832]])\n",
      "[0.05856564]\n",
      "Mode: Train env_steps 200 total rewards -1580.7770447731018 total energy tensor([[103.6011]])\n",
      "[0.95785964]\n",
      "Mode: Train env_steps 200 total rewards -1512.4908434152603 total energy tensor([[110.8012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.30772188]\n",
      "Mode: Test env_steps 200 total rewards -1625.515606880188 total energy tensor([[100.3000]])\n",
      "[-0.22428125]\n",
      "Mode: Test env_steps 200 total rewards -1604.356752872467 total energy tensor([[114.2322]])\n",
      "[0.46931008]\n",
      "Mode: Test env_steps 200 total rewards -1552.39403963089 total energy tensor([[110.1773]])\n",
      "[0.16473104]\n",
      "Mode: Test env_steps 200 total rewards -1523.491629600525 total energy tensor([[148.6658]])\n",
      "[0.7398329]\n",
      "Mode: Test env_steps 200 total rewards -1537.1010149121284 total energy tensor([[102.3904]])\n",
      "[0.07209413]\n",
      "Mode: Test env_steps 200 total rewards -1558.45360994339 total energy tensor([[155.5310]])\n",
      "[-0.891093]\n",
      "Mode: Test env_steps 200 total rewards -1556.2977285385132 total energy tensor([[159.3381]])\n",
      "[0.546712]\n",
      "Mode: Test env_steps 200 total rewards -1481.6221832036972 total energy tensor([[113.8568]])\n",
      "[-0.71470636]\n",
      "Mode: Test env_steps 200 total rewards -1581.5104851722717 total energy tensor([[126.1060]])\n",
      "[0.34701017]\n",
      "Mode: Test env_steps 200 total rewards -1628.6229362487793 total energy tensor([[97.6045]])\n",
      "80000 -1564.936598700285\n",
      "[0.4721757]\n",
      "Mode: Train env_steps 200 total rewards -1552.118076324463 total energy tensor([[101.3169]])\n",
      "[0.56395864]\n",
      "Mode: Train env_steps 200 total rewards -1546.3091782331467 total energy tensor([[105.0051]])\n",
      "[0.01232237]\n",
      "Mode: Train env_steps 200 total rewards -1546.1732094287872 total energy tensor([[121.5060]])\n",
      "[-0.12729381]\n",
      "Mode: Train env_steps 200 total rewards -1183.3231780249625 total energy tensor([[119.3216]])\n",
      "[-0.6130255]\n",
      "Mode: Train env_steps 200 total rewards -1530.630129814148 total energy tensor([[147.9275]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68273884]\n",
      "Mode: Train env_steps 200 total rewards -1628.5273594856262 total energy tensor([[94.5085]])\n",
      "[0.5887959]\n",
      "Mode: Train env_steps 200 total rewards -1524.8214133381844 total energy tensor([[109.8714]])\n",
      "[0.52742034]\n",
      "Mode: Train env_steps 200 total rewards -1592.306100845337 total energy tensor([[107.3927]])\n",
      "[0.7801042]\n",
      "Mode: Train env_steps 200 total rewards -1562.4160432815552 total energy tensor([[149.8883]])\n",
      "[0.04133503]\n",
      "Mode: Train env_steps 200 total rewards -1549.7057188749313 total energy tensor([[112.2586]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92105997]\n",
      "Mode: Train env_steps 200 total rewards -1586.7841582298279 total energy tensor([[98.8864]])\n",
      "[-0.0657215]\n",
      "Mode: Train env_steps 200 total rewards -1579.4452619552612 total energy tensor([[110.8082]])\n",
      "[-0.84673834]\n",
      "Mode: Train env_steps 200 total rewards -1392.0793126821518 total energy tensor([[141.7257]])\n",
      "[0.509745]\n",
      "Mode: Train env_steps 200 total rewards -1640.2670822143555 total energy tensor([[99.8593]])\n",
      "[0.8259618]\n",
      "Mode: Train env_steps 200 total rewards -1639.0220384597778 total energy tensor([[84.7400]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83914626]\n",
      "Mode: Train env_steps 200 total rewards -1640.302728176117 total energy tensor([[72.6796]])\n",
      "[-0.01749951]\n",
      "Mode: Train env_steps 200 total rewards -1458.3483772426844 total energy tensor([[91.9627]])\n",
      "[0.22350945]\n",
      "Mode: Train env_steps 200 total rewards -1639.5899276733398 total energy tensor([[96.9675]])\n",
      "[0.21603316]\n",
      "Mode: Train env_steps 200 total rewards -1265.3915429557383 total energy tensor([[84.6638]])\n",
      "[-0.03553976]\n",
      "Mode: Train env_steps 200 total rewards -1478.0016544610262 total energy tensor([[91.2519]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7782335]\n",
      "Mode: Train env_steps 200 total rewards -1503.1736764907837 total energy tensor([[129.9570]])\n",
      "[-0.605799]\n",
      "Mode: Train env_steps 200 total rewards -1587.0419220924377 total energy tensor([[103.9405]])\n",
      "[-0.6600486]\n",
      "Mode: Train env_steps 200 total rewards -1546.1752753257751 total energy tensor([[151.5362]])\n",
      "[-0.7709025]\n",
      "Mode: Train env_steps 200 total rewards -1577.042341709137 total energy tensor([[148.6188]])\n",
      "[0.8932179]\n",
      "Mode: Train env_steps 200 total rewards -1561.5847845077515 total energy tensor([[140.4607]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7507293]\n",
      "Mode: Test env_steps 200 total rewards -1552.1453533172607 total energy tensor([[161.9438]])\n",
      "[-0.61429584]\n",
      "Mode: Test env_steps 200 total rewards -1591.6818146705627 total energy tensor([[122.0144]])\n",
      "[0.16149563]\n",
      "Mode: Test env_steps 200 total rewards -1355.920825868845 total energy tensor([[113.9500]])\n",
      "[0.52629256]\n",
      "Mode: Test env_steps 200 total rewards -1572.156060218811 total energy tensor([[102.2996]])\n",
      "[0.68025464]\n",
      "Mode: Test env_steps 200 total rewards -1608.1300039291382 total energy tensor([[113.8603]])\n",
      "[-0.8035365]\n",
      "Mode: Test env_steps 200 total rewards -1607.048466682434 total energy tensor([[117.9339]])\n",
      "[-0.5034311]\n",
      "Mode: Test env_steps 200 total rewards -1556.7321186065674 total energy tensor([[118.2932]])\n",
      "[-0.8938926]\n",
      "Mode: Test env_steps 200 total rewards -1526.2228376865387 total energy tensor([[116.5343]])\n",
      "[0.57632613]\n",
      "Mode: Test env_steps 200 total rewards -1217.8360307314433 total energy tensor([[103.2230]])\n",
      "[-0.32210815]\n",
      "Mode: Test env_steps 200 total rewards -1422.4315529316664 total energy tensor([[117.6637]])\n",
      "85000 -1501.0305064643267\n",
      "[-0.42732358]\n",
      "Mode: Train env_steps 200 total rewards -1584.797884464264 total energy tensor([[124.4473]])\n",
      "[-0.21747304]\n",
      "Mode: Train env_steps 200 total rewards -1592.726680278778 total energy tensor([[125.8588]])\n",
      "[-0.69864017]\n",
      "Mode: Train env_steps 200 total rewards -1561.8522908687592 total energy tensor([[103.9861]])\n",
      "[-0.41641095]\n",
      "Mode: Train env_steps 200 total rewards -1586.2745287418365 total energy tensor([[111.6687]])\n",
      "[-0.31589073]\n",
      "Mode: Train env_steps 200 total rewards -1564.0585339069366 total energy tensor([[118.9263]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5401949]\n",
      "Mode: Train env_steps 200 total rewards -1561.943142414093 total energy tensor([[151.3985]])\n",
      "[0.5723848]\n",
      "Mode: Train env_steps 200 total rewards -1629.6789479255676 total energy tensor([[74.7991]])\n",
      "[0.19025354]\n",
      "Mode: Train env_steps 200 total rewards -1576.7453351020813 total energy tensor([[79.7343]])\n",
      "[-0.9706102]\n",
      "Mode: Train env_steps 200 total rewards -1647.5971851348877 total energy tensor([[68.8906]])\n",
      "[-0.40234506]\n",
      "Mode: Train env_steps 200 total rewards -1563.5085139274597 total energy tensor([[154.1318]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69969976]\n",
      "Mode: Train env_steps 200 total rewards -1430.7237547785044 total energy tensor([[129.2969]])\n",
      "[-0.6251574]\n",
      "Mode: Train env_steps 200 total rewards -1621.5782713890076 total energy tensor([[96.8514]])\n",
      "[-0.9836881]\n",
      "Mode: Train env_steps 200 total rewards -1618.8156671524048 total energy tensor([[88.6347]])\n",
      "[0.4904981]\n",
      "Mode: Train env_steps 200 total rewards -1609.2699704170227 total energy tensor([[86.1053]])\n",
      "[0.7012895]\n",
      "Mode: Train env_steps 200 total rewards -1610.5446772575378 total energy tensor([[113.4403]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28320104]\n",
      "Mode: Train env_steps 200 total rewards -1562.953064441681 total energy tensor([[157.3261]])\n",
      "[-0.35386652]\n",
      "Mode: Train env_steps 200 total rewards -1537.3336995840073 total energy tensor([[120.4427]])\n",
      "[-0.05771244]\n",
      "Mode: Train env_steps 200 total rewards -1422.1017041504383 total energy tensor([[135.7051]])\n",
      "[-0.08142734]\n",
      "Mode: Train env_steps 200 total rewards -1453.9487233385444 total energy tensor([[105.4840]])\n",
      "[-0.3987047]\n",
      "Mode: Train env_steps 200 total rewards -1512.569260790944 total energy tensor([[104.6150]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9675688]\n",
      "Mode: Train env_steps 200 total rewards -1614.8487465381622 total energy tensor([[77.4930]])\n",
      "[0.13610244]\n",
      "Mode: Train env_steps 200 total rewards -1584.2363464832306 total energy tensor([[81.0292]])\n",
      "[0.8129242]\n",
      "Mode: Train env_steps 200 total rewards -1524.9534941911697 total energy tensor([[90.9497]])\n",
      "[-0.79174185]\n",
      "Mode: Train env_steps 200 total rewards -1612.803294658661 total energy tensor([[78.6470]])\n",
      "[0.05745966]\n",
      "Mode: Train env_steps 200 total rewards -1608.9270358085632 total energy tensor([[119.9958]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7828569]\n",
      "Mode: Test env_steps 200 total rewards -1365.6901432424784 total energy tensor([[104.7078]])\n",
      "[-0.33583125]\n",
      "Mode: Test env_steps 200 total rewards -1568.1158380508423 total energy tensor([[146.6054]])\n",
      "[-0.50082165]\n",
      "Mode: Test env_steps 200 total rewards -1521.1173123121262 total energy tensor([[104.2998]])\n",
      "[-0.3408939]\n",
      "Mode: Test env_steps 200 total rewards -1405.1691098362207 total energy tensor([[106.2431]])\n",
      "[-0.76351035]\n",
      "Mode: Test env_steps 200 total rewards -1606.8656949996948 total energy tensor([[105.9712]])\n",
      "[-0.00047082]\n",
      "Mode: Test env_steps 200 total rewards -1475.3952506780624 total energy tensor([[110.5207]])\n",
      "[0.39251512]\n",
      "Mode: Test env_steps 200 total rewards -1577.9583532810211 total energy tensor([[97.3045]])\n",
      "[0.70724374]\n",
      "Mode: Test env_steps 200 total rewards -1498.9488156437874 total energy tensor([[108.8647]])\n",
      "[0.28546482]\n",
      "Mode: Test env_steps 200 total rewards -1604.6283648014069 total energy tensor([[104.5221]])\n",
      "[-0.60565484]\n",
      "Mode: Test env_steps 200 total rewards -1586.1598620414734 total energy tensor([[141.5027]])\n",
      "90000 -1521.0048744887113\n",
      "[-0.17531174]\n",
      "Mode: Train env_steps 200 total rewards -1591.1475534439087 total energy tensor([[98.7744]])\n",
      "[0.76721996]\n",
      "Mode: Train env_steps 200 total rewards -1558.5871901512146 total energy tensor([[109.5562]])\n",
      "[0.46928993]\n",
      "Mode: Train env_steps 200 total rewards -1560.0076324939728 total energy tensor([[112.0179]])\n",
      "[0.22407405]\n",
      "Mode: Train env_steps 200 total rewards -1554.1200897693634 total energy tensor([[101.6000]])\n",
      "[-0.506342]\n",
      "Mode: Train env_steps 200 total rewards -1526.6135638952255 total energy tensor([[105.6599]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07373052]\n",
      "Mode: Train env_steps 200 total rewards -1680.8664326667786 total energy tensor([[77.7407]])\n",
      "[0.6964957]\n",
      "Mode: Train env_steps 200 total rewards -1702.942485332489 total energy tensor([[88.6431]])\n",
      "[-0.11894058]\n",
      "Mode: Train env_steps 200 total rewards -1727.5430746078491 total energy tensor([[75.2720]])\n",
      "[0.24334416]\n",
      "Mode: Train env_steps 200 total rewards -1597.5809891223907 total energy tensor([[108.5612]])\n",
      "[-0.9037319]\n",
      "Mode: Train env_steps 200 total rewards -1596.3716042041779 total energy tensor([[105.9782]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01452849]\n",
      "Mode: Train env_steps 200 total rewards -1554.3256343007088 total energy tensor([[91.6416]])\n",
      "[-0.43420246]\n",
      "Mode: Train env_steps 200 total rewards -1654.4040637016296 total energy tensor([[101.6359]])\n",
      "[0.5198965]\n",
      "Mode: Train env_steps 200 total rewards -1672.3697118759155 total energy tensor([[70.2170]])\n",
      "[0.43730065]\n",
      "Mode: Train env_steps 200 total rewards -1597.805109500885 total energy tensor([[134.9160]])\n",
      "[-0.61148816]\n",
      "Mode: Train env_steps 200 total rewards -1456.8086677640676 total energy tensor([[102.0520]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38910416]\n",
      "Mode: Train env_steps 200 total rewards -1109.4116675734986 total energy tensor([[112.9378]])\n",
      "[0.04549142]\n",
      "Mode: Train env_steps 200 total rewards -1199.52821684815 total energy tensor([[121.0262]])\n",
      "[0.5560852]\n",
      "Mode: Train env_steps 200 total rewards -1505.1188871860504 total energy tensor([[139.4964]])\n",
      "[-0.87834215]\n",
      "Mode: Train env_steps 200 total rewards -1514.6642813682556 total energy tensor([[138.3269]])\n",
      "[0.845717]\n",
      "Mode: Train env_steps 200 total rewards -1439.9009275436401 total energy tensor([[145.3354]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89179397]\n",
      "Mode: Train env_steps 200 total rewards -1006.7852686876431 total energy tensor([[107.1422]])\n",
      "[0.5236414]\n",
      "Mode: Train env_steps 200 total rewards -1651.666965007782 total energy tensor([[69.6335]])\n",
      "[-0.64306545]\n",
      "Mode: Train env_steps 200 total rewards -1286.049218956381 total energy tensor([[94.0200]])\n",
      "[0.6947948]\n",
      "Mode: Train env_steps 200 total rewards -1795.647840976715 total energy tensor([[125.9894]])\n",
      "[-0.26209962]\n",
      "Mode: Train env_steps 200 total rewards -1629.161759853363 total energy tensor([[73.9972]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13870898]\n",
      "Mode: Test env_steps 200 total rewards -1463.532980620861 total energy tensor([[124.7141]])\n",
      "[-0.5118484]\n",
      "Mode: Test env_steps 200 total rewards -1564.314365386963 total energy tensor([[128.0843]])\n",
      "[-0.54822797]\n",
      "Mode: Test env_steps 200 total rewards -1582.6054735183716 total energy tensor([[117.2514]])\n",
      "[-0.8807461]\n",
      "Mode: Test env_steps 200 total rewards -1557.6623830795288 total energy tensor([[133.9003]])\n",
      "[0.24345782]\n",
      "Mode: Test env_steps 200 total rewards -1584.8655290603638 total energy tensor([[135.2645]])\n",
      "[0.30057386]\n",
      "Mode: Test env_steps 200 total rewards -1414.5242127776146 total energy tensor([[111.8955]])\n",
      "[0.04996843]\n",
      "Mode: Test env_steps 200 total rewards -1569.7188806533813 total energy tensor([[125.8712]])\n",
      "[0.7635539]\n",
      "Mode: Test env_steps 200 total rewards -1490.9085253477097 total energy tensor([[109.3385]])\n",
      "[-0.82390803]\n",
      "Mode: Test env_steps 200 total rewards -1445.3384843319654 total energy tensor([[113.0738]])\n",
      "[0.91222006]\n",
      "Mode: Test env_steps 200 total rewards -1202.5695909494534 total energy tensor([[119.5451]])\n",
      "95000 -1487.6040425726212\n",
      "[0.27007142]\n",
      "Mode: Train env_steps 200 total rewards -1606.0582003593445 total energy tensor([[146.7508]])\n",
      "[-0.25100505]\n",
      "Mode: Train env_steps 200 total rewards -1503.1733853816986 total energy tensor([[106.5393]])\n",
      "[0.01836198]\n",
      "Mode: Train env_steps 200 total rewards -1649.8985571861267 total energy tensor([[133.9427]])\n",
      "[0.0564531]\n",
      "Mode: Train env_steps 200 total rewards -1552.0125910043716 total energy tensor([[122.0761]])\n",
      "[-0.16674705]\n",
      "Mode: Train env_steps 200 total rewards -1621.9518475532532 total energy tensor([[140.2284]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9499093]\n",
      "Mode: Train env_steps 200 total rewards -1738.7765197753906 total energy tensor([[50.2943]])\n",
      "[-0.81290454]\n",
      "Mode: Train env_steps 200 total rewards -1619.3981292247772 total energy tensor([[71.7483]])\n",
      "[-0.27679625]\n",
      "Mode: Train env_steps 200 total rewards -1535.922562226653 total energy tensor([[80.6974]])\n",
      "[0.145015]\n",
      "Mode: Train env_steps 200 total rewards -1625.5542246103287 total energy tensor([[71.3087]])\n",
      "[0.8184246]\n",
      "Mode: Train env_steps 200 total rewards -1595.8967533111572 total energy tensor([[75.6850]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9326969]\n",
      "Mode: Train env_steps 200 total rewards -1541.5067147016525 total energy tensor([[93.4181]])\n",
      "[-0.7758275]\n",
      "Mode: Train env_steps 200 total rewards -1615.7713027000427 total energy tensor([[86.8225]])\n",
      "[0.15416718]\n",
      "Mode: Train env_steps 200 total rewards -1581.4311010837555 total energy tensor([[89.1308]])\n",
      "[0.45530316]\n",
      "Mode: Train env_steps 200 total rewards -1572.2469792962074 total energy tensor([[89.2607]])\n",
      "[0.2733743]\n",
      "Mode: Train env_steps 200 total rewards -1667.474717617035 total energy tensor([[80.4916]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50612545]\n",
      "Mode: Train env_steps 200 total rewards -1557.1929395198822 total energy tensor([[86.2768]])\n",
      "[0.00349161]\n",
      "Mode: Train env_steps 200 total rewards -1686.5867710113525 total energy tensor([[74.6684]])\n",
      "[0.39131072]\n",
      "Mode: Train env_steps 200 total rewards -1610.4521305561066 total energy tensor([[85.3114]])\n",
      "[-0.43006906]\n",
      "Mode: Train env_steps 200 total rewards -1533.011928319931 total energy tensor([[92.0788]])\n",
      "[0.74406606]\n",
      "Mode: Train env_steps 200 total rewards -1508.627628415823 total energy tensor([[92.1295]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48225713]\n",
      "Mode: Train env_steps 200 total rewards -1599.6543509960175 total energy tensor([[78.5486]])\n",
      "[0.09658568]\n",
      "Mode: Train env_steps 200 total rewards -1402.2411110140383 total energy tensor([[91.6459]])\n",
      "[0.38219446]\n",
      "Mode: Train env_steps 200 total rewards -1504.1523551344872 total energy tensor([[93.1968]])\n",
      "[-0.029298]\n",
      "Mode: Train env_steps 200 total rewards -1656.6634140014648 total energy tensor([[136.6402]])\n",
      "[0.23243965]\n",
      "Mode: Train env_steps 200 total rewards -1581.4899972081184 total energy tensor([[82.7014]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00383367]\n",
      "Mode: Test env_steps 200 total rewards -1623.1779372692108 total energy tensor([[75.5002]])\n",
      "[0.3600657]\n",
      "Mode: Test env_steps 200 total rewards -1429.2353965491056 total energy tensor([[100.6433]])\n",
      "[-0.23854238]\n",
      "Mode: Test env_steps 200 total rewards -1478.6158965826035 total energy tensor([[101.8247]])\n",
      "[-0.27309301]\n",
      "Mode: Test env_steps 200 total rewards -1587.6210050582886 total energy tensor([[83.3866]])\n",
      "[0.4126733]\n",
      "Mode: Test env_steps 200 total rewards -1669.4058437347412 total energy tensor([[78.2241]])\n",
      "[0.02797867]\n",
      "Mode: Test env_steps 200 total rewards -1507.5750976204872 total energy tensor([[98.6728]])\n",
      "[-0.02248109]\n",
      "Mode: Test env_steps 200 total rewards -1656.9853587150574 total energy tensor([[78.3737]])\n",
      "[0.05252816]\n",
      "Mode: Test env_steps 200 total rewards -1666.7074522972107 total energy tensor([[80.7456]])\n",
      "[0.14355725]\n",
      "Mode: Test env_steps 200 total rewards -1668.4065618515015 total energy tensor([[79.5452]])\n",
      "[-0.88523567]\n",
      "Mode: Test env_steps 200 total rewards -1499.6773426532745 total energy tensor([[99.1645]])\n",
      "100000 -1578.740789233148\n",
      "[0.44349033]\n",
      "Mode: Train env_steps 200 total rewards -1459.8011292219162 total energy tensor([[102.4972]])\n",
      "[-0.8708303]\n",
      "Mode: Train env_steps 200 total rewards -1358.8443596363068 total energy tensor([[106.6246]])\n",
      "[-0.01009795]\n",
      "Mode: Train env_steps 200 total rewards -1421.2672944813967 total energy tensor([[105.2796]])\n",
      "[-0.7731786]\n",
      "Mode: Train env_steps 200 total rewards -1624.4348983764648 total energy tensor([[80.9121]])\n",
      "[0.06506853]\n",
      "Mode: Train env_steps 200 total rewards -1657.1332626342773 total energy tensor([[92.3798]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3190819]\n",
      "Mode: Train env_steps 200 total rewards -1065.9883233830333 total energy tensor([[124.9041]])\n",
      "[0.4938191]\n",
      "Mode: Train env_steps 200 total rewards -1596.539698600769 total energy tensor([[86.0544]])\n",
      "[0.33733365]\n",
      "Mode: Train env_steps 200 total rewards -1643.068431854248 total energy tensor([[75.8319]])\n",
      "[0.97110176]\n",
      "Mode: Train env_steps 200 total rewards -1560.393358707428 total energy tensor([[160.7007]])\n",
      "[0.54091287]\n",
      "Mode: Train env_steps 200 total rewards -1610.2970423698425 total energy tensor([[89.9254]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.34108034]\n",
      "Mode: Train env_steps 200 total rewards -1628.5697088241577 total energy tensor([[106.4572]])\n",
      "[-0.31580204]\n",
      "Mode: Train env_steps 200 total rewards -1587.5990521907806 total energy tensor([[101.8391]])\n",
      "[-0.97480714]\n",
      "Mode: Train env_steps 200 total rewards -1441.9494568109512 total energy tensor([[113.3649]])\n",
      "[0.30803475]\n",
      "Mode: Train env_steps 200 total rewards -1497.0480346381664 total energy tensor([[108.2628]])\n",
      "[0.15369537]\n",
      "Mode: Train env_steps 200 total rewards -1534.9203275442123 total energy tensor([[104.9442]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9028509]\n",
      "Mode: Train env_steps 200 total rewards -1325.9066115617752 total energy tensor([[112.0473]])\n",
      "[-0.8112009]\n",
      "Mode: Train env_steps 200 total rewards -1538.0523563623428 total energy tensor([[90.8116]])\n",
      "[0.31392723]\n",
      "Mode: Train env_steps 200 total rewards -1532.0165618658066 total energy tensor([[90.9375]])\n",
      "[0.6105494]\n",
      "Mode: Train env_steps 200 total rewards -1115.4798126226524 total energy tensor([[114.7210]])\n",
      "[0.17564]\n",
      "Mode: Train env_steps 200 total rewards -1623.6915743350983 total energy tensor([[77.6083]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8316326]\n",
      "Mode: Train env_steps 200 total rewards -1640.3677735328674 total energy tensor([[137.3811]])\n",
      "[-0.67215776]\n",
      "Mode: Train env_steps 200 total rewards -1031.9747109077289 total energy tensor([[112.7649]])\n",
      "[0.5222231]\n",
      "Mode: Train env_steps 200 total rewards -1517.6386845111847 total energy tensor([[129.9937]])\n",
      "[0.21502301]\n",
      "Mode: Train env_steps 200 total rewards -1499.5279428958893 total energy tensor([[132.8071]])\n",
      "[0.6101668]\n",
      "Mode: Train env_steps 200 total rewards -1612.3525552749634 total energy tensor([[114.4275]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5045512]\n",
      "Mode: Test env_steps 200 total rewards -1643.2560033798218 total energy tensor([[92.7943]])\n",
      "[-0.579073]\n",
      "Mode: Test env_steps 200 total rewards -1419.0051241368055 total energy tensor([[95.9318]])\n",
      "[-0.7912324]\n",
      "Mode: Test env_steps 200 total rewards -1614.7416961193085 total energy tensor([[80.6773]])\n",
      "[0.12789826]\n",
      "Mode: Test env_steps 200 total rewards -1614.773021697998 total energy tensor([[78.4156]])\n",
      "[0.7665983]\n",
      "Mode: Test env_steps 200 total rewards -1663.6527800559998 total energy tensor([[89.8611]])\n",
      "[0.4035706]\n",
      "Mode: Test env_steps 200 total rewards -1448.0522091388702 total energy tensor([[100.6916]])\n",
      "[0.20612922]\n",
      "Mode: Test env_steps 200 total rewards -1665.2636828422546 total energy tensor([[66.4102]])\n",
      "[0.7914893]\n",
      "Mode: Test env_steps 200 total rewards -1639.3961882591248 total energy tensor([[81.4439]])\n",
      "[0.05522531]\n",
      "Mode: Test env_steps 200 total rewards -1552.6470596790314 total energy tensor([[91.2405]])\n",
      "[-0.40917188]\n",
      "Mode: Test env_steps 200 total rewards -1655.360417842865 total energy tensor([[68.8924]])\n",
      "105000 -1591.614818315208\n",
      "[-0.08276781]\n",
      "Mode: Train env_steps 200 total rewards -1618.452198266983 total energy tensor([[79.2641]])\n",
      "[0.22061172]\n",
      "Mode: Train env_steps 200 total rewards -1450.1620730757713 total energy tensor([[100.4826]])\n",
      "[-0.04578642]\n",
      "Mode: Train env_steps 200 total rewards -1673.622458934784 total energy tensor([[79.6415]])\n",
      "[0.17268258]\n",
      "Mode: Train env_steps 200 total rewards -1597.1569242477417 total energy tensor([[84.4247]])\n",
      "[-0.38168684]\n",
      "Mode: Train env_steps 200 total rewards -1602.7521977424622 total energy tensor([[79.5109]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.86112654]\n",
      "Mode: Train env_steps 200 total rewards -1670.5092096328735 total energy tensor([[74.7246]])\n",
      "[0.28504947]\n",
      "Mode: Train env_steps 200 total rewards -1637.5719347000122 total energy tensor([[76.9353]])\n",
      "[0.9491082]\n",
      "Mode: Train env_steps 200 total rewards -1684.1649651527405 total energy tensor([[66.9249]])\n",
      "[-0.49554995]\n",
      "Mode: Train env_steps 200 total rewards -1499.2840159535408 total energy tensor([[97.6618]])\n",
      "[-0.22397804]\n",
      "Mode: Train env_steps 200 total rewards -1659.056143283844 total energy tensor([[88.5880]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6498753]\n",
      "Mode: Train env_steps 200 total rewards -1512.3417316675186 total energy tensor([[97.5131]])\n",
      "[0.7987462]\n",
      "Mode: Train env_steps 200 total rewards -709.4711904512951 total energy tensor([[121.7399]])\n",
      "[0.32541755]\n",
      "Mode: Train env_steps 200 total rewards -1057.8167102448642 total energy tensor([[106.3346]])\n",
      "[0.12627977]\n",
      "Mode: Train env_steps 200 total rewards -1613.4565467834473 total energy tensor([[127.4158]])\n",
      "[0.91589236]\n",
      "Mode: Train env_steps 200 total rewards -1649.4343934059143 total energy tensor([[88.8406]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10269181]\n",
      "Mode: Train env_steps 200 total rewards -892.5366609944613 total energy tensor([[114.2003]])\n",
      "[-0.26227543]\n",
      "Mode: Train env_steps 200 total rewards -1584.3202917575836 total energy tensor([[115.4380]])\n",
      "[-0.8336527]\n",
      "Mode: Train env_steps 200 total rewards -1512.6967306137085 total energy tensor([[117.0091]])\n",
      "[-0.9011538]\n",
      "Mode: Train env_steps 200 total rewards -1596.9927854537964 total energy tensor([[107.6144]])\n",
      "[0.53603345]\n",
      "Mode: Train env_steps 200 total rewards -1472.3735806941986 total energy tensor([[117.0746]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07754599]\n",
      "Mode: Train env_steps 200 total rewards -1706.0268993377686 total energy tensor([[63.7323]])\n",
      "[0.09065915]\n",
      "Mode: Train env_steps 200 total rewards -1409.3508306145668 total energy tensor([[116.4763]])\n",
      "[0.26503]\n",
      "Mode: Train env_steps 200 total rewards -1198.5954565741122 total energy tensor([[133.1915]])\n",
      "[-0.96898264]\n",
      "Mode: Train env_steps 200 total rewards -1418.5404576063156 total energy tensor([[116.5395]])\n",
      "[0.44181782]\n",
      "Mode: Train env_steps 200 total rewards -407.758779194206 total energy tensor([[140.7610]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7323642]\n",
      "Mode: Test env_steps 200 total rewards -1247.811504431069 total energy tensor([[116.3815]])\n",
      "[0.7949126]\n",
      "Mode: Test env_steps 200 total rewards -1152.0540078878403 total energy tensor([[130.7821]])\n",
      "[-0.6129523]\n",
      "Mode: Test env_steps 200 total rewards -1503.614580154419 total energy tensor([[98.3055]])\n",
      "[-0.337747]\n",
      "Mode: Test env_steps 200 total rewards -1.5495750966947526 total energy tensor([[153.0281]])\n",
      "[-0.7543227]\n",
      "Mode: Test env_steps 200 total rewards -1166.9161105719395 total energy tensor([[118.9370]])\n",
      "[-0.44114313]\n",
      "Mode: Test env_steps 200 total rewards -1505.0918322205544 total energy tensor([[100.0027]])\n",
      "[0.49831578]\n",
      "Mode: Test env_steps 200 total rewards -1517.984641134739 total energy tensor([[100.1345]])\n",
      "[-0.22435822]\n",
      "Mode: Test env_steps 200 total rewards -1539.6094529628754 total energy tensor([[137.7734]])\n",
      "[-0.54827684]\n",
      "Mode: Test env_steps 200 total rewards -1710.5536346435547 total energy tensor([[127.9345]])\n",
      "[0.30288285]\n",
      "Mode: Test env_steps 200 total rewards -1643.1936695575714 total energy tensor([[90.2396]])\n",
      "110000 -1298.8379008661257\n",
      "[0.96983904]\n",
      "Mode: Train env_steps 200 total rewards -1632.8946061134338 total energy tensor([[82.3213]])\n",
      "[-0.5258061]\n",
      "Mode: Train env_steps 200 total rewards -1593.9116089344025 total energy tensor([[112.5877]])\n",
      "[0.31874532]\n",
      "Mode: Train env_steps 200 total rewards -1639.12353515625 total energy tensor([[86.7281]])\n",
      "[-0.2910853]\n",
      "Mode: Train env_steps 200 total rewards -1657.1303339004517 total energy tensor([[127.1929]])\n",
      "[-0.16316953]\n",
      "Mode: Train env_steps 200 total rewards -1454.801557302475 total energy tensor([[101.5228]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84055376]\n",
      "Mode: Train env_steps 200 total rewards -528.383603528142 total energy tensor([[117.2529]])\n",
      "[0.363213]\n",
      "Mode: Train env_steps 200 total rewards -1311.093288872391 total energy tensor([[116.1961]])\n",
      "[0.36171427]\n",
      "Mode: Train env_steps 200 total rewards -1265.4753732383251 total energy tensor([[120.6114]])\n",
      "[0.3204204]\n",
      "Mode: Train env_steps 200 total rewards -1668.4764127731323 total energy tensor([[80.9846]])\n",
      "[0.976218]\n",
      "Mode: Train env_steps 200 total rewards -1558.1981174945831 total energy tensor([[113.3980]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4593525]\n",
      "Mode: Train env_steps 200 total rewards -398.4801153629087 total energy tensor([[118.3013]])\n",
      "[0.1163701]\n",
      "Mode: Train env_steps 200 total rewards -1565.1286878585815 total energy tensor([[107.8457]])\n",
      "[-0.87715477]\n",
      "Mode: Train env_steps 200 total rewards -1605.2115406990051 total energy tensor([[97.3178]])\n",
      "[0.3511852]\n",
      "Mode: Train env_steps 200 total rewards -1505.4955953359604 total energy tensor([[113.7876]])\n",
      "[0.9151995]\n",
      "Mode: Train env_steps 200 total rewards -1232.3560808897018 total energy tensor([[136.0424]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4083663]\n",
      "Mode: Train env_steps 200 total rewards -1559.993308544159 total energy tensor([[118.0810]])\n",
      "[-0.28076538]\n",
      "Mode: Train env_steps 200 total rewards -1543.495433330536 total energy tensor([[119.1530]])\n",
      "[0.4167203]\n",
      "Mode: Train env_steps 200 total rewards -1602.4002408981323 total energy tensor([[112.5359]])\n",
      "[0.5469856]\n",
      "Mode: Train env_steps 200 total rewards -1084.863408997655 total energy tensor([[150.1889]])\n",
      "[-0.8320526]\n",
      "Mode: Train env_steps 200 total rewards -1463.4560191631317 total energy tensor([[127.2322]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13731945]\n",
      "Mode: Train env_steps 200 total rewards -829.9190558176488 total energy tensor([[137.9313]])\n",
      "[0.4966272]\n",
      "Mode: Train env_steps 200 total rewards -1517.405350804329 total energy tensor([[103.3202]])\n",
      "[-0.6577878]\n",
      "Mode: Train env_steps 200 total rewards -1116.266253264621 total energy tensor([[131.4369]])\n",
      "[-0.14505972]\n",
      "Mode: Train env_steps 200 total rewards -1378.7554162740707 total energy tensor([[117.7931]])\n",
      "[-0.5871299]\n",
      "Mode: Train env_steps 200 total rewards -1672.3683037757874 total energy tensor([[87.9753]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6928231]\n",
      "Mode: Test env_steps 200 total rewards -1570.762375831604 total energy tensor([[115.9208]])\n",
      "[0.05598188]\n",
      "Mode: Test env_steps 200 total rewards -388.406575800851 total energy tensor([[125.9909]])\n",
      "[-0.35553995]\n",
      "Mode: Test env_steps 200 total rewards -1584.0880661010742 total energy tensor([[131.2756]])\n",
      "[0.9159582]\n",
      "Mode: Test env_steps 200 total rewards -396.7601306736469 total energy tensor([[124.7078]])\n",
      "[0.9934409]\n",
      "Mode: Test env_steps 200 total rewards -1451.5905888080597 total energy tensor([[137.6791]])\n",
      "[-0.5149405]\n",
      "Mode: Test env_steps 200 total rewards -494.125478615053 total energy tensor([[128.0019]])\n",
      "[0.43912584]\n",
      "Mode: Test env_steps 200 total rewards -398.18434261670336 total energy tensor([[134.5568]])\n",
      "[0.08225003]\n",
      "Mode: Test env_steps 200 total rewards -520.916812479496 total energy tensor([[130.9863]])\n",
      "[0.5152309]\n",
      "Mode: Test env_steps 200 total rewards -1644.1231665611267 total energy tensor([[151.1060]])\n",
      "[0.35562763]\n",
      "Mode: Test env_steps 200 total rewards -1354.67538022995 total energy tensor([[142.1118]])\n",
      "115000 -980.3632917717565\n",
      "[0.36509773]\n",
      "Mode: Train env_steps 200 total rewards -1600.1150612831116 total energy tensor([[104.3012]])\n",
      "[-0.5308233]\n",
      "Mode: Train env_steps 200 total rewards -1172.882541745901 total energy tensor([[149.3019]])\n",
      "[0.67892617]\n",
      "Mode: Train env_steps 200 total rewards -1530.8108439445496 total energy tensor([[126.0754]])\n",
      "[0.76343864]\n",
      "Mode: Train env_steps 200 total rewards -412.3787890165113 total energy tensor([[133.6295]])\n",
      "[0.5607207]\n",
      "Mode: Train env_steps 200 total rewards -1618.0425834655762 total energy tensor([[103.0083]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6046197]\n",
      "Mode: Train env_steps 200 total rewards -1604.8153357505798 total energy tensor([[103.3771]])\n",
      "[-0.43950143]\n",
      "Mode: Train env_steps 200 total rewards -1361.3251622915268 total energy tensor([[139.8842]])\n",
      "[0.9414323]\n",
      "Mode: Train env_steps 200 total rewards -1268.1876238584518 total energy tensor([[145.1738]])\n",
      "[0.9675696]\n",
      "Mode: Train env_steps 200 total rewards -1556.990594625473 total energy tensor([[116.5218]])\n",
      "[-0.7464172]\n",
      "Mode: Train env_steps 200 total rewards -1583.170124053955 total energy tensor([[106.8443]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9760201]\n",
      "Mode: Train env_steps 200 total rewards -644.3151671737432 total energy tensor([[132.2324]])\n",
      "[0.7471629]\n",
      "Mode: Train env_steps 200 total rewards -1292.8788739442825 total energy tensor([[151.5038]])\n",
      "[-0.60032356]\n",
      "Mode: Train env_steps 200 total rewards -1280.138890862465 total energy tensor([[151.9015]])\n",
      "[0.44621655]\n",
      "Mode: Train env_steps 200 total rewards -651.6519753038883 total energy tensor([[120.3617]])\n",
      "[0.5490474]\n",
      "Mode: Train env_steps 200 total rewards -1425.4837036132812 total energy tensor([[136.5543]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90138006]\n",
      "Mode: Train env_steps 200 total rewards -1354.3549511432648 total energy tensor([[152.0313]])\n",
      "[-0.57173413]\n",
      "Mode: Train env_steps 200 total rewards -666.6470477133989 total energy tensor([[142.9570]])\n",
      "[0.728252]\n",
      "Mode: Train env_steps 200 total rewards -1608.0156121253967 total energy tensor([[109.8027]])\n",
      "[-0.5761999]\n",
      "Mode: Train env_steps 200 total rewards -652.661480192095 total energy tensor([[137.2802]])\n",
      "[-0.7471551]\n",
      "Mode: Train env_steps 200 total rewards -662.5190753787756 total energy tensor([[140.8262]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8768156]\n",
      "Mode: Train env_steps 200 total rewards -527.1289798989892 total energy tensor([[134.5356]])\n",
      "[-0.37049696]\n",
      "Mode: Train env_steps 200 total rewards -1395.4923479557037 total energy tensor([[149.1509]])\n",
      "[0.5425367]\n",
      "Mode: Train env_steps 200 total rewards -1019.9952337630093 total energy tensor([[161.4024]])\n",
      "[0.26390928]\n",
      "Mode: Train env_steps 200 total rewards -518.6479014493525 total energy tensor([[137.7469]])\n",
      "[0.35555995]\n",
      "Mode: Train env_steps 200 total rewards -1569.042887210846 total energy tensor([[121.6056]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3070574]\n",
      "Mode: Test env_steps 200 total rewards -1351.6201331615448 total energy tensor([[144.7614]])\n",
      "[-0.7788745]\n",
      "Mode: Test env_steps 200 total rewards -1320.0208361148834 total energy tensor([[145.6951]])\n",
      "[0.15519427]\n",
      "Mode: Test env_steps 200 total rewards -1549.6411366462708 total energy tensor([[133.1543]])\n",
      "[-0.53789395]\n",
      "Mode: Test env_steps 200 total rewards -1553.1433682441711 total energy tensor([[129.8659]])\n",
      "[-0.07612247]\n",
      "Mode: Test env_steps 200 total rewards -1208.0168393850327 total energy tensor([[157.9920]])\n",
      "[0.9870619]\n",
      "Mode: Test env_steps 200 total rewards -1520.486165046692 total energy tensor([[140.7597]])\n",
      "[0.7426069]\n",
      "Mode: Test env_steps 200 total rewards -1601.2631678581238 total energy tensor([[114.6004]])\n",
      "[-0.0733355]\n",
      "Mode: Test env_steps 200 total rewards -368.19739846419543 total energy tensor([[143.2722]])\n",
      "[-0.14413428]\n",
      "Mode: Test env_steps 200 total rewards -1363.8677802085876 total energy tensor([[149.9388]])\n",
      "[-0.76034135]\n",
      "Mode: Test env_steps 200 total rewards -1596.4594764709473 total energy tensor([[117.1387]])\n",
      "120000 -1343.2716301600449\n",
      "[0.31340367]\n",
      "Mode: Train env_steps 200 total rewards -1405.4740719795227 total energy tensor([[156.6928]])\n",
      "[0.29594076]\n",
      "Mode: Train env_steps 200 total rewards -1298.0529016256332 total energy tensor([[148.0757]])\n",
      "[-0.2000248]\n",
      "Mode: Train env_steps 200 total rewards -1455.0137031078339 total energy tensor([[150.6305]])\n",
      "[-0.42296863]\n",
      "Mode: Train env_steps 200 total rewards -1525.8373341560364 total energy tensor([[139.4381]])\n",
      "[0.39271185]\n",
      "Mode: Train env_steps 200 total rewards -378.2657917784527 total energy tensor([[144.9831]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6349442]\n",
      "Mode: Train env_steps 200 total rewards -1285.5281265974045 total energy tensor([[146.4570]])\n",
      "[-0.32472965]\n",
      "Mode: Train env_steps 200 total rewards -265.3458553375676 total energy tensor([[162.5513]])\n",
      "[-0.7115116]\n",
      "Mode: Train env_steps 200 total rewards -132.6983084869571 total energy tensor([[168.9692]])\n",
      "[-0.75851715]\n",
      "Mode: Train env_steps 200 total rewards -1255.3231429606676 total energy tensor([[155.6225]])\n",
      "[-0.81225073]\n",
      "Mode: Train env_steps 200 total rewards -1291.952476322651 total energy tensor([[154.8994]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9670528]\n",
      "Mode: Train env_steps 200 total rewards -1606.4363203048706 total energy tensor([[118.3584]])\n",
      "[-0.25518352]\n",
      "Mode: Train env_steps 200 total rewards -528.5611577630043 total energy tensor([[136.4488]])\n",
      "[-0.49630803]\n",
      "Mode: Train env_steps 200 total rewards -1601.095154285431 total energy tensor([[121.6912]])\n",
      "[0.5966422]\n",
      "Mode: Train env_steps 200 total rewards -1231.0970219373703 total energy tensor([[173.6119]])\n",
      "[-0.8246921]\n",
      "Mode: Train env_steps 200 total rewards -1563.5258626937866 total energy tensor([[128.7722]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3855477]\n",
      "Mode: Train env_steps 200 total rewards -1409.7181837558746 total energy tensor([[160.0558]])\n",
      "[0.19954433]\n",
      "Mode: Train env_steps 200 total rewards -1257.2722828388214 total energy tensor([[167.7176]])\n",
      "[-0.8382542]\n",
      "Mode: Train env_steps 200 total rewards -1243.1284452676773 total energy tensor([[160.9609]])\n",
      "[-0.17756242]\n",
      "Mode: Train env_steps 200 total rewards -520.0104673635215 total energy tensor([[144.9643]])\n",
      "[-0.04544107]\n",
      "Mode: Train env_steps 200 total rewards -393.17276612017304 total energy tensor([[147.1095]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68807495]\n",
      "Mode: Train env_steps 200 total rewards -1418.1721060276031 total energy tensor([[164.5519]])\n",
      "[-0.41906133]\n",
      "Mode: Train env_steps 200 total rewards -518.937687734142 total energy tensor([[155.3079]])\n",
      "[0.10451704]\n",
      "Mode: Train env_steps 200 total rewards -1629.1805768013 total energy tensor([[102.7974]])\n",
      "[0.68541265]\n",
      "Mode: Train env_steps 200 total rewards -510.9316954649985 total energy tensor([[153.0868]])\n",
      "[-0.4132947]\n",
      "Mode: Train env_steps 200 total rewards -400.7081211572513 total energy tensor([[160.0312]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72428507]\n",
      "Mode: Test env_steps 200 total rewards -1282.9268511533737 total energy tensor([[153.6976]])\n",
      "[-0.94065297]\n",
      "Mode: Test env_steps 200 total rewards -1596.9026260375977 total energy tensor([[120.1347]])\n",
      "[0.8954139]\n",
      "Mode: Test env_steps 200 total rewards -979.0375956892967 total energy tensor([[152.6142]])\n",
      "[-0.8740014]\n",
      "Mode: Test env_steps 200 total rewards -1580.370587348938 total energy tensor([[179.3937]])\n",
      "[0.76820046]\n",
      "Mode: Test env_steps 200 total rewards -1554.9429655075073 total energy tensor([[135.1685]])\n",
      "[0.51222616]\n",
      "Mode: Test env_steps 200 total rewards -1262.3041939735413 total energy tensor([[151.9231]])\n",
      "[0.57933116]\n",
      "Mode: Test env_steps 200 total rewards -1132.8783213421702 total energy tensor([[158.2367]])\n",
      "[-0.7264742]\n",
      "Mode: Test env_steps 200 total rewards -1533.481704711914 total energy tensor([[182.8017]])\n",
      "[-0.9306259]\n",
      "Mode: Test env_steps 200 total rewards -1400.3508338928223 total energy tensor([[153.1304]])\n",
      "[0.5591085]\n",
      "Mode: Test env_steps 200 total rewards -1276.9067842960358 total energy tensor([[151.7735]])\n",
      "125000 -1360.0102463953197\n",
      "[0.98538154]\n",
      "Mode: Train env_steps 200 total rewards -1269.937069118023 total energy tensor([[158.3393]])\n",
      "[0.44780174]\n",
      "Mode: Train env_steps 200 total rewards -973.2421521232463 total energy tensor([[161.3811]])\n",
      "[-0.9052385]\n",
      "Mode: Train env_steps 200 total rewards -1291.9459173083305 total energy tensor([[159.0852]])\n",
      "[0.45049396]\n",
      "Mode: Train env_steps 200 total rewards -1270.2827507257462 total energy tensor([[152.1143]])\n",
      "[0.74344486]\n",
      "Mode: Train env_steps 200 total rewards -1154.1709176301956 total energy tensor([[156.3280]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54506016]\n",
      "Mode: Train env_steps 200 total rewards -1153.530167967081 total energy tensor([[161.9427]])\n",
      "[0.9975676]\n",
      "Mode: Train env_steps 200 total rewards -1252.6518134474754 total energy tensor([[160.0466]])\n",
      "[-0.4824275]\n",
      "Mode: Train env_steps 200 total rewards -1214.612260401249 total energy tensor([[160.5907]])\n",
      "[0.3547069]\n",
      "Mode: Train env_steps 200 total rewards -1365.561627149582 total energy tensor([[158.8451]])\n",
      "[0.9274044]\n",
      "Mode: Train env_steps 200 total rewards -937.5161825055256 total energy tensor([[153.9905]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02575599]\n",
      "Mode: Train env_steps 200 total rewards -837.5106194168329 total energy tensor([[188.0965]])\n",
      "[0.3257845]\n",
      "Mode: Train env_steps 200 total rewards -1092.481961429119 total energy tensor([[175.1889]])\n",
      "[0.62651706]\n",
      "Mode: Train env_steps 200 total rewards -811.0945413801819 total energy tensor([[178.8588]])\n",
      "[0.35432243]\n",
      "Mode: Train env_steps 200 total rewards -1268.7213246822357 total energy tensor([[177.2030]])\n",
      "[-0.26227158]\n",
      "Mode: Train env_steps 200 total rewards -1007.2553953826427 total energy tensor([[183.8650]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80071676]\n",
      "Mode: Train env_steps 200 total rewards -769.1938657313585 total energy tensor([[177.2425]])\n",
      "[0.29343778]\n",
      "Mode: Train env_steps 200 total rewards -1217.7514734268188 total energy tensor([[180.0473]])\n",
      "[0.64652413]\n",
      "Mode: Train env_steps 200 total rewards -1209.2677545547485 total energy tensor([[181.4444]])\n",
      "[-0.07678264]\n",
      "Mode: Train env_steps 200 total rewards -1188.7004557847977 total energy tensor([[180.4207]])\n",
      "[-0.00810381]\n",
      "Mode: Train env_steps 200 total rewards -1297.3293099403381 total energy tensor([[177.8565]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07237037]\n",
      "Mode: Train env_steps 200 total rewards -1338.35906124115 total energy tensor([[175.2950]])\n",
      "[0.26823214]\n",
      "Mode: Train env_steps 200 total rewards -648.4767475053668 total energy tensor([[170.3126]])\n",
      "[-0.37772304]\n",
      "Mode: Train env_steps 200 total rewards -1343.7968344688416 total energy tensor([[177.9120]])\n",
      "[-0.22696795]\n",
      "Mode: Train env_steps 200 total rewards -1546.3677563667297 total energy tensor([[161.5241]])\n",
      "[-0.34412497]\n",
      "Mode: Train env_steps 200 total rewards -1360.7633051872253 total energy tensor([[175.4896]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05569313]\n",
      "Mode: Test env_steps 200 total rewards -1444.9975690841675 total energy tensor([[171.2759]])\n",
      "[-0.5502507]\n",
      "Mode: Test env_steps 200 total rewards -1477.8827538490295 total energy tensor([[171.1160]])\n",
      "[0.19805183]\n",
      "Mode: Test env_steps 200 total rewards -1097.2503694295883 total energy tensor([[174.5098]])\n",
      "[-0.70205164]\n",
      "Mode: Test env_steps 200 total rewards -1092.0205999612808 total energy tensor([[175.2871]])\n",
      "[-0.88492733]\n",
      "Mode: Test env_steps 200 total rewards -517.3456375468522 total energy tensor([[167.5269]])\n",
      "[-0.83684963]\n",
      "Mode: Test env_steps 200 total rewards -1352.0279593467712 total energy tensor([[179.0860]])\n",
      "[0.86227787]\n",
      "Mode: Test env_steps 200 total rewards -1536.0440182685852 total energy tensor([[165.9114]])\n",
      "[-0.8957083]\n",
      "Mode: Test env_steps 200 total rewards -515.2109152786434 total energy tensor([[167.1512]])\n",
      "[0.45273122]\n",
      "Mode: Test env_steps 200 total rewards -1381.3057408332825 total energy tensor([[178.9967]])\n",
      "[-0.37688485]\n",
      "Mode: Test env_steps 200 total rewards -515.6554452553391 total energy tensor([[169.3256]])\n",
      "130000 -1092.974100885354\n",
      "[0.8233242]\n",
      "Mode: Train env_steps 200 total rewards -1071.4941914379597 total energy tensor([[181.9333]])\n",
      "[-0.69992983]\n",
      "Mode: Train env_steps 200 total rewards -1565.4707803726196 total energy tensor([[156.5050]])\n",
      "[-0.80817837]\n",
      "Mode: Train env_steps 200 total rewards -1189.8263992071152 total energy tensor([[178.2164]])\n",
      "[-0.31024906]\n",
      "Mode: Train env_steps 200 total rewards -516.4115921631455 total energy tensor([[169.6986]])\n",
      "[-0.49997815]\n",
      "Mode: Train env_steps 200 total rewards -1089.2130576372147 total energy tensor([[175.1039]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98931354]\n",
      "Mode: Train env_steps 200 total rewards -1040.6106257140636 total energy tensor([[179.8142]])\n",
      "[-0.76146746]\n",
      "Mode: Train env_steps 200 total rewards -698.9881047545932 total energy tensor([[166.4406]])\n",
      "[-0.42140645]\n",
      "Mode: Train env_steps 200 total rewards -1322.7169036865234 total energy tensor([[178.3986]])\n",
      "[-0.13084917]\n",
      "Mode: Train env_steps 200 total rewards -964.1345559954643 total energy tensor([[185.0467]])\n",
      "[0.9689044]\n",
      "Mode: Train env_steps 200 total rewards -1508.8884682655334 total energy tensor([[177.3685]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16298999]\n",
      "Mode: Train env_steps 200 total rewards -997.1473268568516 total energy tensor([[185.3634]])\n",
      "[0.65147567]\n",
      "Mode: Train env_steps 200 total rewards -1410.2452075481415 total energy tensor([[178.6927]])\n",
      "[0.05998013]\n",
      "Mode: Train env_steps 200 total rewards -618.7794077992439 total energy tensor([[173.5092]])\n",
      "[0.860393]\n",
      "Mode: Train env_steps 200 total rewards -1244.0684719085693 total energy tensor([[177.7368]])\n",
      "[0.16445571]\n",
      "Mode: Train env_steps 200 total rewards -1104.9219409227371 total energy tensor([[178.4857]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2843376]\n",
      "Mode: Train env_steps 200 total rewards -1475.9463334083557 total energy tensor([[175.5380]])\n",
      "[0.6530922]\n",
      "Mode: Train env_steps 200 total rewards -1106.1785243749619 total energy tensor([[184.3129]])\n",
      "[0.2604625]\n",
      "Mode: Train env_steps 200 total rewards -935.4846561998129 total energy tensor([[184.3933]])\n",
      "[-0.0604559]\n",
      "Mode: Train env_steps 200 total rewards -1467.1086056232452 total energy tensor([[174.1302]])\n",
      "[-0.8870901]\n",
      "Mode: Train env_steps 200 total rewards -1075.9579066634178 total energy tensor([[183.5544]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77007115]\n",
      "Mode: Train env_steps 200 total rewards -1538.6722440719604 total energy tensor([[170.3872]])\n",
      "[-0.37451136]\n",
      "Mode: Train env_steps 200 total rewards -521.1997071318328 total energy tensor([[150.7562]])\n",
      "[0.6964451]\n",
      "Mode: Train env_steps 200 total rewards -1172.9606996774673 total energy tensor([[181.7933]])\n",
      "[-0.02885612]\n",
      "Mode: Train env_steps 200 total rewards -520.8143201693892 total energy tensor([[151.7170]])\n",
      "[-0.04081723]\n",
      "Mode: Train env_steps 200 total rewards -532.3265498355031 total energy tensor([[141.0039]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6669653]\n",
      "Mode: Test env_steps 200 total rewards -1541.0717177391052 total energy tensor([[164.8887]])\n",
      "[-0.2742913]\n",
      "Mode: Test env_steps 200 total rewards -1486.136929988861 total energy tensor([[173.4226]])\n",
      "[0.15947135]\n",
      "Mode: Test env_steps 200 total rewards -954.875934034586 total energy tensor([[184.5785]])\n",
      "[0.29287115]\n",
      "Mode: Test env_steps 200 total rewards -1530.8982434272766 total energy tensor([[171.5432]])\n",
      "[-0.09398792]\n",
      "Mode: Test env_steps 200 total rewards -1084.289199769497 total energy tensor([[171.9142]])\n",
      "[0.6529644]\n",
      "Mode: Test env_steps 200 total rewards -1534.2527213096619 total energy tensor([[170.3060]])\n",
      "[-0.7752718]\n",
      "Mode: Test env_steps 200 total rewards -1509.6804504394531 total energy tensor([[170.8279]])\n",
      "[-0.73609155]\n",
      "Mode: Test env_steps 200 total rewards -1194.766769528389 total energy tensor([[182.4071]])\n",
      "[-0.84480804]\n",
      "Mode: Test env_steps 200 total rewards -1542.5922646522522 total energy tensor([[168.0794]])\n",
      "[-0.40030104]\n",
      "Mode: Test env_steps 200 total rewards -1587.0612387657166 total energy tensor([[142.7583]])\n",
      "135000 -1396.56254696548\n",
      "[-0.36472306]\n",
      "Mode: Train env_steps 200 total rewards -519.6893653795123 total energy tensor([[157.0706]])\n",
      "[-0.15311728]\n",
      "Mode: Train env_steps 200 total rewards -977.9664816260338 total energy tensor([[174.6538]])\n",
      "[0.07571835]\n",
      "Mode: Train env_steps 200 total rewards -516.2060167826712 total energy tensor([[151.0600]])\n",
      "[-0.18425466]\n",
      "Mode: Train env_steps 200 total rewards -518.6219526082277 total energy tensor([[146.8012]])\n",
      "[-0.03422897]\n",
      "Mode: Train env_steps 200 total rewards -1201.9479134082794 total energy tensor([[181.8791]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01349975]\n",
      "Mode: Train env_steps 200 total rewards -1258.3019857406616 total energy tensor([[182.7773]])\n",
      "[-0.8447816]\n",
      "Mode: Train env_steps 200 total rewards -981.3303913027048 total energy tensor([[185.7039]])\n",
      "[0.03099733]\n",
      "Mode: Train env_steps 200 total rewards -1335.456167459488 total energy tensor([[185.5639]])\n",
      "[-0.6949189]\n",
      "Mode: Train env_steps 200 total rewards -1384.0742111206055 total energy tensor([[185.0300]])\n",
      "[-0.31314844]\n",
      "Mode: Train env_steps 200 total rewards -965.6658124402165 total energy tensor([[185.1183]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09481364]\n",
      "Mode: Train env_steps 200 total rewards -1178.2715722322464 total energy tensor([[185.9513]])\n",
      "[0.77406824]\n",
      "Mode: Train env_steps 200 total rewards -983.988320171833 total energy tensor([[174.3710]])\n",
      "[-0.4965682]\n",
      "Mode: Train env_steps 200 total rewards -1072.9989352822304 total energy tensor([[176.0631]])\n",
      "[-0.96630234]\n",
      "Mode: Train env_steps 200 total rewards -1574.3060426712036 total energy tensor([[154.1878]])\n",
      "[-0.11049262]\n",
      "Mode: Train env_steps 200 total rewards -955.9147817492485 total energy tensor([[185.5846]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35025334]\n",
      "Mode: Train env_steps 200 total rewards -1173.1955721974373 total energy tensor([[181.0230]])\n",
      "[0.66862583]\n",
      "Mode: Train env_steps 200 total rewards -965.135156288743 total energy tensor([[177.4981]])\n",
      "[-0.967369]\n",
      "Mode: Train env_steps 200 total rewards -1159.9031924903393 total energy tensor([[180.8896]])\n",
      "[0.68822825]\n",
      "Mode: Train env_steps 200 total rewards -1540.8877758979797 total energy tensor([[168.4744]])\n",
      "[0.16502136]\n",
      "Mode: Train env_steps 200 total rewards -523.9813743159175 total energy tensor([[154.8395]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78795457]\n",
      "Mode: Train env_steps 200 total rewards -1485.6585216522217 total energy tensor([[178.5353]])\n",
      "[-0.02047412]\n",
      "Mode: Train env_steps 200 total rewards -407.1362830167636 total energy tensor([[146.6873]])\n",
      "[0.33048925]\n",
      "Mode: Train env_steps 200 total rewards -1305.9835755825043 total energy tensor([[186.7351]])\n",
      "[0.9675778]\n",
      "Mode: Train env_steps 200 total rewards -1223.0505137443542 total energy tensor([[187.5772]])\n",
      "[0.26178217]\n",
      "Mode: Train env_steps 200 total rewards -400.48725454322994 total energy tensor([[149.5313]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57194525]\n",
      "Mode: Test env_steps 200 total rewards -935.8075504601002 total energy tensor([[183.0718]])\n",
      "[-0.5180215]\n",
      "Mode: Test env_steps 200 total rewards -1168.024956703186 total energy tensor([[186.0812]])\n",
      "[0.7669365]\n",
      "Mode: Test env_steps 200 total rewards -1216.2903499603271 total energy tensor([[187.4666]])\n",
      "[0.6878777]\n",
      "Mode: Test env_steps 200 total rewards -1107.984133720398 total energy tensor([[183.7432]])\n",
      "[0.759775]\n",
      "Mode: Test env_steps 200 total rewards -1073.2795281410217 total energy tensor([[179.0114]])\n",
      "[-0.58518773]\n",
      "Mode: Test env_steps 200 total rewards -1010.6897961422801 total energy tensor([[184.1039]])\n",
      "[0.6419295]\n",
      "Mode: Test env_steps 200 total rewards -1351.352219581604 total energy tensor([[184.5347]])\n",
      "[-0.5419887]\n",
      "Mode: Test env_steps 200 total rewards -1424.8237850666046 total energy tensor([[184.4990]])\n",
      "[0.21568798]\n",
      "Mode: Test env_steps 200 total rewards -1123.411453962326 total energy tensor([[184.3992]])\n",
      "[0.16374213]\n",
      "Mode: Test env_steps 200 total rewards -1545.0247344970703 total energy tensor([[172.9261]])\n",
      "140000 -1195.6688508234918\n",
      "[0.10390934]\n",
      "Mode: Train env_steps 200 total rewards -1444.265730381012 total energy tensor([[183.4881]])\n",
      "[0.004658]\n",
      "Mode: Train env_steps 200 total rewards -1388.4578115940094 total energy tensor([[183.5466]])\n",
      "[0.44413292]\n",
      "Mode: Train env_steps 200 total rewards -1492.7449231147766 total energy tensor([[175.6627]])\n",
      "[-0.6774782]\n",
      "Mode: Train env_steps 200 total rewards -614.578256790177 total energy tensor([[147.4610]])\n",
      "[-0.17741682]\n",
      "Mode: Train env_steps 200 total rewards -1119.1735406517982 total energy tensor([[184.7506]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08818442]\n",
      "Mode: Train env_steps 200 total rewards -1081.633307814598 total energy tensor([[172.2950]])\n",
      "[0.60151625]\n",
      "Mode: Train env_steps 200 total rewards -866.1252987086773 total energy tensor([[172.4980]])\n",
      "[0.34545922]\n",
      "Mode: Train env_steps 200 total rewards -1092.242136478424 total energy tensor([[175.3522]])\n",
      "[-0.22218451]\n",
      "Mode: Train env_steps 200 total rewards -743.9127790424973 total energy tensor([[152.3984]])\n",
      "[0.23543017]\n",
      "Mode: Train env_steps 200 total rewards -982.2107108533382 total energy tensor([[178.5007]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97467434]\n",
      "Mode: Train env_steps 200 total rewards -1444.1678144931793 total energy tensor([[180.6819]])\n",
      "[0.41981858]\n",
      "Mode: Train env_steps 200 total rewards -1066.1439584195614 total energy tensor([[182.3563]])\n",
      "[-0.3929492]\n",
      "Mode: Train env_steps 200 total rewards -1079.7349581718445 total energy tensor([[177.3755]])\n",
      "[0.51163554]\n",
      "Mode: Train env_steps 200 total rewards -1542.622974395752 total energy tensor([[174.2968]])\n",
      "[-0.38484854]\n",
      "Mode: Train env_steps 200 total rewards -1092.1098548173904 total energy tensor([[181.5973]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5946007]\n",
      "Mode: Train env_steps 200 total rewards -1130.411458492279 total energy tensor([[183.0643]])\n",
      "[-0.7811984]\n",
      "Mode: Train env_steps 200 total rewards -1061.9798217713833 total energy tensor([[175.8176]])\n",
      "[0.6956826]\n",
      "Mode: Train env_steps 200 total rewards -1538.543122291565 total energy tensor([[169.0441]])\n",
      "[-0.6540252]\n",
      "Mode: Train env_steps 200 total rewards -505.4042468355037 total energy tensor([[143.5876]])\n",
      "[0.92500895]\n",
      "Mode: Train env_steps 200 total rewards -1173.570169389248 total energy tensor([[181.5085]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36113986]\n",
      "Mode: Train env_steps 200 total rewards -1118.398114234209 total energy tensor([[181.0438]])\n",
      "[-0.5202998]\n",
      "Mode: Train env_steps 200 total rewards -1194.5771082639694 total energy tensor([[184.7657]])\n",
      "[0.7058302]\n",
      "Mode: Train env_steps 200 total rewards -748.9024089835584 total energy tensor([[169.3119]])\n",
      "[0.11442358]\n",
      "Mode: Train env_steps 200 total rewards -1238.935749053955 total energy tensor([[184.6293]])\n",
      "[-0.7339291]\n",
      "Mode: Train env_steps 200 total rewards -1093.3919743299484 total energy tensor([[176.0865]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5609893]\n",
      "Mode: Test env_steps 200 total rewards -1228.2480206489563 total energy tensor([[187.1450]])\n",
      "[-0.34628072]\n",
      "Mode: Test env_steps 200 total rewards -1074.3114887475967 total energy tensor([[182.0378]])\n",
      "[-0.33900324]\n",
      "Mode: Test env_steps 200 total rewards -1234.4094574451447 total energy tensor([[187.9047]])\n",
      "[-0.45069394]\n",
      "Mode: Test env_steps 200 total rewards -1477.1292686462402 total energy tensor([[179.2434]])\n",
      "[0.75466806]\n",
      "Mode: Test env_steps 200 total rewards -1538.328709602356 total energy tensor([[171.2002]])\n",
      "[-0.02996522]\n",
      "Mode: Test env_steps 200 total rewards -779.7080541551113 total energy tensor([[176.8655]])\n",
      "[-0.6630319]\n",
      "Mode: Test env_steps 200 total rewards -1322.7438411712646 total energy tensor([[188.1328]])\n",
      "[0.07722199]\n",
      "Mode: Test env_steps 200 total rewards -1112.6316970586777 total energy tensor([[179.0008]])\n",
      "[-0.64368695]\n",
      "Mode: Test env_steps 200 total rewards -1466.7830259799957 total energy tensor([[177.7362]])\n",
      "[-0.33569205]\n",
      "Mode: Test env_steps 200 total rewards -1540.5260276794434 total energy tensor([[174.7114]])\n",
      "145000 -1277.4819591134788\n",
      "[0.8375201]\n",
      "Mode: Train env_steps 200 total rewards -1338.5351932048798 total energy tensor([[186.7987]])\n",
      "[-0.42022663]\n",
      "Mode: Train env_steps 200 total rewards -1280.6904909610748 total energy tensor([[188.1566]])\n",
      "[0.11713081]\n",
      "Mode: Train env_steps 200 total rewards -287.15349375782534 total energy tensor([[132.0357]])\n",
      "[0.76828486]\n",
      "Mode: Train env_steps 200 total rewards -852.7281033471227 total energy tensor([[172.1051]])\n",
      "[0.6433126]\n",
      "Mode: Train env_steps 200 total rewards -855.5754458084702 total energy tensor([[190.0845]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5722869]\n",
      "Mode: Train env_steps 200 total rewards -1554.8606791496277 total energy tensor([[161.7796]])\n",
      "[-0.12695959]\n",
      "Mode: Train env_steps 200 total rewards -1545.9240775108337 total energy tensor([[169.6141]])\n",
      "[-0.89464355]\n",
      "Mode: Train env_steps 200 total rewards -1215.2851479053497 total energy tensor([[187.9601]])\n",
      "[-0.8012832]\n",
      "Mode: Train env_steps 200 total rewards -534.3085175454617 total energy tensor([[152.4087]])\n",
      "[0.34496915]\n",
      "Mode: Train env_steps 200 total rewards -1108.0037237405777 total energy tensor([[186.5151]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:21<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27811244]\n",
      "Mode: Train env_steps 200 total rewards -1049.2070258259773 total energy tensor([[179.5716]])\n",
      "[-0.72152567]\n",
      "Mode: Train env_steps 200 total rewards -400.85924285277724 total energy tensor([[156.9739]])\n",
      "[0.01564918]\n",
      "Mode: Train env_steps 200 total rewards -524.7284728549421 total energy tensor([[160.6775]])\n",
      "[-0.5217555]\n",
      "Mode: Train env_steps 200 total rewards -1309.6179504394531 total energy tensor([[188.3397]])\n",
      "[0.7086849]\n",
      "Mode: Train env_steps 200 total rewards -1079.5861812829971 total energy tensor([[172.5925]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2488411]\n",
      "Mode: Train env_steps 200 total rewards -1202.6314853429794 total energy tensor([[187.9082]])\n",
      "[0.9869289]\n",
      "Mode: Train env_steps 200 total rewards -1172.8912768363953 total energy tensor([[187.5210]])\n",
      "[-0.95281154]\n",
      "Mode: Train env_steps 200 total rewards -1539.059109210968 total energy tensor([[167.5027]])\n",
      "[0.11121329]\n",
      "Mode: Train env_steps 200 total rewards -1083.416196525097 total energy tensor([[187.2979]])\n",
      "[-0.21092433]\n",
      "Mode: Train env_steps 200 total rewards -395.0983277698979 total energy tensor([[122.0491]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:23<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7791627]\n",
      "Mode: Train env_steps 200 total rewards -1135.8246606588364 total energy tensor([[184.1584]])\n",
      "[0.923015]\n",
      "Mode: Train env_steps 200 total rewards -1526.7389450073242 total energy tensor([[163.9826]])\n",
      "[-0.71752846]\n",
      "Mode: Train env_steps 200 total rewards -1301.6881759166718 total energy tensor([[187.5801]])\n",
      "[0.74434906]\n",
      "Mode: Train env_steps 200 total rewards -1474.9567975997925 total energy tensor([[174.2859]])\n",
      "[0.6893187]\n",
      "Mode: Train env_steps 200 total rewards -1151.0193617343903 total energy tensor([[184.9772]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12875211]\n",
      "Mode: Test env_steps 200 total rewards -981.9541702270508 total energy tensor([[186.4376]])\n",
      "[-0.7178625]\n",
      "Mode: Test env_steps 200 total rewards -514.5779809392989 total energy tensor([[155.5427]])\n",
      "[0.11740422]\n",
      "Mode: Test env_steps 200 total rewards -402.82241975329816 total energy tensor([[162.5560]])\n",
      "[-0.8708221]\n",
      "Mode: Test env_steps 200 total rewards -1375.794756412506 total energy tensor([[188.4187]])\n",
      "[0.28874332]\n",
      "Mode: Test env_steps 200 total rewards -1452.5461819171906 total energy tensor([[179.4012]])\n",
      "[-0.2056852]\n",
      "Mode: Test env_steps 200 total rewards -1234.540685415268 total energy tensor([[189.6950]])\n",
      "[0.3791521]\n",
      "Mode: Test env_steps 200 total rewards -1503.7828681468964 total energy tensor([[170.4151]])\n",
      "[0.7523319]\n",
      "Mode: Test env_steps 200 total rewards -1128.3361974954605 total energy tensor([[188.8385]])\n",
      "[0.10701285]\n",
      "Mode: Test env_steps 200 total rewards -1210.2698150873184 total energy tensor([[188.7569]])\n",
      "[-0.1611259]\n",
      "Mode: Test env_steps 200 total rewards -270.7648631562479 total energy tensor([[140.8891]])\n",
      "150000 -1007.5389938550536\n",
      "[0.7417072]\n",
      "Mode: Train env_steps 200 total rewards -1340.485454082489 total energy tensor([[189.0856]])\n",
      "[-0.32065514]\n",
      "Mode: Train env_steps 200 total rewards -944.5491000413895 total energy tensor([[179.3912]])\n",
      "[0.95024824]\n",
      "Mode: Train env_steps 200 total rewards -400.6412298763171 total energy tensor([[162.2557]])\n",
      "[0.6162498]\n",
      "Mode: Train env_steps 200 total rewards -1467.0225830078125 total energy tensor([[176.2154]])\n",
      "[-0.3037304]\n",
      "Mode: Train env_steps 200 total rewards -514.8092294801027 total energy tensor([[153.4200]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:23<00:00,  3.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0757383]\n",
      "Mode: Train env_steps 200 total rewards -966.0026924014091 total energy tensor([[188.7940]])\n",
      "[-0.21958485]\n",
      "Mode: Train env_steps 200 total rewards -521.4225729182363 total energy tensor([[157.3636]])\n",
      "[0.43966946]\n",
      "Mode: Train env_steps 200 total rewards -516.2836780864745 total energy tensor([[160.7978]])\n",
      "[-0.21604222]\n",
      "Mode: Train env_steps 200 total rewards -1521.8242554664612 total energy tensor([[167.7518]])\n",
      "[0.14211592]\n",
      "Mode: Train env_steps 200 total rewards -1133.8726296424866 total energy tensor([[189.1893]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:31<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.27287015]\n",
      "Mode: Train env_steps 200 total rewards -1419.8391015529633 total energy tensor([[183.8979]])\n",
      "[0.5186057]\n",
      "Mode: Train env_steps 200 total rewards -1474.2985637187958 total energy tensor([[178.1362]])\n",
      "[-0.03966216]\n",
      "Mode: Train env_steps 200 total rewards -1405.591845035553 total energy tensor([[185.1209]])\n",
      "[-0.27444836]\n",
      "Mode: Train env_steps 200 total rewards -620.0471767429262 total energy tensor([[160.3992]])\n",
      "[0.21474874]\n",
      "Mode: Train env_steps 200 total rewards -1363.6575412750244 total energy tensor([[189.1998]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:30<00:00,  3.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4030701]\n",
      "Mode: Train env_steps 200 total rewards -381.7929781647399 total energy tensor([[123.9963]])\n",
      "[-0.00092258]\n",
      "Mode: Train env_steps 200 total rewards -1436.4415254592896 total energy tensor([[175.0727]])\n",
      "[0.82405066]\n",
      "Mode: Train env_steps 200 total rewards -389.91492572799325 total energy tensor([[123.7678]])\n",
      "[-0.50841546]\n",
      "Mode: Train env_steps 200 total rewards -1152.9317741394043 total energy tensor([[188.3780]])\n",
      "[0.8029141]\n",
      "Mode: Train env_steps 200 total rewards -1419.760412454605 total energy tensor([[177.0742]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78403956]\n",
      "Mode: Train env_steps 200 total rewards -1305.1147193908691 total energy tensor([[190.8796]])\n",
      "[-0.6088145]\n",
      "Mode: Train env_steps 200 total rewards -918.9660805761814 total energy tensor([[180.9040]])\n",
      "[0.50037414]\n",
      "Mode: Train env_steps 200 total rewards -1504.6715774536133 total energy tensor([[176.6298]])\n",
      "[0.13343017]\n",
      "Mode: Train env_steps 200 total rewards -1210.9822998046875 total energy tensor([[191.3029]])\n",
      "[-0.2997224]\n",
      "Mode: Train env_steps 200 total rewards -1225.191611647606 total energy tensor([[190.4780]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93381196]\n",
      "Mode: Test env_steps 200 total rewards -1061.5924320220947 total energy tensor([[189.7946]])\n",
      "[-0.89942765]\n",
      "Mode: Test env_steps 200 total rewards -911.9305348992348 total energy tensor([[181.4241]])\n",
      "[-0.507781]\n",
      "Mode: Test env_steps 200 total rewards -1517.5121417045593 total energy tensor([[172.8377]])\n",
      "[0.9298905]\n",
      "Mode: Test env_steps 200 total rewards -313.343318358995 total energy tensor([[137.4744]])\n",
      "[0.9810664]\n",
      "Mode: Test env_steps 200 total rewards -1523.749363899231 total energy tensor([[170.7813]])\n",
      "[-0.6880333]\n",
      "Mode: Test env_steps 200 total rewards -1240.088318347931 total energy tensor([[187.9462]])\n",
      "[-0.41610134]\n",
      "Mode: Test env_steps 200 total rewards -950.1242761276662 total energy tensor([[187.9430]])\n",
      "[0.8916967]\n",
      "Mode: Test env_steps 200 total rewards -400.4998486312106 total energy tensor([[146.6366]])\n",
      "[-0.20510323]\n",
      "Mode: Test env_steps 200 total rewards -1407.4988222122192 total energy tensor([[185.7978]])\n",
      "[0.31858343]\n",
      "Mode: Test env_steps 200 total rewards -1118.6743395328522 total energy tensor([[189.5379]])\n",
      "155000 -1044.5013395735994\n",
      "[-0.14425854]\n",
      "Mode: Train env_steps 200 total rewards -506.45466846972704 total energy tensor([[165.9184]])\n",
      "[0.01674027]\n",
      "Mode: Train env_steps 200 total rewards -1093.624984741211 total energy tensor([[189.5727]])\n",
      "[-0.9287272]\n",
      "Mode: Train env_steps 200 total rewards -353.2150456951931 total energy tensor([[127.7735]])\n",
      "[0.33193278]\n",
      "Mode: Train env_steps 200 total rewards -1377.6457152366638 total energy tensor([[189.1482]])\n",
      "[0.43193823]\n",
      "Mode: Train env_steps 200 total rewards -1328.4234976768494 total energy tensor([[190.4755]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31799775]\n",
      "Mode: Train env_steps 200 total rewards -1511.3862147331238 total energy tensor([[177.4641]])\n",
      "[-0.5844324]\n",
      "Mode: Train env_steps 200 total rewards -1460.6362135410309 total energy tensor([[181.6561]])\n",
      "[0.50009954]\n",
      "Mode: Train env_steps 200 total rewards -1453.8988761901855 total energy tensor([[187.3427]])\n",
      "[0.30984184]\n",
      "Mode: Train env_steps 200 total rewards -1520.689459323883 total energy tensor([[175.3484]])\n",
      "[-0.42034385]\n",
      "Mode: Train env_steps 200 total rewards -1466.2660834789276 total energy tensor([[184.0008]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3714377]\n",
      "Mode: Train env_steps 200 total rewards -1410.8223905563354 total energy tensor([[188.1682]])\n",
      "[0.66852415]\n",
      "Mode: Train env_steps 200 total rewards -1193.7662271261215 total energy tensor([[189.2372]])\n",
      "[0.71077394]\n",
      "Mode: Train env_steps 200 total rewards -947.9842092096806 total energy tensor([[190.2592]])\n",
      "[0.41543236]\n",
      "Mode: Train env_steps 200 total rewards -1439.0805559158325 total energy tensor([[182.7225]])\n",
      "[-0.00483453]\n",
      "Mode: Train env_steps 200 total rewards -1442.5204808712006 total energy tensor([[185.3805]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8590372]\n",
      "Mode: Train env_steps 200 total rewards -274.70357150491327 total energy tensor([[152.8816]])\n",
      "[-0.11296197]\n",
      "Mode: Train env_steps 200 total rewards -1486.5089354515076 total energy tensor([[173.4913]])\n",
      "[0.4556002]\n",
      "Mode: Train env_steps 200 total rewards -1429.0775277614594 total energy tensor([[180.5106]])\n",
      "[0.6535967]\n",
      "Mode: Train env_steps 200 total rewards -1317.922644853592 total energy tensor([[189.4299]])\n",
      "[-0.44959015]\n",
      "Mode: Train env_steps 200 total rewards -1278.3963735103607 total energy tensor([[190.0837]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0264931]\n",
      "Mode: Train env_steps 200 total rewards -1220.1462905406952 total energy tensor([[188.8493]])\n",
      "[0.44853404]\n",
      "Mode: Train env_steps 200 total rewards -400.4074572203681 total energy tensor([[157.8411]])\n",
      "[-0.63609564]\n",
      "Mode: Train env_steps 200 total rewards -717.2127091884613 total energy tensor([[192.0350]])\n",
      "[-0.08770315]\n",
      "Mode: Train env_steps 200 total rewards -1018.0152286291122 total energy tensor([[190.2392]])\n",
      "[-0.75249404]\n",
      "Mode: Train env_steps 200 total rewards -1448.2324516773224 total energy tensor([[180.0021]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45042923]\n",
      "Mode: Test env_steps 200 total rewards -395.1153754031984 total energy tensor([[132.4791]])\n",
      "[0.31038666]\n",
      "Mode: Test env_steps 200 total rewards -506.9028127696365 total energy tensor([[150.6171]])\n",
      "[-0.6860284]\n",
      "Mode: Test env_steps 200 total rewards -330.1058350286912 total energy tensor([[125.2883]])\n",
      "[0.895642]\n",
      "Mode: Test env_steps 200 total rewards -1519.0130944252014 total energy tensor([[170.6532]])\n",
      "[-0.7483424]\n",
      "Mode: Test env_steps 200 total rewards -1457.5862245559692 total energy tensor([[182.5416]])\n",
      "[0.5151737]\n",
      "Mode: Test env_steps 200 total rewards -1142.2028105258942 total energy tensor([[189.9755]])\n",
      "[-0.63188344]\n",
      "Mode: Test env_steps 200 total rewards -406.76593286544085 total energy tensor([[153.4893]])\n",
      "[0.31322646]\n",
      "Mode: Test env_steps 200 total rewards -400.6296330578625 total energy tensor([[152.0435]])\n",
      "[-0.27824607]\n",
      "Mode: Test env_steps 200 total rewards -1404.6993680000305 total energy tensor([[189.7190]])\n",
      "[-0.295469]\n",
      "Mode: Test env_steps 200 total rewards -402.7045551985502 total energy tensor([[152.7960]])\n",
      "160000 -796.5725641830475\n",
      "[0.5591795]\n",
      "Mode: Train env_steps 200 total rewards -398.96473044808954 total energy tensor([[134.0400]])\n",
      "[0.01874759]\n",
      "Mode: Train env_steps 200 total rewards -1480.6052808761597 total energy tensor([[177.1989]])\n",
      "[-0.78933346]\n",
      "Mode: Train env_steps 200 total rewards -996.7345463037491 total energy tensor([[181.5376]])\n",
      "[-0.16582145]\n",
      "Mode: Train env_steps 200 total rewards -726.9255631715059 total energy tensor([[192.1586]])\n",
      "[0.16830228]\n",
      "Mode: Train env_steps 200 total rewards -399.2208003969863 total energy tensor([[140.4935]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6177329]\n",
      "Mode: Train env_steps 200 total rewards -1529.0760226249695 total energy tensor([[161.3364]])\n",
      "[0.19666523]\n",
      "Mode: Train env_steps 200 total rewards -1461.1101491451263 total energy tensor([[175.7563]])\n",
      "[-0.2899469]\n",
      "Mode: Train env_steps 200 total rewards -965.7692719995975 total energy tensor([[187.5130]])\n",
      "[-0.42812455]\n",
      "Mode: Train env_steps 200 total rewards -1139.6053931713104 total energy tensor([[186.7015]])\n",
      "[0.5053962]\n",
      "Mode: Train env_steps 200 total rewards -746.4737644530833 total energy tensor([[170.7065]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00553235]\n",
      "Mode: Train env_steps 200 total rewards -1302.0227720737457 total energy tensor([[192.4258]])\n",
      "[-0.19914888]\n",
      "Mode: Train env_steps 200 total rewards -505.76908604055643 total energy tensor([[160.8857]])\n",
      "[0.06009683]\n",
      "Mode: Train env_steps 200 total rewards -1200.593614578247 total energy tensor([[189.3413]])\n",
      "[-0.5675278]\n",
      "Mode: Train env_steps 200 total rewards -1401.8585035800934 total energy tensor([[189.9793]])\n",
      "[0.00737984]\n",
      "Mode: Train env_steps 200 total rewards -1008.508310854435 total energy tensor([[189.7468]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23770478]\n",
      "Mode: Train env_steps 200 total rewards -1427.8855829238892 total energy tensor([[192.3374]])\n",
      "[0.42530426]\n",
      "Mode: Train env_steps 200 total rewards -1166.3156340122223 total energy tensor([[188.9881]])\n",
      "[0.19581065]\n",
      "Mode: Train env_steps 200 total rewards -438.64023746550083 total energy tensor([[128.2773]])\n",
      "[-0.16281746]\n",
      "Mode: Train env_steps 200 total rewards -1043.8362720012665 total energy tensor([[190.1739]])\n",
      "[0.9804702]\n",
      "Mode: Train env_steps 200 total rewards -985.8338121175766 total energy tensor([[190.7841]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29647514]\n",
      "Mode: Train env_steps 200 total rewards -839.9398567974567 total energy tensor([[192.2595]])\n",
      "[-0.04670202]\n",
      "Mode: Train env_steps 200 total rewards -392.55955562274903 total energy tensor([[109.5460]])\n",
      "[0.6081664]\n",
      "Mode: Train env_steps 200 total rewards -273.0245473384857 total energy tensor([[113.8958]])\n",
      "[0.8908281]\n",
      "Mode: Train env_steps 200 total rewards -22.33794660307467 total energy tensor([[143.2599]])\n",
      "[-0.22096108]\n",
      "Mode: Train env_steps 200 total rewards -957.122781932354 total energy tensor([[192.3770]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25429058]\n",
      "Mode: Test env_steps 200 total rewards -1206.6989632844925 total energy tensor([[193.5741]])\n",
      "[0.78507]\n",
      "Mode: Test env_steps 200 total rewards -1283.5887362957 total energy tensor([[193.5650]])\n",
      "[0.18648863]\n",
      "Mode: Test env_steps 200 total rewards -1195.5044862031937 total energy tensor([[193.2990]])\n",
      "[0.8838175]\n",
      "Mode: Test env_steps 200 total rewards -987.0831294059753 total energy tensor([[192.6556]])\n",
      "[0.741817]\n",
      "Mode: Test env_steps 200 total rewards -399.6742730466649 total energy tensor([[135.0186]])\n",
      "[0.7766442]\n",
      "Mode: Test env_steps 200 total rewards -1206.258687376976 total energy tensor([[193.5806]])\n",
      "[-0.7812469]\n",
      "Mode: Test env_steps 200 total rewards -408.19353547878563 total energy tensor([[158.6885]])\n",
      "[-0.1699331]\n",
      "Mode: Test env_steps 200 total rewards -735.402579754591 total energy tensor([[194.5964]])\n",
      "[-0.26142538]\n",
      "Mode: Test env_steps 200 total rewards -1393.2749526500702 total energy tensor([[198.5237]])\n",
      "[0.5673145]\n",
      "Mode: Test env_steps 200 total rewards -404.1497949436307 total energy tensor([[153.2161]])\n",
      "165000 -921.982913844008\n",
      "[-0.47423327]\n",
      "Mode: Train env_steps 200 total rewards -1509.82382106781 total energy tensor([[192.1723]])\n",
      "[-0.9087048]\n",
      "Mode: Train env_steps 200 total rewards -726.4627782553434 total energy tensor([[194.6379]])\n",
      "[-0.6010941]\n",
      "Mode: Train env_steps 200 total rewards -1508.3665490150452 total energy tensor([[192.6902]])\n",
      "[0.8613245]\n",
      "Mode: Train env_steps 200 total rewards -1537.0168056488037 total energy tensor([[191.4362]])\n",
      "[-0.51881623]\n",
      "Mode: Train env_steps 200 total rewards -1058.9741629362106 total energy tensor([[192.7079]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22474745]\n",
      "Mode: Train env_steps 200 total rewards -397.59304747823626 total energy tensor([[145.4266]])\n",
      "[0.9185019]\n",
      "Mode: Train env_steps 200 total rewards -1528.779733657837 total energy tensor([[182.7434]])\n",
      "[0.42197117]\n",
      "Mode: Train env_steps 200 total rewards -400.93359159165993 total energy tensor([[149.8141]])\n",
      "[0.06575507]\n",
      "Mode: Train env_steps 200 total rewards -1239.757744550705 total energy tensor([[189.3209]])\n",
      "[-0.01816796]\n",
      "Mode: Train env_steps 200 total rewards -1204.6572136878967 total energy tensor([[189.6622]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29263034]\n",
      "Mode: Train env_steps 200 total rewards -416.1495076324791 total energy tensor([[146.6394]])\n",
      "[-0.8029672]\n",
      "Mode: Train env_steps 200 total rewards -269.75604216428474 total energy tensor([[127.3455]])\n",
      "[-0.3522392]\n",
      "Mode: Train env_steps 200 total rewards -400.8089530887082 total energy tensor([[141.2137]])\n",
      "[0.4119794]\n",
      "Mode: Train env_steps 200 total rewards -406.2699087103829 total energy tensor([[142.1705]])\n",
      "[0.5764028]\n",
      "Mode: Train env_steps 200 total rewards -398.60206837486476 total energy tensor([[140.6054]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88959163]\n",
      "Mode: Train env_steps 200 total rewards -461.95923155732453 total energy tensor([[151.6528]])\n",
      "[-0.35692644]\n",
      "Mode: Train env_steps 200 total rewards -1124.3705540895462 total energy tensor([[189.0627]])\n",
      "[-0.01422258]\n",
      "Mode: Train env_steps 200 total rewards -1508.5214018821716 total energy tensor([[186.9934]])\n",
      "[0.41257012]\n",
      "Mode: Train env_steps 200 total rewards -247.7232872673776 total energy tensor([[134.5007]])\n",
      "[-0.30378294]\n",
      "Mode: Train env_steps 200 total rewards -405.23889174871147 total energy tensor([[156.2630]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32250458]\n",
      "Mode: Train env_steps 200 total rewards -443.74799304641783 total energy tensor([[156.9581]])\n",
      "[-0.01101935]\n",
      "Mode: Train env_steps 200 total rewards -1016.7556113600731 total energy tensor([[179.7983]])\n",
      "[0.91969556]\n",
      "Mode: Train env_steps 200 total rewards -1487.3423840999603 total energy tensor([[177.5976]])\n",
      "[-0.10326119]\n",
      "Mode: Train env_steps 200 total rewards -1543.7966327667236 total energy tensor([[178.1848]])\n",
      "[0.7175667]\n",
      "Mode: Train env_steps 200 total rewards -1104.8035308122635 total energy tensor([[188.7170]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5048967]\n",
      "Mode: Test env_steps 200 total rewards -390.9953732378781 total energy tensor([[136.1947]])\n",
      "[0.6024732]\n",
      "Mode: Test env_steps 200 total rewards -1533.2971482276917 total energy tensor([[188.9347]])\n",
      "[-0.46104625]\n",
      "Mode: Test env_steps 200 total rewards -1532.278064250946 total energy tensor([[189.1748]])\n",
      "[0.74026996]\n",
      "Mode: Test env_steps 200 total rewards -1360.9994449615479 total energy tensor([[189.3898]])\n",
      "[-0.87477773]\n",
      "Mode: Test env_steps 200 total rewards -258.2066607326269 total energy tensor([[174.1828]])\n",
      "[0.9676059]\n",
      "Mode: Test env_steps 200 total rewards -1517.8234643936157 total energy tensor([[188.2220]])\n",
      "[-0.07332326]\n",
      "Mode: Test env_steps 200 total rewards -1342.981896162033 total energy tensor([[190.5308]])\n",
      "[0.56739527]\n",
      "Mode: Test env_steps 200 total rewards -1528.6470589637756 total energy tensor([[184.4250]])\n",
      "[-0.35488564]\n",
      "Mode: Test env_steps 200 total rewards -147.9418757451931 total energy tensor([[118.1535]])\n",
      "[-0.89193505]\n",
      "Mode: Test env_steps 200 total rewards -1535.955241203308 total energy tensor([[185.7362]])\n",
      "170000 -1114.9126227878617\n",
      "[-0.29668015]\n",
      "Mode: Train env_steps 200 total rewards -773.0184648931026 total energy tensor([[192.5316]])\n",
      "[0.8061734]\n",
      "Mode: Train env_steps 200 total rewards -235.0025503047509 total energy tensor([[131.5493]])\n",
      "[0.4261166]\n",
      "Mode: Train env_steps 200 total rewards -955.0533665418625 total energy tensor([[190.2730]])\n",
      "[0.8785437]\n",
      "Mode: Train env_steps 200 total rewards -397.9054035404697 total energy tensor([[143.6418]])\n",
      "[-0.40463847]\n",
      "Mode: Train env_steps 200 total rewards -397.3275316786021 total energy tensor([[146.2029]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41375738]\n",
      "Mode: Train env_steps 200 total rewards -1530.9520993232727 total energy tensor([[171.5142]])\n",
      "[-0.41910484]\n",
      "Mode: Train env_steps 200 total rewards -725.1317854248919 total energy tensor([[165.9195]])\n",
      "[0.11255928]\n",
      "Mode: Train env_steps 200 total rewards -989.7516286373138 total energy tensor([[177.9005]])\n",
      "[-0.86037046]\n",
      "Mode: Train env_steps 200 total rewards -964.5474735945463 total energy tensor([[186.7746]])\n",
      "[0.85040975]\n",
      "Mode: Train env_steps 200 total rewards -962.319288611412 total energy tensor([[187.8160]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.287101]\n",
      "Mode: Train env_steps 200 total rewards -1221.2088140249252 total energy tensor([[187.9517]])\n",
      "[-0.8142284]\n",
      "Mode: Train env_steps 200 total rewards -726.3273221477866 total energy tensor([[190.1452]])\n",
      "[-0.9332471]\n",
      "Mode: Train env_steps 200 total rewards -400.63616813905537 total energy tensor([[147.7374]])\n",
      "[0.6643533]\n",
      "Mode: Train env_steps 200 total rewards -1524.6852822303772 total energy tensor([[176.0979]])\n",
      "[0.3042787]\n",
      "Mode: Train env_steps 200 total rewards -925.2312095761299 total energy tensor([[180.6873]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7612385]\n",
      "Mode: Train env_steps 200 total rewards -1527.2502083778381 total energy tensor([[191.1472]])\n",
      "[0.65214956]\n",
      "Mode: Train env_steps 200 total rewards -1098.0956156253815 total energy tensor([[190.7131]])\n",
      "[0.39866528]\n",
      "Mode: Train env_steps 200 total rewards -1217.3799458742142 total energy tensor([[190.3375]])\n",
      "[0.2064641]\n",
      "Mode: Train env_steps 200 total rewards -1540.321171283722 total energy tensor([[189.5517]])\n",
      "[0.4352824]\n",
      "Mode: Train env_steps 200 total rewards -1212.3703875541687 total energy tensor([[191.0240]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81921375]\n",
      "Mode: Train env_steps 200 total rewards -1017.495588183403 total energy tensor([[184.7555]])\n",
      "[0.1723309]\n",
      "Mode: Train env_steps 200 total rewards -1445.6728954315186 total energy tensor([[196.7163]])\n",
      "[0.708632]\n",
      "Mode: Train env_steps 200 total rewards -401.143414396327 total energy tensor([[145.1123]])\n",
      "[-0.767268]\n",
      "Mode: Train env_steps 200 total rewards -1216.9547650814056 total energy tensor([[191.4341]])\n",
      "[0.68956095]\n",
      "Mode: Train env_steps 200 total rewards -847.7290331721306 total energy tensor([[190.6603]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:17<00:00,  3.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00975672]\n",
      "Mode: Test env_steps 200 total rewards -378.78535725548863 total energy tensor([[145.6579]])\n",
      "[-0.7032145]\n",
      "Mode: Test env_steps 200 total rewards -1503.387140750885 total energy tensor([[181.6880]])\n",
      "[0.21659987]\n",
      "Mode: Test env_steps 200 total rewards -398.5120855960995 total energy tensor([[140.2339]])\n",
      "[0.5167978]\n",
      "Mode: Test env_steps 200 total rewards -510.7544767539948 total energy tensor([[132.5315]])\n",
      "[0.9890047]\n",
      "Mode: Test env_steps 200 total rewards -398.60232859198004 total energy tensor([[143.5456]])\n",
      "[0.50524217]\n",
      "Mode: Test env_steps 200 total rewards -398.8853027415462 total energy tensor([[137.1901]])\n",
      "[-0.5049511]\n",
      "Mode: Test env_steps 200 total rewards -503.6837106840685 total energy tensor([[133.1552]])\n",
      "[-0.61492527]\n",
      "Mode: Test env_steps 200 total rewards -410.92066316958517 total energy tensor([[146.9533]])\n",
      "[0.10449971]\n",
      "Mode: Test env_steps 200 total rewards -1297.6990706920624 total energy tensor([[191.7618]])\n",
      "[-0.2825437]\n",
      "Mode: Test env_steps 200 total rewards -384.9014959130436 total energy tensor([[149.2400]])\n",
      "175000 -618.6131632148754\n",
      "[-0.23882319]\n",
      "Mode: Train env_steps 200 total rewards -1482.2944192886353 total energy tensor([[182.5985]])\n",
      "[-0.78542024]\n",
      "Mode: Train env_steps 200 total rewards -397.9947196226567 total energy tensor([[139.8880]])\n",
      "[0.19120556]\n",
      "Mode: Train env_steps 200 total rewards -1146.285649895668 total energy tensor([[191.0879]])\n",
      "[0.88983417]\n",
      "Mode: Train env_steps 200 total rewards -1442.7444438934326 total energy tensor([[189.9731]])\n",
      "[0.9884581]\n",
      "Mode: Train env_steps 200 total rewards -288.4519318579696 total energy tensor([[155.6220]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1572991]\n",
      "Mode: Train env_steps 200 total rewards -945.4787305891514 total energy tensor([[191.9496]])\n",
      "[0.27963352]\n",
      "Mode: Train env_steps 200 total rewards -420.2262143269181 total energy tensor([[120.9042]])\n",
      "[0.35651898]\n",
      "Mode: Train env_steps 200 total rewards -1363.7332499027252 total energy tensor([[194.5060]])\n",
      "[0.2093975]\n",
      "Mode: Train env_steps 200 total rewards -408.67085572332144 total energy tensor([[124.0091]])\n",
      "[-0.58819354]\n",
      "Mode: Train env_steps 200 total rewards -1517.702754020691 total energy tensor([[194.9367]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4943327]\n",
      "Mode: Train env_steps 200 total rewards -1496.611198425293 total energy tensor([[191.4980]])\n",
      "[-0.18406913]\n",
      "Mode: Train env_steps 200 total rewards -1357.6168005466461 total energy tensor([[196.3471]])\n",
      "[-0.29289296]\n",
      "Mode: Train env_steps 200 total rewards -1339.3771982192993 total energy tensor([[194.9117]])\n",
      "[-0.7249926]\n",
      "Mode: Train env_steps 200 total rewards -1535.0966753959656 total energy tensor([[192.3954]])\n",
      "[0.4976764]\n",
      "Mode: Train env_steps 200 total rewards -1502.1428360939026 total energy tensor([[193.1764]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2576083]\n",
      "Mode: Train env_steps 200 total rewards -547.0865812045522 total energy tensor([[161.6591]])\n",
      "[-0.3055675]\n",
      "Mode: Train env_steps 200 total rewards -1493.3083424568176 total energy tensor([[194.2231]])\n",
      "[0.2143451]\n",
      "Mode: Train env_steps 200 total rewards -1393.9371485710144 total energy tensor([[197.4740]])\n",
      "[0.27022237]\n",
      "Mode: Train env_steps 200 total rewards -973.0008088946342 total energy tensor([[192.5711]])\n",
      "[0.9534617]\n",
      "Mode: Train env_steps 200 total rewards -654.6892998963594 total energy tensor([[138.2497]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98667794]\n",
      "Mode: Train env_steps 200 total rewards -1460.1494889259338 total energy tensor([[188.5561]])\n",
      "[-0.80913764]\n",
      "Mode: Train env_steps 200 total rewards -1524.8988819122314 total energy tensor([[193.6530]])\n",
      "[-0.10246198]\n",
      "Mode: Train env_steps 200 total rewards -419.60929535515606 total energy tensor([[149.2351]])\n",
      "[-0.3324226]\n",
      "Mode: Train env_steps 200 total rewards -406.4468646440655 total energy tensor([[154.4548]])\n",
      "[-0.17483206]\n",
      "Mode: Train env_steps 200 total rewards -1351.4647438526154 total energy tensor([[193.2747]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14053446]\n",
      "Mode: Test env_steps 200 total rewards -1427.1365139484406 total energy tensor([[193.5816]])\n",
      "[-0.01626278]\n",
      "Mode: Test env_steps 200 total rewards -1518.4708285331726 total energy tensor([[187.4149]])\n",
      "[0.9511873]\n",
      "Mode: Test env_steps 200 total rewards -614.7891249582171 total energy tensor([[185.1685]])\n",
      "[-0.5284602]\n",
      "Mode: Test env_steps 200 total rewards -1400.44016623497 total energy tensor([[194.0062]])\n",
      "[-0.5367706]\n",
      "Mode: Test env_steps 200 total rewards -400.2376457368955 total energy tensor([[141.5030]])\n",
      "[0.14662215]\n",
      "Mode: Test env_steps 200 total rewards -400.85702685266733 total energy tensor([[147.5069]])\n",
      "[-0.9941929]\n",
      "Mode: Test env_steps 200 total rewards -1191.1940581798553 total energy tensor([[189.1569]])\n",
      "[0.04654205]\n",
      "Mode: Test env_steps 200 total rewards -294.4881049981341 total energy tensor([[139.5217]])\n",
      "[-0.20414528]\n",
      "Mode: Test env_steps 200 total rewards -1373.8794331550598 total energy tensor([[195.4173]])\n",
      "[0.33385235]\n",
      "Mode: Test env_steps 200 total rewards -268.0850589601323 total energy tensor([[118.7097]])\n",
      "180000 -888.9577961557545\n",
      "[-0.47203425]\n",
      "Mode: Train env_steps 200 total rewards -854.2657947838306 total energy tensor([[190.8431]])\n",
      "[-0.28021327]\n",
      "Mode: Train env_steps 200 total rewards -269.2518492070958 total energy tensor([[122.6300]])\n",
      "[0.9776849]\n",
      "Mode: Train env_steps 200 total rewards -1150.3386067152023 total energy tensor([[191.2156]])\n",
      "[-0.921111]\n",
      "Mode: Train env_steps 200 total rewards -398.9824937386438 total energy tensor([[135.0434]])\n",
      "[0.7901611]\n",
      "Mode: Train env_steps 200 total rewards -1500.9303050041199 total energy tensor([[192.6875]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13191459]\n",
      "Mode: Train env_steps 200 total rewards -875.5854222178459 total energy tensor([[192.4639]])\n",
      "[-0.74534106]\n",
      "Mode: Train env_steps 200 total rewards -27.96855591982603 total energy tensor([[168.8719]])\n",
      "[-0.6353184]\n",
      "Mode: Train env_steps 200 total rewards -1217.5129400491714 total energy tensor([[190.1139]])\n",
      "[0.18168823]\n",
      "Mode: Train env_steps 200 total rewards -394.4716692036018 total energy tensor([[124.4689]])\n",
      "[0.58691204]\n",
      "Mode: Train env_steps 200 total rewards -1523.3768410682678 total energy tensor([[191.2066]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59096026]\n",
      "Mode: Train env_steps 200 total rewards -1200.1376115083694 total energy tensor([[189.1684]])\n",
      "[-0.87319726]\n",
      "Mode: Train env_steps 200 total rewards -946.9387748241425 total energy tensor([[183.2317]])\n",
      "[-0.7365908]\n",
      "Mode: Train env_steps 200 total rewards -1497.2909336090088 total energy tensor([[195.2350]])\n",
      "[0.65876687]\n",
      "Mode: Train env_steps 200 total rewards -1510.1447701454163 total energy tensor([[193.5918]])\n",
      "[0.8827276]\n",
      "Mode: Train env_steps 200 total rewards -398.45870849490166 total energy tensor([[137.5892]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31237864]\n",
      "Mode: Train env_steps 200 total rewards -1504.5527429580688 total energy tensor([[187.2584]])\n",
      "[-0.05528984]\n",
      "Mode: Train env_steps 200 total rewards -1507.4855198860168 total energy tensor([[186.5266]])\n",
      "[-0.39770108]\n",
      "Mode: Train env_steps 200 total rewards -1528.2604975700378 total energy tensor([[187.9576]])\n",
      "[-0.19306579]\n",
      "Mode: Train env_steps 200 total rewards -500.38360737264156 total energy tensor([[187.3315]])\n",
      "[-0.58205134]\n",
      "Mode: Train env_steps 200 total rewards -1220.5090789794922 total energy tensor([[189.5854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62149686]\n",
      "Mode: Train env_steps 200 total rewards -1188.003442287445 total energy tensor([[187.3690]])\n",
      "[-0.23779748]\n",
      "Mode: Train env_steps 200 total rewards -1540.4557967185974 total energy tensor([[187.9917]])\n",
      "[0.7769665]\n",
      "Mode: Train env_steps 200 total rewards -396.7601252393797 total energy tensor([[118.7830]])\n",
      "[-0.07284282]\n",
      "Mode: Train env_steps 200 total rewards -1482.352102279663 total energy tensor([[187.2775]])\n",
      "[-0.4935116]\n",
      "Mode: Train env_steps 200 total rewards -1522.9160356521606 total energy tensor([[192.2387]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41788274]\n",
      "Mode: Test env_steps 200 total rewards -266.8109787136782 total energy tensor([[101.7803]])\n",
      "[-0.4166038]\n",
      "Mode: Test env_steps 200 total rewards -385.2856610022718 total energy tensor([[115.5823]])\n",
      "[-0.17634398]\n",
      "Mode: Test env_steps 200 total rewards -1517.4225277900696 total energy tensor([[189.1107]])\n",
      "[0.9331683]\n",
      "Mode: Test env_steps 200 total rewards -1437.439125776291 total energy tensor([[185.4517]])\n",
      "[0.30190113]\n",
      "Mode: Test env_steps 200 total rewards -1367.9210381507874 total energy tensor([[190.3507]])\n",
      "[-0.66062695]\n",
      "Mode: Test env_steps 200 total rewards -393.25475322222337 total energy tensor([[127.5584]])\n",
      "[-0.18863896]\n",
      "Mode: Test env_steps 200 total rewards -1525.91028881073 total energy tensor([[187.9686]])\n",
      "[-0.72689635]\n",
      "Mode: Test env_steps 200 total rewards -393.6461180606857 total energy tensor([[117.7867]])\n",
      "[0.31150496]\n",
      "Mode: Test env_steps 200 total rewards -843.7543337345123 total energy tensor([[192.0779]])\n",
      "[-0.8100792]\n",
      "Mode: Test env_steps 200 total rewards -1339.582501411438 total energy tensor([[188.3898]])\n",
      "185000 -947.1027326672687\n",
      "[0.15704204]\n",
      "Mode: Train env_steps 200 total rewards -391.9479974000715 total energy tensor([[127.1067]])\n",
      "[-0.50515395]\n",
      "Mode: Train env_steps 200 total rewards -398.39626145595685 total energy tensor([[133.9371]])\n",
      "[0.26316074]\n",
      "Mode: Train env_steps 200 total rewards -1532.526512145996 total energy tensor([[191.1315]])\n",
      "[0.77544516]\n",
      "Mode: Train env_steps 200 total rewards -388.2710940117249 total energy tensor([[127.4463]])\n",
      "[-0.4603521]\n",
      "Mode: Train env_steps 200 total rewards -1325.2540545463562 total energy tensor([[188.6748]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5520527]\n",
      "Mode: Train env_steps 200 total rewards -1183.8253427743912 total energy tensor([[189.3435]])\n",
      "[-0.2897266]\n",
      "Mode: Train env_steps 200 total rewards -1523.6873540878296 total energy tensor([[191.1942]])\n",
      "[0.48931265]\n",
      "Mode: Train env_steps 200 total rewards -531.3834625184536 total energy tensor([[136.5848]])\n",
      "[-0.984667]\n",
      "Mode: Train env_steps 200 total rewards -1531.134108543396 total energy tensor([[194.5033]])\n",
      "[0.40079084]\n",
      "Mode: Train env_steps 200 total rewards -408.6462581604719 total energy tensor([[137.6296]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27181527]\n",
      "Mode: Train env_steps 200 total rewards -401.27437965758145 total energy tensor([[136.4940]])\n",
      "[-0.2307828]\n",
      "Mode: Train env_steps 200 total rewards -294.78051495412365 total energy tensor([[108.1570]])\n",
      "[0.07190905]\n",
      "Mode: Train env_steps 200 total rewards -1312.0793101787567 total energy tensor([[189.1208]])\n",
      "[-0.47529984]\n",
      "Mode: Train env_steps 200 total rewards -989.0316091775894 total energy tensor([[189.4209]])\n",
      "[-0.60108405]\n",
      "Mode: Train env_steps 200 total rewards -1428.4086594581604 total energy tensor([[183.8061]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6316574]\n",
      "Mode: Train env_steps 200 total rewards -1082.5999376773834 total energy tensor([[189.8819]])\n",
      "[-0.43154213]\n",
      "Mode: Train env_steps 200 total rewards -397.2598519809544 total energy tensor([[110.1049]])\n",
      "[0.37352684]\n",
      "Mode: Train env_steps 200 total rewards -512.5160342808813 total energy tensor([[119.0554]])\n",
      "[0.70629376]\n",
      "Mode: Train env_steps 200 total rewards -1183.6265305280685 total energy tensor([[188.5735]])\n",
      "[0.7189105]\n",
      "Mode: Train env_steps 200 total rewards -1151.049573302269 total energy tensor([[189.1319]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00097209]\n",
      "Mode: Train env_steps 200 total rewards -1225.781601190567 total energy tensor([[188.9773]])\n",
      "[0.17417762]\n",
      "Mode: Train env_steps 200 total rewards -725.7137969732285 total energy tensor([[193.8991]])\n",
      "[-0.6097571]\n",
      "Mode: Train env_steps 200 total rewards -525.9797847960144 total energy tensor([[150.6603]])\n",
      "[-0.11277992]\n",
      "Mode: Train env_steps 200 total rewards -652.4073321372271 total energy tensor([[140.2146]])\n",
      "[0.5041601]\n",
      "Mode: Train env_steps 200 total rewards -1474.223014831543 total energy tensor([[190.6021]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39513764]\n",
      "Mode: Test env_steps 200 total rewards -529.4237429015338 total energy tensor([[138.3095]])\n",
      "[0.07489571]\n",
      "Mode: Test env_steps 200 total rewards -530.5640744380653 total energy tensor([[144.1017]])\n",
      "[-0.19101845]\n",
      "Mode: Test env_steps 200 total rewards -405.3743040333502 total energy tensor([[138.7851]])\n",
      "[0.79207414]\n",
      "Mode: Test env_steps 200 total rewards -1518.1014819145203 total energy tensor([[185.9585]])\n",
      "[-0.8619571]\n",
      "Mode: Test env_steps 200 total rewards -508.4963816762902 total energy tensor([[156.3243]])\n",
      "[0.6463478]\n",
      "Mode: Test env_steps 200 total rewards -1412.917700767517 total energy tensor([[190.8916]])\n",
      "[0.7292722]\n",
      "Mode: Test env_steps 200 total rewards -1097.6424449682236 total energy tensor([[190.7541]])\n",
      "[-0.38561216]\n",
      "Mode: Test env_steps 200 total rewards -868.7546707093716 total energy tensor([[188.4716]])\n",
      "[-0.5718904]\n",
      "Mode: Test env_steps 200 total rewards -1517.7110342979431 total energy tensor([[192.5227]])\n",
      "[0.17648602]\n",
      "Mode: Test env_steps 200 total rewards -1533.7882471084595 total energy tensor([[192.1253]])\n",
      "190000 -992.2774082815274\n",
      "[0.5235661]\n",
      "Mode: Train env_steps 200 total rewards -529.2879675123841 total energy tensor([[139.1507]])\n",
      "[0.06795302]\n",
      "Mode: Train env_steps 200 total rewards -950.2007393240929 total energy tensor([[190.2987]])\n",
      "[-0.02043283]\n",
      "Mode: Train env_steps 200 total rewards -955.2696576714516 total energy tensor([[189.6586]])\n",
      "[0.0569131]\n",
      "Mode: Train env_steps 200 total rewards -527.6562131345272 total energy tensor([[142.9106]])\n",
      "[-0.5023927]\n",
      "Mode: Train env_steps 200 total rewards -954.2485564947128 total energy tensor([[190.8612]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9593042]\n",
      "Mode: Train env_steps 200 total rewards -1204.283170223236 total energy tensor([[187.9801]])\n",
      "[0.6778627]\n",
      "Mode: Train env_steps 200 total rewards -866.3439771831036 total energy tensor([[182.6848]])\n",
      "[0.4102419]\n",
      "Mode: Train env_steps 200 total rewards -958.4842234179378 total energy tensor([[187.6533]])\n",
      "[0.31279072]\n",
      "Mode: Train env_steps 200 total rewards -904.8021459281445 total energy tensor([[182.3117]])\n",
      "[-0.8577432]\n",
      "Mode: Train env_steps 200 total rewards -397.937505324604 total energy tensor([[123.8905]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5064446]\n",
      "Mode: Train env_steps 200 total rewards -267.5579650583677 total energy tensor([[118.5792]])\n",
      "[0.89359266]\n",
      "Mode: Train env_steps 200 total rewards -1452.590812921524 total energy tensor([[186.7387]])\n",
      "[0.08871579]\n",
      "Mode: Train env_steps 200 total rewards -490.22503177588806 total energy tensor([[144.0978]])\n",
      "[0.08383466]\n",
      "Mode: Train env_steps 200 total rewards -839.1588313877583 total energy tensor([[191.7017]])\n",
      "[-0.3631237]\n",
      "Mode: Train env_steps 200 total rewards -1194.5783021450043 total energy tensor([[188.6791]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8595236]\n",
      "Mode: Train env_steps 200 total rewards -1510.2348771095276 total energy tensor([[193.2102]])\n",
      "[-0.35574877]\n",
      "Mode: Train env_steps 200 total rewards -1280.3579969406128 total energy tensor([[187.4982]])\n",
      "[-0.18192656]\n",
      "Mode: Train env_steps 200 total rewards -966.226655125618 total energy tensor([[190.8483]])\n",
      "[0.732673]\n",
      "Mode: Train env_steps 200 total rewards -1519.8609528541565 total energy tensor([[188.5281]])\n",
      "[0.4871447]\n",
      "Mode: Train env_steps 200 total rewards -942.8325902819633 total energy tensor([[190.4405]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4937318]\n",
      "Mode: Train env_steps 200 total rewards -1510.6468176841736 total energy tensor([[195.1996]])\n",
      "[-0.85127985]\n",
      "Mode: Train env_steps 200 total rewards -1467.3252530097961 total energy tensor([[193.3865]])\n",
      "[0.5888845]\n",
      "Mode: Train env_steps 200 total rewards -667.762975522317 total energy tensor([[135.1579]])\n",
      "[-0.1952128]\n",
      "Mode: Train env_steps 200 total rewards -722.0479843914509 total energy tensor([[139.8895]])\n",
      "[-0.5498623]\n",
      "Mode: Train env_steps 200 total rewards -662.6778649482876 total energy tensor([[133.6801]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08276951]\n",
      "Mode: Test env_steps 200 total rewards -317.1368951559998 total energy tensor([[141.8316]])\n",
      "[0.34834403]\n",
      "Mode: Test env_steps 200 total rewards -987.8335001468658 total energy tensor([[178.5496]])\n",
      "[0.5159606]\n",
      "Mode: Test env_steps 200 total rewards -1342.3192846775055 total energy tensor([[190.9338]])\n",
      "[0.714573]\n",
      "Mode: Test env_steps 200 total rewards -995.0442489981651 total energy tensor([[188.6115]])\n",
      "[-0.7711554]\n",
      "Mode: Test env_steps 200 total rewards -1074.3477063775063 total energy tensor([[180.3172]])\n",
      "[-0.50907916]\n",
      "Mode: Test env_steps 200 total rewards -988.6148574352264 total energy tensor([[190.1483]])\n",
      "[0.10140134]\n",
      "Mode: Test env_steps 200 total rewards -1538.5742192268372 total energy tensor([[185.0350]])\n",
      "[0.96325374]\n",
      "Mode: Test env_steps 200 total rewards -1082.1046409606934 total energy tensor([[182.8926]])\n",
      "[0.73480684]\n",
      "Mode: Test env_steps 200 total rewards -1415.9363143444061 total energy tensor([[190.3313]])\n",
      "[-0.49874845]\n",
      "Mode: Test env_steps 200 total rewards -1533.0781631469727 total energy tensor([[189.0747]])\n",
      "195000 -1127.4989830470179\n",
      "[-0.6295933]\n",
      "Mode: Train env_steps 200 total rewards -271.60136922230595 total energy tensor([[114.8435]])\n",
      "[-0.02144636]\n",
      "Mode: Train env_steps 200 total rewards -1062.720457315445 total energy tensor([[188.6270]])\n",
      "[0.15110719]\n",
      "Mode: Train env_steps 200 total rewards -1206.9020916223526 total energy tensor([[188.9480]])\n",
      "[-0.5111758]\n",
      "Mode: Train env_steps 200 total rewards -1023.5748224258423 total energy tensor([[178.6064]])\n",
      "[-0.81188685]\n",
      "Mode: Train env_steps 200 total rewards -153.12844718713313 total energy tensor([[129.3861]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69171304]\n",
      "Mode: Train env_steps 200 total rewards -1532.2699618339539 total energy tensor([[184.7555]])\n",
      "[-0.17502376]\n",
      "Mode: Train env_steps 200 total rewards -890.3371805548668 total energy tensor([[181.2087]])\n",
      "[-0.29604793]\n",
      "Mode: Train env_steps 200 total rewards -1400.5911085605621 total energy tensor([[188.9140]])\n",
      "[-0.860745]\n",
      "Mode: Train env_steps 200 total rewards -1204.6965981721878 total energy tensor([[187.2560]])\n",
      "[-0.4476658]\n",
      "Mode: Train env_steps 200 total rewards -406.7565090954304 total energy tensor([[140.7930]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5975771]\n",
      "Mode: Train env_steps 200 total rewards -375.2362972823903 total energy tensor([[135.6195]])\n",
      "[0.08248572]\n",
      "Mode: Train env_steps 200 total rewards -1520.4307284355164 total energy tensor([[191.0687]])\n",
      "[0.70784825]\n",
      "Mode: Train env_steps 200 total rewards -1181.3442071676254 total energy tensor([[188.5548]])\n",
      "[-0.89780617]\n",
      "Mode: Train env_steps 200 total rewards -751.7525714337826 total energy tensor([[191.0545]])\n",
      "[-0.22413856]\n",
      "Mode: Train env_steps 200 total rewards -1033.5561038851738 total energy tensor([[190.9132]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17996153]\n",
      "Mode: Train env_steps 200 total rewards -498.5804516961798 total energy tensor([[147.6859]])\n",
      "[0.52388924]\n",
      "Mode: Train env_steps 200 total rewards -1543.4382376670837 total energy tensor([[181.0460]])\n",
      "[0.6520076]\n",
      "Mode: Train env_steps 200 total rewards -1507.3782272338867 total energy tensor([[186.6667]])\n",
      "[0.28619727]\n",
      "Mode: Train env_steps 200 total rewards -1477.3769345283508 total energy tensor([[185.2572]])\n",
      "[-0.40838644]\n",
      "Mode: Train env_steps 200 total rewards -960.3112863302231 total energy tensor([[190.1928]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.97581416]\n",
      "Mode: Train env_steps 200 total rewards -1376.7385845184326 total energy tensor([[187.1149]])\n",
      "[0.97542036]\n",
      "Mode: Train env_steps 200 total rewards -1217.2178211212158 total energy tensor([[186.4835]])\n",
      "[-0.601726]\n",
      "Mode: Train env_steps 200 total rewards -399.6408801143989 total energy tensor([[132.7072]])\n",
      "[0.9547978]\n",
      "Mode: Train env_steps 200 total rewards -521.5404568389058 total energy tensor([[145.9281]])\n",
      "[-0.57231385]\n",
      "Mode: Train env_steps 200 total rewards -956.738273113966 total energy tensor([[187.3133]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8713745]\n",
      "Mode: Test env_steps 200 total rewards -401.0477791503072 total energy tensor([[133.6922]])\n",
      "[-0.70376354]\n",
      "Mode: Test env_steps 200 total rewards -420.8950489535928 total energy tensor([[134.3497]])\n",
      "[-0.78893733]\n",
      "Mode: Test env_steps 200 total rewards -392.8467667326331 total energy tensor([[135.7982]])\n",
      "[0.5047731]\n",
      "Mode: Test env_steps 200 total rewards -403.260246315971 total energy tensor([[139.9290]])\n",
      "[0.09735343]\n",
      "Mode: Test env_steps 200 total rewards -1308.3907189369202 total energy tensor([[190.8420]])\n",
      "[-0.8186057]\n",
      "Mode: Test env_steps 200 total rewards -1501.589490890503 total energy tensor([[186.4749]])\n",
      "[0.56514364]\n",
      "Mode: Test env_steps 200 total rewards -1445.5517070293427 total energy tensor([[185.7106]])\n",
      "[-0.07251404]\n",
      "Mode: Test env_steps 200 total rewards -521.9058192707598 total energy tensor([[137.4756]])\n",
      "[-0.9546573]\n",
      "Mode: Test env_steps 200 total rewards -964.8713151216507 total energy tensor([[188.4254]])\n",
      "[0.27605158]\n",
      "Mode: Test env_steps 200 total rewards -401.9467250108719 total energy tensor([[136.9610]])\n",
      "200000 -776.2305617412552\n",
      "[-0.5950712]\n",
      "Mode: Train env_steps 200 total rewards -192.24090250837617 total energy tensor([[118.8836]])\n",
      "[-0.5413809]\n",
      "Mode: Train env_steps 200 total rewards -266.2740311785601 total energy tensor([[101.3893]])\n",
      "[-0.9275826]\n",
      "Mode: Train env_steps 200 total rewards -401.32405460625887 total energy tensor([[142.6895]])\n",
      "[-0.42982554]\n",
      "Mode: Train env_steps 200 total rewards -1396.9771003723145 total energy tensor([[189.4451]])\n",
      "[0.6045784]\n",
      "Mode: Train env_steps 200 total rewards -1493.1084055900574 total energy tensor([[186.8518]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46470284]\n",
      "Mode: Train env_steps 200 total rewards -395.8622450828552 total energy tensor([[128.6707]])\n",
      "[0.8798128]\n",
      "Mode: Train env_steps 200 total rewards -1479.5242347717285 total energy tensor([[183.2085]])\n",
      "[0.6903854]\n",
      "Mode: Train env_steps 200 total rewards -403.08769910410047 total energy tensor([[131.1689]])\n",
      "[0.617077]\n",
      "Mode: Train env_steps 200 total rewards -1005.2305601835251 total energy tensor([[189.5739]])\n",
      "[0.79404706]\n",
      "Mode: Train env_steps 200 total rewards -957.602406591177 total energy tensor([[188.8963]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7585707]\n",
      "Mode: Train env_steps 200 total rewards -1527.3898768424988 total energy tensor([[190.5169]])\n",
      "[-0.4320481]\n",
      "Mode: Train env_steps 200 total rewards -1507.2109246253967 total energy tensor([[193.1369]])\n",
      "[0.41584593]\n",
      "Mode: Train env_steps 200 total rewards -1066.8210080564022 total energy tensor([[184.3725]])\n",
      "[0.6229705]\n",
      "Mode: Train env_steps 200 total rewards -1005.4773960709572 total energy tensor([[185.2351]])\n",
      "[0.29056418]\n",
      "Mode: Train env_steps 200 total rewards -967.8265655636787 total energy tensor([[185.4023]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88847643]\n",
      "Mode: Train env_steps 200 total rewards -1501.4992628097534 total energy tensor([[191.2389]])\n",
      "[0.37137207]\n",
      "Mode: Train env_steps 200 total rewards -270.4817408826202 total energy tensor([[124.9058]])\n",
      "[0.87668586]\n",
      "Mode: Train env_steps 200 total rewards -960.5357453227043 total energy tensor([[185.4974]])\n",
      "[-0.83186466]\n",
      "Mode: Train env_steps 200 total rewards -262.77555321645923 total energy tensor([[118.2165]])\n",
      "[-0.50117445]\n",
      "Mode: Train env_steps 200 total rewards -1415.845275402069 total energy tensor([[186.6012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60224575]\n",
      "Mode: Train env_steps 200 total rewards -1541.762324333191 total energy tensor([[183.6803]])\n",
      "[0.10138795]\n",
      "Mode: Train env_steps 200 total rewards -117.57792146557836 total energy tensor([[27.0703]])\n",
      "[0.55896544]\n",
      "Mode: Train env_steps 200 total rewards -273.64670123532414 total energy tensor([[127.9168]])\n",
      "[-0.3429113]\n",
      "Mode: Train env_steps 200 total rewards -1501.608491897583 total energy tensor([[182.7135]])\n",
      "[-0.11902932]\n",
      "Mode: Train env_steps 200 total rewards -1527.2167592048645 total energy tensor([[186.9776]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6441647]\n",
      "Mode: Test env_steps 200 total rewards -1496.2539238929749 total energy tensor([[188.2782]])\n",
      "[0.34772608]\n",
      "Mode: Test env_steps 200 total rewards -1520.9747667312622 total energy tensor([[188.8655]])\n",
      "[-0.31490684]\n",
      "Mode: Test env_steps 200 total rewards -1387.9764423370361 total energy tensor([[186.6632]])\n",
      "[-0.6737087]\n",
      "Mode: Test env_steps 200 total rewards -1528.1672406196594 total energy tensor([[189.4309]])\n",
      "[-0.9029804]\n",
      "Mode: Test env_steps 200 total rewards -1508.5058584213257 total energy tensor([[183.7076]])\n",
      "[0.15654941]\n",
      "Mode: Test env_steps 200 total rewards -1073.0070161223412 total energy tensor([[184.1564]])\n",
      "[-0.40641248]\n",
      "Mode: Test env_steps 200 total rewards -1007.858294904232 total energy tensor([[187.8282]])\n",
      "[0.9936199]\n",
      "Mode: Test env_steps 200 total rewards -393.3970189988613 total energy tensor([[130.4534]])\n",
      "[0.93472326]\n",
      "Mode: Test env_steps 200 total rewards -619.0491569936275 total energy tensor([[184.2317]])\n",
      "[0.05931908]\n",
      "Mode: Test env_steps 200 total rewards -1425.033213376999 total energy tensor([[184.1669]])\n",
      "205000 -1196.022293239832\n",
      "[0.0434355]\n",
      "Mode: Train env_steps 200 total rewards -1534.7411336898804 total energy tensor([[183.1112]])\n",
      "[-0.5058925]\n",
      "Mode: Train env_steps 200 total rewards -872.8928865492344 total energy tensor([[187.1674]])\n",
      "[0.08773571]\n",
      "Mode: Train env_steps 200 total rewards -1398.251531124115 total energy tensor([[186.1554]])\n",
      "[0.3530897]\n",
      "Mode: Train env_steps 200 total rewards -1206.4075781106949 total energy tensor([[186.2910]])\n",
      "[-0.80892]\n",
      "Mode: Train env_steps 200 total rewards -397.5505338013172 total energy tensor([[133.5675]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70257705]\n",
      "Mode: Train env_steps 200 total rewards -1126.2471319437027 total energy tensor([[186.9076]])\n",
      "[0.91487014]\n",
      "Mode: Train env_steps 200 total rewards -1522.2077493667603 total energy tensor([[184.5524]])\n",
      "[0.59009844]\n",
      "Mode: Train env_steps 200 total rewards -394.80338624026626 total energy tensor([[131.0440]])\n",
      "[-0.7630162]\n",
      "Mode: Train env_steps 200 total rewards -273.2985908538103 total energy tensor([[142.8960]])\n",
      "[0.46519724]\n",
      "Mode: Train env_steps 200 total rewards -395.6044943793677 total energy tensor([[130.7303]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7054603]\n",
      "Mode: Train env_steps 200 total rewards -1144.1284927129745 total energy tensor([[187.5449]])\n",
      "[0.8621811]\n",
      "Mode: Train env_steps 200 total rewards -391.760269200895 total energy tensor([[108.1843]])\n",
      "[-0.28395143]\n",
      "Mode: Train env_steps 200 total rewards -1496.3528237342834 total energy tensor([[189.7899]])\n",
      "[0.30517125]\n",
      "Mode: Train env_steps 200 total rewards -332.58489018818364 total energy tensor([[121.6103]])\n",
      "[-0.72783524]\n",
      "Mode: Train env_steps 200 total rewards -1186.2882758378983 total energy tensor([[188.0080]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57590944]\n",
      "Mode: Train env_steps 200 total rewards -389.3648711433634 total energy tensor([[119.6081]])\n",
      "[0.563255]\n",
      "Mode: Train env_steps 200 total rewards -1508.6082782745361 total energy tensor([[191.8668]])\n",
      "[-0.11038442]\n",
      "Mode: Train env_steps 200 total rewards -269.42765010055155 total energy tensor([[120.4814]])\n",
      "[0.6224721]\n",
      "Mode: Train env_steps 200 total rewards -1529.0252571105957 total energy tensor([[190.3116]])\n",
      "[-0.33512998]\n",
      "Mode: Train env_steps 200 total rewards -276.17611353006214 total energy tensor([[127.7459]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2976245]\n",
      "Mode: Train env_steps 200 total rewards -1526.3001413345337 total energy tensor([[183.7772]])\n",
      "[-0.7893495]\n",
      "Mode: Train env_steps 200 total rewards -399.33873525139643 total energy tensor([[128.6051]])\n",
      "[-0.5526747]\n",
      "Mode: Train env_steps 200 total rewards -1259.8070633411407 total energy tensor([[187.7051]])\n",
      "[0.63654095]\n",
      "Mode: Train env_steps 200 total rewards -393.4853050559759 total energy tensor([[134.0881]])\n",
      "[-0.26741678]\n",
      "Mode: Train env_steps 200 total rewards -389.548133875709 total energy tensor([[129.7339]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53885454]\n",
      "Mode: Test env_steps 200 total rewards -269.3087514064973 total energy tensor([[108.1772]])\n",
      "[0.20214109]\n",
      "Mode: Test env_steps 200 total rewards -274.98546306602657 total energy tensor([[131.0116]])\n",
      "[-0.6084348]\n",
      "Mode: Test env_steps 200 total rewards -1394.6335670948029 total energy tensor([[185.2172]])\n",
      "[0.40491953]\n",
      "Mode: Test env_steps 200 total rewards -376.6368205512408 total energy tensor([[114.2690]])\n",
      "[0.4189521]\n",
      "Mode: Test env_steps 200 total rewards -395.3120093271136 total energy tensor([[119.5739]])\n",
      "[0.9415138]\n",
      "Mode: Test env_steps 200 total rewards -396.3028820855543 total energy tensor([[119.3151]])\n",
      "[0.6585823]\n",
      "Mode: Test env_steps 200 total rewards -1249.772955417633 total energy tensor([[185.0079]])\n",
      "[-0.6950214]\n",
      "Mode: Test env_steps 200 total rewards -398.64134821947664 total energy tensor([[120.0755]])\n",
      "[0.6642814]\n",
      "Mode: Test env_steps 200 total rewards -1080.4345289468765 total energy tensor([[183.6282]])\n",
      "[0.3952521]\n",
      "Mode: Test env_steps 200 total rewards -1509.2416939735413 total energy tensor([[191.8059]])\n",
      "210000 -734.5270020088763\n",
      "[0.54616505]\n",
      "Mode: Train env_steps 200 total rewards -1297.6728916168213 total energy tensor([[186.1155]])\n",
      "[-0.76923805]\n",
      "Mode: Train env_steps 200 total rewards -1505.2620992660522 total energy tensor([[188.6380]])\n",
      "[-0.75819176]\n",
      "Mode: Train env_steps 200 total rewards -1218.2205564975739 total energy tensor([[182.9037]])\n",
      "[-0.64297706]\n",
      "Mode: Train env_steps 200 total rewards -1522.1111340522766 total energy tensor([[190.2495]])\n",
      "[-0.39038336]\n",
      "Mode: Train env_steps 200 total rewards -271.6588840764016 total energy tensor([[122.3105]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20683117]\n",
      "Mode: Train env_steps 200 total rewards -1055.5723549127579 total energy tensor([[180.6053]])\n",
      "[-0.5211102]\n",
      "Mode: Train env_steps 200 total rewards -1088.4067566394806 total energy tensor([[185.3338]])\n",
      "[0.27715644]\n",
      "Mode: Train env_steps 200 total rewards -68.39484261907637 total energy tensor([[182.8287]])\n",
      "[-0.44857812]\n",
      "Mode: Train env_steps 200 total rewards -1388.5989940166473 total energy tensor([[185.7688]])\n",
      "[0.47615772]\n",
      "Mode: Train env_steps 200 total rewards -1000.51528018713 total energy tensor([[187.0855]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6758604]\n",
      "Mode: Train env_steps 200 total rewards -1211.9134576320648 total energy tensor([[187.2569]])\n",
      "[0.46083507]\n",
      "Mode: Train env_steps 200 total rewards -1537.7558197975159 total energy tensor([[187.7398]])\n",
      "[-0.44514]\n",
      "Mode: Train env_steps 200 total rewards -1531.3998517990112 total energy tensor([[189.5817]])\n",
      "[0.26342258]\n",
      "Mode: Train env_steps 200 total rewards -1502.5520477294922 total energy tensor([[189.7434]])\n",
      "[0.9529998]\n",
      "Mode: Train env_steps 200 total rewards -1349.7344424724579 total energy tensor([[191.5738]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5478445]\n",
      "Mode: Train env_steps 200 total rewards -269.56601154245436 total energy tensor([[116.3097]])\n",
      "[-0.4002445]\n",
      "Mode: Train env_steps 200 total rewards -1451.668579339981 total energy tensor([[183.5309]])\n",
      "[-0.9762174]\n",
      "Mode: Train env_steps 200 total rewards -1243.1797671318054 total energy tensor([[183.3462]])\n",
      "[0.5756426]\n",
      "Mode: Train env_steps 200 total rewards -1213.5500893592834 total energy tensor([[181.8146]])\n",
      "[-0.9894621]\n",
      "Mode: Train env_steps 200 total rewards -391.5903949011117 total energy tensor([[121.9220]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26435181]\n",
      "Mode: Train env_steps 200 total rewards -1221.8004332780838 total energy tensor([[182.7050]])\n",
      "[-0.25324616]\n",
      "Mode: Train env_steps 200 total rewards -976.3994933068752 total energy tensor([[180.6681]])\n",
      "[-0.82596374]\n",
      "Mode: Train env_steps 200 total rewards -1381.3910858631134 total energy tensor([[187.7130]])\n",
      "[0.73084974]\n",
      "Mode: Train env_steps 200 total rewards -291.1709473230876 total energy tensor([[124.0871]])\n",
      "[0.14252783]\n",
      "Mode: Train env_steps 200 total rewards -1221.9990211725235 total energy tensor([[183.8679]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.819793]\n",
      "Mode: Test env_steps 200 total rewards -1050.9476915597916 total energy tensor([[187.1873]])\n",
      "[0.9608282]\n",
      "Mode: Test env_steps 200 total rewards -1510.9759359359741 total energy tensor([[193.6761]])\n",
      "[0.42794725]\n",
      "Mode: Test env_steps 200 total rewards -397.0990374777466 total energy tensor([[117.5079]])\n",
      "[0.66898644]\n",
      "Mode: Test env_steps 200 total rewards -1403.960189819336 total energy tensor([[188.8866]])\n",
      "[0.5823668]\n",
      "Mode: Test env_steps 200 total rewards -1333.971967458725 total energy tensor([[188.3636]])\n",
      "[0.05208939]\n",
      "Mode: Test env_steps 200 total rewards -384.0938857770525 total energy tensor([[128.4647]])\n",
      "[0.30812743]\n",
      "Mode: Test env_steps 200 total rewards -399.92506697773933 total energy tensor([[130.7814]])\n",
      "[0.7770692]\n",
      "Mode: Test env_steps 200 total rewards -273.58208659663796 total energy tensor([[128.8516]])\n",
      "[-0.45859408]\n",
      "Mode: Test env_steps 200 total rewards -394.98189861141145 total energy tensor([[124.8470]])\n",
      "[0.5857146]\n",
      "Mode: Test env_steps 200 total rewards -394.66921904846095 total energy tensor([[113.4058]])\n",
      "215000 -754.4206979262875\n",
      "[-0.15718041]\n",
      "Mode: Train env_steps 200 total rewards -729.0747453272343 total energy tensor([[190.4749]])\n",
      "[0.46679997]\n",
      "Mode: Train env_steps 200 total rewards -283.94635185599327 total energy tensor([[146.6219]])\n",
      "[0.94880843]\n",
      "Mode: Train env_steps 200 total rewards -1377.9844365119934 total energy tensor([[189.7457]])\n",
      "[0.6054916]\n",
      "Mode: Train env_steps 200 total rewards -1530.9596061706543 total energy tensor([[189.7265]])\n",
      "[0.57270074]\n",
      "Mode: Train env_steps 200 total rewards -413.6575756110251 total energy tensor([[142.9848]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84248734]\n",
      "Mode: Train env_steps 200 total rewards -964.3899119496346 total energy tensor([[185.2694]])\n",
      "[-0.67814565]\n",
      "Mode: Train env_steps 200 total rewards -257.45453551533865 total energy tensor([[85.7106]])\n",
      "[0.41619396]\n",
      "Mode: Train env_steps 200 total rewards -1048.9248830080032 total energy tensor([[185.6039]])\n",
      "[-0.4665132]\n",
      "Mode: Train env_steps 200 total rewards -1313.7610125541687 total energy tensor([[185.7029]])\n",
      "[-0.40450847]\n",
      "Mode: Train env_steps 200 total rewards -1084.8502406477928 total energy tensor([[184.0339]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.516282]\n",
      "Mode: Train env_steps 200 total rewards -255.69959864369594 total energy tensor([[126.7439]])\n",
      "[0.22026475]\n",
      "Mode: Train env_steps 200 total rewards -1409.6579763889313 total energy tensor([[188.2431]])\n",
      "[0.90803826]\n",
      "Mode: Train env_steps 200 total rewards -254.77705991384573 total energy tensor([[91.8432]])\n",
      "[0.3069576]\n",
      "Mode: Train env_steps 200 total rewards -1486.1365938186646 total energy tensor([[193.6995]])\n",
      "[0.11043374]\n",
      "Mode: Train env_steps 200 total rewards -1413.7812063694 total energy tensor([[188.2160]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01262223]\n",
      "Mode: Train env_steps 200 total rewards -1381.382934808731 total energy tensor([[185.8462]])\n",
      "[0.22484453]\n",
      "Mode: Train env_steps 200 total rewards -1518.3631582260132 total energy tensor([[184.5417]])\n",
      "[0.4446558]\n",
      "Mode: Train env_steps 200 total rewards -404.4384829737246 total energy tensor([[130.8139]])\n",
      "[0.6944792]\n",
      "Mode: Train env_steps 200 total rewards -1207.104970216751 total energy tensor([[178.9033]])\n",
      "[0.23556821]\n",
      "Mode: Train env_steps 200 total rewards -1388.136578798294 total energy tensor([[186.1057]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8450412]\n",
      "Mode: Train env_steps 200 total rewards -1111.185109615326 total energy tensor([[186.1039]])\n",
      "[0.28923786]\n",
      "Mode: Train env_steps 200 total rewards -969.259188324213 total energy tensor([[184.5783]])\n",
      "[0.18776011]\n",
      "Mode: Train env_steps 200 total rewards -267.1209172802046 total energy tensor([[106.1425]])\n",
      "[-0.9487227]\n",
      "Mode: Train env_steps 200 total rewards -1163.7748606204987 total energy tensor([[182.7610]])\n",
      "[0.10898422]\n",
      "Mode: Train env_steps 200 total rewards -270.5120420958847 total energy tensor([[120.2869]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5334045]\n",
      "Mode: Test env_steps 200 total rewards -267.4866671377031 total energy tensor([[89.2545]])\n",
      "[-0.52555305]\n",
      "Mode: Test env_steps 200 total rewards -265.39571798883844 total energy tensor([[85.1687]])\n",
      "[0.81214964]\n",
      "Mode: Test env_steps 200 total rewards -970.5697827935219 total energy tensor([[187.3131]])\n",
      "[0.8051216]\n",
      "Mode: Test env_steps 200 total rewards -263.3561426937049 total energy tensor([[93.6276]])\n",
      "[-0.02012181]\n",
      "Mode: Test env_steps 200 total rewards -1232.594161272049 total energy tensor([[185.9503]])\n",
      "[-0.38968495]\n",
      "Mode: Test env_steps 200 total rewards -1458.0855894088745 total energy tensor([[189.4776]])\n",
      "[-0.03161056]\n",
      "Mode: Test env_steps 200 total rewards -268.07075868640095 total energy tensor([[104.0782]])\n",
      "[-0.3763967]\n",
      "Mode: Test env_steps 200 total rewards -245.3644908502465 total energy tensor([[85.0397]])\n",
      "[0.75595784]\n",
      "Mode: Test env_steps 200 total rewards -302.58389517851174 total energy tensor([[137.4621]])\n",
      "[0.85628533]\n",
      "Mode: Test env_steps 200 total rewards -264.16863056321745 total energy tensor([[88.9602]])\n",
      "220000 -553.7675836573069\n",
      "[-0.6240912]\n",
      "Mode: Train env_steps 200 total rewards -269.54664270952344 total energy tensor([[111.3584]])\n",
      "[0.8513608]\n",
      "Mode: Train env_steps 200 total rewards -731.9986145794392 total energy tensor([[189.7242]])\n",
      "[0.07581428]\n",
      "Mode: Train env_steps 200 total rewards -267.31006710999645 total energy tensor([[90.5225]])\n",
      "[-0.23761152]\n",
      "Mode: Train env_steps 200 total rewards -1434.1792917251587 total energy tensor([[184.9444]])\n",
      "[0.51225007]\n",
      "Mode: Train env_steps 200 total rewards -1504.3691172599792 total energy tensor([[185.3877]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69331014]\n",
      "Mode: Train env_steps 200 total rewards -1508.5183124542236 total energy tensor([[194.8094]])\n",
      "[0.08123419]\n",
      "Mode: Train env_steps 200 total rewards -378.0847579357214 total energy tensor([[120.9038]])\n",
      "[-0.38698655]\n",
      "Mode: Train env_steps 200 total rewards -1212.9339439868927 total energy tensor([[186.6350]])\n",
      "[0.1302251]\n",
      "Mode: Train env_steps 200 total rewards -1513.018193244934 total energy tensor([[195.1118]])\n",
      "[0.78437173]\n",
      "Mode: Train env_steps 200 total rewards -401.9000154696405 total energy tensor([[144.9216]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.60978323]\n",
      "Mode: Train env_steps 200 total rewards -1548.33842086792 total energy tensor([[176.2023]])\n",
      "[0.89167875]\n",
      "Mode: Train env_steps 200 total rewards -240.63680037710583 total energy tensor([[83.0310]])\n",
      "[-0.29364505]\n",
      "Mode: Train env_steps 200 total rewards -276.54959086328745 total energy tensor([[136.9162]])\n",
      "[-0.62619215]\n",
      "Mode: Train env_steps 200 total rewards -724.9848474413157 total energy tensor([[180.1841]])\n",
      "[-0.12350548]\n",
      "Mode: Train env_steps 200 total rewards -353.5515746861056 total energy tensor([[91.7595]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5663746]\n",
      "Mode: Train env_steps 200 total rewards -378.98956366841594 total energy tensor([[126.9418]])\n",
      "[-0.03855868]\n",
      "Mode: Train env_steps 200 total rewards -1097.6852124929428 total energy tensor([[179.1899]])\n",
      "[0.44079718]\n",
      "Mode: Train env_steps 200 total rewards -1215.1462112665176 total energy tensor([[181.2867]])\n",
      "[-0.38181296]\n",
      "Mode: Train env_steps 200 total rewards -492.0244329008274 total energy tensor([[162.7475]])\n",
      "[0.3613489]\n",
      "Mode: Train env_steps 200 total rewards -1403.5622355937958 total energy tensor([[185.1297]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6483099]\n",
      "Mode: Train env_steps 200 total rewards -1504.9014444351196 total energy tensor([[180.1766]])\n",
      "[-0.06611174]\n",
      "Mode: Train env_steps 200 total rewards -1335.6527688503265 total energy tensor([[185.8504]])\n",
      "[-0.33834258]\n",
      "Mode: Train env_steps 200 total rewards -1473.8585777282715 total energy tensor([[183.2166]])\n",
      "[0.8524184]\n",
      "Mode: Train env_steps 200 total rewards -963.8142134845257 total energy tensor([[180.7756]])\n",
      "[0.8984251]\n",
      "Mode: Train env_steps 200 total rewards -1411.3196170330048 total energy tensor([[180.9937]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56268215]\n",
      "Mode: Test env_steps 200 total rewards -737.6418943554163 total energy tensor([[187.6347]])\n",
      "[-0.6944816]\n",
      "Mode: Test env_steps 200 total rewards -989.0211191773415 total energy tensor([[184.5904]])\n",
      "[0.34248593]\n",
      "Mode: Test env_steps 200 total rewards -1109.9981347322464 total energy tensor([[181.9921]])\n",
      "[-0.67975307]\n",
      "Mode: Test env_steps 200 total rewards -399.7527958638966 total energy tensor([[132.4194]])\n",
      "[-0.904214]\n",
      "Mode: Test env_steps 200 total rewards -281.89105345401913 total energy tensor([[146.1881]])\n",
      "[-0.04421592]\n",
      "Mode: Test env_steps 200 total rewards -1206.9697647094727 total energy tensor([[182.7831]])\n",
      "[-0.6807235]\n",
      "Mode: Test env_steps 200 total rewards -401.70287430100143 total energy tensor([[135.4794]])\n",
      "[-0.4516339]\n",
      "Mode: Test env_steps 200 total rewards -1217.7802648544312 total energy tensor([[184.2786]])\n",
      "[0.01615976]\n",
      "Mode: Test env_steps 200 total rewards -392.10144241177477 total energy tensor([[109.5590]])\n",
      "[0.45439076]\n",
      "Mode: Test env_steps 200 total rewards -1400.5306341648102 total energy tensor([[188.6196]])\n",
      "225000 -813.738997802441\n",
      "[-0.26797464]\n",
      "Mode: Train env_steps 200 total rewards -1537.2653012275696 total energy tensor([[185.8897]])\n",
      "[0.8190658]\n",
      "Mode: Train env_steps 200 total rewards -1502.2154932022095 total energy tensor([[197.2519]])\n",
      "[-0.8824297]\n",
      "Mode: Train env_steps 200 total rewards -1285.5563025474548 total energy tensor([[187.1714]])\n",
      "[-0.5294741]\n",
      "Mode: Train env_steps 200 total rewards -1485.6022672653198 total energy tensor([[191.4525]])\n",
      "[0.3227267]\n",
      "Mode: Train env_steps 200 total rewards -394.4346709549427 total energy tensor([[116.2989]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7900133]\n",
      "Mode: Train env_steps 200 total rewards -1201.3534429073334 total energy tensor([[187.0503]])\n",
      "[0.258515]\n",
      "Mode: Train env_steps 200 total rewards -1491.4368019104004 total energy tensor([[194.8124]])\n",
      "[-0.92623615]\n",
      "Mode: Train env_steps 200 total rewards -1478.646143913269 total energy tensor([[192.1009]])\n",
      "[-0.84094733]\n",
      "Mode: Train env_steps 200 total rewards -961.4576881527901 total energy tensor([[184.3653]])\n",
      "[-0.48559752]\n",
      "Mode: Train env_steps 200 total rewards -1471.664939403534 total energy tensor([[193.6069]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08015271]\n",
      "Mode: Train env_steps 200 total rewards -279.450202109816 total energy tensor([[106.7028]])\n",
      "[0.6270807]\n",
      "Mode: Train env_steps 200 total rewards -1009.8502523303032 total energy tensor([[183.6012]])\n",
      "[-0.2628494]\n",
      "Mode: Train env_steps 200 total rewards -977.2888520359993 total energy tensor([[183.7104]])\n",
      "[-0.6835905]\n",
      "Mode: Train env_steps 200 total rewards -1399.7870004177094 total energy tensor([[189.0671]])\n",
      "[-0.76061743]\n",
      "Mode: Train env_steps 200 total rewards -1171.3986822366714 total energy tensor([[186.2094]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60313797]\n",
      "Mode: Train env_steps 200 total rewards -1253.1081628799438 total energy tensor([[186.8912]])\n",
      "[0.62265074]\n",
      "Mode: Train env_steps 200 total rewards -1218.7452001571655 total energy tensor([[185.2372]])\n",
      "[-0.33395705]\n",
      "Mode: Train env_steps 200 total rewards -240.32840997353196 total energy tensor([[65.7012]])\n",
      "[0.90056163]\n",
      "Mode: Train env_steps 200 total rewards -1431.406819343567 total energy tensor([[186.8024]])\n",
      "[0.7946696]\n",
      "Mode: Train env_steps 200 total rewards -258.888438935508 total energy tensor([[72.5099]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.45192263]\n",
      "Mode: Train env_steps 200 total rewards -267.1352677231116 total energy tensor([[95.5845]])\n",
      "[-0.1685006]\n",
      "Mode: Train env_steps 200 total rewards -367.5525125107961 total energy tensor([[111.3468]])\n",
      "[0.09964992]\n",
      "Mode: Train env_steps 200 total rewards -398.91545019857585 total energy tensor([[126.6319]])\n",
      "[0.16835102]\n",
      "Mode: Train env_steps 200 total rewards -1108.6020431518555 total energy tensor([[181.7604]])\n",
      "[-0.10047237]\n",
      "Mode: Train env_steps 200 total rewards -957.4380891695619 total energy tensor([[182.5539]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7026076]\n",
      "Mode: Test env_steps 200 total rewards -1395.4257442951202 total energy tensor([[181.6303]])\n",
      "[-0.45248508]\n",
      "Mode: Test env_steps 200 total rewards -1541.0778222084045 total energy tensor([[173.0722]])\n",
      "[0.73675144]\n",
      "Mode: Test env_steps 200 total rewards -266.4591990755871 total energy tensor([[93.6987]])\n",
      "[-0.94351983]\n",
      "Mode: Test env_steps 200 total rewards -1485.6413626670837 total energy tensor([[182.7383]])\n",
      "[-0.14367737]\n",
      "Mode: Test env_steps 200 total rewards -943.6143574118614 total energy tensor([[183.7457]])\n",
      "[-0.48797843]\n",
      "Mode: Test env_steps 200 total rewards -1548.633954524994 total energy tensor([[182.3777]])\n",
      "[0.17250495]\n",
      "Mode: Test env_steps 200 total rewards -966.4861977100372 total energy tensor([[178.6532]])\n",
      "[0.1628088]\n",
      "Mode: Test env_steps 200 total rewards -1362.6954684257507 total energy tensor([[186.5384]])\n",
      "[-0.51387376]\n",
      "Mode: Test env_steps 200 total rewards -965.7919968664646 total energy tensor([[178.6659]])\n",
      "[-0.7041955]\n",
      "Mode: Test env_steps 200 total rewards -1207.7256387472153 total energy tensor([[180.8864]])\n",
      "230000 -1168.355174193252\n",
      "[-0.6476039]\n",
      "Mode: Train env_steps 200 total rewards -979.958232820034 total energy tensor([[176.2932]])\n",
      "[-0.03788951]\n",
      "Mode: Train env_steps 200 total rewards -1147.8328627347946 total energy tensor([[181.9287]])\n",
      "[0.3924344]\n",
      "Mode: Train env_steps 200 total rewards -136.42006234437576 total energy tensor([[62.8251]])\n",
      "[-0.5069308]\n",
      "Mode: Train env_steps 200 total rewards -1438.2906560897827 total energy tensor([[174.7425]])\n",
      "[-0.5301748]\n",
      "Mode: Train env_steps 200 total rewards -120.4694874941506 total energy tensor([[46.7712]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6777725]\n",
      "Mode: Train env_steps 200 total rewards -275.87986999968416 total energy tensor([[96.8732]])\n",
      "[-0.3202826]\n",
      "Mode: Train env_steps 200 total rewards -399.6025837697089 total energy tensor([[120.1369]])\n",
      "[-0.56943375]\n",
      "Mode: Train env_steps 200 total rewards -1086.6445131897926 total energy tensor([[178.2029]])\n",
      "[-0.77005005]\n",
      "Mode: Train env_steps 200 total rewards -145.55542989482637 total energy tensor([[97.7803]])\n",
      "[0.13533191]\n",
      "Mode: Train env_steps 200 total rewards -914.5151382163167 total energy tensor([[178.2832]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7288181]\n",
      "Mode: Train env_steps 200 total rewards -1208.4316202402115 total energy tensor([[182.4587]])\n",
      "[-0.50377744]\n",
      "Mode: Train env_steps 200 total rewards -1431.933878660202 total energy tensor([[185.1514]])\n",
      "[0.9789179]\n",
      "Mode: Train env_steps 200 total rewards -265.6802569248248 total energy tensor([[91.9217]])\n",
      "[-0.56141555]\n",
      "Mode: Train env_steps 200 total rewards -268.5432276974898 total energy tensor([[99.0397]])\n",
      "[-0.8469769]\n",
      "Mode: Train env_steps 200 total rewards -254.95852139702765 total energy tensor([[70.0126]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69257134]\n",
      "Mode: Train env_steps 200 total rewards -1501.8833694458008 total energy tensor([[193.2817]])\n",
      "[-0.69185364]\n",
      "Mode: Train env_steps 200 total rewards -257.49181263650826 total energy tensor([[66.7370]])\n",
      "[0.51464015]\n",
      "Mode: Train env_steps 200 total rewards -126.6603229213506 total energy tensor([[83.4317]])\n",
      "[-0.00422045]\n",
      "Mode: Train env_steps 200 total rewards -266.35584021225804 total energy tensor([[87.8385]])\n",
      "[-0.10183224]\n",
      "Mode: Train env_steps 200 total rewards -263.75248105367064 total energy tensor([[75.1686]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.650286]\n",
      "Mode: Train env_steps 200 total rewards -1495.1287598609924 total energy tensor([[190.8783]])\n",
      "[0.8531853]\n",
      "Mode: Train env_steps 200 total rewards -162.01157175097615 total energy tensor([[108.9503]])\n",
      "[0.46830916]\n",
      "Mode: Train env_steps 200 total rewards -269.18583074887283 total energy tensor([[100.8128]])\n",
      "[-0.6217017]\n",
      "Mode: Train env_steps 200 total rewards -1498.7010335922241 total energy tensor([[194.9665]])\n",
      "[0.7365724]\n",
      "Mode: Train env_steps 200 total rewards -964.0454509556293 total energy tensor([[183.9940]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28965402]\n",
      "Mode: Test env_steps 200 total rewards -122.64922348491382 total energy tensor([[27.1059]])\n",
      "[0.278856]\n",
      "Mode: Test env_steps 200 total rewards -1396.4965870380402 total energy tensor([[183.4661]])\n",
      "[0.37324753]\n",
      "Mode: Test env_steps 200 total rewards -1360.1052417755127 total energy tensor([[184.0633]])\n",
      "[0.9226486]\n",
      "Mode: Test env_steps 200 total rewards -1233.2102177143097 total energy tensor([[180.3464]])\n",
      "[-0.37670162]\n",
      "Mode: Test env_steps 200 total rewards -0.432001402208698 total energy tensor([[6.6270]])\n",
      "[0.09940389]\n",
      "Mode: Test env_steps 200 total rewards -369.51859417557716 total energy tensor([[121.6648]])\n",
      "[-0.9271909]\n",
      "Mode: Test env_steps 200 total rewards -323.6252708211541 total energy tensor([[123.2514]])\n",
      "[0.6400758]\n",
      "Mode: Test env_steps 200 total rewards -1242.1214380264282 total energy tensor([[180.5698]])\n",
      "[-0.16310167]\n",
      "Mode: Test env_steps 200 total rewards -1.688847541809082 total energy tensor([[16.1547]])\n",
      "[-0.77113897]\n",
      "Mode: Test env_steps 200 total rewards -266.0534498039633 total energy tensor([[84.2556]])\n",
      "235000 -631.5900871783917\n",
      "[-0.9014127]\n",
      "Mode: Train env_steps 200 total rewards -1534.3102593421936 total energy tensor([[181.5612]])\n",
      "[-0.44251198]\n",
      "Mode: Train env_steps 200 total rewards -1224.3749556541443 total energy tensor([[180.4485]])\n",
      "[0.64746284]\n",
      "Mode: Train env_steps 200 total rewards -255.83301280252635 total energy tensor([[138.8640]])\n",
      "[-0.14265774]\n",
      "Mode: Train env_steps 200 total rewards -967.0132714956999 total energy tensor([[177.3998]])\n",
      "[-0.48293188]\n",
      "Mode: Train env_steps 200 total rewards -1507.4746165275574 total energy tensor([[189.2081]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8756192]\n",
      "Mode: Train env_steps 200 total rewards -1345.4683213233948 total energy tensor([[189.0794]])\n",
      "[0.3348314]\n",
      "Mode: Train env_steps 200 total rewards -1314.1162428855896 total energy tensor([[185.6157]])\n",
      "[-0.7368661]\n",
      "Mode: Train env_steps 200 total rewards -399.55833753943443 total energy tensor([[128.7391]])\n",
      "[-0.69433427]\n",
      "Mode: Train env_steps 200 total rewards -274.54827337758616 total energy tensor([[128.9166]])\n",
      "[-0.59707564]\n",
      "Mode: Train env_steps 200 total rewards -1509.7793636322021 total energy tensor([[191.1130]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.74036026]\n",
      "Mode: Train env_steps 200 total rewards -532.0040246769786 total energy tensor([[138.6650]])\n",
      "[0.01123144]\n",
      "Mode: Train env_steps 200 total rewards -402.91239723563194 total energy tensor([[126.8927]])\n",
      "[0.14863676]\n",
      "Mode: Train env_steps 200 total rewards -462.63210083544254 total energy tensor([[127.0122]])\n",
      "[0.4599225]\n",
      "Mode: Train env_steps 200 total rewards -936.4261681959033 total energy tensor([[180.9812]])\n",
      "[-0.7500946]\n",
      "Mode: Train env_steps 200 total rewards -973.3798112869263 total energy tensor([[181.7839]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73180497]\n",
      "Mode: Train env_steps 200 total rewards -265.17182284453884 total energy tensor([[97.8643]])\n",
      "[0.95236987]\n",
      "Mode: Train env_steps 200 total rewards -151.27802433038596 total energy tensor([[104.7587]])\n",
      "[-0.6566852]\n",
      "Mode: Train env_steps 200 total rewards -1464.7993261814117 total energy tensor([[179.4607]])\n",
      "[0.25203782]\n",
      "Mode: Train env_steps 200 total rewards -266.1181799140759 total energy tensor([[98.9487]])\n",
      "[-0.06582687]\n",
      "Mode: Train env_steps 200 total rewards -1205.5262976884842 total energy tensor([[180.2849]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9508824]\n",
      "Mode: Train env_steps 200 total rewards -962.4536933898926 total energy tensor([[184.6305]])\n",
      "[0.6954647]\n",
      "Mode: Train env_steps 200 total rewards -1446.6647019386292 total energy tensor([[188.4357]])\n",
      "[0.05853606]\n",
      "Mode: Train env_steps 200 total rewards -1163.005538702011 total energy tensor([[182.9903]])\n",
      "[0.0374272]\n",
      "Mode: Train env_steps 200 total rewards -139.70627272396814 total energy tensor([[92.9000]])\n",
      "[0.9319069]\n",
      "Mode: Train env_steps 200 total rewards -961.3152458369732 total energy tensor([[183.7287]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3825323]\n",
      "Mode: Test env_steps 200 total rewards -1234.0457231998444 total energy tensor([[181.3194]])\n",
      "[0.05530879]\n",
      "Mode: Test env_steps 200 total rewards -342.56504925340414 total energy tensor([[139.5265]])\n",
      "[-0.293119]\n",
      "Mode: Test env_steps 200 total rewards -258.57324110576883 total energy tensor([[90.0392]])\n",
      "[0.29818314]\n",
      "Mode: Test env_steps 200 total rewards -1444.581919670105 total energy tensor([[191.0688]])\n",
      "[0.80324996]\n",
      "Mode: Test env_steps 200 total rewards -1426.1997666358948 total energy tensor([[188.9634]])\n",
      "[0.97317594]\n",
      "Mode: Test env_steps 200 total rewards -1411.3904566764832 total energy tensor([[186.1527]])\n",
      "[-0.88309216]\n",
      "Mode: Test env_steps 200 total rewards -1519.1709051132202 total energy tensor([[195.6634]])\n",
      "[-0.08038597]\n",
      "Mode: Test env_steps 200 total rewards -1232.4698859453201 total energy tensor([[181.4011]])\n",
      "[0.35636604]\n",
      "Mode: Test env_steps 200 total rewards -1487.425223827362 total energy tensor([[195.5778]])\n",
      "[-0.3877246]\n",
      "Mode: Test env_steps 200 total rewards -266.7467162730172 total energy tensor([[125.9004]])\n",
      "240000 -1062.316888770042\n",
      "[-0.47989818]\n",
      "Mode: Train env_steps 200 total rewards -348.59924694523215 total energy tensor([[143.6680]])\n",
      "[-0.450582]\n",
      "Mode: Train env_steps 200 total rewards -984.5404405593872 total energy tensor([[181.3542]])\n",
      "[0.9975427]\n",
      "Mode: Train env_steps 200 total rewards -1098.6104742884636 total energy tensor([[177.3753]])\n",
      "[-0.05240832]\n",
      "Mode: Train env_steps 200 total rewards -399.2811949495226 total energy tensor([[127.0028]])\n",
      "[-0.56458664]\n",
      "Mode: Train env_steps 200 total rewards -1534.0086860656738 total energy tensor([[193.7574]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11466321]\n",
      "Mode: Train env_steps 200 total rewards -397.9020448885858 total energy tensor([[129.8136]])\n",
      "[0.10658349]\n",
      "Mode: Train env_steps 200 total rewards -401.21366387605667 total energy tensor([[132.6282]])\n",
      "[-0.2784385]\n",
      "Mode: Train env_steps 200 total rewards -404.13423866033554 total energy tensor([[139.8400]])\n",
      "[-0.03112474]\n",
      "Mode: Train env_steps 200 total rewards -1303.8313779830933 total energy tensor([[186.7782]])\n",
      "[0.87917197]\n",
      "Mode: Train env_steps 200 total rewards -1204.6287972927094 total energy tensor([[179.1874]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6548539]\n",
      "Mode: Train env_steps 200 total rewards -1520.853449344635 total energy tensor([[189.8026]])\n",
      "[0.6784315]\n",
      "Mode: Train env_steps 200 total rewards -990.7321671843529 total energy tensor([[184.5674]])\n",
      "[0.48837245]\n",
      "Mode: Train env_steps 200 total rewards -1257.9921219348907 total energy tensor([[184.3813]])\n",
      "[-0.23175368]\n",
      "Mode: Train env_steps 200 total rewards -0.3843060478970983 total energy tensor([[6.4830]])\n",
      "[0.27374765]\n",
      "Mode: Train env_steps 200 total rewards -1272.672883272171 total energy tensor([[182.9685]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06037586]\n",
      "Mode: Train env_steps 200 total rewards -1452.8712134361267 total energy tensor([[190.0520]])\n",
      "[-0.4436393]\n",
      "Mode: Train env_steps 200 total rewards -1522.4357633590698 total energy tensor([[177.7514]])\n",
      "[-0.84916943]\n",
      "Mode: Train env_steps 200 total rewards -1504.4652280807495 total energy tensor([[187.0637]])\n",
      "[0.68788654]\n",
      "Mode: Train env_steps 200 total rewards -1162.7863278388977 total energy tensor([[175.8388]])\n",
      "[0.91207296]\n",
      "Mode: Train env_steps 200 total rewards -1523.1940717697144 total energy tensor([[190.0662]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74291694]\n",
      "Mode: Train env_steps 200 total rewards -1484.8944153785706 total energy tensor([[184.4409]])\n",
      "[-0.06651627]\n",
      "Mode: Train env_steps 200 total rewards -264.5514932301594 total energy tensor([[79.7001]])\n",
      "[-0.3677162]\n",
      "Mode: Train env_steps 200 total rewards -1272.5736944675446 total energy tensor([[183.9590]])\n",
      "[-0.35231322]\n",
      "Mode: Train env_steps 200 total rewards -1533.015296459198 total energy tensor([[189.8445]])\n",
      "[-0.8186089]\n",
      "Mode: Train env_steps 200 total rewards -1459.333297252655 total energy tensor([[190.3360]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04565967]\n",
      "Mode: Test env_steps 200 total rewards -402.93016977235675 total energy tensor([[149.9905]])\n",
      "[0.50596285]\n",
      "Mode: Test env_steps 200 total rewards -391.6421656818129 total energy tensor([[103.8693]])\n",
      "[0.81995994]\n",
      "Mode: Test env_steps 200 total rewards -1321.3806574344635 total energy tensor([[189.2561]])\n",
      "[-0.4451681]\n",
      "Mode: Test env_steps 200 total rewards -400.24293681327254 total energy tensor([[123.8641]])\n",
      "[-0.6355305]\n",
      "Mode: Test env_steps 200 total rewards -401.6014377903193 total energy tensor([[128.5935]])\n",
      "[0.49779135]\n",
      "Mode: Test env_steps 200 total rewards -1282.3160498142242 total energy tensor([[190.7230]])\n",
      "[-0.9216665]\n",
      "Mode: Test env_steps 200 total rewards -1228.8289692401886 total energy tensor([[188.9116]])\n",
      "[-0.47645816]\n",
      "Mode: Test env_steps 200 total rewards -402.9590426273644 total energy tensor([[142.3466]])\n",
      "[0.18996167]\n",
      "Mode: Test env_steps 200 total rewards -1411.3942539691925 total energy tensor([[192.9411]])\n",
      "[0.8046793]\n",
      "Mode: Test env_steps 200 total rewards -1498.5459485054016 total energy tensor([[194.8822]])\n",
      "245000 -874.1841631648597\n",
      "[-0.7026564]\n",
      "Mode: Train env_steps 200 total rewards -1260.8644330501556 total energy tensor([[188.2741]])\n",
      "[-0.40030786]\n",
      "Mode: Train env_steps 200 total rewards -389.06625490495935 total energy tensor([[112.7606]])\n",
      "[-0.08181819]\n",
      "Mode: Train env_steps 200 total rewards -1489.185429096222 total energy tensor([[195.3794]])\n",
      "[-0.7804652]\n",
      "Mode: Train env_steps 200 total rewards -969.0113387107849 total energy tensor([[183.2676]])\n",
      "[0.40946108]\n",
      "Mode: Train env_steps 200 total rewards -1449.8465156555176 total energy tensor([[194.0270]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.519148]\n",
      "Mode: Train env_steps 200 total rewards -963.190582036972 total energy tensor([[177.5281]])\n",
      "[-0.5030702]\n",
      "Mode: Train env_steps 200 total rewards -265.273378881393 total energy tensor([[89.6860]])\n",
      "[-0.22752726]\n",
      "Mode: Train env_steps 200 total rewards -270.3341762414202 total energy tensor([[109.5649]])\n",
      "[0.69849753]\n",
      "Mode: Train env_steps 200 total rewards -257.0906859689858 total energy tensor([[112.9550]])\n",
      "[-0.99189204]\n",
      "Mode: Train env_steps 200 total rewards -1245.574021577835 total energy tensor([[182.6714]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08368153]\n",
      "Mode: Train env_steps 200 total rewards -983.9754250049591 total energy tensor([[174.9498]])\n",
      "[-0.07290735]\n",
      "Mode: Train env_steps 200 total rewards -226.26474781287834 total energy tensor([[102.4582]])\n",
      "[-0.5091324]\n",
      "Mode: Train env_steps 200 total rewards -268.57059108186513 total energy tensor([[92.2002]])\n",
      "[-0.66994435]\n",
      "Mode: Train env_steps 200 total rewards -1384.6306858062744 total energy tensor([[185.5093]])\n",
      "[-0.01526341]\n",
      "Mode: Train env_steps 200 total rewards -1075.635690689087 total energy tensor([[179.0019]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2895712]\n",
      "Mode: Train env_steps 200 total rewards -965.707554101944 total energy tensor([[184.8457]])\n",
      "[-0.50454235]\n",
      "Mode: Train env_steps 200 total rewards -1517.4608178138733 total energy tensor([[182.4445]])\n",
      "[-0.7686103]\n",
      "Mode: Train env_steps 200 total rewards -1496.2581872940063 total energy tensor([[187.0385]])\n",
      "[-0.87430686]\n",
      "Mode: Train env_steps 200 total rewards -522.7037877719849 total energy tensor([[132.2873]])\n",
      "[0.28179264]\n",
      "Mode: Train env_steps 200 total rewards -1534.8085131645203 total energy tensor([[189.0242]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75983995]\n",
      "Mode: Train env_steps 200 total rewards -1398.9471487998962 total energy tensor([[185.7221]])\n",
      "[-0.76298916]\n",
      "Mode: Train env_steps 200 total rewards -246.88641525432467 total energy tensor([[101.3991]])\n",
      "[0.7848834]\n",
      "Mode: Train env_steps 200 total rewards -250.06514971982688 total energy tensor([[111.0825]])\n",
      "[-0.94521767]\n",
      "Mode: Train env_steps 200 total rewards -1174.2969299554825 total energy tensor([[175.2840]])\n",
      "[0.4976446]\n",
      "Mode: Train env_steps 200 total rewards -269.71211680490524 total energy tensor([[106.5617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79095244]\n",
      "Mode: Test env_steps 200 total rewards -1473.952754497528 total energy tensor([[182.8964]])\n",
      "[-0.87539166]\n",
      "Mode: Test env_steps 200 total rewards -1483.2633991241455 total energy tensor([[182.0992]])\n",
      "[0.9198636]\n",
      "Mode: Test env_steps 200 total rewards -276.82790421694517 total energy tensor([[131.8209]])\n",
      "[-0.31327125]\n",
      "Mode: Test env_steps 200 total rewards -1404.9281611442566 total energy tensor([[182.7939]])\n",
      "[-0.8974732]\n",
      "Mode: Test env_steps 200 total rewards -1368.6326162815094 total energy tensor([[185.1256]])\n",
      "[0.5207875]\n",
      "Mode: Test env_steps 200 total rewards -1534.8129777908325 total energy tensor([[183.6003]])\n",
      "[-0.5404135]\n",
      "Mode: Test env_steps 200 total rewards -1215.170972943306 total energy tensor([[184.2826]])\n",
      "[0.42038107]\n",
      "Mode: Test env_steps 200 total rewards -1268.4878866672516 total energy tensor([[184.8056]])\n",
      "[0.15586992]\n",
      "Mode: Test env_steps 200 total rewards -245.40212781960145 total energy tensor([[90.9456]])\n",
      "[0.5566753]\n",
      "Mode: Test env_steps 200 total rewards -1380.0324490070343 total energy tensor([[185.7597]])\n",
      "250000 -1165.151124949241\n",
      "[-0.9307223]\n",
      "Mode: Train env_steps 200 total rewards -1339.0134136676788 total energy tensor([[184.5377]])\n",
      "[-0.04624409]\n",
      "Mode: Train env_steps 200 total rewards -1077.2780858278275 total energy tensor([[182.6901]])\n",
      "[-0.09367487]\n",
      "Mode: Train env_steps 200 total rewards -1207.7459033727646 total energy tensor([[181.9102]])\n",
      "[-0.00210153]\n",
      "Mode: Train env_steps 200 total rewards -242.09663646901026 total energy tensor([[81.3137]])\n",
      "[0.812373]\n",
      "Mode: Train env_steps 200 total rewards -2.4188741194084287 total energy tensor([[23.5066]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5434455]\n",
      "Mode: Train env_steps 200 total rewards -380.38091026153415 total energy tensor([[125.8758]])\n",
      "[-0.7976286]\n",
      "Mode: Train env_steps 200 total rewards -1474.7925589084625 total energy tensor([[186.4346]])\n",
      "[-0.2983448]\n",
      "Mode: Train env_steps 200 total rewards -1475.6010384559631 total energy tensor([[187.5549]])\n",
      "[-0.08298172]\n",
      "Mode: Train env_steps 200 total rewards -1448.608136177063 total energy tensor([[186.6371]])\n",
      "[0.9253736]\n",
      "Mode: Train env_steps 200 total rewards -531.9481073934585 total energy tensor([[139.5627]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10556164]\n",
      "Mode: Train env_steps 200 total rewards -1507.1642518043518 total energy tensor([[192.4118]])\n",
      "[-0.732965]\n",
      "Mode: Train env_steps 200 total rewards -1116.6351935863495 total energy tensor([[178.3523]])\n",
      "[0.01781227]\n",
      "Mode: Train env_steps 200 total rewards -404.3026505559683 total energy tensor([[146.4776]])\n",
      "[-0.47209433]\n",
      "Mode: Train env_steps 200 total rewards -1328.8214838504791 total energy tensor([[185.3419]])\n",
      "[-0.9873493]\n",
      "Mode: Train env_steps 200 total rewards -153.71111534594093 total energy tensor([[110.2322]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39608923]\n",
      "Mode: Train env_steps 200 total rewards -858.7085047364235 total energy tensor([[184.7338]])\n",
      "[0.17094529]\n",
      "Mode: Train env_steps 200 total rewards -1397.987556219101 total energy tensor([[189.6518]])\n",
      "[-0.0020767]\n",
      "Mode: Train env_steps 200 total rewards -405.44359673187137 total energy tensor([[134.7156]])\n",
      "[0.7942637]\n",
      "Mode: Train env_steps 200 total rewards -1507.9235348701477 total energy tensor([[188.2316]])\n",
      "[0.6119595]\n",
      "Mode: Train env_steps 200 total rewards -131.20221163891256 total energy tensor([[117.0341]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24196376]\n",
      "Mode: Train env_steps 200 total rewards -1064.4037100672722 total energy tensor([[179.8699]])\n",
      "[0.02895189]\n",
      "Mode: Train env_steps 200 total rewards -276.86955269798636 total energy tensor([[138.6518]])\n",
      "[-0.2073117]\n",
      "Mode: Train env_steps 200 total rewards -1389.4048655033112 total energy tensor([[186.6185]])\n",
      "[-0.65148324]\n",
      "Mode: Train env_steps 200 total rewards -766.4549816548824 total energy tensor([[181.4174]])\n",
      "[0.00200293]\n",
      "Mode: Train env_steps 200 total rewards -244.89140031626448 total energy tensor([[70.1322]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21310562]\n",
      "Mode: Test env_steps 200 total rewards -1526.9070148468018 total energy tensor([[184.1331]])\n",
      "[0.01388291]\n",
      "Mode: Test env_steps 200 total rewards -1208.858379483223 total energy tensor([[182.2827]])\n",
      "[0.51779]\n",
      "Mode: Test env_steps 200 total rewards -263.65934402286075 total energy tensor([[69.7511]])\n",
      "[0.54676414]\n",
      "Mode: Test env_steps 200 total rewards -263.48206815759477 total energy tensor([[69.4077]])\n",
      "[0.81678313]\n",
      "Mode: Test env_steps 200 total rewards -1270.841470003128 total energy tensor([[184.2464]])\n",
      "[-0.9951545]\n",
      "Mode: Test env_steps 200 total rewards -253.65175831948363 total energy tensor([[66.7641]])\n",
      "[-0.621287]\n",
      "Mode: Test env_steps 200 total rewards -238.12680468102917 total energy tensor([[94.1408]])\n",
      "[-0.6116224]\n",
      "Mode: Test env_steps 200 total rewards -256.1416569247376 total energy tensor([[70.1647]])\n",
      "[0.0026063]\n",
      "Mode: Test env_steps 200 total rewards -1386.4044778347015 total energy tensor([[184.8876]])\n",
      "[0.3044802]\n",
      "Mode: Test env_steps 200 total rewards -265.26119172797917 total energy tensor([[82.2076]])\n",
      "255000 -693.3334166001539\n",
      "[-0.5260119]\n",
      "Mode: Train env_steps 200 total rewards -1015.2139662504196 total energy tensor([[182.7406]])\n",
      "[-0.40090698]\n",
      "Mode: Train env_steps 200 total rewards -266.3472458385513 total energy tensor([[75.8142]])\n",
      "[-0.86029476]\n",
      "Mode: Train env_steps 200 total rewards -1217.6679376363754 total energy tensor([[182.8137]])\n",
      "[0.9056721]\n",
      "Mode: Train env_steps 200 total rewards -1183.3433339595795 total energy tensor([[181.5505]])\n",
      "[0.04131817]\n",
      "Mode: Train env_steps 200 total rewards -214.6439331928268 total energy tensor([[91.8546]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9659339]\n",
      "Mode: Train env_steps 200 total rewards -1194.38454246521 total energy tensor([[180.8615]])\n",
      "[0.06643764]\n",
      "Mode: Train env_steps 200 total rewards -952.0486134290695 total energy tensor([[179.2917]])\n",
      "[0.9559797]\n",
      "Mode: Train env_steps 200 total rewards -933.4413923770189 total energy tensor([[179.0003]])\n",
      "[-0.41019654]\n",
      "Mode: Train env_steps 200 total rewards -966.8426257967949 total energy tensor([[180.0983]])\n",
      "[-0.1297431]\n",
      "Mode: Train env_steps 200 total rewards -965.7718298137188 total energy tensor([[180.9018]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68523735]\n",
      "Mode: Train env_steps 200 total rewards -1072.5805982351303 total energy tensor([[181.9656]])\n",
      "[0.11492395]\n",
      "Mode: Train env_steps 200 total rewards -1530.8937964439392 total energy tensor([[166.2871]])\n",
      "[0.04779125]\n",
      "Mode: Train env_steps 200 total rewards -1093.9446321725845 total energy tensor([[180.9285]])\n",
      "[-0.04434955]\n",
      "Mode: Train env_steps 200 total rewards -871.8039364218712 total energy tensor([[178.3168]])\n",
      "[0.9088751]\n",
      "Mode: Train env_steps 200 total rewards -1457.4198071956635 total energy tensor([[176.8967]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48894873]\n",
      "Mode: Train env_steps 200 total rewards -1265.1802489757538 total energy tensor([[180.2132]])\n",
      "[-0.21866773]\n",
      "Mode: Train env_steps 200 total rewards -1494.0287351608276 total energy tensor([[188.6558]])\n",
      "[0.9424888]\n",
      "Mode: Train env_steps 200 total rewards -1431.8290452957153 total energy tensor([[191.9040]])\n",
      "[-0.258691]\n",
      "Mode: Train env_steps 200 total rewards -2.8647246009277296 total energy tensor([[25.3936]])\n",
      "[0.44898918]\n",
      "Mode: Train env_steps 200 total rewards -274.9162054359913 total energy tensor([[131.3529]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.997613]\n",
      "Mode: Train env_steps 200 total rewards -955.3880454599857 total energy tensor([[180.4385]])\n",
      "[-0.8148073]\n",
      "Mode: Train env_steps 200 total rewards -9.892652641050518 total energy tensor([[61.4708]])\n",
      "[0.8877211]\n",
      "Mode: Train env_steps 200 total rewards -1352.357833623886 total energy tensor([[186.9182]])\n",
      "[0.19722983]\n",
      "Mode: Train env_steps 200 total rewards -1209.7311819791794 total energy tensor([[180.7955]])\n",
      "[0.47225443]\n",
      "Mode: Train env_steps 200 total rewards -137.7361536063254 total energy tensor([[67.8844]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21296138]\n",
      "Mode: Test env_steps 200 total rewards -146.74926379183307 total energy tensor([[117.9181]])\n",
      "[0.40182883]\n",
      "Mode: Test env_steps 200 total rewards -260.1197118884884 total energy tensor([[82.1700]])\n",
      "[-0.65765727]\n",
      "Mode: Test env_steps 200 total rewards -1228.979786992073 total energy tensor([[181.0288]])\n",
      "[-0.5519327]\n",
      "Mode: Test env_steps 200 total rewards -141.08046634111088 total energy tensor([[82.0680]])\n",
      "[-0.2769549]\n",
      "Mode: Test env_steps 200 total rewards -1516.7653183937073 total energy tensor([[189.5518]])\n",
      "[0.82270455]\n",
      "Mode: Test env_steps 200 total rewards -1480.105221271515 total energy tensor([[192.0423]])\n",
      "[0.23335303]\n",
      "Mode: Test env_steps 200 total rewards -1306.9726586341858 total energy tensor([[182.3673]])\n",
      "[-0.56976944]\n",
      "Mode: Test env_steps 200 total rewards -1512.1288142204285 total energy tensor([[192.2922]])\n",
      "[0.8095311]\n",
      "Mode: Test env_steps 200 total rewards -1505.3346185684204 total energy tensor([[192.6741]])\n",
      "[0.3253478]\n",
      "Mode: Test env_steps 200 total rewards -1490.3638548851013 total energy tensor([[191.4058]])\n",
      "260000 -1058.8599714986863\n",
      "[0.9280574]\n",
      "Mode: Train env_steps 200 total rewards -1506.7870001792908 total energy tensor([[189.6485]])\n",
      "[0.75140625]\n",
      "Mode: Train env_steps 200 total rewards -400.6444995626807 total energy tensor([[130.4679]])\n",
      "[-0.9714611]\n",
      "Mode: Train env_steps 200 total rewards -1533.027705192566 total energy tensor([[182.4448]])\n",
      "[0.06640794]\n",
      "Mode: Train env_steps 200 total rewards -1530.5723023414612 total energy tensor([[186.7518]])\n",
      "[0.67126435]\n",
      "Mode: Train env_steps 200 total rewards -401.1210799738765 total energy tensor([[130.0814]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.73080117]\n",
      "Mode: Train env_steps 200 total rewards -1357.3450241088867 total energy tensor([[188.4460]])\n",
      "[0.6980264]\n",
      "Mode: Train env_steps 200 total rewards -399.5604213885963 total energy tensor([[124.1975]])\n",
      "[-0.07785936]\n",
      "Mode: Train env_steps 200 total rewards -963.0120263695717 total energy tensor([[182.7490]])\n",
      "[-0.6874543]\n",
      "Mode: Train env_steps 200 total rewards -1530.4384055137634 total energy tensor([[187.1027]])\n",
      "[0.6123873]\n",
      "Mode: Train env_steps 200 total rewards -356.32655751053244 total energy tensor([[106.6634]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43829095]\n",
      "Mode: Train env_steps 200 total rewards -1214.005476474762 total energy tensor([[181.0350]])\n",
      "[-0.50457174]\n",
      "Mode: Train env_steps 200 total rewards -1102.7902973890305 total energy tensor([[179.3071]])\n",
      "[0.95074683]\n",
      "Mode: Train env_steps 200 total rewards -149.15270837768912 total energy tensor([[133.7301]])\n",
      "[0.04292955]\n",
      "Mode: Train env_steps 200 total rewards -1519.8000059127808 total energy tensor([[181.7412]])\n",
      "[0.38780767]\n",
      "Mode: Train env_steps 200 total rewards -1102.3152376413345 total energy tensor([[182.2153]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4058627]\n",
      "Mode: Train env_steps 200 total rewards -860.1088908612728 total energy tensor([[183.9652]])\n",
      "[0.88636416]\n",
      "Mode: Train env_steps 200 total rewards -142.0690326106269 total energy tensor([[96.0021]])\n",
      "[0.11461487]\n",
      "Mode: Train env_steps 200 total rewards -261.1734604488083 total energy tensor([[87.5822]])\n",
      "[-0.01295843]\n",
      "Mode: Train env_steps 200 total rewards -1508.481113433838 total energy tensor([[188.6126]])\n",
      "[0.7572731]\n",
      "Mode: Train env_steps 200 total rewards -1493.274971961975 total energy tensor([[186.4583]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9327898]\n",
      "Mode: Train env_steps 200 total rewards -1069.7466064095497 total energy tensor([[178.3492]])\n",
      "[-0.24364294]\n",
      "Mode: Train env_steps 200 total rewards -1090.0818266272545 total energy tensor([[181.4897]])\n",
      "[-0.4763357]\n",
      "Mode: Train env_steps 200 total rewards -1491.6352491378784 total energy tensor([[179.1172]])\n",
      "[-0.6436584]\n",
      "Mode: Train env_steps 200 total rewards -141.75464825052768 total energy tensor([[90.4613]])\n",
      "[-0.39736703]\n",
      "Mode: Train env_steps 200 total rewards -267.5271792743297 total energy tensor([[83.0190]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.332495]\n",
      "Mode: Test env_steps 200 total rewards -492.57184049487114 total energy tensor([[168.5055]])\n",
      "[0.53776544]\n",
      "Mode: Test env_steps 200 total rewards -8.047017687465996 total energy tensor([[71.7541]])\n",
      "[-0.55508274]\n",
      "Mode: Test env_steps 200 total rewards -307.0370428785682 total energy tensor([[109.5033]])\n",
      "[-0.5111781]\n",
      "Mode: Test env_steps 200 total rewards -844.9759252145886 total energy tensor([[177.6328]])\n",
      "[0.17748041]\n",
      "Mode: Test env_steps 200 total rewards -437.9209758117795 total energy tensor([[142.0473]])\n",
      "[-0.22544107]\n",
      "Mode: Test env_steps 200 total rewards -1469.4800362586975 total energy tensor([[184.6766]])\n",
      "[0.3385803]\n",
      "Mode: Test env_steps 200 total rewards -1048.9467294812202 total energy tensor([[182.8861]])\n",
      "[0.6523363]\n",
      "Mode: Test env_steps 200 total rewards -1466.7449686527252 total energy tensor([[184.3871]])\n",
      "[-0.15454051]\n",
      "Mode: Test env_steps 200 total rewards -333.8973750276491 total energy tensor([[109.3626]])\n",
      "[0.13355035]\n",
      "Mode: Test env_steps 200 total rewards -1532.8572459220886 total energy tensor([[182.1041]])\n",
      "265000 -794.2479157429655\n",
      "[-0.53745496]\n",
      "Mode: Train env_steps 200 total rewards -1450.6563544273376 total energy tensor([[192.8367]])\n",
      "[0.47411698]\n",
      "Mode: Train env_steps 200 total rewards -249.56373097002506 total energy tensor([[122.7179]])\n",
      "[0.13595536]\n",
      "Mode: Train env_steps 200 total rewards -272.33767487015575 total energy tensor([[119.1596]])\n",
      "[0.5337962]\n",
      "Mode: Train env_steps 200 total rewards -1538.156982421875 total energy tensor([[186.9565]])\n",
      "[0.9734567]\n",
      "Mode: Train env_steps 200 total rewards -490.6538670361042 total energy tensor([[167.7334]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38428295]\n",
      "Mode: Train env_steps 200 total rewards -1345.7050173282623 total energy tensor([[184.3026]])\n",
      "[0.27050686]\n",
      "Mode: Train env_steps 200 total rewards -1503.8464698791504 total energy tensor([[191.3801]])\n",
      "[0.33752644]\n",
      "Mode: Train env_steps 200 total rewards -1481.2468404769897 total energy tensor([[184.6432]])\n",
      "[0.35938713]\n",
      "Mode: Train env_steps 200 total rewards -127.18578360101674 total energy tensor([[47.5109]])\n",
      "[0.8388106]\n",
      "Mode: Train env_steps 200 total rewards -937.8618920594454 total energy tensor([[176.2618]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6639109]\n",
      "Mode: Train env_steps 200 total rewards -122.99240743603877 total energy tensor([[36.7502]])\n",
      "[0.6964357]\n",
      "Mode: Train env_steps 200 total rewards -1533.7920627593994 total energy tensor([[183.7900]])\n",
      "[-0.574202]\n",
      "Mode: Train env_steps 200 total rewards -1468.6939153671265 total energy tensor([[183.6001]])\n",
      "[-0.5820784]\n",
      "Mode: Train env_steps 200 total rewards -135.60170236905105 total energy tensor([[56.3135]])\n",
      "[-0.5654433]\n",
      "Mode: Train env_steps 200 total rewards -1400.8743796348572 total energy tensor([[189.4607]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6655399]\n",
      "Mode: Train env_steps 200 total rewards -1212.9245649576187 total energy tensor([[181.2801]])\n",
      "[0.1675922]\n",
      "Mode: Train env_steps 200 total rewards -1067.3851971030235 total energy tensor([[182.9736]])\n",
      "[0.25786576]\n",
      "Mode: Train env_steps 200 total rewards -940.2983960211277 total energy tensor([[178.9257]])\n",
      "[-0.20981169]\n",
      "Mode: Train env_steps 200 total rewards -140.50635131564923 total energy tensor([[98.0855]])\n",
      "[-0.8696099]\n",
      "Mode: Train env_steps 200 total rewards -1273.546909570694 total energy tensor([[183.5306]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12916455]\n",
      "Mode: Train env_steps 200 total rewards -1249.9896116256714 total energy tensor([[185.1445]])\n",
      "[-0.84218127]\n",
      "Mode: Train env_steps 200 total rewards -3.523385675420286 total energy tensor([[18.9983]])\n",
      "[0.5510044]\n",
      "Mode: Train env_steps 200 total rewards -136.15960468910635 total energy tensor([[59.5639]])\n",
      "[0.12175094]\n",
      "Mode: Train env_steps 200 total rewards -497.8467349112034 total energy tensor([[152.3193]])\n",
      "[-0.93344283]\n",
      "Mode: Train env_steps 200 total rewards -265.2109177590173 total energy tensor([[94.4311]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.87721825]\n",
      "Mode: Test env_steps 200 total rewards -613.5562451630831 total energy tensor([[161.9043]])\n",
      "[0.14070094]\n",
      "Mode: Test env_steps 200 total rewards -1447.266696214676 total energy tensor([[191.8566]])\n",
      "[0.5281379]\n",
      "Mode: Test env_steps 200 total rewards -946.1618188843131 total energy tensor([[178.4187]])\n",
      "[-0.60574573]\n",
      "Mode: Test env_steps 200 total rewards -1419.7990610599518 total energy tensor([[191.4860]])\n",
      "[-0.46654007]\n",
      "Mode: Test env_steps 200 total rewards -139.63806975324405 total energy tensor([[77.9108]])\n",
      "[-0.5604707]\n",
      "Mode: Test env_steps 200 total rewards -1455.6410999298096 total energy tensor([[188.8198]])\n",
      "[0.6611049]\n",
      "Mode: Test env_steps 200 total rewards -1446.4423587322235 total energy tensor([[191.6313]])\n",
      "[-0.6210029]\n",
      "Mode: Test env_steps 200 total rewards -131.51977128791623 total energy tensor([[52.8575]])\n",
      "[-0.61176234]\n",
      "Mode: Test env_steps 200 total rewards -1264.3726298809052 total energy tensor([[184.5565]])\n",
      "[-0.5616981]\n",
      "Mode: Test env_steps 200 total rewards -1397.9027931690216 total energy tensor([[188.0027]])\n",
      "270000 -1026.2300544075144\n",
      "[0.80992365]\n",
      "Mode: Train env_steps 200 total rewards -960.7185399383307 total energy tensor([[178.8523]])\n",
      "[-0.6515511]\n",
      "Mode: Train env_steps 200 total rewards -134.58834020217182 total energy tensor([[81.4428]])\n",
      "[0.20076315]\n",
      "Mode: Train env_steps 200 total rewards -414.22164168953896 total energy tensor([[150.6711]])\n",
      "[0.45030963]\n",
      "Mode: Train env_steps 200 total rewards -137.04491938525462 total energy tensor([[70.0844]])\n",
      "[0.9883077]\n",
      "Mode: Train env_steps 200 total rewards -1195.664335489273 total energy tensor([[183.3111]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6729532]\n",
      "Mode: Train env_steps 200 total rewards -1450.2703049182892 total energy tensor([[185.1485]])\n",
      "[-0.5306889]\n",
      "Mode: Train env_steps 200 total rewards -1547.0198287963867 total energy tensor([[173.8818]])\n",
      "[0.45717898]\n",
      "Mode: Train env_steps 200 total rewards -0.912077839486301 total energy tensor([[10.0157]])\n",
      "[0.10952987]\n",
      "Mode: Train env_steps 200 total rewards -1488.692536830902 total energy tensor([[190.5542]])\n",
      "[-0.07276752]\n",
      "Mode: Train env_steps 200 total rewards -249.31552285328507 total energy tensor([[121.1563]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92601365]\n",
      "Mode: Train env_steps 200 total rewards -1327.4210314750671 total energy tensor([[183.4845]])\n",
      "[0.3661065]\n",
      "Mode: Train env_steps 200 total rewards -1536.5107049942017 total energy tensor([[189.2310]])\n",
      "[-0.07050778]\n",
      "Mode: Train env_steps 200 total rewards -485.26877263979986 total energy tensor([[114.4164]])\n",
      "[-0.31607196]\n",
      "Mode: Train env_steps 200 total rewards -123.6696140919812 total energy tensor([[32.0834]])\n",
      "[0.8937532]\n",
      "Mode: Train env_steps 200 total rewards -966.5243141055107 total energy tensor([[183.0237]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.861947]\n",
      "Mode: Train env_steps 200 total rewards -132.6606385750929 total energy tensor([[59.9732]])\n",
      "[0.19608504]\n",
      "Mode: Train env_steps 200 total rewards -813.699910454452 total energy tensor([[183.9338]])\n",
      "[-0.53327703]\n",
      "Mode: Train env_steps 200 total rewards -945.2844897806644 total energy tensor([[180.6647]])\n",
      "[0.41532946]\n",
      "Mode: Train env_steps 200 total rewards -1528.047224521637 total energy tensor([[187.5137]])\n",
      "[-0.7607433]\n",
      "Mode: Train env_steps 200 total rewards -810.6193655580282 total energy tensor([[184.7414]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27196613]\n",
      "Mode: Train env_steps 200 total rewards -1444.753164768219 total energy tensor([[186.8816]])\n",
      "[-0.18702151]\n",
      "Mode: Train env_steps 200 total rewards -1413.194316625595 total energy tensor([[185.4626]])\n",
      "[-0.5957176]\n",
      "Mode: Train env_steps 200 total rewards -6.451456246446469 total energy tensor([[41.7683]])\n",
      "[0.4883557]\n",
      "Mode: Train env_steps 200 total rewards -1213.9635844230652 total energy tensor([[182.7101]])\n",
      "[0.85487247]\n",
      "Mode: Train env_steps 200 total rewards -1470.268714427948 total energy tensor([[191.1484]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71379936]\n",
      "Mode: Test env_steps 200 total rewards -1055.2812628746033 total energy tensor([[178.1566]])\n",
      "[-0.7332962]\n",
      "Mode: Test env_steps 200 total rewards -137.77233221754432 total energy tensor([[71.0010]])\n",
      "[0.40549222]\n",
      "Mode: Test env_steps 200 total rewards -1341.8414633274078 total energy tensor([[186.6813]])\n",
      "[-0.4515074]\n",
      "Mode: Test env_steps 200 total rewards -990.7308961749077 total energy tensor([[178.0788]])\n",
      "[0.18956034]\n",
      "Mode: Test env_steps 200 total rewards -1530.345341682434 total energy tensor([[183.5302]])\n",
      "[-0.9579636]\n",
      "Mode: Test env_steps 200 total rewards -1315.3570268154144 total energy tensor([[185.9495]])\n",
      "[-0.5003909]\n",
      "Mode: Test env_steps 200 total rewards -1368.6881835460663 total energy tensor([[185.2798]])\n",
      "[0.27778822]\n",
      "Mode: Test env_steps 200 total rewards -1507.1232376098633 total energy tensor([[186.2501]])\n",
      "[-0.12444454]\n",
      "Mode: Test env_steps 200 total rewards -1472.0700016021729 total energy tensor([[187.2137]])\n",
      "[-0.44780657]\n",
      "Mode: Test env_steps 200 total rewards -1026.5967225432396 total energy tensor([[175.1854]])\n",
      "275000 -1174.5806468393653\n",
      "[0.077772]\n",
      "Mode: Train env_steps 200 total rewards -1470.4826493263245 total energy tensor([[193.4166]])\n",
      "[-0.8252043]\n",
      "Mode: Train env_steps 200 total rewards -1063.3354435563087 total energy tensor([[174.2793]])\n",
      "[-0.36242095]\n",
      "Mode: Train env_steps 200 total rewards -138.94231536239386 total energy tensor([[76.9087]])\n",
      "[0.13792343]\n",
      "Mode: Train env_steps 200 total rewards -151.11445921298582 total energy tensor([[91.7141]])\n",
      "[-0.39122272]\n",
      "Mode: Train env_steps 200 total rewards -1425.7101140022278 total energy tensor([[186.8217]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56837684]\n",
      "Mode: Train env_steps 200 total rewards -145.8336945772171 total energy tensor([[118.9255]])\n",
      "[0.60874134]\n",
      "Mode: Train env_steps 200 total rewards -1457.700912952423 total energy tensor([[194.0495]])\n",
      "[-0.969319]\n",
      "Mode: Train env_steps 200 total rewards -136.02205952149234 total energy tensor([[63.8884]])\n",
      "[-0.6976475]\n",
      "Mode: Train env_steps 200 total rewards -126.94880938250571 total energy tensor([[28.9936]])\n",
      "[0.6960189]\n",
      "Mode: Train env_steps 200 total rewards -132.71509758150205 total energy tensor([[28.7368]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.85274273]\n",
      "Mode: Train env_steps 200 total rewards -1354.8662645816803 total energy tensor([[183.4347]])\n",
      "[0.34570843]\n",
      "Mode: Train env_steps 200 total rewards -2.792183888319414 total energy tensor([[25.7547]])\n",
      "[0.46977636]\n",
      "Mode: Train env_steps 200 total rewards -1521.127640247345 total energy tensor([[187.8211]])\n",
      "[-0.15732166]\n",
      "Mode: Train env_steps 200 total rewards -132.7357909588609 total energy tensor([[65.4487]])\n",
      "[-0.87124664]\n",
      "Mode: Train env_steps 200 total rewards -1376.4164686203003 total energy tensor([[184.7437]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6367003]\n",
      "Mode: Train env_steps 200 total rewards -1201.7682620286942 total energy tensor([[179.3294]])\n",
      "[-0.42003328]\n",
      "Mode: Train env_steps 200 total rewards -1279.8989052772522 total energy tensor([[182.0356]])\n",
      "[0.20539586]\n",
      "Mode: Train env_steps 200 total rewards -261.39298020210117 total energy tensor([[101.4445]])\n",
      "[0.14732005]\n",
      "Mode: Train env_steps 200 total rewards -966.9770008772612 total energy tensor([[182.2724]])\n",
      "[0.8234053]\n",
      "Mode: Train env_steps 200 total rewards -1394.1200771331787 total energy tensor([[184.8299]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6067022]\n",
      "Mode: Train env_steps 200 total rewards -1502.4521484375 total energy tensor([[178.6094]])\n",
      "[-0.08386162]\n",
      "Mode: Train env_steps 200 total rewards -849.1873576194048 total energy tensor([[177.9957]])\n",
      "[-0.51509047]\n",
      "Mode: Train env_steps 200 total rewards -916.0034271627665 total energy tensor([[181.3526]])\n",
      "[0.2737925]\n",
      "Mode: Train env_steps 200 total rewards -1062.7434731721878 total energy tensor([[181.9337]])\n",
      "[-0.34694368]\n",
      "Mode: Train env_steps 200 total rewards -131.07109923067037 total energy tensor([[36.0481]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.625326]\n",
      "Mode: Test env_steps 200 total rewards -1535.2758693695068 total energy tensor([[181.2927]])\n",
      "[-0.11896811]\n",
      "Mode: Test env_steps 200 total rewards -1541.8094482421875 total energy tensor([[184.2292]])\n",
      "[0.75679547]\n",
      "Mode: Test env_steps 200 total rewards -1449.7304763793945 total energy tensor([[185.7952]])\n",
      "[0.53117096]\n",
      "Mode: Test env_steps 200 total rewards -265.9650954012759 total energy tensor([[88.1816]])\n",
      "[0.0309937]\n",
      "Mode: Test env_steps 200 total rewards -276.3344490788877 total energy tensor([[123.2088]])\n",
      "[-0.8489351]\n",
      "Mode: Test env_steps 200 total rewards -1209.950374364853 total energy tensor([[177.0376]])\n",
      "[-0.6623452]\n",
      "Mode: Test env_steps 200 total rewards -272.9119357597083 total energy tensor([[112.6303]])\n",
      "[0.7519885]\n",
      "Mode: Test env_steps 200 total rewards -1220.8055229187012 total energy tensor([[177.2296]])\n",
      "[-0.42201552]\n",
      "Mode: Test env_steps 200 total rewards -1432.8832573890686 total energy tensor([[179.2404]])\n",
      "[0.90607995]\n",
      "Mode: Test env_steps 200 total rewards -1414.2804369926453 total energy tensor([[180.9010]])\n",
      "280000 -1061.994686589623\n",
      "[-0.8037198]\n",
      "Mode: Train env_steps 200 total rewards -277.721207851544 total energy tensor([[119.3212]])\n",
      "[0.38059622]\n",
      "Mode: Train env_steps 200 total rewards -376.58597071236 total energy tensor([[107.9695]])\n",
      "[-0.8999305]\n",
      "Mode: Train env_steps 200 total rewards -1537.1375274658203 total energy tensor([[185.2049]])\n",
      "[0.83513147]\n",
      "Mode: Train env_steps 200 total rewards -1344.5303926467896 total energy tensor([[182.7016]])\n",
      "[0.34881294]\n",
      "Mode: Train env_steps 200 total rewards -268.73432466201484 total energy tensor([[100.4613]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94767076]\n",
      "Mode: Train env_steps 200 total rewards -965.0372073352337 total energy tensor([[179.0593]])\n",
      "[-0.26028872]\n",
      "Mode: Train env_steps 200 total rewards -1248.2077059745789 total energy tensor([[180.5041]])\n",
      "[0.75075644]\n",
      "Mode: Train env_steps 200 total rewards -276.93865614011884 total energy tensor([[134.0287]])\n",
      "[-0.8369549]\n",
      "Mode: Train env_steps 200 total rewards -273.8264555595815 total energy tensor([[111.1215]])\n",
      "[0.49526802]\n",
      "Mode: Train env_steps 200 total rewards -252.93275772733614 total energy tensor([[119.7492]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15450697]\n",
      "Mode: Train env_steps 200 total rewards -1056.6543467640877 total energy tensor([[179.3127]])\n",
      "[-0.29443514]\n",
      "Mode: Train env_steps 200 total rewards -1368.1985421180725 total energy tensor([[185.1409]])\n",
      "[-0.43962047]\n",
      "Mode: Train env_steps 200 total rewards -142.44425966311246 total energy tensor([[94.0422]])\n",
      "[-0.31712124]\n",
      "Mode: Train env_steps 200 total rewards -265.90189521946013 total energy tensor([[92.6135]])\n",
      "[-0.8057203]\n",
      "Mode: Train env_steps 200 total rewards -1091.293868303299 total energy tensor([[181.4103]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69841295]\n",
      "Mode: Train env_steps 200 total rewards -735.7823434919119 total energy tensor([[179.2675]])\n",
      "[-0.1457772]\n",
      "Mode: Train env_steps 200 total rewards -734.7077592015266 total energy tensor([[173.0731]])\n",
      "[0.10912191]\n",
      "Mode: Train env_steps 200 total rewards -1185.6317394971848 total energy tensor([[179.8708]])\n",
      "[0.21880504]\n",
      "Mode: Train env_steps 200 total rewards -1381.1951010227203 total energy tensor([[174.5046]])\n",
      "[-0.5260817]\n",
      "Mode: Train env_steps 200 total rewards -1492.1148931980133 total energy tensor([[169.0739]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.70335865]\n",
      "Mode: Train env_steps 200 total rewards -135.27490700408816 total energy tensor([[53.6702]])\n",
      "[0.04033511]\n",
      "Mode: Train env_steps 200 total rewards -1025.532309949398 total energy tensor([[180.2708]])\n",
      "[-0.17193383]\n",
      "Mode: Train env_steps 200 total rewards -1498.1406717300415 total energy tensor([[184.7945]])\n",
      "[0.99225557]\n",
      "Mode: Train env_steps 200 total rewards -1466.025948047638 total energy tensor([[184.7786]])\n",
      "[-0.63466966]\n",
      "Mode: Train env_steps 200 total rewards -1372.1921787261963 total energy tensor([[183.8207]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.747364]\n",
      "Mode: Test env_steps 200 total rewards -131.8748473166488 total energy tensor([[41.5942]])\n",
      "[0.5662945]\n",
      "Mode: Test env_steps 200 total rewards -138.9556742515415 total energy tensor([[73.1298]])\n",
      "[-0.9975291]\n",
      "Mode: Test env_steps 200 total rewards -922.7029239162803 total energy tensor([[176.5671]])\n",
      "[-0.12486968]\n",
      "Mode: Test env_steps 200 total rewards -9.168001553975046 total energy tensor([[53.9082]])\n",
      "[0.24025491]\n",
      "Mode: Test env_steps 200 total rewards -124.8117455583997 total energy tensor([[41.6482]])\n",
      "[0.39293432]\n",
      "Mode: Test env_steps 200 total rewards -1504.0794234275818 total energy tensor([[189.2909]])\n",
      "[-0.718772]\n",
      "Mode: Test env_steps 200 total rewards -1504.4457259178162 total energy tensor([[189.6204]])\n",
      "[-0.46087942]\n",
      "Mode: Test env_steps 200 total rewards -1415.5942397117615 total energy tensor([[180.9236]])\n",
      "[0.5008209]\n",
      "Mode: Test env_steps 200 total rewards -133.27707817906048 total energy tensor([[61.0066]])\n",
      "[0.861127]\n",
      "Mode: Test env_steps 200 total rewards -7.949803236871958 total energy tensor([[50.5253]])\n",
      "285000 -589.2859463069938\n",
      "[0.9865562]\n",
      "Mode: Train env_steps 200 total rewards -1522.2892007827759 total energy tensor([[181.4708]])\n",
      "[-0.50380725]\n",
      "Mode: Train env_steps 200 total rewards -1154.8661086559296 total energy tensor([[181.7105]])\n",
      "[-0.24241921]\n",
      "Mode: Train env_steps 200 total rewards -1325.6213192939758 total energy tensor([[181.7123]])\n",
      "[0.35045215]\n",
      "Mode: Train env_steps 200 total rewards -968.0129473805428 total energy tensor([[177.5485]])\n",
      "[0.4974865]\n",
      "Mode: Train env_steps 200 total rewards -1059.347898542881 total energy tensor([[180.7464]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5006938]\n",
      "Mode: Train env_steps 200 total rewards -495.31198651343584 total energy tensor([[180.8808]])\n",
      "[0.32011637]\n",
      "Mode: Train env_steps 200 total rewards -138.37239199969918 total energy tensor([[63.4342]])\n",
      "[0.0704919]\n",
      "Mode: Train env_steps 200 total rewards -1317.9340417385101 total energy tensor([[186.3328]])\n",
      "[-0.7815629]\n",
      "Mode: Train env_steps 200 total rewards -1275.3383247852325 total energy tensor([[182.0558]])\n",
      "[-0.30686614]\n",
      "Mode: Train env_steps 200 total rewards -1357.4668757915497 total energy tensor([[185.9768]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6932322]\n",
      "Mode: Train env_steps 200 total rewards -11.225346027873456 total energy tensor([[76.1798]])\n",
      "[-0.13609387]\n",
      "Mode: Train env_steps 200 total rewards -1463.8188829421997 total energy tensor([[192.5795]])\n",
      "[0.1502779]\n",
      "Mode: Train env_steps 200 total rewards -256.0798239290016 total energy tensor([[109.7464]])\n",
      "[0.34666738]\n",
      "Mode: Train env_steps 200 total rewards -228.58432915550657 total energy tensor([[111.9505]])\n",
      "[-0.8223486]\n",
      "Mode: Train env_steps 200 total rewards -932.3288978338242 total energy tensor([[182.6013]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.85200745]\n",
      "Mode: Train env_steps 200 total rewards -8.055132682435215 total energy tensor([[49.7427]])\n",
      "[-0.25788888]\n",
      "Mode: Train env_steps 200 total rewards -264.7374688833952 total energy tensor([[107.1630]])\n",
      "[-0.36663395]\n",
      "Mode: Train env_steps 200 total rewards -257.00172531604767 total energy tensor([[117.1794]])\n",
      "[0.38627356]\n",
      "Mode: Train env_steps 200 total rewards -1389.4725215435028 total energy tensor([[179.6761]])\n",
      "[-0.21607459]\n",
      "Mode: Train env_steps 200 total rewards -9.070020344806835 total energy tensor([[57.9946]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.662341]\n",
      "Mode: Train env_steps 200 total rewards -1489.3684902191162 total energy tensor([[185.9430]])\n",
      "[0.71634364]\n",
      "Mode: Train env_steps 200 total rewards -1405.839740037918 total energy tensor([[179.0739]])\n",
      "[-0.5455284]\n",
      "Mode: Train env_steps 200 total rewards -850.1827808246017 total energy tensor([[175.4441]])\n",
      "[0.36789253]\n",
      "Mode: Train env_steps 200 total rewards -270.49708511307836 total energy tensor([[95.6183]])\n",
      "[0.67742336]\n",
      "Mode: Train env_steps 200 total rewards -1212.17047560215 total energy tensor([[177.1631]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32493442]\n",
      "Mode: Test env_steps 200 total rewards -1018.7195118665695 total energy tensor([[182.9265]])\n",
      "[0.32492587]\n",
      "Mode: Test env_steps 200 total rewards -128.02455144532723 total energy tensor([[41.2892]])\n",
      "[-0.46273005]\n",
      "Mode: Test env_steps 200 total rewards -133.75986453023506 total energy tensor([[38.6901]])\n",
      "[-0.10662103]\n",
      "Mode: Test env_steps 200 total rewards -135.29625839041546 total energy tensor([[70.3459]])\n",
      "[0.5961762]\n",
      "Mode: Test env_steps 200 total rewards -134.24719977000495 total energy tensor([[40.7754]])\n",
      "[-0.7754869]\n",
      "Mode: Test env_steps 200 total rewards -1532.3181686401367 total energy tensor([[184.2526]])\n",
      "[-0.955757]\n",
      "Mode: Test env_steps 200 total rewards -139.57183001935482 total energy tensor([[81.2680]])\n",
      "[0.8214033]\n",
      "Mode: Test env_steps 200 total rewards -1514.602843284607 total energy tensor([[181.1195]])\n",
      "[0.36146542]\n",
      "Mode: Test env_steps 200 total rewards -255.7371902987361 total energy tensor([[146.0744]])\n",
      "[-0.8734043]\n",
      "Mode: Test env_steps 200 total rewards -134.4589929349022 total energy tensor([[57.2824]])\n",
      "290000 -512.6736411180289\n",
      "[0.7774292]\n",
      "Mode: Train env_steps 200 total rewards -135.259935738286 total energy tensor([[62.0284]])\n",
      "[-0.25542766]\n",
      "Mode: Train env_steps 200 total rewards -1472.871113538742 total energy tensor([[180.8775]])\n",
      "[-0.7542154]\n",
      "Mode: Train env_steps 200 total rewards -5.872018941794522 total energy tensor([[41.6285]])\n",
      "[-0.05330594]\n",
      "Mode: Train env_steps 200 total rewards -1379.7497835159302 total energy tensor([[183.2253]])\n",
      "[-0.7364925]\n",
      "Mode: Train env_steps 200 total rewards -1408.4732456207275 total energy tensor([[183.6902]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5128145]\n",
      "Mode: Train env_steps 200 total rewards -262.0931372847408 total energy tensor([[96.1418]])\n",
      "[-0.93985724]\n",
      "Mode: Train env_steps 200 total rewards -245.19047070713714 total energy tensor([[76.7604]])\n",
      "[0.06941812]\n",
      "Mode: Train env_steps 200 total rewards -1374.5355088710785 total energy tensor([[185.6763]])\n",
      "[-0.3677624]\n",
      "Mode: Train env_steps 200 total rewards -267.4618748854846 total energy tensor([[93.8416]])\n",
      "[-0.2932092]\n",
      "Mode: Train env_steps 200 total rewards -212.97254588082433 total energy tensor([[115.1502]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22385544]\n",
      "Mode: Train env_steps 200 total rewards -965.4362235367298 total energy tensor([[180.0948]])\n",
      "[-0.52055055]\n",
      "Mode: Train env_steps 200 total rewards -1532.159513950348 total energy tensor([[184.0185]])\n",
      "[0.7569191]\n",
      "Mode: Train env_steps 200 total rewards -1241.096309542656 total energy tensor([[179.0301]])\n",
      "[0.13765734]\n",
      "Mode: Train env_steps 200 total rewards -1351.5451588630676 total energy tensor([[180.5597]])\n",
      "[-0.4971775]\n",
      "Mode: Train env_steps 200 total rewards -967.7695759534836 total energy tensor([[179.6864]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22518986]\n",
      "Mode: Train env_steps 200 total rewards -1230.74358355999 total energy tensor([[178.3349]])\n",
      "[0.6354784]\n",
      "Mode: Train env_steps 200 total rewards -249.60138955782168 total energy tensor([[93.4952]])\n",
      "[0.8841657]\n",
      "Mode: Train env_steps 200 total rewards -242.5501524778083 total energy tensor([[62.1232]])\n",
      "[0.4091193]\n",
      "Mode: Train env_steps 200 total rewards -140.71853037318215 total energy tensor([[82.1601]])\n",
      "[-0.17688613]\n",
      "Mode: Train env_steps 200 total rewards -972.3275779783726 total energy tensor([[180.0554]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08058128]\n",
      "Mode: Train env_steps 200 total rewards -1390.453510761261 total energy tensor([[183.6357]])\n",
      "[0.3490535]\n",
      "Mode: Train env_steps 200 total rewards -1500.736970424652 total energy tensor([[178.9286]])\n",
      "[-0.73881775]\n",
      "Mode: Train env_steps 200 total rewards -266.3272377066314 total energy tensor([[89.8823]])\n",
      "[-0.69322217]\n",
      "Mode: Train env_steps 200 total rewards -1220.3107401132584 total energy tensor([[177.1308]])\n",
      "[-0.23027518]\n",
      "Mode: Train env_steps 200 total rewards -978.2420545220375 total energy tensor([[181.5230]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.726978]\n",
      "Mode: Test env_steps 200 total rewards -1412.604237318039 total energy tensor([[182.3527]])\n",
      "[-0.611677]\n",
      "Mode: Test env_steps 200 total rewards -249.18292688392103 total energy tensor([[101.4200]])\n",
      "[-0.5298272]\n",
      "Mode: Test env_steps 200 total rewards -367.82216793112457 total energy tensor([[108.0263]])\n",
      "[0.6688856]\n",
      "Mode: Test env_steps 200 total rewards -132.56861584173748 total energy tensor([[38.8165]])\n",
      "[0.13416022]\n",
      "Mode: Test env_steps 200 total rewards -1532.208014011383 total energy tensor([[181.8417]])\n",
      "[0.8068186]\n",
      "Mode: Test env_steps 200 total rewards -729.8272126317024 total energy tensor([[172.1725]])\n",
      "[0.3032235]\n",
      "Mode: Test env_steps 200 total rewards -125.82140030432492 total energy tensor([[48.8423]])\n",
      "[0.24455765]\n",
      "Mode: Test env_steps 200 total rewards -133.2331978493312 total energy tensor([[40.3799]])\n",
      "[-0.9032977]\n",
      "Mode: Test env_steps 200 total rewards -1251.1156482696533 total energy tensor([[181.5616]])\n",
      "[0.98231894]\n",
      "Mode: Test env_steps 200 total rewards -131.68253627605736 total energy tensor([[49.1340]])\n",
      "295000 -606.6065957317275\n",
      "[-0.11305195]\n",
      "Mode: Train env_steps 200 total rewards -126.54253263387363 total energy tensor([[36.1018]])\n",
      "[0.13558301]\n",
      "Mode: Train env_steps 200 total rewards -132.48889499733923 total energy tensor([[37.6828]])\n",
      "[0.83433825]\n",
      "Mode: Train env_steps 200 total rewards -133.1432094500633 total energy tensor([[41.5556]])\n",
      "[-0.62497216]\n",
      "Mode: Train env_steps 200 total rewards -248.02960548363626 total energy tensor([[98.4670]])\n",
      "[-0.9241544]\n",
      "Mode: Train env_steps 200 total rewards -1514.7401490211487 total energy tensor([[184.6791]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38285866]\n",
      "Mode: Train env_steps 200 total rewards -274.4179890798405 total energy tensor([[121.3335]])\n",
      "[-0.63506997]\n",
      "Mode: Train env_steps 200 total rewards -10.374398603336886 total energy tensor([[58.4279]])\n",
      "[-0.32539657]\n",
      "Mode: Train env_steps 200 total rewards -135.1829243991524 total energy tensor([[43.8552]])\n",
      "[0.7847519]\n",
      "Mode: Train env_steps 200 total rewards -10.971054538153112 total energy tensor([[63.7970]])\n",
      "[0.24598329]\n",
      "Mode: Train env_steps 200 total rewards -131.1086522617843 total energy tensor([[50.1632]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53439915]\n",
      "Mode: Train env_steps 200 total rewards -1092.9532714486122 total energy tensor([[175.1976]])\n",
      "[0.5956345]\n",
      "Mode: Train env_steps 200 total rewards -1378.076474905014 total energy tensor([[172.5822]])\n",
      "[-0.77916276]\n",
      "Mode: Train env_steps 200 total rewards -1.6355861031915992 total energy tensor([[21.5703]])\n",
      "[-0.4101871]\n",
      "Mode: Train env_steps 200 total rewards -1356.7742166519165 total energy tensor([[174.2658]])\n",
      "[0.21721654]\n",
      "Mode: Train env_steps 200 total rewards -129.27116664909408 total energy tensor([[29.4435]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3578789]\n",
      "Mode: Train env_steps 200 total rewards -1416.552269935608 total energy tensor([[182.4718]])\n",
      "[-0.26112843]\n",
      "Mode: Train env_steps 200 total rewards -1536.8701567649841 total energy tensor([[183.3129]])\n",
      "[0.57878864]\n",
      "Mode: Train env_steps 200 total rewards -242.3732016432332 total energy tensor([[70.6230]])\n",
      "[0.21116592]\n",
      "Mode: Train env_steps 200 total rewards -1482.327612876892 total energy tensor([[179.2234]])\n",
      "[-0.44243622]\n",
      "Mode: Train env_steps 200 total rewards -1432.9898858070374 total energy tensor([[178.3559]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80833614]\n",
      "Mode: Train env_steps 200 total rewards -1409.8455610275269 total energy tensor([[179.2448]])\n",
      "[-0.1545744]\n",
      "Mode: Train env_steps 200 total rewards -135.8323203343898 total energy tensor([[58.3562]])\n",
      "[0.43024108]\n",
      "Mode: Train env_steps 200 total rewards -1403.6804752349854 total energy tensor([[175.5772]])\n",
      "[-0.62355757]\n",
      "Mode: Train env_steps 200 total rewards -1370.4338607788086 total energy tensor([[178.9057]])\n",
      "[0.4302963]\n",
      "Mode: Train env_steps 200 total rewards -131.64086326875258 total energy tensor([[47.7564]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24194925]\n",
      "Mode: Test env_steps 200 total rewards -1429.900237083435 total energy tensor([[178.2750]])\n",
      "[-0.8404172]\n",
      "Mode: Test env_steps 200 total rewards -1432.3491127490997 total energy tensor([[177.5423]])\n",
      "[0.22424084]\n",
      "Mode: Test env_steps 200 total rewards -1542.900460243225 total energy tensor([[179.4695]])\n",
      "[-0.39343733]\n",
      "Mode: Test env_steps 200 total rewards -265.9774716936663 total energy tensor([[92.1544]])\n",
      "[0.7971657]\n",
      "Mode: Test env_steps 200 total rewards -725.8268643519841 total energy tensor([[145.2484]])\n",
      "[0.39365306]\n",
      "Mode: Test env_steps 200 total rewards -1399.8774485588074 total energy tensor([[180.2422]])\n",
      "[-0.64260405]\n",
      "Mode: Test env_steps 200 total rewards -1274.5350658893585 total energy tensor([[182.9625]])\n",
      "[-0.70148844]\n",
      "Mode: Test env_steps 200 total rewards -1479.0085368156433 total energy tensor([[188.5788]])\n",
      "[-0.58445233]\n",
      "Mode: Test env_steps 200 total rewards -1376.1705813407898 total energy tensor([[183.8754]])\n",
      "[-0.7914206]\n",
      "Mode: Test env_steps 200 total rewards -1499.6501920223236 total energy tensor([[178.1235]])\n",
      "300000 -1242.6195970748333\n",
      "[-0.31156793]\n",
      "Mode: Train env_steps 200 total rewards -1487.010966539383 total energy tensor([[181.9437]])\n",
      "[0.8345303]\n",
      "Mode: Train env_steps 200 total rewards -1332.8507025241852 total energy tensor([[184.0565]])\n",
      "[-0.38984647]\n",
      "Mode: Train env_steps 200 total rewards -1415.2937424182892 total energy tensor([[179.0180]])\n",
      "[0.39730924]\n",
      "Mode: Train env_steps 200 total rewards -263.90416215727237 total energy tensor([[86.5117]])\n",
      "[-0.4237317]\n",
      "Mode: Train env_steps 200 total rewards -140.71988918061834 total energy tensor([[90.4776]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25610796]\n",
      "Mode: Train env_steps 200 total rewards -1202.8791242837906 total energy tensor([[180.2708]])\n",
      "[-0.99279886]\n",
      "Mode: Train env_steps 200 total rewards -1032.7386425733566 total energy tensor([[177.8296]])\n",
      "[-0.62226886]\n",
      "Mode: Train env_steps 200 total rewards -1253.070841550827 total energy tensor([[177.5314]])\n",
      "[0.25697702]\n",
      "Mode: Train env_steps 200 total rewards -141.72958687040955 total energy tensor([[87.7746]])\n",
      "[0.14952856]\n",
      "Mode: Train env_steps 200 total rewards -36.8912812769413 total energy tensor([[71.8524]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9307051]\n",
      "Mode: Train env_steps 200 total rewards -1548.538092136383 total energy tensor([[177.4229]])\n",
      "[-0.32612926]\n",
      "Mode: Train env_steps 200 total rewards -1099.495627462864 total energy tensor([[175.3016]])\n",
      "[0.9241388]\n",
      "Mode: Train env_steps 200 total rewards -984.3069943785667 total energy tensor([[180.2254]])\n",
      "[-0.97009486]\n",
      "Mode: Train env_steps 200 total rewards -1119.8972162008286 total energy tensor([[175.4170]])\n",
      "[0.4946902]\n",
      "Mode: Train env_steps 200 total rewards -1238.0505411624908 total energy tensor([[177.5751]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9011183]\n",
      "Mode: Train env_steps 200 total rewards -235.4543666113168 total energy tensor([[120.1446]])\n",
      "[-0.7339791]\n",
      "Mode: Train env_steps 200 total rewards -725.4401003941894 total energy tensor([[162.3930]])\n",
      "[-0.47934058]\n",
      "Mode: Train env_steps 200 total rewards -1485.3155007362366 total energy tensor([[193.7068]])\n",
      "[-0.6769449]\n",
      "Mode: Train env_steps 200 total rewards -127.91587973292917 total energy tensor([[39.7768]])\n",
      "[0.34597522]\n",
      "Mode: Train env_steps 200 total rewards -1204.5580879449844 total energy tensor([[178.9604]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53737354]\n",
      "Mode: Train env_steps 200 total rewards -130.25688722915947 total energy tensor([[29.2183]])\n",
      "[-0.24118935]\n",
      "Mode: Train env_steps 200 total rewards -489.043512545526 total energy tensor([[142.4836]])\n",
      "[-0.2883475]\n",
      "Mode: Train env_steps 200 total rewards -129.06867154838983 total energy tensor([[30.8323]])\n",
      "[0.8205209]\n",
      "Mode: Train env_steps 200 total rewards -130.843679767102 total energy tensor([[33.0520]])\n",
      "[-0.25007868]\n",
      "Mode: Train env_steps 200 total rewards -130.2159302807413 total energy tensor([[29.8891]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52876973]\n",
      "Mode: Test env_steps 200 total rewards -272.14388216659427 total energy tensor([[105.4037]])\n",
      "[-0.4492058]\n",
      "Mode: Test env_steps 200 total rewards -270.9550033606356 total energy tensor([[83.7075]])\n",
      "[-0.9271708]\n",
      "Mode: Test env_steps 200 total rewards -1441.7628819942474 total energy tensor([[175.3291]])\n",
      "[0.35857266]\n",
      "Mode: Test env_steps 200 total rewards -488.5269326120615 total energy tensor([[122.7643]])\n",
      "[0.52144235]\n",
      "Mode: Test env_steps 200 total rewards -1333.8193078041077 total energy tensor([[181.7732]])\n",
      "[-0.36131507]\n",
      "Mode: Test env_steps 200 total rewards -231.53626849502325 total energy tensor([[122.4692]])\n",
      "[0.9054684]\n",
      "Mode: Test env_steps 200 total rewards -1443.9446806907654 total energy tensor([[173.3856]])\n",
      "[0.11132459]\n",
      "Mode: Test env_steps 200 total rewards -1301.3481504917145 total energy tensor([[180.2063]])\n",
      "[0.49327174]\n",
      "Mode: Test env_steps 200 total rewards -1228.5457904338837 total energy tensor([[181.1693]])\n",
      "[-0.24405]\n",
      "Mode: Test env_steps 200 total rewards -268.8456141259521 total energy tensor([[100.1577]])\n",
      "305000 -828.1428512174986\n",
      "[0.0473206]\n",
      "Mode: Train env_steps 200 total rewards -262.8975675040856 total energy tensor([[87.1425]])\n",
      "[0.07918]\n",
      "Mode: Train env_steps 200 total rewards -376.7811576910317 total energy tensor([[106.4753]])\n",
      "[-0.86784965]\n",
      "Mode: Train env_steps 200 total rewards -1489.5747718811035 total energy tensor([[194.8527]])\n",
      "[0.4110882]\n",
      "Mode: Train env_steps 200 total rewards -9.266943644732237 total energy tensor([[64.1322]])\n",
      "[0.8931404]\n",
      "Mode: Train env_steps 200 total rewards -1460.89697599411 total energy tensor([[174.5154]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9323003]\n",
      "Mode: Train env_steps 200 total rewards -1255.0867664813995 total energy tensor([[179.3418]])\n",
      "[0.9007021]\n",
      "Mode: Train env_steps 200 total rewards -1197.0499877929688 total energy tensor([[180.8089]])\n",
      "[0.39708656]\n",
      "Mode: Train env_steps 200 total rewards -1456.3821086883545 total energy tensor([[189.8236]])\n",
      "[-0.19729346]\n",
      "Mode: Train env_steps 200 total rewards -149.25272250720445 total energy tensor([[96.3145]])\n",
      "[-0.3574464]\n",
      "Mode: Train env_steps 200 total rewards -1488.3886151313782 total energy tensor([[190.8093]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36243483]\n",
      "Mode: Train env_steps 200 total rewards -1518.08736038208 total energy tensor([[190.9603]])\n",
      "[0.91488343]\n",
      "Mode: Train env_steps 200 total rewards -1415.896758556366 total energy tensor([[185.9231]])\n",
      "[-0.10953213]\n",
      "Mode: Train env_steps 200 total rewards -137.70676897885278 total energy tensor([[71.4469]])\n",
      "[0.71425617]\n",
      "Mode: Train env_steps 200 total rewards -1199.896591424942 total energy tensor([[179.2748]])\n",
      "[0.03686193]\n",
      "Mode: Train env_steps 200 total rewards -1415.1672780513763 total energy tensor([[185.4918]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47865954]\n",
      "Mode: Train env_steps 200 total rewards -1275.9811000823975 total energy tensor([[180.9008]])\n",
      "[0.76211345]\n",
      "Mode: Train env_steps 200 total rewards -1382.8896825313568 total energy tensor([[181.5728]])\n",
      "[-0.1645504]\n",
      "Mode: Train env_steps 200 total rewards -270.1181505105924 total energy tensor([[83.2329]])\n",
      "[-0.19168536]\n",
      "Mode: Train env_steps 200 total rewards -1057.511205971241 total energy tensor([[180.9281]])\n",
      "[-0.26500046]\n",
      "Mode: Train env_steps 200 total rewards -1027.046085268259 total energy tensor([[179.4832]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33360258]\n",
      "Mode: Train env_steps 200 total rewards -1250.0513439178467 total energy tensor([[177.0551]])\n",
      "[0.5155769]\n",
      "Mode: Train env_steps 200 total rewards -1505.992525100708 total energy tensor([[190.0193]])\n",
      "[-0.5296704]\n",
      "Mode: Train env_steps 200 total rewards -165.70268876850605 total energy tensor([[104.7266]])\n",
      "[0.76335835]\n",
      "Mode: Train env_steps 200 total rewards -253.1836795322597 total energy tensor([[103.1018]])\n",
      "[-0.33254853]\n",
      "Mode: Train env_steps 200 total rewards -1530.8097047805786 total energy tensor([[180.3409]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26204175]\n",
      "Mode: Test env_steps 200 total rewards -1463.7393827438354 total energy tensor([[175.9873]])\n",
      "[0.22279339]\n",
      "Mode: Test env_steps 200 total rewards -252.39406230300665 total energy tensor([[131.6830]])\n",
      "[0.93018526]\n",
      "Mode: Test env_steps 200 total rewards -136.8753925046185 total energy tensor([[63.3130]])\n",
      "[-0.08465977]\n",
      "Mode: Test env_steps 200 total rewards -1294.1207659244537 total energy tensor([[177.4624]])\n",
      "[0.09985865]\n",
      "Mode: Test env_steps 200 total rewards -1518.6245098114014 total energy tensor([[191.6447]])\n",
      "[0.342008]\n",
      "Mode: Test env_steps 200 total rewards -853.3807619027793 total energy tensor([[167.5037]])\n",
      "[0.14411862]\n",
      "Mode: Test env_steps 200 total rewards -4.164699116488919 total energy tensor([[41.4943]])\n",
      "[0.3998619]\n",
      "Mode: Test env_steps 200 total rewards -14.019592585304054 total energy tensor([[107.9978]])\n",
      "[-0.23115516]\n",
      "Mode: Test env_steps 200 total rewards -131.4869138095528 total energy tensor([[66.1142]])\n",
      "[0.9505916]\n",
      "Mode: Test env_steps 200 total rewards -1246.6142808198929 total energy tensor([[176.9476]])\n",
      "310000 -691.5420361521334\n",
      "[0.73002005]\n",
      "Mode: Train env_steps 200 total rewards -491.61865593492985 total energy tensor([[146.2264]])\n",
      "[-0.85529345]\n",
      "Mode: Train env_steps 200 total rewards -251.49190120771527 total energy tensor([[124.5847]])\n",
      "[0.9263383]\n",
      "Mode: Train env_steps 200 total rewards -6.063426708802581 total energy tensor([[53.9736]])\n",
      "[-0.08448967]\n",
      "Mode: Train env_steps 200 total rewards -135.43343040905893 total energy tensor([[61.7431]])\n",
      "[-0.39980423]\n",
      "Mode: Train env_steps 200 total rewards -135.04634647071362 total energy tensor([[66.7326]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53158885]\n",
      "Mode: Train env_steps 200 total rewards -252.23069244413637 total energy tensor([[109.9695]])\n",
      "[-0.48810837]\n",
      "Mode: Train env_steps 200 total rewards -275.4932632360142 total energy tensor([[103.8993]])\n",
      "[0.6441372]\n",
      "Mode: Train env_steps 200 total rewards -250.60186290810816 total energy tensor([[102.2737]])\n",
      "[0.15477921]\n",
      "Mode: Train env_steps 200 total rewards -577.2653739713132 total energy tensor([[156.6452]])\n",
      "[0.30058154]\n",
      "Mode: Train env_steps 200 total rewards -1258.3239798545837 total energy tensor([[177.0556]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7354964]\n",
      "Mode: Train env_steps 200 total rewards -1106.0377915501595 total energy tensor([[179.4349]])\n",
      "[-0.25484875]\n",
      "Mode: Train env_steps 200 total rewards -1337.8799731731415 total energy tensor([[180.2345]])\n",
      "[0.8579775]\n",
      "Mode: Train env_steps 200 total rewards -132.27860316971783 total energy tensor([[34.8090]])\n",
      "[-0.98055124]\n",
      "Mode: Train env_steps 200 total rewards -457.1979111582041 total energy tensor([[159.5991]])\n",
      "[-0.85908175]\n",
      "Mode: Train env_steps 200 total rewards -1528.402638912201 total energy tensor([[186.6263]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95034057]\n",
      "Mode: Train env_steps 200 total rewards -1335.3743855953217 total energy tensor([[174.7037]])\n",
      "[-0.50110424]\n",
      "Mode: Train env_steps 200 total rewards -631.2727074325085 total energy tensor([[162.7870]])\n",
      "[0.10355525]\n",
      "Mode: Train env_steps 200 total rewards -548.5000777859241 total energy tensor([[144.4968]])\n",
      "[-0.8924427]\n",
      "Mode: Train env_steps 200 total rewards -490.8505092188716 total energy tensor([[128.0649]])\n",
      "[-0.82060176]\n",
      "Mode: Train env_steps 200 total rewards -1511.9944162368774 total energy tensor([[188.8204]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5599737]\n",
      "Mode: Train env_steps 200 total rewards -141.0602514827624 total energy tensor([[84.6401]])\n",
      "[-0.46076757]\n",
      "Mode: Train env_steps 200 total rewards -267.53263218305074 total energy tensor([[89.5919]])\n",
      "[0.13589832]\n",
      "Mode: Train env_steps 200 total rewards -493.99397768080235 total energy tensor([[144.7154]])\n",
      "[0.8650994]\n",
      "Mode: Train env_steps 200 total rewards -1214.5998154878616 total energy tensor([[177.1916]])\n",
      "[0.68085194]\n",
      "Mode: Train env_steps 200 total rewards -1247.853298664093 total energy tensor([[172.9052]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16029003]\n",
      "Mode: Test env_steps 200 total rewards -140.2481858804822 total energy tensor([[82.1995]])\n",
      "[0.7630229]\n",
      "Mode: Test env_steps 200 total rewards -267.9757034378126 total energy tensor([[88.1918]])\n",
      "[-0.04654777]\n",
      "Mode: Test env_steps 200 total rewards -1362.5463864803314 total energy tensor([[179.6512]])\n",
      "[0.0838143]\n",
      "Mode: Test env_steps 200 total rewards -269.917743941769 total energy tensor([[89.4874]])\n",
      "[-0.16839848]\n",
      "Mode: Test env_steps 200 total rewards -378.5037010819651 total energy tensor([[122.2078]])\n",
      "[-0.98956156]\n",
      "Mode: Test env_steps 200 total rewards -1472.0419673919678 total energy tensor([[188.0060]])\n",
      "[-0.14150967]\n",
      "Mode: Test env_steps 200 total rewards -268.61879911087453 total energy tensor([[96.2258]])\n",
      "[0.53774285]\n",
      "Mode: Test env_steps 200 total rewards -616.5834798635915 total energy tensor([[123.5131]])\n",
      "[0.60345924]\n",
      "Mode: Test env_steps 200 total rewards -139.38812689646147 total energy tensor([[79.0656]])\n",
      "[0.31059894]\n",
      "Mode: Test env_steps 200 total rewards -1253.5214400291443 total energy tensor([[177.5089]])\n",
      "315000 -616.93455341144\n",
      "[0.04003337]\n",
      "Mode: Train env_steps 200 total rewards -1526.83677816391 total energy tensor([[188.6870]])\n",
      "[-0.4198987]\n",
      "Mode: Train env_steps 200 total rewards -268.2529186690226 total energy tensor([[85.2479]])\n",
      "[0.4821555]\n",
      "Mode: Train env_steps 200 total rewards -1311.8808698654175 total energy tensor([[176.3805]])\n",
      "[-0.8470406]\n",
      "Mode: Train env_steps 200 total rewards -729.3862738369498 total energy tensor([[132.4460]])\n",
      "[0.25660113]\n",
      "Mode: Train env_steps 200 total rewards -1216.5369758605957 total energy tensor([[173.8856]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47479263]\n",
      "Mode: Train env_steps 200 total rewards -728.0227275043726 total energy tensor([[135.7873]])\n",
      "[0.9555491]\n",
      "Mode: Train env_steps 200 total rewards -131.39071232522838 total energy tensor([[35.1608]])\n",
      "[0.28854683]\n",
      "Mode: Train env_steps 200 total rewards -130.7909765318036 total energy tensor([[26.9759]])\n",
      "[0.41952673]\n",
      "Mode: Train env_steps 200 total rewards -249.40926858130842 total energy tensor([[92.4834]])\n",
      "[-0.81491005]\n",
      "Mode: Train env_steps 200 total rewards -3.5687991129234433 total energy tensor([[23.3189]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9799957]\n",
      "Mode: Train env_steps 200 total rewards -378.1979024371831 total energy tensor([[105.2333]])\n",
      "[0.9297469]\n",
      "Mode: Train env_steps 200 total rewards -269.6573544610292 total energy tensor([[100.1764]])\n",
      "[-0.7208517]\n",
      "Mode: Train env_steps 200 total rewards -1358.6316108703613 total energy tensor([[182.1788]])\n",
      "[-0.3313597]\n",
      "Mode: Train env_steps 200 total rewards -1311.4285039901733 total energy tensor([[181.0398]])\n",
      "[-0.38448945]\n",
      "Mode: Train env_steps 200 total rewards -1455.9978413581848 total energy tensor([[190.0611]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8981742]\n",
      "Mode: Train env_steps 200 total rewards -269.38208753056824 total energy tensor([[97.4921]])\n",
      "[0.22973482]\n",
      "Mode: Train env_steps 200 total rewards -1360.4231958389282 total energy tensor([[183.2610]])\n",
      "[-0.7517619]\n",
      "Mode: Train env_steps 200 total rewards -140.1179400170222 total energy tensor([[79.3517]])\n",
      "[-0.71576834]\n",
      "Mode: Train env_steps 200 total rewards -269.1425991235301 total energy tensor([[96.5760]])\n",
      "[0.41836193]\n",
      "Mode: Train env_steps 200 total rewards -270.3556145876646 total energy tensor([[96.2409]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6527573]\n",
      "Mode: Train env_steps 200 total rewards -1239.9028700590134 total energy tensor([[179.1089]])\n",
      "[-0.46406016]\n",
      "Mode: Train env_steps 200 total rewards -1249.688908815384 total energy tensor([[180.1082]])\n",
      "[-0.12591033]\n",
      "Mode: Train env_steps 200 total rewards -1278.407788515091 total energy tensor([[181.2619]])\n",
      "[-0.45018202]\n",
      "Mode: Train env_steps 200 total rewards -272.5108929760754 total energy tensor([[102.4655]])\n",
      "[0.6547308]\n",
      "Mode: Train env_steps 200 total rewards -15.233661718666553 total energy tensor([[90.5839]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28043246]\n",
      "Mode: Test env_steps 200 total rewards -140.9147834070027 total energy tensor([[85.5588]])\n",
      "[0.28930226]\n",
      "Mode: Test env_steps 200 total rewards -1233.2565732002258 total energy tensor([[175.4277]])\n",
      "[-0.6274575]\n",
      "Mode: Test env_steps 200 total rewards -976.4791844040155 total energy tensor([[171.5231]])\n",
      "[-0.38388973]\n",
      "Mode: Test env_steps 200 total rewards -488.88771874134545 total energy tensor([[119.6517]])\n",
      "[-0.06105342]\n",
      "Mode: Test env_steps 200 total rewards -487.8514938047156 total energy tensor([[115.2875]])\n",
      "[-0.24247076]\n",
      "Mode: Test env_steps 200 total rewards -1504.4500184059143 total energy tensor([[189.6753]])\n",
      "[0.76627815]\n",
      "Mode: Test env_steps 200 total rewards -1405.675940990448 total energy tensor([[173.3216]])\n",
      "[0.9364882]\n",
      "Mode: Test env_steps 200 total rewards -140.510137620382 total energy tensor([[64.9676]])\n",
      "[0.9073573]\n",
      "Mode: Test env_steps 200 total rewards -372.3705321828602 total energy tensor([[94.3598]])\n",
      "[0.7219104]\n",
      "Mode: Test env_steps 200 total rewards -1281.9038906097412 total energy tensor([[177.6158]])\n",
      "320000 -803.2300273366651\n",
      "[-0.2634026]\n",
      "Mode: Train env_steps 200 total rewards -1312.7164628505707 total energy tensor([[178.1282]])\n",
      "[0.4729726]\n",
      "Mode: Train env_steps 200 total rewards -1359.1049365997314 total energy tensor([[180.2132]])\n",
      "[-0.19855873]\n",
      "Mode: Train env_steps 200 total rewards -250.98383974074386 total energy tensor([[96.0151]])\n",
      "[0.28952906]\n",
      "Mode: Train env_steps 200 total rewards -226.85463429614902 total energy tensor([[102.8278]])\n",
      "[0.3479425]\n",
      "Mode: Train env_steps 200 total rewards -1112.8181688189507 total energy tensor([[172.0047]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4291974]\n",
      "Mode: Train env_steps 200 total rewards -973.1226631551981 total energy tensor([[165.7893]])\n",
      "[0.73025286]\n",
      "Mode: Train env_steps 200 total rewards -1268.3331084251404 total energy tensor([[179.9358]])\n",
      "[0.3442368]\n",
      "Mode: Train env_steps 200 total rewards -1519.5777702331543 total energy tensor([[182.6407]])\n",
      "[0.84012604]\n",
      "Mode: Train env_steps 200 total rewards -1204.109480023384 total energy tensor([[177.6840]])\n",
      "[0.19248755]\n",
      "Mode: Train env_steps 200 total rewards -1246.1255087852478 total energy tensor([[177.1382]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47074637]\n",
      "Mode: Train env_steps 200 total rewards -1149.0547018051147 total energy tensor([[181.9828]])\n",
      "[0.18641362]\n",
      "Mode: Train env_steps 200 total rewards -263.62811319809407 total energy tensor([[84.8277]])\n",
      "[-0.04623818]\n",
      "Mode: Train env_steps 200 total rewards -373.53061387722846 total energy tensor([[109.3792]])\n",
      "[0.4546723]\n",
      "Mode: Train env_steps 200 total rewards -140.154611803242 total energy tensor([[83.8889]])\n",
      "[-0.18575501]\n",
      "Mode: Train env_steps 200 total rewards -268.2763408633182 total energy tensor([[88.8564]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42010966]\n",
      "Mode: Train env_steps 200 total rewards -243.869184687268 total energy tensor([[92.9841]])\n",
      "[-0.2463755]\n",
      "Mode: Train env_steps 200 total rewards -1099.1334705352783 total energy tensor([[177.6784]])\n",
      "[0.22038224]\n",
      "Mode: Train env_steps 200 total rewards -141.03500557289226 total energy tensor([[83.6951]])\n",
      "[0.76157516]\n",
      "Mode: Train env_steps 200 total rewards -266.0830562063493 total energy tensor([[100.9259]])\n",
      "[-0.3316804]\n",
      "Mode: Train env_steps 200 total rewards -1179.554226398468 total energy tensor([[174.1588]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18397322]\n",
      "Mode: Train env_steps 200 total rewards -133.43953229532053 total energy tensor([[44.4479]])\n",
      "[0.39331]\n",
      "Mode: Train env_steps 200 total rewards -1340.7819101810455 total energy tensor([[177.2413]])\n",
      "[0.12611525]\n",
      "Mode: Train env_steps 200 total rewards -132.63399675185792 total energy tensor([[39.1210]])\n",
      "[0.9159563]\n",
      "Mode: Train env_steps 200 total rewards -133.93053197860718 total energy tensor([[39.0718]])\n",
      "[0.5394583]\n",
      "Mode: Train env_steps 200 total rewards -1097.7203621864319 total energy tensor([[175.3071]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10810603]\n",
      "Mode: Test env_steps 200 total rewards -1327.7953383922577 total energy tensor([[165.3178]])\n",
      "[0.19966973]\n",
      "Mode: Test env_steps 200 total rewards -490.8343472518027 total energy tensor([[134.9069]])\n",
      "[0.98068964]\n",
      "Mode: Test env_steps 200 total rewards -1077.5686511397362 total energy tensor([[175.8228]])\n",
      "[-0.15582414]\n",
      "Mode: Test env_steps 200 total rewards -1190.9642934799194 total energy tensor([[171.0556]])\n",
      "[-0.2218884]\n",
      "Mode: Test env_steps 200 total rewards -1434.8880541324615 total energy tensor([[176.6363]])\n",
      "[0.9043209]\n",
      "Mode: Test env_steps 200 total rewards -489.2966451882385 total energy tensor([[126.6114]])\n",
      "[-0.73327744]\n",
      "Mode: Test env_steps 200 total rewards -1458.834320306778 total energy tensor([[176.0938]])\n",
      "[-0.53719807]\n",
      "Mode: Test env_steps 200 total rewards -227.44965321896598 total energy tensor([[83.1494]])\n",
      "[-0.41800967]\n",
      "Mode: Test env_steps 200 total rewards -1356.4850733280182 total energy tensor([[170.5329]])\n",
      "[0.4059279]\n",
      "Mode: Test env_steps 200 total rewards -1455.3990862369537 total energy tensor([[166.4434]])\n",
      "325000 -1050.951546267513\n",
      "[-0.7715875]\n",
      "Mode: Train env_steps 200 total rewards -488.5339672511909 total energy tensor([[123.7400]])\n",
      "[-0.5115352]\n",
      "Mode: Train env_steps 200 total rewards -730.1267334064469 total energy tensor([[141.2674]])\n",
      "[0.7221138]\n",
      "Mode: Train env_steps 200 total rewards -371.1340698709246 total energy tensor([[100.7742]])\n",
      "[0.2821681]\n",
      "Mode: Train env_steps 200 total rewards -1369.543844461441 total energy tensor([[165.9360]])\n",
      "[-0.6032053]\n",
      "Mode: Train env_steps 200 total rewards -490.3232352347113 total energy tensor([[130.0623]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38208234]\n",
      "Mode: Train env_steps 200 total rewards -1431.9465820789337 total energy tensor([[175.3874]])\n",
      "[-0.39110687]\n",
      "Mode: Train env_steps 200 total rewards -1516.8529381752014 total energy tensor([[190.1044]])\n",
      "[-0.00195288]\n",
      "Mode: Train env_steps 200 total rewards -378.29857313330285 total energy tensor([[112.5823]])\n",
      "[0.9874803]\n",
      "Mode: Train env_steps 200 total rewards -492.5625333599746 total energy tensor([[145.6777]])\n",
      "[0.00859032]\n",
      "Mode: Train env_steps 200 total rewards -378.86046418966725 total energy tensor([[112.2189]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12079439]\n",
      "Mode: Train env_steps 200 total rewards -621.6546216309071 total energy tensor([[147.9349]])\n",
      "[0.3840779]\n",
      "Mode: Train env_steps 200 total rewards -604.8395551368594 total energy tensor([[145.0339]])\n",
      "[-0.28794304]\n",
      "Mode: Train env_steps 200 total rewards -1277.1425080299377 total energy tensor([[177.2162]])\n",
      "[-0.3931282]\n",
      "Mode: Train env_steps 200 total rewards -379.72076609171927 total energy tensor([[111.1629]])\n",
      "[0.12671949]\n",
      "Mode: Train env_steps 200 total rewards -731.5179696977139 total energy tensor([[148.3952]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.76718456]\n",
      "Mode: Train env_steps 200 total rewards -1281.6350164413452 total energy tensor([[178.3143]])\n",
      "[0.78506845]\n",
      "Mode: Train env_steps 200 total rewards -267.4027211656794 total energy tensor([[102.7969]])\n",
      "[0.20447747]\n",
      "Mode: Train env_steps 200 total rewards -267.33164430595934 total energy tensor([[103.9948]])\n",
      "[0.09711897]\n",
      "Mode: Train env_steps 200 total rewards -142.1462818318978 total energy tensor([[92.7294]])\n",
      "[-0.7148232]\n",
      "Mode: Train env_steps 200 total rewards -264.55216896161437 total energy tensor([[109.8037]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03487772]\n",
      "Mode: Train env_steps 200 total rewards -267.80608742311597 total energy tensor([[84.4135]])\n",
      "[0.18960537]\n",
      "Mode: Train env_steps 200 total rewards -263.35920743690804 total energy tensor([[83.9619]])\n",
      "[0.3906646]\n",
      "Mode: Train env_steps 200 total rewards -268.7322208331898 total energy tensor([[89.3209]])\n",
      "[-0.52579534]\n",
      "Mode: Train env_steps 200 total rewards -1321.9301455020905 total energy tensor([[182.7290]])\n",
      "[-0.6178784]\n",
      "Mode: Train env_steps 200 total rewards -1123.6746318936348 total energy tensor([[179.2362]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5819651]\n",
      "Mode: Test env_steps 200 total rewards -253.64627311273944 total energy tensor([[105.4072]])\n",
      "[-0.04488922]\n",
      "Mode: Test env_steps 200 total rewards -730.0244493216742 total energy tensor([[135.8481]])\n",
      "[-0.22260222]\n",
      "Mode: Test env_steps 200 total rewards -604.9699709643901 total energy tensor([[121.3230]])\n",
      "[0.94992006]\n",
      "Mode: Test env_steps 200 total rewards -271.0176478875801 total energy tensor([[88.3422]])\n",
      "[0.652114]\n",
      "Mode: Test env_steps 200 total rewards -139.03275607532123 total energy tensor([[74.2558]])\n",
      "[0.49504557]\n",
      "Mode: Test env_steps 200 total rewards -1100.4640849232674 total energy tensor([[176.6422]])\n",
      "[-0.30056715]\n",
      "Mode: Test env_steps 200 total rewards -1375.7994632720947 total energy tensor([[180.0739]])\n",
      "[0.6467604]\n",
      "Mode: Test env_steps 200 total rewards -1516.8468976020813 total energy tensor([[184.7042]])\n",
      "[-0.98165685]\n",
      "Mode: Test env_steps 200 total rewards -253.86573198402766 total energy tensor([[101.8042]])\n",
      "[0.9039274]\n",
      "Mode: Test env_steps 200 total rewards -254.78748013603035 total energy tensor([[104.4044]])\n",
      "330000 -650.0454755279206\n",
      "[0.18239404]\n",
      "Mode: Train env_steps 200 total rewards -270.53522019134834 total energy tensor([[90.6393]])\n",
      "[-0.61084723]\n",
      "Mode: Train env_steps 200 total rewards -1230.1973977088928 total energy tensor([[175.9609]])\n",
      "[-0.16177434]\n",
      "Mode: Train env_steps 200 total rewards -266.67729840707034 total energy tensor([[84.1291]])\n",
      "[-0.8835653]\n",
      "Mode: Train env_steps 200 total rewards -1441.1863327026367 total energy tensor([[183.1675]])\n",
      "[0.17226508]\n",
      "Mode: Train env_steps 200 total rewards -1382.9811532497406 total energy tensor([[178.5537]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98627853]\n",
      "Mode: Train env_steps 200 total rewards -1528.3153162002563 total energy tensor([[186.9752]])\n",
      "[0.8444085]\n",
      "Mode: Train env_steps 200 total rewards -132.40688125655652 total energy tensor([[20.2814]])\n",
      "[-0.84316885]\n",
      "Mode: Train env_steps 200 total rewards -226.73627283237875 total energy tensor([[98.6205]])\n",
      "[-0.23069231]\n",
      "Mode: Train env_steps 200 total rewards -153.25030169449747 total energy tensor([[94.1202]])\n",
      "[0.51564467]\n",
      "Mode: Train env_steps 200 total rewards -376.05543174175546 total energy tensor([[87.2320]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23989876]\n",
      "Mode: Train env_steps 200 total rewards -245.39666522690095 total energy tensor([[80.5831]])\n",
      "[0.53002024]\n",
      "Mode: Train env_steps 200 total rewards -1339.2237222194672 total energy tensor([[165.4512]])\n",
      "[-0.13017997]\n",
      "Mode: Train env_steps 200 total rewards -1404.499310016632 total energy tensor([[163.0079]])\n",
      "[-0.7526504]\n",
      "Mode: Train env_steps 200 total rewards -160.98279198957607 total energy tensor([[75.8162]])\n",
      "[0.17128597]\n",
      "Mode: Train env_steps 200 total rewards -1268.788194656372 total energy tensor([[167.5968]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13014156]\n",
      "Mode: Train env_steps 200 total rewards -1302.8225433826447 total energy tensor([[176.1126]])\n",
      "[0.01450047]\n",
      "Mode: Train env_steps 200 total rewards -1330.4155695438385 total energy tensor([[176.9965]])\n",
      "[-0.36076266]\n",
      "Mode: Train env_steps 200 total rewards -1099.7123021483421 total energy tensor([[175.3170]])\n",
      "[-0.3830586]\n",
      "Mode: Train env_steps 200 total rewards -129.42317989561707 total energy tensor([[70.8992]])\n",
      "[-0.19421756]\n",
      "Mode: Train env_steps 200 total rewards -11.605977891013026 total energy tensor([[77.0699]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6920961]\n",
      "Mode: Train env_steps 200 total rewards -228.85454746708274 total energy tensor([[122.8532]])\n",
      "[0.80356216]\n",
      "Mode: Train env_steps 200 total rewards -1259.4254801273346 total energy tensor([[170.7913]])\n",
      "[0.66538554]\n",
      "Mode: Train env_steps 200 total rewards -1304.1327424049377 total energy tensor([[173.4385]])\n",
      "[-0.7418197]\n",
      "Mode: Train env_steps 200 total rewards -1347.1293714046478 total energy tensor([[173.2159]])\n",
      "[0.09407995]\n",
      "Mode: Train env_steps 200 total rewards -7.256985890096985 total energy tensor([[42.9062]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10855576]\n",
      "Mode: Test env_steps 200 total rewards -1148.3458700180054 total energy tensor([[169.8737]])\n",
      "[-0.40473092]\n",
      "Mode: Test env_steps 200 total rewards -245.9279129532806 total energy tensor([[75.3054]])\n",
      "[-0.80044234]\n",
      "Mode: Test env_steps 200 total rewards -1513.0858855247498 total energy tensor([[189.7984]])\n",
      "[-0.7999211]\n",
      "Mode: Test env_steps 200 total rewards -142.3031656909734 total energy tensor([[91.8936]])\n",
      "[0.16544285]\n",
      "Mode: Test env_steps 200 total rewards -1227.6420924663544 total energy tensor([[172.0708]])\n",
      "[0.43335316]\n",
      "Mode: Test env_steps 200 total rewards -265.6394769619219 total energy tensor([[80.9422]])\n",
      "[0.3493629]\n",
      "Mode: Test env_steps 200 total rewards -263.3079842873849 total energy tensor([[82.8512]])\n",
      "[-0.5052657]\n",
      "Mode: Test env_steps 200 total rewards -267.66551094315946 total energy tensor([[92.7588]])\n",
      "[0.30422807]\n",
      "Mode: Test env_steps 200 total rewards -489.7374934530817 total energy tensor([[105.5637]])\n",
      "[0.79539835]\n",
      "Mode: Test env_steps 200 total rewards -268.0925762662664 total energy tensor([[86.5446]])\n",
      "335000 -583.1747968565178\n",
      "[-0.00988982]\n",
      "Mode: Train env_steps 200 total rewards -1483.7627437114716 total energy tensor([[174.5170]])\n",
      "[0.09778076]\n",
      "Mode: Train env_steps 200 total rewards -1236.3352452516556 total energy tensor([[173.6874]])\n",
      "[-0.9614284]\n",
      "Mode: Train env_steps 200 total rewards -257.24513372039655 total energy tensor([[83.0129]])\n",
      "[0.11700583]\n",
      "Mode: Train env_steps 200 total rewards -1228.612029671669 total energy tensor([[171.8329]])\n",
      "[0.8568501]\n",
      "Mode: Train env_steps 200 total rewards -1375.118912935257 total energy tensor([[166.4894]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43709534]\n",
      "Mode: Train env_steps 200 total rewards -1163.2996765971184 total energy tensor([[172.0579]])\n",
      "[0.27701813]\n",
      "Mode: Train env_steps 200 total rewards -1364.5160944461823 total energy tensor([[172.9253]])\n",
      "[-0.30033073]\n",
      "Mode: Train env_steps 200 total rewards -266.622592412401 total energy tensor([[85.9686]])\n",
      "[-0.699353]\n",
      "Mode: Train env_steps 200 total rewards -230.31207591854036 total energy tensor([[78.6720]])\n",
      "[-0.3809955]\n",
      "Mode: Train env_steps 200 total rewards -1478.2604327201843 total energy tensor([[195.9509]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5652337]\n",
      "Mode: Train env_steps 200 total rewards -271.5115865524858 total energy tensor([[103.2774]])\n",
      "[-0.20672677]\n",
      "Mode: Train env_steps 200 total rewards -270.38602896779776 total energy tensor([[104.3052]])\n",
      "[-0.5050904]\n",
      "Mode: Train env_steps 200 total rewards -141.29662500551785 total energy tensor([[87.4295]])\n",
      "[-0.54016155]\n",
      "Mode: Train env_steps 200 total rewards -141.5905761832837 total energy tensor([[92.0053]])\n",
      "[0.14215812]\n",
      "Mode: Train env_steps 200 total rewards -138.42716590111377 total energy tensor([[70.6145]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7894558]\n",
      "Mode: Train env_steps 200 total rewards -349.169936809456 total energy tensor([[95.8425]])\n",
      "[-0.97185177]\n",
      "Mode: Train env_steps 200 total rewards -141.4866916211322 total energy tensor([[93.3722]])\n",
      "[0.70253414]\n",
      "Mode: Train env_steps 200 total rewards -731.274448633194 total energy tensor([[132.2449]])\n",
      "[-0.21673357]\n",
      "Mode: Train env_steps 200 total rewards -245.39800496767566 total energy tensor([[74.9443]])\n",
      "[-0.08050297]\n",
      "Mode: Train env_steps 200 total rewards -1246.42389190197 total energy tensor([[171.8556]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7718009]\n",
      "Mode: Train env_steps 200 total rewards -377.4918765150942 total energy tensor([[96.4318]])\n",
      "[-0.31113687]\n",
      "Mode: Train env_steps 200 total rewards -1168.8236643075943 total energy tensor([[174.7482]])\n",
      "[-0.1581627]\n",
      "Mode: Train env_steps 200 total rewards -501.9557065013796 total energy tensor([[110.0959]])\n",
      "[-0.871804]\n",
      "Mode: Train env_steps 200 total rewards -1378.5504822731018 total energy tensor([[171.9920]])\n",
      "[0.3108507]\n",
      "Mode: Train env_steps 200 total rewards -1500.5421385765076 total energy tensor([[198.1334]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24763972]\n",
      "Mode: Test env_steps 200 total rewards -249.28658782038838 total energy tensor([[94.7699]])\n",
      "[-0.36032224]\n",
      "Mode: Test env_steps 200 total rewards -1510.2499899864197 total energy tensor([[193.2802]])\n",
      "[-0.2760648]\n",
      "Mode: Test env_steps 200 total rewards -127.44093776820228 total energy tensor([[38.4363]])\n",
      "[0.92133915]\n",
      "Mode: Test env_steps 200 total rewards -133.5067827226594 total energy tensor([[47.2164]])\n",
      "[-0.578523]\n",
      "Mode: Test env_steps 200 total rewards -1239.3091939091682 total energy tensor([[166.7876]])\n",
      "[0.24893786]\n",
      "Mode: Test env_steps 200 total rewards -134.72203376109246 total energy tensor([[49.9057]])\n",
      "[0.28102553]\n",
      "Mode: Test env_steps 200 total rewards -133.58005555998534 total energy tensor([[45.4970]])\n",
      "[0.15011838]\n",
      "Mode: Test env_steps 200 total rewards -246.25470844376832 total energy tensor([[90.4220]])\n",
      "[-0.10437966]\n",
      "Mode: Test env_steps 200 total rewards -124.83636606298387 total energy tensor([[42.4500]])\n",
      "[0.98632544]\n",
      "Mode: Test env_steps 200 total rewards -1243.5034455060959 total energy tensor([[166.0387]])\n",
      "340000 -514.2690101540763\n",
      "[-0.789254]\n",
      "Mode: Train env_steps 200 total rewards -250.3908259565942 total energy tensor([[101.1400]])\n",
      "[0.98978287]\n",
      "Mode: Train env_steps 200 total rewards -4.245105111018347 total energy tensor([[26.0671]])\n",
      "[0.38792711]\n",
      "Mode: Train env_steps 200 total rewards -11.614232625812292 total energy tensor([[64.6435]])\n",
      "[-0.63752824]\n",
      "Mode: Train env_steps 200 total rewards -249.72035443782806 total energy tensor([[97.3680]])\n",
      "[-0.3494773]\n",
      "Mode: Train env_steps 200 total rewards -1371.1597828865051 total energy tensor([[173.5617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98274964]\n",
      "Mode: Train env_steps 200 total rewards -251.81683235242963 total energy tensor([[100.8501]])\n",
      "[-0.5196544]\n",
      "Mode: Train env_steps 200 total rewards -1444.09783244133 total energy tensor([[188.5605]])\n",
      "[0.9985991]\n",
      "Mode: Train env_steps 200 total rewards -139.00384208842297 total energy tensor([[73.5318]])\n",
      "[0.39476946]\n",
      "Mode: Train env_steps 200 total rewards -1394.290195941925 total energy tensor([[179.0119]])\n",
      "[0.36403853]\n",
      "Mode: Train env_steps 200 total rewards -246.33317294251174 total energy tensor([[89.6670]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08164295]\n",
      "Mode: Train env_steps 200 total rewards -1485.1171441078186 total energy tensor([[178.7955]])\n",
      "[-0.54913825]\n",
      "Mode: Train env_steps 200 total rewards -146.75907550938427 total energy tensor([[128.6878]])\n",
      "[-0.02929159]\n",
      "Mode: Train env_steps 200 total rewards -1333.4119925498962 total energy tensor([[165.8203]])\n",
      "[-0.05653412]\n",
      "Mode: Train env_steps 200 total rewards -1256.312217950821 total energy tensor([[163.2877]])\n",
      "[-0.8107942]\n",
      "Mode: Train env_steps 200 total rewards -1512.0919342041016 total energy tensor([[188.6422]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6147832]\n",
      "Mode: Train env_steps 200 total rewards -263.7329404470511 total energy tensor([[66.4947]])\n",
      "[0.6062899]\n",
      "Mode: Train env_steps 200 total rewards -263.4082602635026 total energy tensor([[69.9922]])\n",
      "[-0.18601617]\n",
      "Mode: Train env_steps 200 total rewards -375.6157926786691 total energy tensor([[98.6573]])\n",
      "[0.8448727]\n",
      "Mode: Train env_steps 200 total rewards -1511.305989742279 total energy tensor([[175.9929]])\n",
      "[0.2985555]\n",
      "Mode: Train env_steps 200 total rewards -730.1513028342742 total energy tensor([[116.0546]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14755115]\n",
      "Mode: Train env_steps 200 total rewards -730.8347668673377 total energy tensor([[115.7534]])\n",
      "[0.7763052]\n",
      "Mode: Train env_steps 200 total rewards -145.4620483603212 total energy tensor([[108.8401]])\n",
      "[-0.7633934]\n",
      "Mode: Train env_steps 200 total rewards -374.2904781086836 total energy tensor([[93.3238]])\n",
      "[0.6005019]\n",
      "Mode: Train env_steps 200 total rewards -1537.5867500305176 total energy tensor([[185.9873]])\n",
      "[-0.8120743]\n",
      "Mode: Train env_steps 200 total rewards -609.857443149094 total energy tensor([[101.6069]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5552693]\n",
      "Mode: Test env_steps 200 total rewards -245.98983081639744 total energy tensor([[80.4552]])\n",
      "[0.59948957]\n",
      "Mode: Test env_steps 200 total rewards -1098.4261725097895 total energy tensor([[170.1772]])\n",
      "[-0.30928633]\n",
      "Mode: Test env_steps 200 total rewards -1512.8427057266235 total energy tensor([[173.7172]])\n",
      "[0.63158923]\n",
      "Mode: Test env_steps 200 total rewards -142.12195454910398 total energy tensor([[100.2739]])\n",
      "[0.41606143]\n",
      "Mode: Test env_steps 200 total rewards -1094.766315130517 total energy tensor([[164.4128]])\n",
      "[-0.5872992]\n",
      "Mode: Test env_steps 200 total rewards -1398.0596010684967 total energy tensor([[166.5909]])\n",
      "[-0.17890105]\n",
      "Mode: Test env_steps 200 total rewards -1409.334064245224 total energy tensor([[168.6078]])\n",
      "[0.35155016]\n",
      "Mode: Test env_steps 200 total rewards -385.70212129107676 total energy tensor([[98.4288]])\n",
      "[0.2625595]\n",
      "Mode: Test env_steps 200 total rewards -370.6535450833617 total energy tensor([[86.1267]])\n",
      "[-0.46012676]\n",
      "Mode: Test env_steps 200 total rewards -1500.6588616371155 total energy tensor([[175.7706]])\n",
      "345000 -915.8555172057706\n",
      "[-0.24698651]\n",
      "Mode: Train env_steps 200 total rewards -974.2364962971333 total energy tensor([[148.3514]])\n",
      "[0.7148489]\n",
      "Mode: Train env_steps 200 total rewards -482.67365405044984 total energy tensor([[105.1500]])\n",
      "[-0.40519178]\n",
      "Mode: Train env_steps 200 total rewards -603.1101593491621 total energy tensor([[111.7840]])\n",
      "[0.11559742]\n",
      "Mode: Train env_steps 200 total rewards -1266.489988207817 total energy tensor([[172.2705]])\n",
      "[-0.37274808]\n",
      "Mode: Train env_steps 200 total rewards -483.82048150355695 total energy tensor([[109.7021]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84739834]\n",
      "Mode: Train env_steps 200 total rewards -137.73408502619714 total energy tensor([[78.9316]])\n",
      "[-0.01567863]\n",
      "Mode: Train env_steps 200 total rewards -1315.5663394927979 total energy tensor([[167.7603]])\n",
      "[-0.20968573]\n",
      "Mode: Train env_steps 200 total rewards -1317.7997815608978 total energy tensor([[168.1999]])\n",
      "[-0.94671303]\n",
      "Mode: Train env_steps 200 total rewards -243.47357773478143 total energy tensor([[72.1429]])\n",
      "[0.7857948]\n",
      "Mode: Train env_steps 200 total rewards -251.5518085444346 total energy tensor([[107.0353]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04904095]\n",
      "Mode: Train env_steps 200 total rewards -615.0337897222489 total energy tensor([[126.1676]])\n",
      "[-0.52127165]\n",
      "Mode: Train env_steps 200 total rewards -971.6801646966487 total energy tensor([[145.3745]])\n",
      "[-0.589559]\n",
      "Mode: Train env_steps 200 total rewards -492.87722041644156 total energy tensor([[145.2387]])\n",
      "[0.90214354]\n",
      "Mode: Train env_steps 200 total rewards -1472.8738706111908 total energy tensor([[167.7495]])\n",
      "[-0.11659951]\n",
      "Mode: Train env_steps 200 total rewards -1246.5197681188583 total energy tensor([[171.9617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55128694]\n",
      "Mode: Train env_steps 200 total rewards -1250.1168619990349 total energy tensor([[166.2571]])\n",
      "[0.92804307]\n",
      "Mode: Train env_steps 200 total rewards -853.8478094222955 total energy tensor([[122.0760]])\n",
      "[0.5853668]\n",
      "Mode: Train env_steps 200 total rewards -1521.017319202423 total energy tensor([[189.8329]])\n",
      "[-0.1557806]\n",
      "Mode: Train env_steps 200 total rewards -1404.221488237381 total energy tensor([[165.7440]])\n",
      "[0.7832742]\n",
      "Mode: Train env_steps 200 total rewards -1259.7095979452133 total energy tensor([[170.3344]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02948886]\n",
      "Mode: Train env_steps 200 total rewards -1513.470778465271 total energy tensor([[180.7875]])\n",
      "[0.9725177]\n",
      "Mode: Train env_steps 200 total rewards -1527.8576760292053 total energy tensor([[188.1263]])\n",
      "[0.5851125]\n",
      "Mode: Train env_steps 200 total rewards -4.131375916302204 total energy tensor([[24.2077]])\n",
      "[-0.36682197]\n",
      "Mode: Train env_steps 200 total rewards -133.41531389858574 total energy tensor([[41.6147]])\n",
      "[0.5111666]\n",
      "Mode: Train env_steps 200 total rewards -136.70914830919355 total energy tensor([[64.4468]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14900726]\n",
      "Mode: Test env_steps 200 total rewards -380.35143472999334 total energy tensor([[117.9659]])\n",
      "[-0.84043324]\n",
      "Mode: Test env_steps 200 total rewards -265.6004994250834 total energy tensor([[101.9183]])\n",
      "[-0.60809493]\n",
      "Mode: Test env_steps 200 total rewards -140.5537430975819 total energy tensor([[86.1436]])\n",
      "[0.56358254]\n",
      "Mode: Test env_steps 200 total rewards -379.511834166944 total energy tensor([[113.5861]])\n",
      "[-0.09126517]\n",
      "Mode: Test env_steps 200 total rewards -379.1143731023185 total energy tensor([[103.9699]])\n",
      "[0.09538182]\n",
      "Mode: Test env_steps 200 total rewards -1279.6900861263275 total energy tensor([[176.9088]])\n",
      "[0.00686585]\n",
      "Mode: Test env_steps 200 total rewards -618.5285116601735 total energy tensor([[127.3071]])\n",
      "[-0.42943704]\n",
      "Mode: Test env_steps 200 total rewards -1529.9687399864197 total energy tensor([[186.8651]])\n",
      "[0.18223894]\n",
      "Mode: Test env_steps 200 total rewards -1369.5305387973785 total energy tensor([[175.5288]])\n",
      "[-0.673131]\n",
      "Mode: Test env_steps 200 total rewards -138.6861001229845 total energy tensor([[74.7064]])\n",
      "350000 -648.1535861215204\n",
      "[0.6957599]\n",
      "Mode: Train env_steps 200 total rewards -1339.9148619174957 total energy tensor([[176.3590]])\n",
      "[-0.10061881]\n",
      "Mode: Train env_steps 200 total rewards -1293.7518227100372 total energy tensor([[174.8110]])\n",
      "[0.47125077]\n",
      "Mode: Train env_steps 200 total rewards -274.4715398051776 total energy tensor([[104.7627]])\n",
      "[-0.25842047]\n",
      "Mode: Train env_steps 200 total rewards -1280.9001846313477 total energy tensor([[174.7414]])\n",
      "[0.9345647]\n",
      "Mode: Train env_steps 200 total rewards -380.0378827806562 total energy tensor([[115.4531]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5639662]\n",
      "Mode: Train env_steps 200 total rewards -140.57774537662044 total energy tensor([[83.9051]])\n",
      "[-0.7210175]\n",
      "Mode: Train env_steps 200 total rewards -379.4119609333575 total energy tensor([[110.1697]])\n",
      "[0.09672578]\n",
      "Mode: Train env_steps 200 total rewards -1354.4243214130402 total energy tensor([[170.7655]])\n",
      "[0.34165224]\n",
      "Mode: Train env_steps 200 total rewards -1282.592844247818 total energy tensor([[165.8391]])\n",
      "[0.7862549]\n",
      "Mode: Train env_steps 200 total rewards -137.9932368817681 total energy tensor([[71.4468]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74877703]\n",
      "Mode: Train env_steps 200 total rewards -7.8347123198909685 total energy tensor([[46.6634]])\n",
      "[0.279913]\n",
      "Mode: Train env_steps 200 total rewards -133.47617841046304 total energy tensor([[42.0921]])\n",
      "[0.84794694]\n",
      "Mode: Train env_steps 200 total rewards -1340.7005763053894 total energy tensor([[170.0869]])\n",
      "[0.85724413]\n",
      "Mode: Train env_steps 200 total rewards -8.59872983477544 total energy tensor([[52.3379]])\n",
      "[0.63808334]\n",
      "Mode: Train env_steps 200 total rewards -1382.2764694690704 total energy tensor([[177.9031]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7903519]\n",
      "Mode: Train env_steps 200 total rewards -733.1275214906782 total energy tensor([[115.6564]])\n",
      "[0.12784636]\n",
      "Mode: Train env_steps 200 total rewards -1500.8614249229431 total energy tensor([[189.0018]])\n",
      "[0.68088984]\n",
      "Mode: Train env_steps 200 total rewards -1240.9995272755623 total energy tensor([[164.2867]])\n",
      "[-0.6301067]\n",
      "Mode: Train env_steps 200 total rewards -981.9488611482084 total energy tensor([[152.0340]])\n",
      "[-0.35832185]\n",
      "Mode: Train env_steps 200 total rewards -1102.175338178873 total energy tensor([[168.9700]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72453994]\n",
      "Mode: Train env_steps 200 total rewards -376.08162476774305 total energy tensor([[93.7476]])\n",
      "[-0.87829417]\n",
      "Mode: Train env_steps 200 total rewards -1250.8008691072464 total energy tensor([[171.7135]])\n",
      "[-0.555114]\n",
      "Mode: Train env_steps 200 total rewards -731.5391361168586 total energy tensor([[114.3621]])\n",
      "[-0.36801052]\n",
      "Mode: Train env_steps 200 total rewards -494.4132380820811 total energy tensor([[107.2170]])\n",
      "[0.67408425]\n",
      "Mode: Train env_steps 200 total rewards -262.2576888385229 total energy tensor([[71.3321]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5767021]\n",
      "Mode: Test env_steps 200 total rewards -269.4140507830307 total energy tensor([[96.7962]])\n",
      "[0.03448704]\n",
      "Mode: Test env_steps 200 total rewards -614.1324701625854 total energy tensor([[116.4747]])\n",
      "[-0.30076802]\n",
      "Mode: Test env_steps 200 total rewards -269.0363595983945 total energy tensor([[98.6719]])\n",
      "[-0.65351003]\n",
      "Mode: Test env_steps 200 total rewards -1446.604820728302 total energy tensor([[177.0058]])\n",
      "[0.5298588]\n",
      "Mode: Test env_steps 200 total rewards -138.70675805219207 total energy tensor([[74.2827]])\n",
      "[0.9765711]\n",
      "Mode: Test env_steps 200 total rewards -1267.5300413370132 total energy tensor([[168.3278]])\n",
      "[0.5435477]\n",
      "Mode: Test env_steps 200 total rewards -613.0316742090508 total energy tensor([[117.2254]])\n",
      "[0.5442567]\n",
      "Mode: Test env_steps 200 total rewards -265.72412921334035 total energy tensor([[80.9230]])\n",
      "[-0.27554762]\n",
      "Mode: Test env_steps 200 total rewards -267.0897974026575 total energy tensor([[81.4570]])\n",
      "[-0.34849077]\n",
      "Mode: Test env_steps 200 total rewards -504.80608403868973 total energy tensor([[115.0922]])\n",
      "355000 -565.6076185525257\n",
      "[-0.5864767]\n",
      "Mode: Train env_steps 200 total rewards -139.2973223774461 total energy tensor([[79.7358]])\n",
      "[-0.43815547]\n",
      "Mode: Train env_steps 200 total rewards -1267.4006578922272 total energy tensor([[169.4948]])\n",
      "[-0.8366232]\n",
      "Mode: Train env_steps 200 total rewards -1229.7988456487656 total energy tensor([[167.7722]])\n",
      "[-0.043958]\n",
      "Mode: Train env_steps 200 total rewards -516.8262885408476 total energy tensor([[113.7559]])\n",
      "[0.5315975]\n",
      "Mode: Train env_steps 200 total rewards -980.5859952680767 total energy tensor([[137.7692]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8142016]\n",
      "Mode: Train env_steps 200 total rewards -488.3190057814354 total energy tensor([[95.2021]])\n",
      "[0.9321882]\n",
      "Mode: Train env_steps 200 total rewards -182.76602528151125 total energy tensor([[116.7961]])\n",
      "[0.52071464]\n",
      "Mode: Train env_steps 200 total rewards -1527.1164169311523 total energy tensor([[178.4473]])\n",
      "[0.8867774]\n",
      "Mode: Train env_steps 200 total rewards -1272.7841206789017 total energy tensor([[170.7292]])\n",
      "[-0.25958923]\n",
      "Mode: Train env_steps 200 total rewards -142.42738869802997 total energy tensor([[104.1353]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6413479]\n",
      "Mode: Train env_steps 200 total rewards -251.13640318345279 total energy tensor([[101.2125]])\n",
      "[0.87052226]\n",
      "Mode: Train env_steps 200 total rewards -481.4307405044674 total energy tensor([[74.6574]])\n",
      "[0.44424805]\n",
      "Mode: Train env_steps 200 total rewards -610.7041619179945 total energy tensor([[91.2283]])\n",
      "[0.02982188]\n",
      "Mode: Train env_steps 200 total rewards -971.5512547023172 total energy tensor([[132.7493]])\n",
      "[-0.59354293]\n",
      "Mode: Train env_steps 200 total rewards -131.56266941144713 total energy tensor([[21.3228]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.58718777]\n",
      "Mode: Train env_steps 200 total rewards -1510.3168592453003 total energy tensor([[195.5400]])\n",
      "[0.28572777]\n",
      "Mode: Train env_steps 200 total rewards -124.1400524588762 total energy tensor([[33.4881]])\n",
      "[0.8863376]\n",
      "Mode: Train env_steps 200 total rewards -1500.4938960075378 total energy tensor([[198.8044]])\n",
      "[0.3317954]\n",
      "Mode: Train env_steps 200 total rewards -1311.1537685394287 total energy tensor([[177.1418]])\n",
      "[-0.1248121]\n",
      "Mode: Train env_steps 200 total rewards -1411.1236934661865 total energy tensor([[183.3943]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9066254]\n",
      "Mode: Train env_steps 200 total rewards -482.326620164793 total energy tensor([[93.2026]])\n",
      "[0.21259448]\n",
      "Mode: Train env_steps 200 total rewards -1276.3542140722275 total energy tensor([[174.7088]])\n",
      "[0.14500445]\n",
      "Mode: Train env_steps 200 total rewards -1294.4966526031494 total energy tensor([[174.9719]])\n",
      "[-0.11650132]\n",
      "Mode: Train env_steps 200 total rewards -607.9755717283115 total energy tensor([[114.4843]])\n",
      "[0.0830595]\n",
      "Mode: Train env_steps 200 total rewards -169.0187939745374 total energy tensor([[98.7749]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7707565]\n",
      "Mode: Test env_steps 200 total rewards -249.37206839911778 total energy tensor([[88.9635]])\n",
      "[-0.21206991]\n",
      "Mode: Test env_steps 200 total rewards -135.32477399031632 total energy tensor([[91.8319]])\n",
      "[-0.72579914]\n",
      "Mode: Test env_steps 200 total rewards -1135.1876927614212 total energy tensor([[179.8293]])\n",
      "[0.9886525]\n",
      "Mode: Test env_steps 200 total rewards -247.76107378082816 total energy tensor([[90.4596]])\n",
      "[-0.69538206]\n",
      "Mode: Test env_steps 200 total rewards -1257.3656661510468 total energy tensor([[181.1504]])\n",
      "[-0.4531267]\n",
      "Mode: Test env_steps 200 total rewards -1309.311802148819 total energy tensor([[179.8834]])\n",
      "[-0.64111626]\n",
      "Mode: Test env_steps 200 total rewards -1491.4553723335266 total energy tensor([[189.9784]])\n",
      "[0.8649039]\n",
      "Mode: Test env_steps 200 total rewards -6.62238972238265 total energy tensor([[37.3807]])\n",
      "[0.6885948]\n",
      "Mode: Test env_steps 200 total rewards -1417.1230306625366 total energy tensor([[184.6106]])\n",
      "[0.69098717]\n",
      "Mode: Test env_steps 200 total rewards -1483.6022024154663 total energy tensor([[197.2141]])\n",
      "360000 -873.3126072365461\n",
      "[-0.47045022]\n",
      "Mode: Train env_steps 200 total rewards -246.86590539590725 total energy tensor([[87.6587]])\n",
      "[0.638886]\n",
      "Mode: Train env_steps 200 total rewards -142.2494095917791 total energy tensor([[94.3758]])\n",
      "[0.22905728]\n",
      "Mode: Train env_steps 200 total rewards -1476.3588206768036 total energy tensor([[183.2931]])\n",
      "[0.58290684]\n",
      "Mode: Train env_steps 200 total rewards -1328.1206767559052 total energy tensor([[182.2098]])\n",
      "[0.5737536]\n",
      "Mode: Train env_steps 200 total rewards -141.21123343333602 total energy tensor([[78.7066]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14740996]\n",
      "Mode: Train env_steps 200 total rewards -374.7767985669052 total energy tensor([[84.0047]])\n",
      "[-0.70244455]\n",
      "Mode: Train env_steps 200 total rewards -264.4896891268436 total energy tensor([[74.6028]])\n",
      "[-0.7203146]\n",
      "Mode: Train env_steps 200 total rewards -135.76587677266798 total energy tensor([[55.7505]])\n",
      "[-0.537274]\n",
      "Mode: Train env_steps 200 total rewards -263.3566497980646 total energy tensor([[63.3311]])\n",
      "[-0.94624376]\n",
      "Mode: Train env_steps 200 total rewards -504.171746547916 total energy tensor([[104.7251]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3944749]\n",
      "Mode: Train env_steps 200 total rewards -739.4577857875265 total energy tensor([[118.9899]])\n",
      "[-0.46097746]\n",
      "Mode: Train env_steps 200 total rewards -260.70413366379216 total energy tensor([[77.5401]])\n",
      "[0.16907433]\n",
      "Mode: Train env_steps 200 total rewards -1257.6851878762245 total energy tensor([[159.5077]])\n",
      "[-0.55967015]\n",
      "Mode: Train env_steps 200 total rewards -268.14594017737545 total energy tensor([[87.6269]])\n",
      "[-0.788613]\n",
      "Mode: Train env_steps 200 total rewards -613.6893070619553 total energy tensor([[124.3251]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24964567]\n",
      "Mode: Train env_steps 200 total rewards -375.82866662554443 total energy tensor([[102.3495]])\n",
      "[0.8452138]\n",
      "Mode: Train env_steps 200 total rewards -1246.2174731492996 total energy tensor([[174.4460]])\n",
      "[-0.30512175]\n",
      "Mode: Train env_steps 200 total rewards -1444.3755857944489 total energy tensor([[178.2030]])\n",
      "[-0.79302347]\n",
      "Mode: Train env_steps 200 total rewards -861.4164604702964 total energy tensor([[138.0867]])\n",
      "[-0.07362897]\n",
      "Mode: Train env_steps 200 total rewards -1327.8082437515259 total energy tensor([[167.5666]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9952337]\n",
      "Mode: Train env_steps 200 total rewards -732.4516540344339 total energy tensor([[92.0984]])\n",
      "[0.5553489]\n",
      "Mode: Train env_steps 200 total rewards -142.3902469642926 total energy tensor([[100.7619]])\n",
      "[-0.938398]\n",
      "Mode: Train env_steps 200 total rewards -969.808682432631 total energy tensor([[123.1426]])\n",
      "[0.27764112]\n",
      "Mode: Train env_steps 200 total rewards -7.953832473576767 total energy tensor([[51.2351]])\n",
      "[-0.57806796]\n",
      "Mode: Train env_steps 200 total rewards -741.097109930939 total energy tensor([[91.0845]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5106903]\n",
      "Mode: Test env_steps 200 total rewards -375.6335282588843 total energy tensor([[84.7432]])\n",
      "[0.7958308]\n",
      "Mode: Test env_steps 200 total rewards -1524.9858531951904 total energy tensor([[171.9204]])\n",
      "[-0.89262956]\n",
      "Mode: Test env_steps 200 total rewards -599.2870707997354 total energy tensor([[117.9658]])\n",
      "[-0.09042152]\n",
      "Mode: Test env_steps 200 total rewards -1263.9234445095062 total energy tensor([[163.0110]])\n",
      "[0.2935428]\n",
      "Mode: Test env_steps 200 total rewards -378.4880569332745 total energy tensor([[88.0772]])\n",
      "[-0.34526238]\n",
      "Mode: Test env_steps 200 total rewards -543.746769354213 total energy tensor([[117.3266]])\n",
      "[-0.800203]\n",
      "Mode: Test env_steps 200 total rewards -252.45232153922552 total energy tensor([[101.0232]])\n",
      "[-0.9525585]\n",
      "Mode: Test env_steps 200 total rewards -1308.2159131765366 total energy tensor([[161.0750]])\n",
      "[0.84239197]\n",
      "Mode: Test env_steps 200 total rewards -1318.3950003385544 total energy tensor([[160.9806]])\n",
      "[-0.75824404]\n",
      "Mode: Test env_steps 200 total rewards -486.1758151142858 total energy tensor([[98.3100]])\n",
      "365000 -805.1303773219406\n",
      "[-0.53382486]\n",
      "Mode: Train env_steps 200 total rewards -1112.7674816548824 total energy tensor([[165.8304]])\n",
      "[0.9200374]\n",
      "Mode: Train env_steps 200 total rewards -488.28110540285707 total energy tensor([[107.0765]])\n",
      "[0.2605419]\n",
      "Mode: Train env_steps 200 total rewards -1204.945019543171 total energy tensor([[168.7789]])\n",
      "[-0.91932654]\n",
      "Mode: Train env_steps 200 total rewards -367.0141110777622 total energy tensor([[81.6225]])\n",
      "[-0.14444245]\n",
      "Mode: Train env_steps 200 total rewards -1227.456135392189 total energy tensor([[165.9963]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40953654]\n",
      "Mode: Train env_steps 200 total rewards -1230.6489907503128 total energy tensor([[172.0122]])\n",
      "[-0.5406183]\n",
      "Mode: Train env_steps 200 total rewards -1444.2078139781952 total energy tensor([[166.8163]])\n",
      "[0.6131467]\n",
      "Mode: Train env_steps 200 total rewards -480.88731627119705 total energy tensor([[122.1124]])\n",
      "[-0.11924206]\n",
      "Mode: Train env_steps 200 total rewards -489.6870870087296 total energy tensor([[120.6602]])\n",
      "[-0.15794225]\n",
      "Mode: Train env_steps 200 total rewards -1296.7771705389023 total energy tensor([[173.1595]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00855371]\n",
      "Mode: Train env_steps 200 total rewards -144.20671784644946 total energy tensor([[118.3085]])\n",
      "[0.9238079]\n",
      "Mode: Train env_steps 200 total rewards -243.5008444549112 total energy tensor([[59.9857]])\n",
      "[0.7817654]\n",
      "Mode: Train env_steps 200 total rewards -1279.51693546772 total energy tensor([[170.3783]])\n",
      "[0.31937584]\n",
      "Mode: Train env_steps 200 total rewards -482.87917934480356 total energy tensor([[90.4172]])\n",
      "[-0.83729607]\n",
      "Mode: Train env_steps 200 total rewards -141.83847069204785 total energy tensor([[113.5221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36198458]\n",
      "Mode: Train env_steps 200 total rewards -378.9594900403172 total energy tensor([[107.7634]])\n",
      "[-0.2976918]\n",
      "Mode: Train env_steps 200 total rewards -265.4554406926036 total energy tensor([[84.6151]])\n",
      "[-0.80401045]\n",
      "Mode: Train env_steps 200 total rewards -1368.7638778686523 total energy tensor([[176.2648]])\n",
      "[0.9966288]\n",
      "Mode: Train env_steps 200 total rewards -144.60536100622267 total energy tensor([[105.8911]])\n",
      "[-0.04373806]\n",
      "Mode: Train env_steps 200 total rewards -1399.4062058925629 total energy tensor([[167.8342]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9923686]\n",
      "Mode: Train env_steps 200 total rewards -1368.8306589126587 total energy tensor([[171.9680]])\n",
      "[-0.90786886]\n",
      "Mode: Train env_steps 200 total rewards -1257.3049960136414 total energy tensor([[170.5372]])\n",
      "[-0.49191248]\n",
      "Mode: Train env_steps 200 total rewards -132.14338956805295 total energy tensor([[40.7256]])\n",
      "[0.56637406]\n",
      "Mode: Train env_steps 200 total rewards -15.374372790043708 total energy tensor([[72.7426]])\n",
      "[0.847789]\n",
      "Mode: Train env_steps 200 total rewards -1475.2676758766174 total energy tensor([[169.2470]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07208595]\n",
      "Mode: Test env_steps 200 total rewards -730.2356096170843 total energy tensor([[129.2959]])\n",
      "[0.5613909]\n",
      "Mode: Test env_steps 200 total rewards -268.78227921016514 total energy tensor([[102.4353]])\n",
      "[-0.8351819]\n",
      "Mode: Test env_steps 200 total rewards -1228.0600348114967 total energy tensor([[157.3431]])\n",
      "[-0.8821222]\n",
      "Mode: Test env_steps 200 total rewards -373.8017186387442 total energy tensor([[97.1972]])\n",
      "[0.73179036]\n",
      "Mode: Test env_steps 200 total rewards -271.8879526667297 total energy tensor([[104.0109]])\n",
      "[0.6716526]\n",
      "Mode: Test env_steps 200 total rewards -1291.6664955615997 total energy tensor([[161.9134]])\n",
      "[0.81983215]\n",
      "Mode: Test env_steps 200 total rewards -1267.997644841671 total energy tensor([[163.1944]])\n",
      "[-0.46654522]\n",
      "Mode: Test env_steps 200 total rewards -977.056427763775 total energy tensor([[137.8956]])\n",
      "[0.13956645]\n",
      "Mode: Test env_steps 200 total rewards -500.9769588895142 total energy tensor([[113.1548]])\n",
      "[-0.27047148]\n",
      "Mode: Test env_steps 200 total rewards -265.3958868533373 total energy tensor([[104.7770]])\n",
      "370000 -717.5861008854117\n",
      "[-0.68468845]\n",
      "Mode: Train env_steps 200 total rewards -376.54449371341616 total energy tensor([[97.4886]])\n",
      "[-0.59477425]\n",
      "Mode: Train env_steps 200 total rewards -1216.0874353647232 total energy tensor([[154.4962]])\n",
      "[-0.01222554]\n",
      "Mode: Train env_steps 200 total rewards -375.439300541766 total energy tensor([[101.2212]])\n",
      "[0.37204045]\n",
      "Mode: Train env_steps 200 total rewards -139.4389059622772 total energy tensor([[81.6428]])\n",
      "[0.61654335]\n",
      "Mode: Train env_steps 200 total rewards -270.67076137661934 total energy tensor([[110.9687]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65222484]\n",
      "Mode: Train env_steps 200 total rewards -140.50343306545983 total energy tensor([[84.8309]])\n",
      "[0.41666025]\n",
      "Mode: Train env_steps 200 total rewards -1151.4989805817604 total energy tensor([[171.6539]])\n",
      "[0.29364705]\n",
      "Mode: Train env_steps 200 total rewards -1343.184592962265 total energy tensor([[172.0732]])\n",
      "[0.4601378]\n",
      "Mode: Train env_steps 200 total rewards -976.9497175253928 total energy tensor([[144.4934]])\n",
      "[0.38782203]\n",
      "Mode: Train env_steps 200 total rewards -1535.0478196144104 total energy tensor([[187.6503]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8719239]\n",
      "Mode: Train env_steps 200 total rewards -140.690935770981 total energy tensor([[86.3004]])\n",
      "[0.24175236]\n",
      "Mode: Train env_steps 200 total rewards -1169.1933635026217 total energy tensor([[145.7455]])\n",
      "[0.3776227]\n",
      "Mode: Train env_steps 200 total rewards -147.62984949350357 total energy tensor([[118.3476]])\n",
      "[0.90068245]\n",
      "Mode: Train env_steps 200 total rewards -380.4284903779626 total energy tensor([[105.6189]])\n",
      "[-0.01439991]\n",
      "Mode: Train env_steps 200 total rewards -267.6930249943398 total energy tensor([[85.6417]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56873244]\n",
      "Mode: Train env_steps 200 total rewards -1414.3239059448242 total energy tensor([[172.1198]])\n",
      "[0.93544114]\n",
      "Mode: Train env_steps 200 total rewards -207.6932422723621 total energy tensor([[110.7787]])\n",
      "[-0.76633865]\n",
      "Mode: Train env_steps 200 total rewards -1247.7019855976105 total energy tensor([[172.1395]])\n",
      "[-0.87301606]\n",
      "Mode: Train env_steps 200 total rewards -277.395942713134 total energy tensor([[116.6320]])\n",
      "[0.99245155]\n",
      "Mode: Train env_steps 200 total rewards -1333.8717198371887 total energy tensor([[172.3391]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10494594]\n",
      "Mode: Train env_steps 200 total rewards -973.26636431925 total energy tensor([[161.1192]])\n",
      "[-0.34250376]\n",
      "Mode: Train env_steps 200 total rewards -484.43464536138345 total energy tensor([[99.8095]])\n",
      "[0.48012176]\n",
      "Mode: Train env_steps 200 total rewards -1293.832018852234 total energy tensor([[167.6156]])\n",
      "[0.5856973]\n",
      "Mode: Train env_steps 200 total rewards -243.71095056063496 total energy tensor([[62.4572]])\n",
      "[-0.48706573]\n",
      "Mode: Train env_steps 200 total rewards -137.53313906583935 total energy tensor([[56.9390]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98907745]\n",
      "Mode: Test env_steps 200 total rewards -371.4809103780426 total energy tensor([[108.3876]])\n",
      "[-0.7174613]\n",
      "Mode: Test env_steps 200 total rewards -6.397182798566064 total energy tensor([[40.6503]])\n",
      "[0.10702983]\n",
      "Mode: Test env_steps 200 total rewards -131.1637588441372 total energy tensor([[52.9739]])\n",
      "[0.49298146]\n",
      "Mode: Test env_steps 200 total rewards -247.47715486818925 total energy tensor([[78.0139]])\n",
      "[-0.7041553]\n",
      "Mode: Test env_steps 200 total rewards -1219.4110584557056 total energy tensor([[169.7362]])\n",
      "[0.3700656]\n",
      "Mode: Test env_steps 200 total rewards -619.1728029958904 total energy tensor([[116.8009]])\n",
      "[0.5851509]\n",
      "Mode: Test env_steps 200 total rewards -135.11260875780135 total energy tensor([[54.1524]])\n",
      "[0.10573973]\n",
      "Mode: Test env_steps 200 total rewards -128.8686076758895 total energy tensor([[50.6810]])\n",
      "[0.10358534]\n",
      "Mode: Test env_steps 200 total rewards -1503.5594058036804 total energy tensor([[196.8727]])\n",
      "[-0.41993937]\n",
      "Mode: Test env_steps 200 total rewards -244.01635428069858 total energy tensor([[69.3397]])\n",
      "375000 -460.6659844858601\n",
      "[0.73765206]\n",
      "Mode: Train env_steps 200 total rewards -136.1760650582146 total energy tensor([[63.0427]])\n",
      "[0.98962736]\n",
      "Mode: Train env_steps 200 total rewards -135.4781719406601 total energy tensor([[54.7954]])\n",
      "[0.0106528]\n",
      "Mode: Train env_steps 200 total rewards -365.8350461041555 total energy tensor([[105.3624]])\n",
      "[0.49937877]\n",
      "Mode: Train env_steps 200 total rewards -244.2806825595908 total energy tensor([[68.5238]])\n",
      "[0.45337525]\n",
      "Mode: Train env_steps 200 total rewards -605.7153682978824 total energy tensor([[127.7336]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30989292]\n",
      "Mode: Train env_steps 200 total rewards -1326.043508052826 total energy tensor([[181.5029]])\n",
      "[0.18998389]\n",
      "Mode: Train env_steps 200 total rewards -1344.5689239501953 total energy tensor([[181.0968]])\n",
      "[-0.00632964]\n",
      "Mode: Train env_steps 200 total rewards -1107.6237163543701 total energy tensor([[180.1498]])\n",
      "[0.10641435]\n",
      "Mode: Train env_steps 200 total rewards -488.0817446461879 total energy tensor([[128.2446]])\n",
      "[-0.47928098]\n",
      "Mode: Train env_steps 200 total rewards -18.973913248773897 total energy tensor([[112.7388]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99932384]\n",
      "Mode: Train env_steps 200 total rewards -1194.7834240198135 total energy tensor([[170.7598]])\n",
      "[-0.25890118]\n",
      "Mode: Train env_steps 200 total rewards -1435.4662716388702 total energy tensor([[169.3784]])\n",
      "[0.9709535]\n",
      "Mode: Train env_steps 200 total rewards -1100.4227165281773 total energy tensor([[162.3031]])\n",
      "[-0.11480737]\n",
      "Mode: Train env_steps 200 total rewards -248.00427564885467 total energy tensor([[86.8809]])\n",
      "[0.24358971]\n",
      "Mode: Train env_steps 200 total rewards -247.97326758597046 total energy tensor([[92.1858]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4066931]\n",
      "Mode: Train env_steps 200 total rewards -1528.6239948272705 total energy tensor([[185.8304]])\n",
      "[0.19681743]\n",
      "Mode: Train env_steps 200 total rewards -1054.8568320572376 total energy tensor([[174.5188]])\n",
      "[-0.98430264]\n",
      "Mode: Train env_steps 200 total rewards -139.20303240418434 total energy tensor([[82.4356]])\n",
      "[0.04614416]\n",
      "Mode: Train env_steps 200 total rewards -248.6362358087208 total energy tensor([[93.5770]])\n",
      "[-0.59057873]\n",
      "Mode: Train env_steps 200 total rewards -12.158659738837741 total energy tensor([[74.4698]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89943945]\n",
      "Mode: Train env_steps 200 total rewards -1235.8129377961159 total energy tensor([[169.9167]])\n",
      "[-0.7234186]\n",
      "Mode: Train env_steps 200 total rewards -375.1013026111759 total energy tensor([[90.4657]])\n",
      "[-0.492711]\n",
      "Mode: Train env_steps 200 total rewards -140.6784409827087 total energy tensor([[89.9354]])\n",
      "[-0.58783495]\n",
      "Mode: Train env_steps 200 total rewards -380.22996209934354 total energy tensor([[121.2598]])\n",
      "[-0.16447118]\n",
      "Mode: Train env_steps 200 total rewards -263.99654429312795 total energy tensor([[89.3537]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24085784]\n",
      "Mode: Test env_steps 200 total rewards -984.2842220575549 total energy tensor([[145.7858]])\n",
      "[-0.77978754]\n",
      "Mode: Test env_steps 200 total rewards -863.6304580876604 total energy tensor([[129.9073]])\n",
      "[-0.14228134]\n",
      "Mode: Test env_steps 200 total rewards -146.84850556403399 total energy tensor([[103.6011]])\n",
      "[-0.02735065]\n",
      "Mode: Test env_steps 200 total rewards -143.99011092539877 total energy tensor([[106.8538]])\n",
      "[-0.08679861]\n",
      "Mode: Test env_steps 200 total rewards -142.5028109047562 total energy tensor([[100.5833]])\n",
      "[-0.7367396]\n",
      "Mode: Test env_steps 200 total rewards -143.168528418988 total energy tensor([[102.6825]])\n",
      "[-0.47485995]\n",
      "Mode: Test env_steps 200 total rewards -142.61347924917936 total energy tensor([[102.1302]])\n",
      "[-0.7522102]\n",
      "Mode: Test env_steps 200 total rewards -253.55844198539853 total energy tensor([[113.2611]])\n",
      "[0.36232737]\n",
      "Mode: Test env_steps 200 total rewards -1234.4602398872375 total energy tensor([[166.4265]])\n",
      "[-0.21931851]\n",
      "Mode: Test env_steps 200 total rewards -1542.5685091018677 total energy tensor([[161.1987]])\n",
      "380000 -559.7625306182075\n",
      "[-0.7171983]\n",
      "Mode: Train env_steps 200 total rewards -252.29054686240852 total energy tensor([[109.9780]])\n",
      "[0.61238474]\n",
      "Mode: Train env_steps 200 total rewards -146.78777655772865 total energy tensor([[109.2226]])\n",
      "[-0.49883503]\n",
      "Mode: Train env_steps 200 total rewards -1543.277666091919 total energy tensor([[163.3724]])\n",
      "[-0.5385167]\n",
      "Mode: Train env_steps 200 total rewards -251.36363216489553 total energy tensor([[108.8594]])\n",
      "[0.39009544]\n",
      "Mode: Train env_steps 200 total rewards -144.4342516604811 total energy tensor([[103.1620]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36395046]\n",
      "Mode: Train env_steps 200 total rewards -847.7754806717276 total energy tensor([[139.0353]])\n",
      "[-0.3018342]\n",
      "Mode: Train env_steps 200 total rewards -10.09957456367556 total energy tensor([[59.5674]])\n",
      "[-0.74666405]\n",
      "Mode: Train env_steps 200 total rewards -260.08704083241173 total energy tensor([[70.3706]])\n",
      "[0.94399375]\n",
      "Mode: Train env_steps 200 total rewards -1407.3975524902344 total energy tensor([[173.9378]])\n",
      "[0.6217593]\n",
      "Mode: Train env_steps 200 total rewards -721.9522017964628 total energy tensor([[115.0564]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25139773]\n",
      "Mode: Train env_steps 200 total rewards -1234.31021296978 total energy tensor([[175.6514]])\n",
      "[-0.00574544]\n",
      "Mode: Train env_steps 200 total rewards -145.07246706215665 total energy tensor([[113.7243]])\n",
      "[-0.38226265]\n",
      "Mode: Train env_steps 200 total rewards -17.90608261601301 total energy tensor([[103.9974]])\n",
      "[-0.48330927]\n",
      "Mode: Train env_steps 200 total rewards -721.8670637784526 total energy tensor([[122.9757]])\n",
      "[-0.78334624]\n",
      "Mode: Train env_steps 200 total rewards -252.45189238572493 total energy tensor([[116.3089]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6337137]\n",
      "Mode: Train env_steps 200 total rewards -377.6647635237314 total energy tensor([[91.1870]])\n",
      "[0.93110913]\n",
      "Mode: Train env_steps 200 total rewards -268.68098045513034 total energy tensor([[85.8190]])\n",
      "[0.03479793]\n",
      "Mode: Train env_steps 200 total rewards -141.57434699611622 total energy tensor([[86.3120]])\n",
      "[-0.7484116]\n",
      "Mode: Train env_steps 200 total rewards -1281.814084649086 total energy tensor([[167.9297]])\n",
      "[-0.16200489]\n",
      "Mode: Train env_steps 200 total rewards -853.5371857117862 total energy tensor([[153.2654]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5432227]\n",
      "Mode: Train env_steps 200 total rewards -725.826912178658 total energy tensor([[132.2924]])\n",
      "[0.43643448]\n",
      "Mode: Train env_steps 200 total rewards -618.2222926979885 total energy tensor([[117.7497]])\n",
      "[-0.78839946]\n",
      "Mode: Train env_steps 200 total rewards -262.86631924379617 total energy tensor([[84.6109]])\n",
      "[0.9533347]\n",
      "Mode: Train env_steps 200 total rewards -499.0278020026162 total energy tensor([[101.1172]])\n",
      "[-0.30703366]\n",
      "Mode: Train env_steps 200 total rewards -266.2653423026204 total energy tensor([[87.4207]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69635445]\n",
      "Mode: Test env_steps 200 total rewards -263.00355608714744 total energy tensor([[69.2599]])\n",
      "[0.0642223]\n",
      "Mode: Test env_steps 200 total rewards -1334.7356615066528 total energy tensor([[176.7977]])\n",
      "[-0.70317864]\n",
      "Mode: Test env_steps 200 total rewards -265.68507974478416 total energy tensor([[79.5576]])\n",
      "[0.8184143]\n",
      "Mode: Test env_steps 200 total rewards -1250.4153208732605 total energy tensor([[177.9360]])\n",
      "[-0.35683045]\n",
      "Mode: Test env_steps 200 total rewards -1253.15414249897 total energy tensor([[176.5477]])\n",
      "[0.61380184]\n",
      "Mode: Test env_steps 200 total rewards -1092.9321169257164 total energy tensor([[176.2951]])\n",
      "[-0.0722642]\n",
      "Mode: Test env_steps 200 total rewards -1335.1335651874542 total energy tensor([[175.2422]])\n",
      "[0.3100736]\n",
      "Mode: Test env_steps 200 total rewards -258.2281236918643 total energy tensor([[73.7054]])\n",
      "[-0.39575565]\n",
      "Mode: Test env_steps 200 total rewards -1214.0429854393005 total energy tensor([[175.1485]])\n",
      "[0.8264653]\n",
      "Mode: Test env_steps 200 total rewards -268.30572814913467 total energy tensor([[75.8344]])\n",
      "385000 -853.5636280104285\n",
      "[0.9436361]\n",
      "Mode: Train env_steps 200 total rewards -259.6475153295323 total energy tensor([[71.3099]])\n",
      "[-0.91344976]\n",
      "Mode: Train env_steps 200 total rewards -1086.2204137444496 total energy tensor([[177.3204]])\n",
      "[0.45130122]\n",
      "Mode: Train env_steps 200 total rewards -264.9587847053772 total energy tensor([[78.5907]])\n",
      "[0.18987565]\n",
      "Mode: Train env_steps 200 total rewards -1314.1785032749176 total energy tensor([[176.2819]])\n",
      "[0.31419292]\n",
      "Mode: Train env_steps 200 total rewards -593.1823440887965 total energy tensor([[124.8656]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18623473]\n",
      "Mode: Train env_steps 200 total rewards -1342.74405169487 total energy tensor([[174.2836]])\n",
      "[-0.2989317]\n",
      "Mode: Train env_steps 200 total rewards -142.2007051368564 total energy tensor([[94.9147]])\n",
      "[0.6319264]\n",
      "Mode: Train env_steps 200 total rewards -1150.674091041088 total energy tensor([[170.7950]])\n",
      "[0.97246146]\n",
      "Mode: Train env_steps 200 total rewards -384.7954243966815 total energy tensor([[102.8474]])\n",
      "[0.38221526]\n",
      "Mode: Train env_steps 200 total rewards -1344.6971856355667 total energy tensor([[166.8397]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1706086]\n",
      "Mode: Train env_steps 200 total rewards -978.4624918731861 total energy tensor([[144.8759]])\n",
      "[0.06826822]\n",
      "Mode: Train env_steps 200 total rewards -1257.8169761896133 total energy tensor([[163.2052]])\n",
      "[-0.7412863]\n",
      "Mode: Train env_steps 200 total rewards -1234.2565422058105 total energy tensor([[166.1858]])\n",
      "[-0.91225266]\n",
      "Mode: Train env_steps 200 total rewards -133.05250169622013 total energy tensor([[66.5052]])\n",
      "[0.45739946]\n",
      "Mode: Train env_steps 200 total rewards -1371.257868528366 total energy tensor([[163.4117]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9592721]\n",
      "Mode: Train env_steps 200 total rewards -502.45401402562857 total energy tensor([[95.0416]])\n",
      "[-0.7668093]\n",
      "Mode: Train env_steps 200 total rewards -736.1120542827994 total energy tensor([[125.9011]])\n",
      "[-0.8717907]\n",
      "Mode: Train env_steps 200 total rewards -266.009016522672 total energy tensor([[81.6033]])\n",
      "[-0.7240509]\n",
      "Mode: Train env_steps 200 total rewards -136.65389047638746 total energy tensor([[59.7133]])\n",
      "[0.9316281]\n",
      "Mode: Train env_steps 200 total rewards -980.392561789602 total energy tensor([[133.8221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94948363]\n",
      "Mode: Train env_steps 200 total rewards -1188.382426559925 total energy tensor([[163.4269]])\n",
      "[-0.32836908]\n",
      "Mode: Train env_steps 200 total rewards -143.62668218277395 total energy tensor([[100.1781]])\n",
      "[0.36709568]\n",
      "Mode: Train env_steps 200 total rewards -264.6059260922484 total energy tensor([[74.4660]])\n",
      "[0.9569033]\n",
      "Mode: Train env_steps 200 total rewards -492.8162466206122 total energy tensor([[94.7154]])\n",
      "[0.8125086]\n",
      "Mode: Train env_steps 200 total rewards -1355.2762643098831 total energy tensor([[163.2426]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98325163]\n",
      "Mode: Test env_steps 200 total rewards -372.092390707694 total energy tensor([[95.6638]])\n",
      "[0.58301973]\n",
      "Mode: Test env_steps 200 total rewards -856.3728813273192 total energy tensor([[113.4909]])\n",
      "[-0.33498612]\n",
      "Mode: Test env_steps 200 total rewards -610.5083177336492 total energy tensor([[105.4915]])\n",
      "[0.52578056]\n",
      "Mode: Test env_steps 200 total rewards -1119.2354286210611 total energy tensor([[141.2361]])\n",
      "[0.7807758]\n",
      "Mode: Test env_steps 200 total rewards -608.5675477243494 total energy tensor([[105.2685]])\n",
      "[-0.36804456]\n",
      "Mode: Test env_steps 200 total rewards -1238.0209869071841 total energy tensor([[141.9921]])\n",
      "[0.921218]\n",
      "Mode: Test env_steps 200 total rewards -986.7537342285505 total energy tensor([[113.5099]])\n",
      "[-0.30007145]\n",
      "Mode: Test env_steps 200 total rewards -260.1128731147837 total energy tensor([[58.9743]])\n",
      "[-0.91509426]\n",
      "Mode: Test env_steps 200 total rewards -268.07216937700287 total energy tensor([[92.9764]])\n",
      "[-0.30383885]\n",
      "Mode: Test env_steps 200 total rewards -376.5586745229375 total energy tensor([[70.7181]])\n",
      "390000 -669.6295004264532\n",
      "[-0.4105414]\n",
      "Mode: Train env_steps 200 total rewards -981.6610893588513 total energy tensor([[115.3551]])\n",
      "[-0.87454355]\n",
      "Mode: Train env_steps 200 total rewards -24.499272726476192 total energy tensor([[136.4142]])\n",
      "[-0.47647387]\n",
      "Mode: Train env_steps 200 total rewards -736.7389967765776 total energy tensor([[99.7924]])\n",
      "[-0.24466223]\n",
      "Mode: Train env_steps 200 total rewards -267.02964055131406 total energy tensor([[79.6371]])\n",
      "[0.16655754]\n",
      "Mode: Train env_steps 200 total rewards -253.54571515019052 total energy tensor([[104.9813]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97357726]\n",
      "Mode: Train env_steps 200 total rewards -376.81196101475507 total energy tensor([[94.0219]])\n",
      "[0.34979272]\n",
      "Mode: Train env_steps 200 total rewards -1240.4166032075882 total energy tensor([[170.1641]])\n",
      "[0.5037532]\n",
      "Mode: Train env_steps 200 total rewards -255.22740403772332 total energy tensor([[117.7923]])\n",
      "[0.6064132]\n",
      "Mode: Train env_steps 200 total rewards -1271.5207973718643 total energy tensor([[167.7201]])\n",
      "[0.77696157]\n",
      "Mode: Train env_steps 200 total rewards -265.27442628971767 total energy tensor([[83.3852]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51329273]\n",
      "Mode: Train env_steps 200 total rewards -265.9811542544048 total energy tensor([[68.7178]])\n",
      "[0.26446885]\n",
      "Mode: Train env_steps 200 total rewards -263.84837161184987 total energy tensor([[67.5605]])\n",
      "[-0.40688458]\n",
      "Mode: Train env_steps 200 total rewards -1505.7126789093018 total energy tensor([[188.7306]])\n",
      "[-0.79669094]\n",
      "Mode: Train env_steps 200 total rewards -375.26921117294114 total energy tensor([[80.3881]])\n",
      "[-0.6515247]\n",
      "Mode: Train env_steps 200 total rewards -260.1812904512044 total energy tensor([[59.5647]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9559047]\n",
      "Mode: Train env_steps 200 total rewards -372.4885971872136 total energy tensor([[85.2983]])\n",
      "[0.9765696]\n",
      "Mode: Train env_steps 200 total rewards -1500.805048942566 total energy tensor([[194.9771]])\n",
      "[0.33402032]\n",
      "Mode: Train env_steps 200 total rewards -1284.948138833046 total energy tensor([[164.8278]])\n",
      "[-0.8575613]\n",
      "Mode: Train env_steps 200 total rewards -1446.0043532848358 total energy tensor([[166.8606]])\n",
      "[-0.1655926]\n",
      "Mode: Train env_steps 200 total rewards -266.78398353699595 total energy tensor([[87.2839]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8464976]\n",
      "Mode: Train env_steps 200 total rewards -249.81682275608182 total energy tensor([[91.5497]])\n",
      "[0.3895069]\n",
      "Mode: Train env_steps 200 total rewards -1423.9876806735992 total energy tensor([[160.2182]])\n",
      "[-0.112929]\n",
      "Mode: Train env_steps 200 total rewards -1297.491026043892 total energy tensor([[166.1111]])\n",
      "[0.38416997]\n",
      "Mode: Train env_steps 200 total rewards -1263.3521248102188 total energy tensor([[164.5144]])\n",
      "[-0.78132826]\n",
      "Mode: Train env_steps 200 total rewards -1250.0515497922897 total energy tensor([[162.3050]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72372335]\n",
      "Mode: Test env_steps 200 total rewards -594.065047275275 total energy tensor([[113.8297]])\n",
      "[-0.12768301]\n",
      "Mode: Test env_steps 200 total rewards -267.31187801994383 total energy tensor([[86.8746]])\n",
      "[-0.5081987]\n",
      "Mode: Test env_steps 200 total rewards -267.6725851232186 total energy tensor([[95.2715]])\n",
      "[-0.14017153]\n",
      "Mode: Test env_steps 200 total rewards -983.8438267661259 total energy tensor([[123.2729]])\n",
      "[0.13239937]\n",
      "Mode: Test env_steps 200 total rewards -265.0083288354799 total energy tensor([[82.2764]])\n",
      "[0.68413496]\n",
      "Mode: Test env_steps 200 total rewards -265.3189088013023 total energy tensor([[88.2181]])\n",
      "[-0.9040708]\n",
      "Mode: Test env_steps 200 total rewards -1296.6689974069595 total energy tensor([[158.0861]])\n",
      "[0.0334419]\n",
      "Mode: Test env_steps 200 total rewards -1364.7119232416153 total energy tensor([[154.9161]])\n",
      "[0.2643237]\n",
      "Mode: Test env_steps 200 total rewards -376.0582306282595 total energy tensor([[89.0589]])\n",
      "[-0.43969297]\n",
      "Mode: Test env_steps 200 total rewards -496.82786016352475 total energy tensor([[116.5948]])\n",
      "395000 -617.7487586261705\n",
      "[-0.34870493]\n",
      "Mode: Train env_steps 200 total rewards -1219.779104422778 total energy tensor([[142.9832]])\n",
      "[0.1515118]\n",
      "Mode: Train env_steps 200 total rewards -266.8889497574419 total energy tensor([[96.3184]])\n",
      "[-0.98235005]\n",
      "Mode: Train env_steps 200 total rewards -264.1033569825813 total energy tensor([[86.4073]])\n",
      "[-0.596088]\n",
      "Mode: Train env_steps 200 total rewards -734.254172930785 total energy tensor([[104.3267]])\n",
      "[0.7400643]\n",
      "Mode: Train env_steps 200 total rewards -981.2926242873073 total energy tensor([[135.3193]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8700111]\n",
      "Mode: Train env_steps 200 total rewards -1426.0697503089905 total energy tensor([[177.6047]])\n",
      "[0.78704345]\n",
      "Mode: Train env_steps 200 total rewards -977.6588836880401 total energy tensor([[117.3337]])\n",
      "[-0.14347069]\n",
      "Mode: Train env_steps 200 total rewards -868.5017963466235 total energy tensor([[113.6072]])\n",
      "[-0.1144909]\n",
      "Mode: Train env_steps 200 total rewards -261.8164003014099 total energy tensor([[69.0569]])\n",
      "[-0.33169848]\n",
      "Mode: Train env_steps 200 total rewards -372.0556503729895 total energy tensor([[78.0932]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5099323]\n",
      "Mode: Train env_steps 200 total rewards -974.743698976934 total energy tensor([[139.6075]])\n",
      "[0.6446435]\n",
      "Mode: Train env_steps 200 total rewards -984.7169537120499 total energy tensor([[143.6417]])\n",
      "[0.82217216]\n",
      "Mode: Train env_steps 200 total rewards -1304.7244983911514 total energy tensor([[166.7737]])\n",
      "[0.26409644]\n",
      "Mode: Train env_steps 200 total rewards -1123.3655340075493 total energy tensor([[164.9820]])\n",
      "[0.8715096]\n",
      "Mode: Train env_steps 200 total rewards -1448.0735263824463 total energy tensor([[171.1751]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20645182]\n",
      "Mode: Train env_steps 200 total rewards -264.21403231269505 total energy tensor([[71.2065]])\n",
      "[-0.7113991]\n",
      "Mode: Train env_steps 200 total rewards -1227.9261068105698 total energy tensor([[169.2181]])\n",
      "[0.17043951]\n",
      "Mode: Train env_steps 200 total rewards -855.7444067189936 total energy tensor([[138.0107]])\n",
      "[0.4999246]\n",
      "Mode: Train env_steps 200 total rewards -374.6227863242966 total energy tensor([[79.7324]])\n",
      "[-0.50251913]\n",
      "Mode: Train env_steps 200 total rewards -1380.9321312904358 total energy tensor([[164.3746]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59208786]\n",
      "Mode: Train env_steps 200 total rewards -1237.1784410476685 total energy tensor([[166.8079]])\n",
      "[-0.77158624]\n",
      "Mode: Train env_steps 200 total rewards -1248.1313389539719 total energy tensor([[162.6971]])\n",
      "[-0.444064]\n",
      "Mode: Train env_steps 200 total rewards -1101.0428127199411 total energy tensor([[163.0996]])\n",
      "[0.5893211]\n",
      "Mode: Train env_steps 200 total rewards -611.8146342332475 total energy tensor([[110.7072]])\n",
      "[-0.35563794]\n",
      "Mode: Train env_steps 200 total rewards -1499.1367173194885 total energy tensor([[190.6127]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40570766]\n",
      "Mode: Test env_steps 200 total rewards -255.12630142648686 total energy tensor([[80.5759]])\n",
      "[0.4454812]\n",
      "Mode: Test env_steps 200 total rewards -256.84773258262794 total energy tensor([[83.5151]])\n",
      "[-0.01003728]\n",
      "Mode: Test env_steps 200 total rewards -1405.4097509384155 total energy tensor([[166.8179]])\n",
      "[-0.68486357]\n",
      "Mode: Test env_steps 200 total rewards -1231.2426413297653 total energy tensor([[164.0018]])\n",
      "[0.8047767]\n",
      "Mode: Test env_steps 200 total rewards -251.361431457859 total energy tensor([[68.0264]])\n",
      "[0.9533899]\n",
      "Mode: Test env_steps 200 total rewards -164.33939268461472 total energy tensor([[79.2535]])\n",
      "[-0.10604542]\n",
      "Mode: Test env_steps 200 total rewards -139.93659996558563 total energy tensor([[77.3588]])\n",
      "[0.4612392]\n",
      "Mode: Test env_steps 200 total rewards -1239.6564019322395 total energy tensor([[160.9161]])\n",
      "[-0.32155034]\n",
      "Mode: Test env_steps 200 total rewards -264.06673237652285 total energy tensor([[80.6031]])\n",
      "[-0.4659347]\n",
      "Mode: Test env_steps 200 total rewards -252.1515119317919 total energy tensor([[101.8810]])\n",
      "400000 -546.0138496625909\n",
      "[0.39369804]\n",
      "Mode: Train env_steps 200 total rewards -7.9728323698509485 total energy tensor([[48.8885]])\n",
      "[0.3029192]\n",
      "Mode: Train env_steps 200 total rewards -240.2515815848601 total energy tensor([[39.4795]])\n",
      "[-0.5216358]\n",
      "Mode: Train env_steps 200 total rewards -7.7704171766527 total energy tensor([[46.4456]])\n",
      "[-0.2431145]\n",
      "Mode: Train env_steps 200 total rewards -249.9397161451634 total energy tensor([[89.8826]])\n",
      "[0.24206115]\n",
      "Mode: Train env_steps 200 total rewards -1453.1262695789337 total energy tensor([[168.5120]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8938501]\n",
      "Mode: Train env_steps 200 total rewards -364.7811168702319 total energy tensor([[68.4006]])\n",
      "[0.01259905]\n",
      "Mode: Train env_steps 200 total rewards -374.20420518843457 total energy tensor([[101.7347]])\n",
      "[-0.11160953]\n",
      "Mode: Train env_steps 200 total rewards -132.83932136274234 total energy tensor([[46.7849]])\n",
      "[0.9627711]\n",
      "Mode: Train env_steps 200 total rewards -133.4696290884749 total energy tensor([[29.8448]])\n",
      "[-0.13917017]\n",
      "Mode: Train env_steps 200 total rewards -131.5987915049991 total energy tensor([[23.9122]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35086566]\n",
      "Mode: Train env_steps 200 total rewards -380.2316843995359 total energy tensor([[106.5511]])\n",
      "[0.07740672]\n",
      "Mode: Train env_steps 200 total rewards -374.3991607998032 total energy tensor([[80.7766]])\n",
      "[-0.28591418]\n",
      "Mode: Train env_steps 200 total rewards -375.40956674632616 total energy tensor([[85.9399]])\n",
      "[-0.20223266]\n",
      "Mode: Train env_steps 200 total rewards -1280.1748886108398 total energy tensor([[167.8515]])\n",
      "[-0.46775246]\n",
      "Mode: Train env_steps 200 total rewards -1350.309145450592 total energy tensor([[171.5852]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00722372]\n",
      "Mode: Train env_steps 200 total rewards -1135.5023378133774 total energy tensor([[173.7780]])\n",
      "[0.51263654]\n",
      "Mode: Train env_steps 200 total rewards -129.5302818755663 total energy tensor([[38.6723]])\n",
      "[-0.24367835]\n",
      "Mode: Train env_steps 200 total rewards -1294.7571818828583 total energy tensor([[169.7270]])\n",
      "[0.38805047]\n",
      "Mode: Train env_steps 200 total rewards -1263.5160160064697 total energy tensor([[167.1221]])\n",
      "[0.05812151]\n",
      "Mode: Train env_steps 200 total rewards -1428.028484582901 total energy tensor([[166.4189]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46531218]\n",
      "Mode: Train env_steps 200 total rewards -442.4605805776082 total energy tensor([[91.2104]])\n",
      "[-0.38232094]\n",
      "Mode: Train env_steps 200 total rewards -448.45794703811407 total energy tensor([[110.5874]])\n",
      "[-0.46760705]\n",
      "Mode: Train env_steps 200 total rewards -1301.2727184295654 total energy tensor([[161.6099]])\n",
      "[0.00356925]\n",
      "Mode: Train env_steps 200 total rewards -505.01709147542715 total energy tensor([[114.8977]])\n",
      "[-0.8680209]\n",
      "Mode: Train env_steps 200 total rewards -508.49368584528565 total energy tensor([[109.2713]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15784377]\n",
      "Mode: Test env_steps 200 total rewards -1437.569317817688 total energy tensor([[162.0111]])\n",
      "[-0.3781997]\n",
      "Mode: Test env_steps 200 total rewards -1113.4496946036816 total energy tensor([[155.3645]])\n",
      "[-0.5171886]\n",
      "Mode: Test env_steps 200 total rewards -977.6246056137607 total energy tensor([[136.3293]])\n",
      "[-0.688846]\n",
      "Mode: Test env_steps 200 total rewards -378.1792920641601 total energy tensor([[97.5962]])\n",
      "[-0.30096185]\n",
      "Mode: Test env_steps 200 total rewards -380.5299565283931 total energy tensor([[87.3030]])\n",
      "[-0.22097957]\n",
      "Mode: Test env_steps 200 total rewards -251.4733482254669 total energy tensor([[82.5309]])\n",
      "[-0.05965098]\n",
      "Mode: Test env_steps 200 total rewards -271.6342036370188 total energy tensor([[109.4095]])\n",
      "[0.67593837]\n",
      "Mode: Test env_steps 200 total rewards -269.1534048486501 total energy tensor([[98.4837]])\n",
      "[0.80125844]\n",
      "Mode: Test env_steps 200 total rewards -1199.1823576688766 total energy tensor([[151.4338]])\n",
      "[0.10829006]\n",
      "Mode: Test env_steps 200 total rewards -270.49469828791916 total energy tensor([[100.3422]])\n",
      "405000 -654.9290879295615\n",
      "[-0.93927824]\n",
      "Mode: Train env_steps 200 total rewards -1425.109981060028 total energy tensor([[169.7811]])\n",
      "[0.32388097]\n",
      "Mode: Train env_steps 200 total rewards -1221.1681580543518 total energy tensor([[157.9220]])\n",
      "[-0.92122144]\n",
      "Mode: Train env_steps 200 total rewards -1278.3908154964447 total energy tensor([[165.5206]])\n",
      "[0.75005776]\n",
      "Mode: Train env_steps 200 total rewards -739.8785149629693 total energy tensor([[122.1949]])\n",
      "[0.7409332]\n",
      "Mode: Train env_steps 200 total rewards -380.41186399385333 total energy tensor([[95.8193]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5012295]\n",
      "Mode: Train env_steps 200 total rewards -138.98468844243325 total energy tensor([[75.8414]])\n",
      "[0.8870207]\n",
      "Mode: Train env_steps 200 total rewards -730.3948566887993 total energy tensor([[119.2426]])\n",
      "[0.52243274]\n",
      "Mode: Train env_steps 200 total rewards -463.8423111878801 total energy tensor([[123.1369]])\n",
      "[-0.6155447]\n",
      "Mode: Train env_steps 200 total rewards -258.6457209214568 total energy tensor([[76.3198]])\n",
      "[0.02716523]\n",
      "Mode: Train env_steps 200 total rewards -1336.641967177391 total energy tensor([[166.8755]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13800563]\n",
      "Mode: Train env_steps 200 total rewards -503.46594149107113 total energy tensor([[105.6562]])\n",
      "[-0.07962376]\n",
      "Mode: Train env_steps 200 total rewards -1261.2232055664062 total energy tensor([[167.3855]])\n",
      "[-0.9337408]\n",
      "Mode: Train env_steps 200 total rewards -1500.339220046997 total energy tensor([[191.9232]])\n",
      "[-0.02076485]\n",
      "Mode: Train env_steps 200 total rewards -139.03079948446248 total energy tensor([[80.3643]])\n",
      "[-0.37043434]\n",
      "Mode: Train env_steps 200 total rewards -1120.7379791736603 total energy tensor([[174.3461]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00029197]\n",
      "Mode: Train env_steps 200 total rewards -249.2897368826416 total energy tensor([[75.4616]])\n",
      "[0.13698114]\n",
      "Mode: Train env_steps 200 total rewards -1489.0262653827667 total energy tensor([[176.9061]])\n",
      "[0.965952]\n",
      "Mode: Train env_steps 200 total rewards -139.708453211264 total energy tensor([[68.6959]])\n",
      "[-0.00342468]\n",
      "Mode: Train env_steps 200 total rewards -136.26034616614197 total energy tensor([[46.8442]])\n",
      "[0.4404519]\n",
      "Mode: Train env_steps 200 total rewards -1221.712308138609 total energy tensor([[155.3510]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5033237]\n",
      "Mode: Train env_steps 200 total rewards -493.24839497357607 total energy tensor([[97.5232]])\n",
      "[0.05986564]\n",
      "Mode: Train env_steps 200 total rewards -143.22263942472637 total energy tensor([[105.8816]])\n",
      "[-0.279413]\n",
      "Mode: Train env_steps 200 total rewards -994.1983987443746 total energy tensor([[132.9156]])\n",
      "[-0.18274876]\n",
      "Mode: Train env_steps 200 total rewards -253.2318839598447 total energy tensor([[98.4899]])\n",
      "[-0.71171206]\n",
      "Mode: Train env_steps 200 total rewards -14.46791280634352 total energy tensor([[88.5165]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8102946]\n",
      "Mode: Test env_steps 200 total rewards -867.4537761052488 total energy tensor([[136.7721]])\n",
      "[0.2089924]\n",
      "Mode: Test env_steps 200 total rewards -1248.6966583132744 total energy tensor([[161.8284]])\n",
      "[-0.7216068]\n",
      "Mode: Test env_steps 200 total rewards -3.88136128777478 total energy tensor([[24.2018]])\n",
      "[0.29543498]\n",
      "Mode: Test env_steps 200 total rewards -488.7686525637964 total energy tensor([[73.5381]])\n",
      "[0.8813568]\n",
      "Mode: Test env_steps 200 total rewards -251.29721401724964 total energy tensor([[79.3040]])\n",
      "[0.35284925]\n",
      "Mode: Test env_steps 200 total rewards -364.77794049377917 total energy tensor([[55.1791]])\n",
      "[0.813308]\n",
      "Mode: Test env_steps 200 total rewards -134.2677959256107 total energy tensor([[50.6844]])\n",
      "[-0.14810476]\n",
      "Mode: Test env_steps 200 total rewards -136.66418681642972 total energy tensor([[66.9455]])\n",
      "[-0.9634593]\n",
      "Mode: Test env_steps 200 total rewards -1251.19200694561 total energy tensor([[163.7770]])\n",
      "[-0.22390993]\n",
      "Mode: Test env_steps 200 total rewards -129.06565583174233 total energy tensor([[28.3070]])\n",
      "410000 -487.6065248300516\n",
      "[0.36411187]\n",
      "Mode: Train env_steps 200 total rewards -251.27229766384698 total energy tensor([[80.1598]])\n",
      "[0.85205394]\n",
      "Mode: Train env_steps 200 total rewards -1101.1203386485577 total energy tensor([[152.9813]])\n",
      "[0.14332575]\n",
      "Mode: Train env_steps 200 total rewards -1493.7582244873047 total energy tensor([[190.8067]])\n",
      "[0.6763421]\n",
      "Mode: Train env_steps 200 total rewards -366.5980915625114 total energy tensor([[51.8520]])\n",
      "[-0.6454805]\n",
      "Mode: Train env_steps 200 total rewards -133.6226551302825 total energy tensor([[44.0254]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92009324]\n",
      "Mode: Train env_steps 200 total rewards -375.92831923321495 total energy tensor([[68.3968]])\n",
      "[0.04682988]\n",
      "Mode: Train env_steps 200 total rewards -139.82385364770926 total energy tensor([[82.4215]])\n",
      "[-0.11079733]\n",
      "Mode: Train env_steps 200 total rewards -249.49534233170561 total energy tensor([[68.7545]])\n",
      "[0.7561312]\n",
      "Mode: Train env_steps 200 total rewards -135.7859048999817 total energy tensor([[58.3311]])\n",
      "[0.6323501]\n",
      "Mode: Train env_steps 200 total rewards -131.21888885377848 total energy tensor([[46.4023]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7941363]\n",
      "Mode: Train env_steps 200 total rewards -266.5211543655023 total energy tensor([[79.0434]])\n",
      "[-0.8397889]\n",
      "Mode: Train env_steps 200 total rewards -1303.2378635406494 total energy tensor([[162.5650]])\n",
      "[0.74035674]\n",
      "Mode: Train env_steps 200 total rewards -256.4375153449364 total energy tensor([[58.0535]])\n",
      "[-0.6217432]\n",
      "Mode: Train env_steps 200 total rewards -261.9805348663358 total energy tensor([[62.5091]])\n",
      "[-0.13115576]\n",
      "Mode: Train env_steps 200 total rewards -1243.014707505703 total energy tensor([[144.8773]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6787886]\n",
      "Mode: Train env_steps 200 total rewards -505.4657732732594 total energy tensor([[95.5435]])\n",
      "[0.10167997]\n",
      "Mode: Train env_steps 200 total rewards -1112.0448008291423 total energy tensor([[150.4921]])\n",
      "[-0.66309315]\n",
      "Mode: Train env_steps 200 total rewards -261.75341315055266 total energy tensor([[66.7929]])\n",
      "[0.6693543]\n",
      "Mode: Train env_steps 200 total rewards -614.7067438485101 total energy tensor([[108.5744]])\n",
      "[0.7509269]\n",
      "Mode: Train env_steps 200 total rewards -138.2035475181474 total energy tensor([[71.5523]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.674425]\n",
      "Mode: Train env_steps 200 total rewards -736.3390750661492 total energy tensor([[137.2688]])\n",
      "[-0.7983896]\n",
      "Mode: Train env_steps 200 total rewards -1499.5842418670654 total energy tensor([[170.2742]])\n",
      "[-0.8625973]\n",
      "Mode: Train env_steps 200 total rewards -1278.527986049652 total energy tensor([[164.6997]])\n",
      "[-0.11635501]\n",
      "Mode: Train env_steps 200 total rewards -235.19580067915376 total energy tensor([[89.6646]])\n",
      "[0.07019391]\n",
      "Mode: Train env_steps 200 total rewards -1348.682400226593 total energy tensor([[165.3113]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90204453]\n",
      "Mode: Test env_steps 200 total rewards -985.0117013962008 total energy tensor([[128.3777]])\n",
      "[-0.15336314]\n",
      "Mode: Test env_steps 200 total rewards -137.93656262452714 total energy tensor([[65.6634]])\n",
      "[0.21906337]\n",
      "Mode: Test env_steps 200 total rewards -10.307194807799533 total energy tensor([[57.1398]])\n",
      "[-0.86846024]\n",
      "Mode: Test env_steps 200 total rewards -734.1527971527539 total energy tensor([[97.8199]])\n",
      "[0.76886815]\n",
      "Mode: Test env_steps 200 total rewards -371.8597663254477 total energy tensor([[74.8639]])\n",
      "[0.27665815]\n",
      "Mode: Test env_steps 200 total rewards -727.4187606177293 total energy tensor([[101.6248]])\n",
      "[0.9736985]\n",
      "Mode: Test env_steps 200 total rewards -247.4512928116601 total energy tensor([[67.1823]])\n",
      "[-0.5250515]\n",
      "Mode: Test env_steps 200 total rewards -488.5773376960424 total energy tensor([[103.7173]])\n",
      "[0.27523533]\n",
      "Mode: Test env_steps 200 total rewards -135.97666889370885 total energy tensor([[61.5601]])\n",
      "[0.43442902]\n",
      "Mode: Test env_steps 200 total rewards -615.2824995790652 total energy tensor([[95.3336]])\n",
      "415000 -445.39745819049347\n",
      "[0.33937043]\n",
      "Mode: Train env_steps 200 total rewards -2.6969405508134514 total energy tensor([[17.3599]])\n",
      "[-0.9969799]\n",
      "Mode: Train env_steps 200 total rewards -135.83289840468206 total energy tensor([[61.2139]])\n",
      "[0.06933893]\n",
      "Mode: Train env_steps 200 total rewards -1234.8447147607803 total energy tensor([[160.5953]])\n",
      "[0.78802377]\n",
      "Mode: Train env_steps 200 total rewards -259.6984543935396 total energy tensor([[85.3512]])\n",
      "[-0.15968809]\n",
      "Mode: Train env_steps 200 total rewards -9.250707373023033 total energy tensor([[54.8895]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35041553]\n",
      "Mode: Train env_steps 200 total rewards -488.3279220573604 total energy tensor([[79.0230]])\n",
      "[0.5154151]\n",
      "Mode: Train env_steps 200 total rewards -458.15384874655865 total energy tensor([[101.8902]])\n",
      "[0.41738915]\n",
      "Mode: Train env_steps 200 total rewards -254.61245089606382 total energy tensor([[88.0285]])\n",
      "[0.87636936]\n",
      "Mode: Train env_steps 200 total rewards -488.20618254551664 total energy tensor([[81.3173]])\n",
      "[-0.30365542]\n",
      "Mode: Train env_steps 200 total rewards -376.4357290903572 total energy tensor([[80.8120]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6474287]\n",
      "Mode: Train env_steps 200 total rewards -245.87309024808928 total energy tensor([[62.1330]])\n",
      "[0.6062976]\n",
      "Mode: Train env_steps 200 total rewards -242.40594086842611 total energy tensor([[60.5322]])\n",
      "[-0.8014039]\n",
      "Mode: Train env_steps 200 total rewards -247.5807328284718 total energy tensor([[70.5830]])\n",
      "[-0.5266084]\n",
      "Mode: Train env_steps 200 total rewards -1133.191066622734 total energy tensor([[171.9556]])\n",
      "[-0.49673977]\n",
      "Mode: Train env_steps 200 total rewards -1362.3544297218323 total energy tensor([[165.2128]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5554379]\n",
      "Mode: Train env_steps 200 total rewards -133.99251635093242 total energy tensor([[48.4209]])\n",
      "[-0.94827497]\n",
      "Mode: Train env_steps 200 total rewards -127.78200763650239 total energy tensor([[45.8120]])\n",
      "[-0.73222953]\n",
      "Mode: Train env_steps 200 total rewards -613.228162785992 total energy tensor([[125.2408]])\n",
      "[0.5024073]\n",
      "Mode: Train env_steps 200 total rewards -1112.1209086347371 total energy tensor([[153.9602]])\n",
      "[-0.742877]\n",
      "Mode: Train env_steps 200 total rewards -4.287970283883624 total energy tensor([[28.0472]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68523717]\n",
      "Mode: Train env_steps 200 total rewards -249.37135056091938 total energy tensor([[77.2886]])\n",
      "[-0.7324919]\n",
      "Mode: Train env_steps 200 total rewards -129.96503994090017 total energy tensor([[66.1620]])\n",
      "[-0.27597186]\n",
      "Mode: Train env_steps 200 total rewards -735.6548462021165 total energy tensor([[95.0522]])\n",
      "[-0.5042346]\n",
      "Mode: Train env_steps 200 total rewards -260.3462843266898 total energy tensor([[81.5445]])\n",
      "[0.43250793]\n",
      "Mode: Train env_steps 200 total rewards -140.38267752714455 total energy tensor([[108.2558]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9894286]\n",
      "Mode: Test env_steps 200 total rewards -1280.839130334556 total energy tensor([[144.2217]])\n",
      "[-0.02178252]\n",
      "Mode: Test env_steps 200 total rewards -1213.7612066566944 total energy tensor([[144.4628]])\n",
      "[-0.9052048]\n",
      "Mode: Test env_steps 200 total rewards -246.3044047304429 total energy tensor([[53.2923]])\n",
      "[-4.696879e-05]\n",
      "Mode: Test env_steps 200 total rewards -859.1374215565156 total energy tensor([[114.8545]])\n",
      "[0.9645524]\n",
      "Mode: Test env_steps 200 total rewards -126.99321810572292 total energy tensor([[27.6926]])\n",
      "[0.8731462]\n",
      "Mode: Test env_steps 200 total rewards -131.0826234868 total energy tensor([[35.5235]])\n",
      "[0.01977936]\n",
      "Mode: Test env_steps 200 total rewards -76.83876741828863 total energy tensor([[71.0642]])\n",
      "[0.95002645]\n",
      "Mode: Test env_steps 200 total rewards -240.21575324419246 total energy tensor([[33.1252]])\n",
      "[-0.44768244]\n",
      "Mode: Test env_steps 200 total rewards -242.75645595607057 total energy tensor([[34.9261]])\n",
      "[0.3508158]\n",
      "Mode: Test env_steps 200 total rewards -979.0789655246772 total energy tensor([[112.4339]])\n",
      "420000 -539.700794701396\n",
      "[-0.8052237]\n",
      "Mode: Train env_steps 200 total rewards -6.300628922064789 total energy tensor([[37.1444]])\n",
      "[-0.40631205]\n",
      "Mode: Train env_steps 200 total rewards -485.89275098318467 total energy tensor([[71.3124]])\n",
      "[0.6714075]\n",
      "Mode: Train env_steps 200 total rewards -242.94247451485717 total energy tensor([[31.9061]])\n",
      "[0.7773784]\n",
      "Mode: Train env_steps 200 total rewards -975.0791108412668 total energy tensor([[119.8136]])\n",
      "[0.2866802]\n",
      "Mode: Train env_steps 200 total rewards -1287.9577320814133 total energy tensor([[159.2951]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09971948]\n",
      "Mode: Train env_steps 200 total rewards -487.98615374369547 total energy tensor([[112.8130]])\n",
      "[0.7087714]\n",
      "Mode: Train env_steps 200 total rewards -1138.1875107884407 total energy tensor([[169.0540]])\n",
      "[0.18754141]\n",
      "Mode: Train env_steps 200 total rewards -376.1671998745296 total energy tensor([[87.0110]])\n",
      "[0.4249222]\n",
      "Mode: Train env_steps 200 total rewards -248.59308596793562 total energy tensor([[78.3694]])\n",
      "[-0.88277715]\n",
      "Mode: Train env_steps 200 total rewards -1112.1849975790828 total energy tensor([[158.8361]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05613944]\n",
      "Mode: Train env_steps 200 total rewards -134.77981605078094 total energy tensor([[42.6362]])\n",
      "[0.5040249]\n",
      "Mode: Train env_steps 200 total rewards -373.38804822275415 total energy tensor([[60.7126]])\n",
      "[0.75908506]\n",
      "Mode: Train env_steps 200 total rewards -616.837658197619 total energy tensor([[95.5530]])\n",
      "[-0.18791743]\n",
      "Mode: Train env_steps 200 total rewards -319.03096571794595 total energy tensor([[82.0247]])\n",
      "[0.16886821]\n",
      "Mode: Train env_steps 200 total rewards -125.35554991394747 total energy tensor([[36.2780]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5573923]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Train env_steps 200 total rewards -1248.8343906775117 total energy tensor([[143.7069]])\n",
      "[0.6559432]\n",
      "Mode: Train env_steps 200 total rewards -370.09675573103596 total energy tensor([[85.4079]])\n",
      "[-0.04974037]\n",
      "Mode: Train env_steps 200 total rewards -373.97483459301293 total energy tensor([[98.2479]])\n",
      "[0.95804894]\n",
      "Mode: Train env_steps 200 total rewards -1396.314840555191 total energy tensor([[170.2910]])\n",
      "[-0.42790577]\n",
      "Mode: Train env_steps 200 total rewards -491.5468391701579 total energy tensor([[92.9548]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7542288]\n",
      "Mode: Train env_steps 200 total rewards -374.972775986942 total energy tensor([[82.9695]])\n",
      "[0.62710613]\n",
      "Mode: Train env_steps 200 total rewards -1188.2800327539444 total energy tensor([[150.9728]])\n",
      "[0.68676007]\n",
      "Mode: Train env_steps 200 total rewards -1212.1273705363274 total energy tensor([[156.3760]])\n",
      "[0.31975064]\n",
      "Mode: Train env_steps 200 total rewards -1138.278123497963 total energy tensor([[171.5652]])\n",
      "[0.7671063]\n",
      "Mode: Train env_steps 200 total rewards -363.3763553451572 total energy tensor([[82.7836]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28253174]\n",
      "Mode: Test env_steps 200 total rewards -980.9906368765514 total energy tensor([[143.0483]])\n",
      "[0.43940887]\n",
      "Mode: Test env_steps 200 total rewards -140.9483801673632 total energy tensor([[90.7559]])\n",
      "[0.5571624]\n",
      "Mode: Test env_steps 200 total rewards -374.53953235875815 total energy tensor([[90.2222]])\n",
      "[0.31933838]\n",
      "Mode: Test env_steps 200 total rewards -143.16349505726248 total energy tensor([[104.1748]])\n",
      "[0.16305476]\n",
      "Mode: Test env_steps 200 total rewards -492.16141487983987 total energy tensor([[107.6476]])\n",
      "[0.91097087]\n",
      "Mode: Test env_steps 200 total rewards -267.283868371509 total energy tensor([[97.3224]])\n",
      "[0.8077047]\n",
      "Mode: Test env_steps 200 total rewards -374.5145606184378 total energy tensor([[95.5607]])\n",
      "[0.23354812]\n",
      "Mode: Test env_steps 200 total rewards -973.0600812103366 total energy tensor([[142.9332]])\n",
      "[-0.520353]\n",
      "Mode: Test env_steps 200 total rewards -255.37806432740763 total energy tensor([[71.1426]])\n",
      "[-0.606052]\n",
      "Mode: Test env_steps 200 total rewards -128.52452211876516 total energy tensor([[30.9393]])\n",
      "425000 -413.05645559862313\n",
      "[0.2808061]\n",
      "Mode: Train env_steps 200 total rewards -1.8662969241850078 total energy tensor([[12.4259]])\n",
      "[-0.92517227]\n",
      "Mode: Train env_steps 200 total rewards -979.7231820207089 total energy tensor([[152.0975]])\n",
      "[-0.24524663]\n",
      "Mode: Train env_steps 200 total rewards -263.63825802877545 total energy tensor([[88.4947]])\n",
      "[-0.49975497]\n",
      "Mode: Train env_steps 200 total rewards -378.03305468149483 total energy tensor([[104.8734]])\n",
      "[0.725546]\n",
      "Mode: Train env_steps 200 total rewards -1366.0793769359589 total energy tensor([[163.8565]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73079705]\n",
      "Mode: Train env_steps 200 total rewards -975.8966704823542 total energy tensor([[133.9583]])\n",
      "[0.90115887]\n",
      "Mode: Train env_steps 200 total rewards -972.2416936270893 total energy tensor([[139.5472]])\n",
      "[0.6961711]\n",
      "Mode: Train env_steps 200 total rewards -1522.159809589386 total energy tensor([[181.6191]])\n",
      "[-0.9309674]\n",
      "Mode: Train env_steps 200 total rewards -854.8541887680767 total energy tensor([[129.3157]])\n",
      "[0.21279196]\n",
      "Mode: Train env_steps 200 total rewards -248.66994868824258 total energy tensor([[71.8671]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93381596]\n",
      "Mode: Train env_steps 200 total rewards -1513.4657216072083 total energy tensor([[186.9607]])\n",
      "[-0.07869097]\n",
      "Mode: Train env_steps 200 total rewards -1224.6197945550084 total energy tensor([[140.3268]])\n",
      "[-0.85620743]\n",
      "Mode: Train env_steps 200 total rewards -381.5781585124205 total energy tensor([[86.9440]])\n",
      "[0.99875695]\n",
      "Mode: Train env_steps 200 total rewards -489.2280795333063 total energy tensor([[84.1289]])\n",
      "[-0.17871727]\n",
      "Mode: Train env_steps 200 total rewards -435.4441549545154 total energy tensor([[92.0409]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6245788]\n",
      "Mode: Train env_steps 200 total rewards -735.0169820350129 total energy tensor([[102.9184]])\n",
      "[0.90963787]\n",
      "Mode: Train env_steps 200 total rewards -1501.2474870681763 total energy tensor([[189.3440]])\n",
      "[-0.1286269]\n",
      "Mode: Train env_steps 200 total rewards -977.0145190991461 total energy tensor([[108.9338]])\n",
      "[-0.19140856]\n",
      "Mode: Train env_steps 200 total rewards -860.7971821108367 total energy tensor([[116.1745]])\n",
      "[-0.740513]\n",
      "Mode: Train env_steps 200 total rewards -361.6523361908039 total energy tensor([[87.0439]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9351569]\n",
      "Mode: Train env_steps 200 total rewards -1241.4115005731583 total energy tensor([[167.2419]])\n",
      "[0.12457237]\n",
      "Mode: Train env_steps 200 total rewards -370.51964684866834 total energy tensor([[109.7158]])\n",
      "[0.29809535]\n",
      "Mode: Train env_steps 200 total rewards -131.4368795985356 total energy tensor([[36.4896]])\n",
      "[0.10829293]\n",
      "Mode: Train env_steps 200 total rewards -1213.4833673238754 total energy tensor([[172.1264]])\n",
      "[0.2639932]\n",
      "Mode: Train env_steps 200 total rewards -1410.0896410942078 total energy tensor([[176.8180]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38837698]\n",
      "Mode: Test env_steps 200 total rewards -132.23806393519044 total energy tensor([[43.2796]])\n",
      "[0.9237514]\n",
      "Mode: Test env_steps 200 total rewards -611.7213248518528 total energy tensor([[94.4008]])\n",
      "[0.776213]\n",
      "Mode: Test env_steps 200 total rewards -1227.129038155079 total energy tensor([[161.9068]])\n",
      "[0.28660345]\n",
      "Mode: Test env_steps 200 total rewards -2.957451847702032 total energy tensor([[13.3552]])\n",
      "[0.36688462]\n",
      "Mode: Test env_steps 200 total rewards -365.5408311225474 total energy tensor([[130.0273]])\n",
      "[-0.72618526]\n",
      "Mode: Test env_steps 200 total rewards -244.19738967840385 total energy tensor([[49.7790]])\n",
      "[-0.48725528]\n",
      "Mode: Test env_steps 200 total rewards -130.57289413231774 total energy tensor([[31.3509]])\n",
      "[-0.23696068]\n",
      "Mode: Test env_steps 200 total rewards -623.7437009122223 total energy tensor([[111.4495]])\n",
      "[0.93997777]\n",
      "Mode: Test env_steps 200 total rewards -130.65048499743716 total energy tensor([[40.1162]])\n",
      "[-0.9340707]\n",
      "Mode: Test env_steps 200 total rewards -131.5480969498676 total energy tensor([[34.4927]])\n",
      "430000 -360.029927658262\n",
      "[-0.20987667]\n",
      "Mode: Train env_steps 200 total rewards -5.921306870877743 total energy tensor([[31.5144]])\n",
      "[0.08019897]\n",
      "Mode: Train env_steps 200 total rewards -1312.651627779007 total energy tensor([[162.7000]])\n",
      "[0.03068482]\n",
      "Mode: Train env_steps 200 total rewards -1198.606901049614 total energy tensor([[154.2265]])\n",
      "[-0.06939483]\n",
      "Mode: Train env_steps 200 total rewards -1347.746572136879 total energy tensor([[163.9621]])\n",
      "[-0.57430464]\n",
      "Mode: Train env_steps 200 total rewards -1220.715634047985 total energy tensor([[156.2159]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7439836]\n",
      "Mode: Train env_steps 200 total rewards -1302.7230031490326 total energy tensor([[164.0231]])\n",
      "[-0.0821383]\n",
      "Mode: Train env_steps 200 total rewards -1358.2977486848831 total energy tensor([[159.6767]])\n",
      "[-0.5604254]\n",
      "Mode: Train env_steps 200 total rewards -855.0378905796679 total energy tensor([[123.6279]])\n",
      "[0.8501284]\n",
      "Mode: Train env_steps 200 total rewards -1440.2432749271393 total energy tensor([[161.9276]])\n",
      "[0.12170623]\n",
      "Mode: Train env_steps 200 total rewards -141.1369075931143 total energy tensor([[62.4204]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02341496]\n",
      "Mode: Train env_steps 200 total rewards -984.0423566740938 total energy tensor([[129.3618]])\n",
      "[0.314461]\n",
      "Mode: Train env_steps 200 total rewards -245.40715193198412 total energy tensor([[45.3022]])\n",
      "[-0.96642226]\n",
      "Mode: Train env_steps 200 total rewards -244.95872417933424 total energy tensor([[48.8660]])\n",
      "[0.5905959]\n",
      "Mode: Train env_steps 200 total rewards -9.246332577429712 total energy tensor([[56.6609]])\n",
      "[-0.80055106]\n",
      "Mode: Train env_steps 200 total rewards -244.67463251265872 total energy tensor([[48.1458]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10241907]\n",
      "Mode: Train env_steps 200 total rewards -134.80941251595505 total energy tensor([[50.7010]])\n",
      "[-0.28405857]\n",
      "Mode: Train env_steps 200 total rewards -982.2864822368138 total energy tensor([[134.0576]])\n",
      "[0.57062715]\n",
      "Mode: Train env_steps 200 total rewards -724.3676839631953 total energy tensor([[106.7961]])\n",
      "[0.2585143]\n",
      "Mode: Train env_steps 200 total rewards -249.4257534299977 total energy tensor([[72.2895]])\n",
      "[0.93696696]\n",
      "Mode: Train env_steps 200 total rewards -858.5458062422695 total energy tensor([[129.6725]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32846084]\n",
      "Mode: Train env_steps 200 total rewards -615.4828419523756 total energy tensor([[78.6058]])\n",
      "[-0.11047101]\n",
      "Mode: Train env_steps 200 total rewards -137.87334072217345 total energy tensor([[78.0624]])\n",
      "[-0.6135862]\n",
      "Mode: Train env_steps 200 total rewards -1454.1390345096588 total energy tensor([[161.9322]])\n",
      "[-0.609393]\n",
      "Mode: Train env_steps 200 total rewards -607.9944067920105 total energy tensor([[80.1504]])\n",
      "[-0.15134628]\n",
      "Mode: Train env_steps 200 total rewards -250.89656227617525 total energy tensor([[85.5840]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17592484]\n",
      "Mode: Test env_steps 200 total rewards -1264.554854735732 total energy tensor([[153.7999]])\n",
      "[0.28860202]\n",
      "Mode: Test env_steps 200 total rewards -250.82576425001025 total energy tensor([[77.6875]])\n",
      "[-0.7916396]\n",
      "Mode: Test env_steps 200 total rewards -371.2844333294779 total energy tensor([[71.8634]])\n",
      "[0.65589964]\n",
      "Mode: Test env_steps 200 total rewards -1446.9890472888947 total energy tensor([[165.0556]])\n",
      "[0.15965767]\n",
      "Mode: Test env_steps 200 total rewards -993.0983888177434 total energy tensor([[135.9533]])\n",
      "[0.89082247]\n",
      "Mode: Test env_steps 200 total rewards -378.8266368743498 total energy tensor([[77.5898]])\n",
      "[0.13677372]\n",
      "Mode: Test env_steps 200 total rewards -1138.1691706534475 total energy tensor([[151.7357]])\n",
      "[0.5017185]\n",
      "Mode: Test env_steps 200 total rewards -628.5309023889713 total energy tensor([[120.9514]])\n",
      "[-0.57242495]\n",
      "Mode: Test env_steps 200 total rewards -1109.0069689708762 total energy tensor([[149.3359]])\n",
      "[-0.5693182]\n",
      "Mode: Test env_steps 200 total rewards -369.9138653113041 total energy tensor([[72.8335]])\n",
      "435000 -795.1200032620807\n",
      "[0.08695554]\n",
      "Mode: Train env_steps 200 total rewards -648.4040860752575 total energy tensor([[110.5990]])\n",
      "[-0.7289182]\n",
      "Mode: Train env_steps 200 total rewards -731.6659645715263 total energy tensor([[117.2994]])\n",
      "[0.08822431]\n",
      "Mode: Train env_steps 200 total rewards -248.34850143094081 total energy tensor([[66.0985]])\n",
      "[0.4111705]\n",
      "Mode: Train env_steps 200 total rewards -1253.4436062574387 total energy tensor([[146.2415]])\n",
      "[-0.9324895]\n",
      "Mode: Train env_steps 200 total rewards -1278.716660618782 total energy tensor([[163.5122]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34542513]\n",
      "Mode: Train env_steps 200 total rewards -265.56376297120005 total energy tensor([[75.2824]])\n",
      "[-0.22839588]\n",
      "Mode: Train env_steps 200 total rewards -1338.5108119249344 total energy tensor([[162.6717]])\n",
      "[0.0709786]\n",
      "Mode: Train env_steps 200 total rewards -374.83890540665016 total energy tensor([[88.1481]])\n",
      "[-0.49133965]\n",
      "Mode: Train env_steps 200 total rewards -373.38999455957673 total energy tensor([[81.0548]])\n",
      "[-0.9233724]\n",
      "Mode: Train env_steps 200 total rewards -1011.3191604069434 total energy tensor([[131.4469]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04826589]\n",
      "Mode: Train env_steps 200 total rewards -616.4561207401566 total energy tensor([[115.1733]])\n",
      "[-0.561531]\n",
      "Mode: Train env_steps 200 total rewards -617.8754366654903 total energy tensor([[102.9551]])\n",
      "[0.38336137]\n",
      "Mode: Train env_steps 200 total rewards -497.6327227426227 total energy tensor([[93.4064]])\n",
      "[0.7755057]\n",
      "Mode: Train env_steps 200 total rewards -264.554052299005 total energy tensor([[70.9413]])\n",
      "[-0.6102137]\n",
      "Mode: Train env_steps 200 total rewards -499.3772123702802 total energy tensor([[97.3545]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08639876]\n",
      "Mode: Train env_steps 200 total rewards -251.83979670266854 total energy tensor([[101.7200]])\n",
      "[0.5383748]\n",
      "Mode: Train env_steps 200 total rewards -1190.9692844748497 total energy tensor([[166.6735]])\n",
      "[0.9780307]\n",
      "Mode: Train env_steps 200 total rewards -1432.1904225349426 total energy tensor([[159.3682]])\n",
      "[0.85496104]\n",
      "Mode: Train env_steps 200 total rewards -375.2154930102988 total energy tensor([[86.7281]])\n",
      "[0.58038545]\n",
      "Mode: Train env_steps 200 total rewards -1104.7877330854535 total energy tensor([[165.4623]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4630611]\n",
      "Mode: Train env_steps 200 total rewards -983.5042639113963 total energy tensor([[142.5357]])\n",
      "[-0.2604495]\n",
      "Mode: Train env_steps 200 total rewards -377.8438459390891 total energy tensor([[89.3457]])\n",
      "[-0.52105767]\n",
      "Mode: Train env_steps 200 total rewards -1128.8690568711609 total energy tensor([[150.7514]])\n",
      "[-0.9327691]\n",
      "Mode: Train env_steps 200 total rewards -269.27276806533337 total energy tensor([[101.0744]])\n",
      "[-0.9666297]\n",
      "Mode: Train env_steps 200 total rewards -1138.904493946582 total energy tensor([[153.9645]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7091264]\n",
      "Mode: Test env_steps 200 total rewards -740.6019116437647 total energy tensor([[97.5185]])\n",
      "[-0.20576996]\n",
      "Mode: Test env_steps 200 total rewards -491.0125402652193 total energy tensor([[98.4561]])\n",
      "[0.01363221]\n",
      "Mode: Test env_steps 200 total rewards -259.4755960605107 total energy tensor([[92.3610]])\n",
      "[-0.05783458]\n",
      "Mode: Test env_steps 200 total rewards -999.9719266088214 total energy tensor([[111.4494]])\n",
      "[-0.927245]\n",
      "Mode: Test env_steps 200 total rewards -271.10000571468845 total energy tensor([[104.5059]])\n",
      "[-0.3599059]\n",
      "Mode: Test env_steps 200 total rewards -871.5129715990042 total energy tensor([[115.5594]])\n",
      "[-0.40802303]\n",
      "Mode: Test env_steps 200 total rewards -268.79264000663534 total energy tensor([[100.0666]])\n",
      "[0.5101024]\n",
      "Mode: Test env_steps 200 total rewards -1286.918107867241 total energy tensor([[160.2365]])\n",
      "[-0.48366293]\n",
      "Mode: Test env_steps 200 total rewards -730.5295947713312 total energy tensor([[100.8880]])\n",
      "[-0.27867216]\n",
      "Mode: Test env_steps 200 total rewards -488.89062396693043 total energy tensor([[107.4093]])\n",
      "440000 -640.8805918504147\n",
      "[-0.607429]\n",
      "Mode: Train env_steps 200 total rewards -970.9805064972606 total energy tensor([[113.2516]])\n",
      "[0.4544151]\n",
      "Mode: Train env_steps 200 total rewards -1493.5989191532135 total energy tensor([[177.1701]])\n",
      "[0.13784261]\n",
      "Mode: Train env_steps 200 total rewards -997.520081940107 total energy tensor([[111.1828]])\n",
      "[-0.7465006]\n",
      "Mode: Train env_steps 200 total rewards -269.58483047410846 total energy tensor([[100.0391]])\n",
      "[-0.11851942]\n",
      "Mode: Train env_steps 200 total rewards -259.09221093845554 total energy tensor([[92.0684]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4647322]\n",
      "Mode: Train env_steps 200 total rewards -741.5626011826098 total energy tensor([[133.6906]])\n",
      "[0.07843478]\n",
      "Mode: Train env_steps 200 total rewards -625.8465609326959 total energy tensor([[124.0001]])\n",
      "[-0.49319506]\n",
      "Mode: Train env_steps 200 total rewards -1003.1504828343168 total energy tensor([[121.9942]])\n",
      "[0.2835764]\n",
      "Mode: Train env_steps 200 total rewards -623.8680822215974 total energy tensor([[121.2222]])\n",
      "[-0.6666769]\n",
      "Mode: Train env_steps 200 total rewards -741.0002602841705 total energy tensor([[127.4683]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54952365]\n",
      "Mode: Train env_steps 200 total rewards -1287.7769761681557 total energy tensor([[156.9377]])\n",
      "[-0.3642587]\n",
      "Mode: Train env_steps 200 total rewards -269.0644681993872 total energy tensor([[85.5713]])\n",
      "[-0.618834]\n",
      "Mode: Train env_steps 200 total rewards -252.24461742304265 total energy tensor([[87.5055]])\n",
      "[0.71868247]\n",
      "Mode: Train env_steps 200 total rewards -1438.3255953788757 total energy tensor([[174.8046]])\n",
      "[0.19296241]\n",
      "Mode: Train env_steps 200 total rewards -265.7921145297587 total energy tensor([[84.7476]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:24<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7153671]\n",
      "Mode: Train env_steps 200 total rewards -728.4946383293718 total energy tensor([[123.4223]])\n",
      "[0.868281]\n",
      "Mode: Train env_steps 200 total rewards -981.6552441325039 total energy tensor([[134.3960]])\n",
      "[-0.24750228]\n",
      "Mode: Train env_steps 200 total rewards -265.6423298912123 total energy tensor([[85.7564]])\n",
      "[-0.4224139]\n",
      "Mode: Train env_steps 200 total rewards -728.3769054997247 total energy tensor([[116.2064]])\n",
      "[-0.5284872]\n",
      "Mode: Train env_steps 200 total rewards -734.1739265006036 total energy tensor([[124.8718]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24171148]\n",
      "Mode: Train env_steps 200 total rewards -261.61647521704435 total energy tensor([[83.1036]])\n",
      "[-0.7286848]\n",
      "Mode: Train env_steps 200 total rewards -731.9759610905312 total energy tensor([[90.8650]])\n",
      "[-0.9435276]\n",
      "Mode: Train env_steps 200 total rewards -268.1672658165917 total energy tensor([[92.1681]])\n",
      "[-0.07113364]\n",
      "Mode: Train env_steps 200 total rewards -259.57470375625417 total energy tensor([[72.1019]])\n",
      "[-0.57979745]\n",
      "Mode: Train env_steps 200 total rewards -268.4627324510366 total energy tensor([[76.6694]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89205486]\n",
      "Mode: Test env_steps 200 total rewards -265.29766463208944 total energy tensor([[80.3581]])\n",
      "[-0.8436398]\n",
      "Mode: Test env_steps 200 total rewards -380.69455043645576 total energy tensor([[96.4834]])\n",
      "[0.853063]\n",
      "Mode: Test env_steps 200 total rewards -259.0979729585815 total energy tensor([[67.0823]])\n",
      "[-0.39115393]\n",
      "Mode: Test env_steps 200 total rewards -380.54359569912776 total energy tensor([[94.8126]])\n",
      "[-0.7345309]\n",
      "Mode: Test env_steps 200 total rewards -769.5675110407174 total energy tensor([[134.0018]])\n",
      "[0.89460176]\n",
      "Mode: Test env_steps 200 total rewards -423.98382330313325 total energy tensor([[101.5037]])\n",
      "[0.09946299]\n",
      "Mode: Test env_steps 200 total rewards -760.6295079458505 total energy tensor([[126.7527]])\n",
      "[-0.9293518]\n",
      "Mode: Test env_steps 200 total rewards -1110.7343771755695 total energy tensor([[141.8533]])\n",
      "[0.2941473]\n",
      "Mode: Test env_steps 200 total rewards -505.06117761624046 total energy tensor([[92.5007]])\n",
      "[0.08356448]\n",
      "Mode: Test env_steps 200 total rewards -384.30667434446514 total energy tensor([[119.5538]])\n",
      "445000 -523.991685515223\n",
      "[-0.09365635]\n",
      "Mode: Train env_steps 200 total rewards -268.1289192312397 total energy tensor([[91.7933]])\n",
      "[-0.35844922]\n",
      "Mode: Train env_steps 200 total rewards -376.00559092126787 total energy tensor([[73.2051]])\n",
      "[-0.3427923]\n",
      "Mode: Train env_steps 200 total rewards -855.5900367554277 total energy tensor([[124.9863]])\n",
      "[0.33150095]\n",
      "Mode: Train env_steps 200 total rewards -262.38071132218465 total energy tensor([[71.1684]])\n",
      "[0.6217752]\n",
      "Mode: Train env_steps 200 total rewards -256.24793682061136 total energy tensor([[65.1724]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31872684]\n",
      "Mode: Train env_steps 200 total rewards -505.72848908090964 total energy tensor([[102.1856]])\n",
      "[0.6149642]\n",
      "Mode: Train env_steps 200 total rewards -140.98514936905121 total energy tensor([[68.3971]])\n",
      "[0.87604654]\n",
      "Mode: Train env_steps 200 total rewards -736.7133582313545 total energy tensor([[103.4355]])\n",
      "[-0.73132116]\n",
      "Mode: Train env_steps 200 total rewards -287.1748536545783 total energy tensor([[100.3173]])\n",
      "[0.5047468]\n",
      "Mode: Train env_steps 200 total rewards -610.462166689802 total energy tensor([[98.1262]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81997323]\n",
      "Mode: Train env_steps 200 total rewards -483.4395089887221 total energy tensor([[77.9253]])\n",
      "[0.227055]\n",
      "Mode: Train env_steps 200 total rewards -361.7814576537203 total energy tensor([[54.8661]])\n",
      "[-0.82596743]\n",
      "Mode: Train env_steps 200 total rewards -616.5867926087467 total energy tensor([[82.9896]])\n",
      "[0.3070604]\n",
      "Mode: Train env_steps 200 total rewards -608.4134789064992 total energy tensor([[92.4728]])\n",
      "[0.49573854]\n",
      "Mode: Train env_steps 200 total rewards -362.9849954008532 total energy tensor([[50.4787]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33029673]\n",
      "Mode: Train env_steps 200 total rewards -255.46854098582116 total energy tensor([[60.6141]])\n",
      "[-0.8191337]\n",
      "Mode: Train env_steps 200 total rewards -250.5042225982179 total energy tensor([[76.8171]])\n",
      "[-0.63863075]\n",
      "Mode: Train env_steps 200 total rewards -629.7669135215215 total energy tensor([[88.2075]])\n",
      "[0.72047]\n",
      "Mode: Train env_steps 200 total rewards -369.3869070650253 total energy tensor([[63.9169]])\n",
      "[-0.08237471]\n",
      "Mode: Train env_steps 200 total rewards -742.740706989367 total energy tensor([[91.3457]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.168433]\n",
      "Mode: Train env_steps 200 total rewards -263.66223670821637 total energy tensor([[71.4250]])\n",
      "[0.81662744]\n",
      "Mode: Train env_steps 200 total rewards -726.5374290749896 total energy tensor([[96.1779]])\n",
      "[0.94929385]\n",
      "Mode: Train env_steps 200 total rewards -1.3037612229818478 total energy tensor([[3.3937]])\n",
      "[0.05295054]\n",
      "Mode: Train env_steps 200 total rewards -486.7198365610093 total energy tensor([[90.0074]])\n",
      "[0.501915]\n",
      "Mode: Train env_steps 200 total rewards -243.0554667941251 total energy tensor([[43.8777]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66350484]\n",
      "Mode: Test env_steps 200 total rewards -260.8456478991702 total energy tensor([[58.4191]])\n",
      "[0.37369183]\n",
      "Mode: Test env_steps 200 total rewards -137.80212649772875 total energy tensor([[64.7593]])\n",
      "[0.5326744]\n",
      "Mode: Test env_steps 200 total rewards -259.81839842157206 total energy tensor([[59.0109]])\n",
      "[0.3960602]\n",
      "Mode: Test env_steps 200 total rewards -734.1859665568918 total energy tensor([[129.7828]])\n",
      "[0.9749406]\n",
      "Mode: Test env_steps 200 total rewards -264.65224347054755 total energy tensor([[69.3405]])\n",
      "[-0.85618776]\n",
      "Mode: Test env_steps 200 total rewards -376.0768286581151 total energy tensor([[108.0148]])\n",
      "[0.09542447]\n",
      "Mode: Test env_steps 200 total rewards -133.87935391886276 total energy tensor([[50.9464]])\n",
      "[0.45515585]\n",
      "Mode: Test env_steps 200 total rewards -383.26550716534257 total energy tensor([[124.1796]])\n",
      "[0.62808967]\n",
      "Mode: Test env_steps 200 total rewards -738.9816164842341 total energy tensor([[117.6570]])\n",
      "[-0.35006097]\n",
      "Mode: Test env_steps 200 total rewards -1232.298630334437 total energy tensor([[143.7971]])\n",
      "450000 -452.1806319406902\n",
      "[0.6355114]\n",
      "Mode: Train env_steps 200 total rewards -383.25719357840717 total energy tensor([[123.9689]])\n",
      "[-0.4763197]\n",
      "Mode: Train env_steps 200 total rewards -487.1373664191924 total energy tensor([[106.1086]])\n",
      "[0.43437502]\n",
      "Mode: Train env_steps 200 total rewards -167.09555267589167 total energy tensor([[77.7196]])\n",
      "[-0.2111516]\n",
      "Mode: Train env_steps 200 total rewards -124.04901442208939 total energy tensor([[28.2943]])\n",
      "[-0.9492358]\n",
      "Mode: Train env_steps 200 total rewards -373.944126958173 total energy tensor([[77.6982]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2918763]\n",
      "Mode: Train env_steps 200 total rewards -368.1801172471605 total energy tensor([[81.3855]])\n",
      "[-0.15773243]\n",
      "Mode: Train env_steps 200 total rewards -633.6454106224701 total energy tensor([[110.7217]])\n",
      "[0.9577116]\n",
      "Mode: Train env_steps 200 total rewards -342.18183845700696 total energy tensor([[95.4202]])\n",
      "[-0.35378912]\n",
      "Mode: Train env_steps 200 total rewards -378.51100475760177 total energy tensor([[88.6735]])\n",
      "[-0.0532536]\n",
      "Mode: Train env_steps 200 total rewards -375.38614900037646 total energy tensor([[83.1106]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3255388]\n",
      "Mode: Train env_steps 200 total rewards -1143.9312076107599 total energy tensor([[142.9101]])\n",
      "[0.27855676]\n",
      "Mode: Train env_steps 200 total rewards -272.7476508584805 total energy tensor([[71.1925]])\n",
      "[0.22415146]\n",
      "Mode: Train env_steps 200 total rewards -3.274990284233354 total energy tensor([[21.6240]])\n",
      "[-0.85627455]\n",
      "Mode: Train env_steps 200 total rewards -147.2025856578257 total energy tensor([[65.7804]])\n",
      "[0.03709063]\n",
      "Mode: Train env_steps 200 total rewards -132.07343547139317 total energy tensor([[32.2666]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.81305844]\n",
      "Mode: Train env_steps 200 total rewards -1024.167288184166 total energy tensor([[121.8713]])\n",
      "[0.8616491]\n",
      "Mode: Train env_steps 200 total rewards -262.8658038342837 total energy tensor([[65.7466]])\n",
      "[-0.25705743]\n",
      "Mode: Train env_steps 200 total rewards -378.90215436695144 total energy tensor([[88.5383]])\n",
      "[0.02579481]\n",
      "Mode: Train env_steps 200 total rewards -384.01415008469485 total energy tensor([[83.2124]])\n",
      "[0.68483615]\n",
      "Mode: Train env_steps 200 total rewards -373.88998658163473 total energy tensor([[69.3204]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88408214]\n",
      "Mode: Train env_steps 200 total rewards -894.8893761830404 total energy tensor([[117.1965]])\n",
      "[0.1010339]\n",
      "Mode: Train env_steps 200 total rewards -251.69504673103802 total energy tensor([[78.3075]])\n",
      "[-0.7231316]\n",
      "Mode: Train env_steps 200 total rewards -242.4333329849178 total energy tensor([[39.6016]])\n",
      "[-0.42167068]\n",
      "Mode: Train env_steps 200 total rewards -374.9498008331284 total energy tensor([[78.4364]])\n",
      "[0.40728635]\n",
      "Mode: Train env_steps 200 total rewards -487.69930229577585 total energy tensor([[71.1417]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5959635]\n",
      "Mode: Test env_steps 200 total rewards -377.6679841589648 total energy tensor([[86.6142]])\n",
      "[0.39913806]\n",
      "Mode: Test env_steps 200 total rewards -265.44978557678405 total energy tensor([[78.3924]])\n",
      "[-0.07285723]\n",
      "Mode: Test env_steps 200 total rewards -143.87277842768526 total energy tensor([[101.0472]])\n",
      "[-0.30550128]\n",
      "Mode: Test env_steps 200 total rewards -261.1081288247442 total energy tensor([[63.4716]])\n",
      "[0.20590706]\n",
      "Mode: Test env_steps 200 total rewards -263.51767014266807 total energy tensor([[62.0829]])\n",
      "[-0.24223644]\n",
      "Mode: Test env_steps 200 total rewards -137.02269995113602 total energy tensor([[66.8125]])\n",
      "[-0.354517]\n",
      "Mode: Test env_steps 200 total rewards -735.949794863991 total energy tensor([[93.7050]])\n",
      "[0.48440412]\n",
      "Mode: Test env_steps 200 total rewards -769.8783987926145 total energy tensor([[84.5615]])\n",
      "[-0.4640995]\n",
      "Mode: Test env_steps 200 total rewards -490.70207188357017 total energy tensor([[89.4194]])\n",
      "[0.9341214]\n",
      "Mode: Test env_steps 200 total rewards -503.0277922512396 total energy tensor([[89.3330]])\n",
      "455000 -394.81971048733976\n",
      "[-0.38357773]\n",
      "Mode: Train env_steps 200 total rewards -611.3112639519386 total energy tensor([[93.7709]])\n",
      "[0.18885311]\n",
      "Mode: Train env_steps 200 total rewards -620.4812123617739 total energy tensor([[91.6041]])\n",
      "[-0.11860295]\n",
      "Mode: Train env_steps 200 total rewards -757.9529974024044 total energy tensor([[88.4776]])\n",
      "[-0.24200377]\n",
      "Mode: Train env_steps 200 total rewards -539.3656545375707 total energy tensor([[95.5136]])\n",
      "[-0.5311139]\n",
      "Mode: Train env_steps 200 total rewards -262.7531566907637 total energy tensor([[66.1845]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42779934]\n",
      "Mode: Train env_steps 200 total rewards -252.34589851787314 total energy tensor([[90.7647]])\n",
      "[0.18317276]\n",
      "Mode: Train env_steps 200 total rewards -376.22017458389746 total energy tensor([[81.6766]])\n",
      "[-0.9363793]\n",
      "Mode: Train env_steps 200 total rewards -251.4944096943218 total energy tensor([[66.3118]])\n",
      "[0.21128188]\n",
      "Mode: Train env_steps 200 total rewards -737.6400864340997 total energy tensor([[82.8507]])\n",
      "[0.35736293]\n",
      "Mode: Train env_steps 200 total rewards -485.3957368474512 total energy tensor([[73.3022]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16000096]\n",
      "Mode: Train env_steps 200 total rewards -635.4108040052015 total energy tensor([[76.7565]])\n",
      "[0.9268878]\n",
      "Mode: Train env_steps 200 total rewards -610.2762896061668 total energy tensor([[79.6971]])\n",
      "[-0.35328722]\n",
      "Mode: Train env_steps 200 total rewards -128.79022799797167 total energy tensor([[21.4805]])\n",
      "[0.5471237]\n",
      "Mode: Train env_steps 200 total rewards -616.1980527529395 total energy tensor([[83.7014]])\n",
      "[-0.12605685]\n",
      "Mode: Train env_steps 200 total rewards -732.0451597672363 total energy tensor([[78.2925]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8100163]\n",
      "Mode: Train env_steps 200 total rewards -246.00239646841553 total energy tensor([[49.3768]])\n",
      "[-0.9939622]\n",
      "Mode: Train env_steps 200 total rewards -492.1554712370271 total energy tensor([[112.1494]])\n",
      "[-0.6914153]\n",
      "Mode: Train env_steps 200 total rewards -883.8849304430187 total energy tensor([[111.5810]])\n",
      "[-0.3998583]\n",
      "Mode: Train env_steps 200 total rewards -725.1243452784838 total energy tensor([[90.5942]])\n",
      "[0.39133433]\n",
      "Mode: Train env_steps 200 total rewards -877.2497913762927 total energy tensor([[141.9834]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.543781]\n",
      "Mode: Train env_steps 200 total rewards -133.0820832958998 total energy tensor([[29.7985]])\n",
      "[-0.66897756]\n",
      "Mode: Train env_steps 200 total rewards -129.90699910234434 total energy tensor([[20.2809]])\n",
      "[0.628097]\n",
      "Mode: Train env_steps 200 total rewards -129.9864918081439 total energy tensor([[65.5938]])\n",
      "[-0.17272776]\n",
      "Mode: Train env_steps 200 total rewards -968.1591066778637 total energy tensor([[116.8968]])\n",
      "[0.9809118]\n",
      "Mode: Train env_steps 200 total rewards -741.8093393685995 total energy tensor([[89.6750]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31507605]\n",
      "Mode: Test env_steps 200 total rewards -719.6481112655019 total energy tensor([[79.6229]])\n",
      "[-0.997766]\n",
      "Mode: Test env_steps 200 total rewards -137.13556037566013 total energy tensor([[59.6540]])\n",
      "[-0.5419212]\n",
      "Mode: Test env_steps 200 total rewards -609.9770157946041 total energy tensor([[80.4521]])\n",
      "[-0.14201619]\n",
      "Mode: Test env_steps 200 total rewards -609.9110687744105 total energy tensor([[102.2057]])\n",
      "[-0.27432704]\n",
      "Mode: Test env_steps 200 total rewards -250.75572240469046 total energy tensor([[76.1359]])\n",
      "[-0.80640644]\n",
      "Mode: Test env_steps 200 total rewards -486.8439288220834 total energy tensor([[64.3150]])\n",
      "[-0.6211009]\n",
      "Mode: Test env_steps 200 total rewards -648.5733442166384 total energy tensor([[87.4848]])\n",
      "[-0.72085524]\n",
      "Mode: Test env_steps 200 total rewards -2.058470784286328 total energy tensor([[10.7060]])\n",
      "[-0.1428447]\n",
      "Mode: Test env_steps 200 total rewards -243.01743602846545 total energy tensor([[28.2507]])\n",
      "[0.8316011]\n",
      "Mode: Test env_steps 200 total rewards -482.5673073437065 total energy tensor([[68.9747]])\n",
      "460000 -419.0487965810047\n",
      "[-0.6953096]\n",
      "Mode: Train env_steps 200 total rewards -260.75098153561703 total energy tensor([[62.3283]])\n",
      "[-0.8653338]\n",
      "Mode: Train env_steps 200 total rewards -263.48226104716014 total energy tensor([[61.6929]])\n",
      "[0.40430087]\n",
      "Mode: Train env_steps 200 total rewards -243.19745344512194 total energy tensor([[34.3348]])\n",
      "[0.59050846]\n",
      "Mode: Train env_steps 200 total rewards -130.59585764095027 total energy tensor([[24.1219]])\n",
      "[0.03479364]\n",
      "Mode: Train env_steps 200 total rewards -262.55582064099144 total energy tensor([[64.7029]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5735916]\n",
      "Mode: Train env_steps 200 total rewards -487.37227229932614 total energy tensor([[65.6173]])\n",
      "[-0.6633992]\n",
      "Mode: Train env_steps 200 total rewards -257.5252582715475 total energy tensor([[120.8046]])\n",
      "[0.26457348]\n",
      "Mode: Train env_steps 200 total rewards -606.6707555736648 total energy tensor([[86.8531]])\n",
      "[-0.25615746]\n",
      "Mode: Train env_steps 200 total rewards -1165.6349924297538 total energy tensor([[134.7991]])\n",
      "[0.59981775]\n",
      "Mode: Train env_steps 200 total rewards -611.4610954915479 total energy tensor([[80.5125]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20225179]\n",
      "Mode: Train env_steps 200 total rewards -374.948628471815 total energy tensor([[81.0424]])\n",
      "[-0.3253657]\n",
      "Mode: Train env_steps 200 total rewards -721.154202449372 total energy tensor([[80.2083]])\n",
      "[-0.2571217]\n",
      "Mode: Train env_steps 200 total rewards -622.7810611459699 total energy tensor([[77.6515]])\n",
      "[0.54670244]\n",
      "Mode: Train env_steps 200 total rewards -264.10081001964863 total energy tensor([[68.9609]])\n",
      "[0.85548943]\n",
      "Mode: Train env_steps 200 total rewards -146.63409226077783 total energy tensor([[55.9214]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93489325]\n",
      "Mode: Train env_steps 200 total rewards -129.18806261004647 total energy tensor([[23.1363]])\n",
      "[0.09417509]\n",
      "Mode: Train env_steps 200 total rewards -905.3979504564777 total energy tensor([[117.0710]])\n",
      "[0.20726097]\n",
      "Mode: Train env_steps 200 total rewards -768.7881985001732 total energy tensor([[98.6720]])\n",
      "[0.58888286]\n",
      "Mode: Train env_steps 200 total rewards -254.0292036663741 total energy tensor([[102.3730]])\n",
      "[-0.2554799]\n",
      "Mode: Train env_steps 200 total rewards -251.31210707950592 total energy tensor([[85.3394]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.38342294]\n",
      "Mode: Train env_steps 200 total rewards -128.16237868753342 total energy tensor([[20.4218]])\n",
      "[-0.37239486]\n",
      "Mode: Train env_steps 200 total rewards -243.35605993052377 total energy tensor([[33.1152]])\n",
      "[0.45195264]\n",
      "Mode: Train env_steps 200 total rewards -263.4536565586459 total energy tensor([[69.3447]])\n",
      "[0.3552321]\n",
      "Mode: Train env_steps 200 total rewards -721.7019547000527 total energy tensor([[138.3149]])\n",
      "[0.23981567]\n",
      "Mode: Train env_steps 200 total rewards -129.55167974631695 total energy tensor([[22.0342]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80344003]\n",
      "Mode: Test env_steps 200 total rewards -378.6215714821592 total energy tensor([[91.5380]])\n",
      "[0.704851]\n",
      "Mode: Test env_steps 200 total rewards -738.9929204080254 total energy tensor([[108.5028]])\n",
      "[0.40060872]\n",
      "Mode: Test env_steps 200 total rewards -260.7032775223488 total energy tensor([[61.5642]])\n",
      "[-0.9879363]\n",
      "Mode: Test env_steps 200 total rewards -264.90428995597176 total energy tensor([[70.1798]])\n",
      "[0.7067385]\n",
      "Mode: Test env_steps 200 total rewards -767.8144127437845 total energy tensor([[86.9831]])\n",
      "[0.6102263]\n",
      "Mode: Test env_steps 200 total rewards -179.84317189166904 total energy tensor([[55.1117]])\n",
      "[0.64426255]\n",
      "Mode: Test env_steps 200 total rewards -136.39825726952404 total energy tensor([[61.7574]])\n",
      "[0.7781197]\n",
      "Mode: Test env_steps 200 total rewards -504.1302066659555 total energy tensor([[101.8254]])\n",
      "[-0.1832179]\n",
      "Mode: Test env_steps 200 total rewards -375.4567756704055 total energy tensor([[76.3125]])\n",
      "[0.09366147]\n",
      "Mode: Test env_steps 200 total rewards -377.2796572917141 total energy tensor([[79.5483]])\n",
      "465000 -398.4144540901558\n",
      "[0.66133755]\n",
      "Mode: Train env_steps 200 total rewards -737.1294272621162 total energy tensor([[90.3970]])\n",
      "[-0.6192796]\n",
      "Mode: Train env_steps 200 total rewards -1360.837686508894 total energy tensor([[159.3520]])\n",
      "[-0.14454988]\n",
      "Mode: Train env_steps 200 total rewards -606.0857617072761 total energy tensor([[117.5615]])\n",
      "[0.5788411]\n",
      "Mode: Train env_steps 200 total rewards -618.1539607526502 total energy tensor([[92.4268]])\n",
      "[0.04782546]\n",
      "Mode: Train env_steps 200 total rewards -135.7040845027659 total energy tensor([[57.5825]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6229479]\n",
      "Mode: Train env_steps 200 total rewards -724.3354412455228 total energy tensor([[85.3336]])\n",
      "[-0.22589363]\n",
      "Mode: Train env_steps 200 total rewards -207.6815306533972 total energy tensor([[85.8092]])\n",
      "[0.69335973]\n",
      "Mode: Train env_steps 200 total rewards -482.6034046810528 total energy tensor([[74.6299]])\n",
      "[0.26327395]\n",
      "Mode: Train env_steps 200 total rewards -190.5524993824365 total energy tensor([[86.0122]])\n",
      "[0.20550373]\n",
      "Mode: Train env_steps 200 total rewards -241.76073969647405 total energy tensor([[27.8025]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58827555]\n",
      "Mode: Train env_steps 200 total rewards -722.0081208224874 total energy tensor([[91.7616]])\n",
      "[0.8130534]\n",
      "Mode: Train env_steps 200 total rewards -137.1640945249237 total energy tensor([[65.2520]])\n",
      "[0.5729754]\n",
      "Mode: Train env_steps 200 total rewards -1136.2252063564956 total energy tensor([[131.6191]])\n",
      "[-0.94471216]\n",
      "Mode: Train env_steps 200 total rewards -250.35724769014632 total energy tensor([[75.0730]])\n",
      "[-0.9407394]\n",
      "Mode: Train env_steps 200 total rewards -742.8429071875144 total energy tensor([[85.4123]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49898016]\n",
      "Mode: Train env_steps 200 total rewards -375.56297104322584 total energy tensor([[73.7590]])\n",
      "[0.3227346]\n",
      "Mode: Train env_steps 200 total rewards -741.426694638074 total energy tensor([[85.8094]])\n",
      "[-0.31439656]\n",
      "Mode: Train env_steps 200 total rewards -364.9519058614969 total energy tensor([[86.5203]])\n",
      "[-0.34556994]\n",
      "Mode: Train env_steps 200 total rewards -628.5318410592881 total energy tensor([[96.5053]])\n",
      "[0.57324547]\n",
      "Mode: Train env_steps 200 total rewards -606.0536282858229 total energy tensor([[84.5007]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84370214]\n",
      "Mode: Train env_steps 200 total rewards -263.52324637863785 total energy tensor([[80.5035]])\n",
      "[0.6428685]\n",
      "Mode: Train env_steps 200 total rewards -479.4163065291941 total energy tensor([[95.6335]])\n",
      "[-0.72112805]\n",
      "Mode: Train env_steps 200 total rewards -366.55220114812255 total energy tensor([[74.6578]])\n",
      "[-0.26712987]\n",
      "Mode: Train env_steps 200 total rewards -256.71464041469153 total energy tensor([[69.9745]])\n",
      "[-0.24507642]\n",
      "Mode: Train env_steps 200 total rewards -383.47966100648046 total energy tensor([[119.5735]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31984484]\n",
      "Mode: Test env_steps 200 total rewards -728.2959991646712 total energy tensor([[94.8882]])\n",
      "[0.7404725]\n",
      "Mode: Test env_steps 200 total rewards -270.75028721545823 total energy tensor([[91.2367]])\n",
      "[0.17351428]\n",
      "Mode: Test env_steps 200 total rewards -741.5205168666289 total energy tensor([[98.6664]])\n",
      "[0.3441121]\n",
      "Mode: Test env_steps 200 total rewards -240.30213814566378 total energy tensor([[36.1656]])\n",
      "[0.25856146]\n",
      "Mode: Test env_steps 200 total rewards -364.22463035030523 total energy tensor([[76.2394]])\n",
      "[-0.9182167]\n",
      "Mode: Test env_steps 200 total rewards -132.8371925134852 total energy tensor([[22.5858]])\n",
      "[0.6440329]\n",
      "Mode: Test env_steps 200 total rewards -384.69618647545576 total energy tensor([[135.9662]])\n",
      "[-0.20927098]\n",
      "Mode: Test env_steps 200 total rewards -734.1351221203804 total energy tensor([[109.6312]])\n",
      "[-0.2068049]\n",
      "Mode: Test env_steps 200 total rewards -138.58013616983953 total energy tensor([[67.0477]])\n",
      "[-0.70593125]\n",
      "Mode: Test env_steps 200 total rewards -375.999373097904 total energy tensor([[113.3551]])\n",
      "470000 -411.13415821197924\n",
      "[-0.7445571]\n",
      "Mode: Train env_steps 200 total rewards -135.90837549356183 total energy tensor([[54.0143]])\n",
      "[0.03691318]\n",
      "Mode: Train env_steps 200 total rewards -487.1748969471664 total energy tensor([[77.7635]])\n",
      "[-0.15238576]\n",
      "Mode: Train env_steps 200 total rewards -607.0640621483326 total energy tensor([[129.3582]])\n",
      "[0.27576742]\n",
      "Mode: Train env_steps 200 total rewards -130.86927902029856 total energy tensor([[35.4462]])\n",
      "[0.17433968]\n",
      "Mode: Train env_steps 200 total rewards -251.69730743020773 total energy tensor([[90.7864]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9150096]\n",
      "Mode: Train env_steps 200 total rewards -1054.0139250829816 total energy tensor([[129.4530]])\n",
      "[0.9986902]\n",
      "Mode: Train env_steps 200 total rewards -260.35124150197953 total energy tensor([[86.1243]])\n",
      "[0.99547654]\n",
      "Mode: Train env_steps 200 total rewards -265.13879131758586 total energy tensor([[86.3904]])\n",
      "[0.05019245]\n",
      "Mode: Train env_steps 200 total rewards -146.64699148759246 total energy tensor([[122.0196]])\n",
      "[-0.93727475]\n",
      "Mode: Train env_steps 200 total rewards -748.5659331521019 total energy tensor([[112.3971]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8146009]\n",
      "Mode: Train env_steps 200 total rewards -265.8355152400909 total energy tensor([[74.4517]])\n",
      "[-0.36588147]\n",
      "Mode: Train env_steps 200 total rewards -374.15218684310094 total energy tensor([[76.9550]])\n",
      "[0.9289418]\n",
      "Mode: Train env_steps 200 total rewards -375.25150411618233 total energy tensor([[64.4757]])\n",
      "[-0.47877225]\n",
      "Mode: Train env_steps 200 total rewards -271.99463448207825 total energy tensor([[87.9441]])\n",
      "[-0.08615611]\n",
      "Mode: Train env_steps 200 total rewards -505.95112182572484 total energy tensor([[96.6096]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6318854]\n",
      "Mode: Train env_steps 200 total rewards -378.217322073644 total energy tensor([[85.7652]])\n",
      "[0.25773138]\n",
      "Mode: Train env_steps 200 total rewards -495.2340199868195 total energy tensor([[90.0972]])\n",
      "[0.03909075]\n",
      "Mode: Train env_steps 200 total rewards -758.2510622953996 total energy tensor([[101.6964]])\n",
      "[0.4001508]\n",
      "Mode: Train env_steps 200 total rewards -772.2376052923792 total energy tensor([[102.8244]])\n",
      "[0.32406765]\n",
      "Mode: Train env_steps 200 total rewards -374.4078446747735 total energy tensor([[87.6504]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04425148]\n",
      "Mode: Train env_steps 200 total rewards -258.72832492832094 total energy tensor([[89.1320]])\n",
      "[0.9173534]\n",
      "Mode: Train env_steps 200 total rewards -267.7959407437593 total energy tensor([[102.4631]])\n",
      "[0.39275518]\n",
      "Mode: Train env_steps 200 total rewards -9.303660218924051 total energy tensor([[56.0095]])\n",
      "[0.83201194]\n",
      "Mode: Train env_steps 200 total rewards -492.61535787954926 total energy tensor([[120.6932]])\n",
      "[0.27535117]\n",
      "Mode: Train env_steps 200 total rewards -269.1380970054306 total energy tensor([[106.1248]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5499356]\n",
      "Mode: Test env_steps 200 total rewards -263.31217777496204 total energy tensor([[65.8601]])\n",
      "[0.6088334]\n",
      "Mode: Test env_steps 200 total rewards -370.44539269036613 total energy tensor([[76.8280]])\n",
      "[0.24795704]\n",
      "Mode: Test env_steps 200 total rewards -252.94349055632483 total energy tensor([[57.7690]])\n",
      "[0.2868573]\n",
      "Mode: Test env_steps 200 total rewards -730.7899377420545 total energy tensor([[100.7826]])\n",
      "[0.8389638]\n",
      "Mode: Test env_steps 200 total rewards -372.5263183834322 total energy tensor([[68.9658]])\n",
      "[-0.831036]\n",
      "Mode: Test env_steps 200 total rewards -137.0990890841931 total energy tensor([[66.1632]])\n",
      "[0.46113867]\n",
      "Mode: Test env_steps 200 total rewards -494.23421708727255 total energy tensor([[89.9477]])\n",
      "[0.5212251]\n",
      "Mode: Test env_steps 200 total rewards -262.1391513762064 total energy tensor([[62.5686]])\n",
      "[0.30625415]\n",
      "Mode: Test env_steps 200 total rewards -374.03693424133235 total energy tensor([[70.0447]])\n",
      "[0.8066132]\n",
      "Mode: Test env_steps 200 total rewards -625.275560186943 total energy tensor([[87.5743]])\n",
      "475000 -388.2802269123087\n",
      "[0.6506034]\n",
      "Mode: Train env_steps 200 total rewards -375.94560560490936 total energy tensor([[77.2063]])\n",
      "[0.33635652]\n",
      "Mode: Train env_steps 200 total rewards -138.9793950249441 total energy tensor([[76.7673]])\n",
      "[0.25277272]\n",
      "Mode: Train env_steps 200 total rewards -372.341224150965 total energy tensor([[68.0119]])\n",
      "[0.45323178]\n",
      "Mode: Train env_steps 200 total rewards -374.33901609806344 total energy tensor([[71.6511]])\n",
      "[-0.7924991]\n",
      "Mode: Train env_steps 200 total rewards -261.2555474494584 total energy tensor([[65.1988]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25764057]\n",
      "Mode: Train env_steps 200 total rewards -246.56508705113083 total energy tensor([[53.5954]])\n",
      "[0.65930754]\n",
      "Mode: Train env_steps 200 total rewards -483.05730322399177 total energy tensor([[66.4559]])\n",
      "[-0.08799852]\n",
      "Mode: Train env_steps 200 total rewards -1080.0393555884948 total energy tensor([[114.9716]])\n",
      "[0.23018214]\n",
      "Mode: Train env_steps 200 total rewards -724.5138059682213 total energy tensor([[80.7861]])\n",
      "[-0.7235213]\n",
      "Mode: Train env_steps 200 total rewards -728.0810935065383 total energy tensor([[88.3267]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5646848]\n",
      "Mode: Train env_steps 200 total rewards -497.73065792233683 total energy tensor([[102.5573]])\n",
      "[-0.59699535]\n",
      "Mode: Train env_steps 200 total rewards -378.60956140770577 total energy tensor([[84.6119]])\n",
      "[-0.70083994]\n",
      "Mode: Train env_steps 200 total rewards -380.4735170686945 total energy tensor([[88.8397]])\n",
      "[0.8498235]\n",
      "Mode: Train env_steps 200 total rewards -364.2295834252873 total energy tensor([[73.9086]])\n",
      "[0.3732448]\n",
      "Mode: Train env_steps 200 total rewards -371.5561929587275 total energy tensor([[95.2127]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27486676]\n",
      "Mode: Train env_steps 200 total rewards -607.5431107565528 total energy tensor([[81.9295]])\n",
      "[-0.48490545]\n",
      "Mode: Train env_steps 200 total rewards -372.67939681126154 total energy tensor([[80.2368]])\n",
      "[-0.07065593]\n",
      "Mode: Train env_steps 200 total rewards -617.8636913476512 total energy tensor([[118.9549]])\n",
      "[-0.8539661]\n",
      "Mode: Train env_steps 200 total rewards -739.0559267008211 total energy tensor([[73.0703]])\n",
      "[-0.8003089]\n",
      "Mode: Train env_steps 200 total rewards -233.14562540364568 total energy tensor([[69.9966]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.81660193]\n",
      "Mode: Train env_steps 200 total rewards -746.7276318081422 total energy tensor([[99.0240]])\n",
      "[-0.7748364]\n",
      "Mode: Train env_steps 200 total rewards -718.2663098480552 total energy tensor([[117.1515]])\n",
      "[-0.7443996]\n",
      "Mode: Train env_steps 200 total rewards -130.4946353638079 total energy tensor([[24.5893]])\n",
      "[-0.24008013]\n",
      "Mode: Train env_steps 200 total rewards -4.9557053971893765 total energy tensor([[28.1128]])\n",
      "[-0.10699359]\n",
      "Mode: Train env_steps 200 total rewards -5.628325399651658 total energy tensor([[34.9882]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49547356]\n",
      "Mode: Test env_steps 200 total rewards -725.3354381881654 total energy tensor([[118.0147]])\n",
      "[0.6469244]\n",
      "Mode: Test env_steps 200 total rewards -128.56924397985858 total energy tensor([[21.2472]])\n",
      "[0.88846207]\n",
      "Mode: Test env_steps 200 total rewards -128.68121648230044 total energy tensor([[19.3451]])\n",
      "[-0.50487363]\n",
      "Mode: Test env_steps 200 total rewards -251.09580215043388 total energy tensor([[38.4458]])\n",
      "[0.04692135]\n",
      "Mode: Test env_steps 200 total rewards -130.2078759924916 total energy tensor([[31.5763]])\n",
      "[0.27740246]\n",
      "Mode: Test env_steps 200 total rewards -374.57357710576616 total energy tensor([[59.2111]])\n",
      "[-0.0086153]\n",
      "Mode: Test env_steps 200 total rewards -252.04303808818804 total energy tensor([[41.2588]])\n",
      "[-0.6613779]\n",
      "Mode: Test env_steps 200 total rewards -125.63582832599786 total energy tensor([[15.9512]])\n",
      "[0.05432899]\n",
      "Mode: Test env_steps 200 total rewards -995.8895024806261 total energy tensor([[138.0660]])\n",
      "[0.65632254]\n",
      "Mode: Test env_steps 200 total rewards -637.1000180712581 total energy tensor([[72.8219]])\n",
      "480000 -374.9131540865086\n",
      "[0.26985082]\n",
      "Mode: Train env_steps 200 total rewards -384.048365810886 total energy tensor([[100.0301]])\n",
      "[-0.06587531]\n",
      "Mode: Train env_steps 200 total rewards -231.97604832958314 total energy tensor([[23.7541]])\n",
      "[0.9152465]\n",
      "Mode: Train env_steps 200 total rewards -371.3783766728593 total energy tensor([[59.8924]])\n",
      "[0.7231872]\n",
      "Mode: Train env_steps 200 total rewards -127.99271625054098 total energy tensor([[16.9879]])\n",
      "[-0.2721282]\n",
      "Mode: Train env_steps 200 total rewards -502.1852458808571 total energy tensor([[108.0228]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58660376]\n",
      "Mode: Train env_steps 200 total rewards -525.0286567492876 total energy tensor([[101.0405]])\n",
      "[-0.98768014]\n",
      "Mode: Train env_steps 200 total rewards -264.46078155504074 total energy tensor([[70.4491]])\n",
      "[-0.98809695]\n",
      "Mode: Train env_steps 200 total rewards -499.45397234731354 total energy tensor([[82.9463]])\n",
      "[-0.4903379]\n",
      "Mode: Train env_steps 200 total rewards -780.3618665356189 total energy tensor([[101.4585]])\n",
      "[0.8171439]\n",
      "Mode: Train env_steps 200 total rewards -506.96967676014174 total energy tensor([[81.7146]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75225186]\n",
      "Mode: Train env_steps 200 total rewards -261.4305308032781 total energy tensor([[69.0070]])\n",
      "[0.4756086]\n",
      "Mode: Train env_steps 200 total rewards -267.36385175958276 total energy tensor([[76.6535]])\n",
      "[0.8565467]\n",
      "Mode: Train env_steps 200 total rewards -265.8112673154101 total energy tensor([[73.3449]])\n",
      "[-0.5471755]\n",
      "Mode: Train env_steps 200 total rewards -263.7746878727339 total energy tensor([[69.7130]])\n",
      "[-0.7997289]\n",
      "Mode: Train env_steps 200 total rewards -270.6706132572144 total energy tensor([[106.2753]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34374547]\n",
      "Mode: Train env_steps 200 total rewards -127.93192193785944 total energy tensor([[22.6156]])\n",
      "[0.23121943]\n",
      "Mode: Train env_steps 200 total rewards -238.78658295213245 total energy tensor([[36.1632]])\n",
      "[-0.95999765]\n",
      "Mode: Train env_steps 200 total rewards -241.22814109081264 total energy tensor([[33.5827]])\n",
      "[-0.75073385]\n",
      "Mode: Train env_steps 200 total rewards -250.43839652067982 total energy tensor([[82.4731]])\n",
      "[-0.4947179]\n",
      "Mode: Train env_steps 200 total rewards -239.16713945354059 total energy tensor([[30.1083]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80858505]\n",
      "Mode: Train env_steps 200 total rewards -370.2532787534001 total energy tensor([[47.6948]])\n",
      "[-0.5946285]\n",
      "Mode: Train env_steps 200 total rewards -371.76319386989053 total energy tensor([[48.3448]])\n",
      "[-0.22914962]\n",
      "Mode: Train env_steps 200 total rewards -640.7776788900665 total energy tensor([[70.5088]])\n",
      "[0.7337289]\n",
      "Mode: Train env_steps 200 total rewards -798.646458673582 total energy tensor([[95.2483]])\n",
      "[-0.8542376]\n",
      "Mode: Train env_steps 200 total rewards -132.21796946469112 total energy tensor([[37.5051]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1291908]\n",
      "Mode: Test env_steps 200 total rewards -486.9113444731338 total energy tensor([[52.3713]])\n",
      "[-0.16704068]\n",
      "Mode: Test env_steps 200 total rewards -248.16512839047937 total energy tensor([[58.1601]])\n",
      "[0.15962273]\n",
      "Mode: Test env_steps 200 total rewards -365.46764783553954 total energy tensor([[46.8404]])\n",
      "[-0.4836657]\n",
      "Mode: Test env_steps 200 total rewards -136.04431278007542 total energy tensor([[62.1361]])\n",
      "[-0.3295285]\n",
      "Mode: Test env_steps 200 total rewards -234.8519381897131 total energy tensor([[54.6335]])\n",
      "[-0.48459738]\n",
      "Mode: Test env_steps 200 total rewards -264.826535135624 total energy tensor([[74.9694]])\n",
      "[-0.6947409]\n",
      "Mode: Test env_steps 200 total rewards -501.31578529555554 total energy tensor([[50.3597]])\n",
      "[-0.450969]\n",
      "Mode: Test env_steps 200 total rewards -258.8788688305576 total energy tensor([[55.9787]])\n",
      "[-0.3241396]\n",
      "Mode: Test env_steps 200 total rewards -495.9287689247867 total energy tensor([[62.8790]])\n",
      "[0.9708355]\n",
      "Mode: Test env_steps 200 total rewards -367.45178070044494 total energy tensor([[59.2970]])\n",
      "485000 -335.984211055591\n",
      "[0.17475806]\n",
      "Mode: Train env_steps 200 total rewards -263.0288338620553 total energy tensor([[61.2010]])\n",
      "[0.8635887]\n",
      "Mode: Train env_steps 200 total rewards -141.58476469702146 total energy tensor([[91.0216]])\n",
      "[-0.78469324]\n",
      "Mode: Train env_steps 200 total rewards -133.2150504010351 total energy tensor([[46.4380]])\n",
      "[0.23656249]\n",
      "Mode: Train env_steps 200 total rewards -261.6735865342707 total energy tensor([[62.2182]])\n",
      "[0.15919513]\n",
      "Mode: Train env_steps 200 total rewards -259.8318131236174 total energy tensor([[60.2460]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34877568]\n",
      "Mode: Train env_steps 200 total rewards -470.9603555997601 total energy tensor([[47.5101]])\n",
      "[0.83096516]\n",
      "Mode: Train env_steps 200 total rewards -372.72060452215374 total energy tensor([[63.8217]])\n",
      "[0.83981746]\n",
      "Mode: Train env_steps 200 total rewards -236.5403462464019 total energy tensor([[29.5292]])\n",
      "[0.00219212]\n",
      "Mode: Train env_steps 200 total rewards -244.2747150334617 total energy tensor([[32.7453]])\n",
      "[-0.26464802]\n",
      "Mode: Train env_steps 200 total rewards -136.79960028993082 total energy tensor([[64.9874]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72570926]\n",
      "Mode: Train env_steps 200 total rewards -141.5751412473619 total energy tensor([[92.2931]])\n",
      "[0.10972686]\n",
      "Mode: Train env_steps 200 total rewards -375.9002570963348 total energy tensor([[75.3142]])\n",
      "[-0.7838017]\n",
      "Mode: Train env_steps 200 total rewards -508.9223486345727 total energy tensor([[93.7048]])\n",
      "[-0.96897316]\n",
      "Mode: Train env_steps 200 total rewards -499.3271970222704 total energy tensor([[89.5063]])\n",
      "[0.54867357]\n",
      "Mode: Train env_steps 200 total rewards -267.0656226471765 total energy tensor([[83.2764]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7730957]\n",
      "Mode: Train env_steps 200 total rewards -132.89744431112194 total energy tensor([[22.5595]])\n",
      "[-0.45947707]\n",
      "Mode: Train env_steps 200 total rewards -120.72370696261714 total energy tensor([[21.0517]])\n",
      "[0.78907025]\n",
      "Mode: Train env_steps 200 total rewards -240.24101433582837 total energy tensor([[25.5617]])\n",
      "[-0.62593216]\n",
      "Mode: Train env_steps 200 total rewards -382.58289988990873 total energy tensor([[48.8305]])\n",
      "[0.9627965]\n",
      "Mode: Train env_steps 200 total rewards -245.36649530422437 total energy tensor([[36.7948]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9623743]\n",
      "Mode: Train env_steps 200 total rewards -605.7412023746874 total energy tensor([[89.9976]])\n",
      "[-0.17471811]\n",
      "Mode: Train env_steps 200 total rewards -613.9692949964665 total energy tensor([[90.3747]])\n",
      "[-0.8717161]\n",
      "Mode: Train env_steps 200 total rewards -269.06696514610667 total energy tensor([[89.6818]])\n",
      "[-0.3328013]\n",
      "Mode: Train env_steps 200 total rewards -605.3967953774263 total energy tensor([[88.8238]])\n",
      "[-0.2619784]\n",
      "Mode: Train env_steps 200 total rewards -373.93485176129616 total energy tensor([[70.1162]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21655285]\n",
      "Mode: Test env_steps 200 total rewards -246.64337038993835 total energy tensor([[58.4934]])\n",
      "[0.5495525]\n",
      "Mode: Test env_steps 200 total rewards -376.53362964792177 total energy tensor([[91.0805]])\n",
      "[0.25943074]\n",
      "Mode: Test env_steps 200 total rewards -381.6743165846565 total energy tensor([[83.7825]])\n",
      "[0.36078936]\n",
      "Mode: Test env_steps 200 total rewards -382.2614103270462 total energy tensor([[83.8653]])\n",
      "[-0.54838866]\n",
      "Mode: Test env_steps 200 total rewards -621.7439712105552 total energy tensor([[79.0097]])\n",
      "[-0.03772044]\n",
      "Mode: Test env_steps 200 total rewards -246.80126302316785 total energy tensor([[44.4035]])\n",
      "[0.2534723]\n",
      "Mode: Test env_steps 200 total rewards -130.94098291476257 total energy tensor([[32.9876]])\n",
      "[0.65911484]\n",
      "Mode: Test env_steps 200 total rewards -256.0714968489483 total energy tensor([[73.4816]])\n",
      "[-0.1574368]\n",
      "Mode: Test env_steps 200 total rewards -638.7821917012334 total energy tensor([[81.8424]])\n",
      "[-0.4025583]\n",
      "Mode: Test env_steps 200 total rewards -153.74664280524667 total energy tensor([[71.1950]])\n",
      "490000 -343.5199275453477\n",
      "[0.68732077]\n",
      "Mode: Train env_steps 200 total rewards -249.05236919631716 total energy tensor([[64.9114]])\n",
      "[-0.44731787]\n",
      "Mode: Train env_steps 200 total rewards -251.8424633454997 total energy tensor([[66.5218]])\n",
      "[0.15493481]\n",
      "Mode: Train env_steps 200 total rewards -236.89937759963505 total energy tensor([[26.7864]])\n",
      "[-0.7794426]\n",
      "Mode: Train env_steps 200 total rewards -132.28175489795103 total energy tensor([[25.9621]])\n",
      "[-0.86227506]\n",
      "Mode: Train env_steps 200 total rewards -122.23909497039858 total energy tensor([[27.9707]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17309666]\n",
      "Mode: Train env_steps 200 total rewards -138.28848151874263 total energy tensor([[76.5881]])\n",
      "[-0.7946924]\n",
      "Mode: Train env_steps 200 total rewards -140.714850770084 total energy tensor([[82.9087]])\n",
      "[-0.2054536]\n",
      "Mode: Train env_steps 200 total rewards -247.8224443924446 total energy tensor([[31.1245]])\n",
      "[0.9373531]\n",
      "Mode: Train env_steps 200 total rewards -139.00464299834675 total energy tensor([[79.0096]])\n",
      "[0.23678377]\n",
      "Mode: Train env_steps 200 total rewards -365.260400118932 total energy tensor([[49.1734]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30421498]\n",
      "Mode: Train env_steps 200 total rewards -437.8226005738559 total energy tensor([[81.5839]])\n",
      "[-0.62136763]\n",
      "Mode: Train env_steps 200 total rewards -536.8093477590737 total energy tensor([[78.9714]])\n",
      "[-0.66547316]\n",
      "Mode: Train env_steps 200 total rewards -499.80294425676766 total energy tensor([[76.4236]])\n",
      "[-0.96181107]\n",
      "Mode: Train env_steps 200 total rewards -135.21556728817814 total energy tensor([[55.5195]])\n",
      "[0.4786867]\n",
      "Mode: Train env_steps 200 total rewards -139.20030453291838 total energy tensor([[77.1422]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8288908]\n",
      "Mode: Train env_steps 200 total rewards -682.7949968501052 total energy tensor([[84.2185]])\n",
      "[0.86217827]\n",
      "Mode: Train env_steps 200 total rewards -746.4285659782472 total energy tensor([[92.1929]])\n",
      "[-0.5697658]\n",
      "Mode: Train env_steps 200 total rewards -151.21305841673166 total energy tensor([[100.7453]])\n",
      "[0.7975413]\n",
      "Mode: Train env_steps 200 total rewards -267.2661160524003 total energy tensor([[93.4260]])\n",
      "[0.78838193]\n",
      "Mode: Train env_steps 200 total rewards -373.0603389880853 total energy tensor([[63.5614]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31978515]\n",
      "Mode: Train env_steps 200 total rewards -266.82979352850816 total energy tensor([[88.5227]])\n",
      "[-0.5009133]\n",
      "Mode: Train env_steps 200 total rewards -379.4356029665796 total energy tensor([[77.5653]])\n",
      "[0.84735316]\n",
      "Mode: Train env_steps 200 total rewards -773.8513322733816 total energy tensor([[81.8650]])\n",
      "[-0.47683153]\n",
      "Mode: Train env_steps 200 total rewards -257.5677298444207 total energy tensor([[65.4690]])\n",
      "[0.72483176]\n",
      "Mode: Train env_steps 200 total rewards -263.66091149519616 total energy tensor([[79.2109]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9546753]\n",
      "Mode: Test env_steps 200 total rewards -510.27303801199014 total energy tensor([[84.9959]])\n",
      "[0.29905885]\n",
      "Mode: Test env_steps 200 total rewards -260.56450168357696 total energy tensor([[70.8622]])\n",
      "[0.6217024]\n",
      "Mode: Test env_steps 200 total rewards -1133.4667776512215 total energy tensor([[113.4514]])\n",
      "[0.20369202]\n",
      "Mode: Test env_steps 200 total rewards -262.647137820255 total energy tensor([[72.4745]])\n",
      "[0.5863449]\n",
      "Mode: Test env_steps 200 total rewards -761.371801239904 total energy tensor([[71.2201]])\n",
      "[-0.61310965]\n",
      "Mode: Test env_steps 200 total rewards -139.6128430943936 total energy tensor([[82.4193]])\n",
      "[0.9398975]\n",
      "Mode: Test env_steps 200 total rewards -655.7029699017512 total energy tensor([[74.9829]])\n",
      "[-0.38727447]\n",
      "Mode: Test env_steps 200 total rewards -367.57682079297956 total energy tensor([[60.6953]])\n",
      "[0.15067302]\n",
      "Mode: Test env_steps 200 total rewards -373.5762510706081 total energy tensor([[46.3795]])\n",
      "[-0.84251666]\n",
      "Mode: Test env_steps 200 total rewards -128.51405876901845 total energy tensor([[23.6089]])\n",
      "495000 -459.33062000356983\n",
      "[0.7988206]\n",
      "Mode: Train env_steps 200 total rewards -485.00392124289647 total energy tensor([[65.2088]])\n",
      "[-0.08135156]\n",
      "Mode: Train env_steps 200 total rewards -268.58355707861483 total energy tensor([[55.9047]])\n",
      "[0.9589869]\n",
      "Mode: Train env_steps 200 total rewards -337.0821951095131 total energy tensor([[67.5074]])\n",
      "[-0.36716363]\n",
      "Mode: Train env_steps 200 total rewards -240.7664439068958 total energy tensor([[51.3204]])\n",
      "[-0.24580625]\n",
      "Mode: Train env_steps 200 total rewards -857.4166525462642 total energy tensor([[108.2705]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51725334]\n",
      "Mode: Train env_steps 200 total rewards -367.57140677352436 total energy tensor([[66.6103]])\n",
      "[-0.632025]\n",
      "Mode: Train env_steps 200 total rewards -661.6357253444148 total energy tensor([[84.1635]])\n",
      "[0.04899991]\n",
      "Mode: Train env_steps 200 total rewards -267.8175913078012 total energy tensor([[87.5455]])\n",
      "[-0.3551989]\n",
      "Mode: Train env_steps 200 total rewards -17.116332232631976 total energy tensor([[102.5628]])\n",
      "[-0.31210303]\n",
      "Mode: Train env_steps 200 total rewards -263.57247549685417 total energy tensor([[73.7648]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7051892]\n",
      "Mode: Train env_steps 200 total rewards -250.41634398333554 total energy tensor([[57.0894]])\n",
      "[0.6894745]\n",
      "Mode: Train env_steps 200 total rewards -5.306864483238314 total energy tensor([[33.7202]])\n",
      "[0.13008796]\n",
      "Mode: Train env_steps 200 total rewards -262.17555499345326 total energy tensor([[66.6850]])\n",
      "[-0.26119527]\n",
      "Mode: Train env_steps 200 total rewards -370.94664294862014 total energy tensor([[59.2834]])\n",
      "[-0.55869204]\n",
      "Mode: Train env_steps 200 total rewards -256.26233115834475 total energy tensor([[52.9609]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37153867]\n",
      "Mode: Train env_steps 200 total rewards -483.3073451651435 total energy tensor([[77.7110]])\n",
      "[-0.73673636]\n",
      "Mode: Train env_steps 200 total rewards -484.28820342118706 total energy tensor([[65.1829]])\n",
      "[0.82606673]\n",
      "Mode: Train env_steps 200 total rewards -481.13888605631655 total energy tensor([[66.3550]])\n",
      "[0.3463688]\n",
      "Mode: Train env_steps 200 total rewards -3.671657056780532 total energy tensor([[25.0496]])\n",
      "[-0.83448625]\n",
      "Mode: Train env_steps 200 total rewards -369.6763946125866 total energy tensor([[60.4082]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6038119]\n",
      "Mode: Train env_steps 200 total rewards -373.1495568774408 total energy tensor([[72.5312]])\n",
      "[0.14123397]\n",
      "Mode: Train env_steps 200 total rewards -127.25662832055241 total energy tensor([[61.6315]])\n",
      "[0.5510675]\n",
      "Mode: Train env_steps 200 total rewards -253.75161069456954 total energy tensor([[87.9817]])\n",
      "[0.13017717]\n",
      "Mode: Train env_steps 200 total rewards -451.56905850127805 total energy tensor([[90.7061]])\n",
      "[0.16501617]\n",
      "Mode: Train env_steps 200 total rewards -140.30419836984947 total energy tensor([[89.4631]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5658075]\n",
      "Mode: Test env_steps 200 total rewards -490.8441941934143 total energy tensor([[73.5265]])\n",
      "[0.44501635]\n",
      "Mode: Test env_steps 200 total rewards -370.4391877555172 total energy tensor([[64.7798]])\n",
      "[-0.658967]\n",
      "Mode: Test env_steps 200 total rewards -635.6820133933215 total energy tensor([[85.0157]])\n",
      "[-0.16233009]\n",
      "Mode: Test env_steps 200 total rewards -263.55128003214486 total energy tensor([[73.4699]])\n",
      "[-0.7678105]\n",
      "Mode: Test env_steps 200 total rewards -652.8299583503976 total energy tensor([[87.6595]])\n",
      "[0.89264154]\n",
      "Mode: Test env_steps 200 total rewards -507.04810402635485 total energy tensor([[97.9850]])\n",
      "[0.9328417]\n",
      "Mode: Test env_steps 200 total rewards -378.1350248644303 total energy tensor([[67.4969]])\n",
      "[0.18954422]\n",
      "Mode: Test env_steps 200 total rewards -680.9257752634585 total energy tensor([[100.5410]])\n",
      "[-0.34140408]\n",
      "Mode: Test env_steps 200 total rewards -799.8563408325426 total energy tensor([[97.2092]])\n",
      "[0.22718625]\n",
      "Mode: Test env_steps 200 total rewards -137.32674300670624 total energy tensor([[67.9029]])\n",
      "500000 -491.6638621718288\n",
      "[0.2153899]\n",
      "Mode: Train env_steps 200 total rewards -260.0127524504205 total energy tensor([[100.1993]])\n",
      "[0.45554215]\n",
      "Mode: Train env_steps 200 total rewards -379.2911549935234 total energy tensor([[69.3009]])\n",
      "[-0.608882]\n",
      "Mode: Train env_steps 200 total rewards -809.6802833492402 total energy tensor([[96.8797]])\n",
      "[0.39533234]\n",
      "Mode: Train env_steps 200 total rewards -368.7272663721815 total energy tensor([[58.7377]])\n",
      "[-0.9730233]\n",
      "Mode: Train env_steps 200 total rewards -204.16896060062572 total energy tensor([[104.3605]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    }
   ],
   "source": [
    "policy_storage = SeqReplayBuffer(\n",
    "    max_replay_buffer_size=buffer_size,\n",
    "    observation_dim=obs_dim,\n",
    "    action_dim=act_dim,\n",
    "    sampled_seq_len=sampled_seq_len,\n",
    "    sample_weight_baseline=0.0,\n",
    ")\n",
    "\n",
    "env_steps = collect_rollouts(\n",
    "    num_rollouts=num_init_rollouts_pool, random_actions=False, train_mode=True\n",
    ")\n",
    "_n_env_steps_total += env_steps\n",
    "\n",
    "# evaluation parameters\n",
    "last_eval_num_iters = 10\n",
    "log_interval = 5\n",
    "eval_num_rollouts = 10\n",
    "learning_curve = {\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": [],\n",
    "}\n",
    "epoch=0\n",
    "lambda_pat = 0.65\n",
    "\n",
    "while _n_env_steps_total < n_env_steps_total:\n",
    "\n",
    "    env_steps = collect_rollouts(num_rollouts=num_rollouts_per_iter, train_mode=True)\n",
    "    _n_env_steps_total += env_steps\n",
    "\n",
    "    #train_stats = update(int(num_updates_per_iter * env_steps))\n",
    "    factor= lambda_pat **(epoch )\n",
    "    #train_stats = update(int(num_updates_per_iter * env_steps))\n",
    "    train_stats = update(25, lr)\n",
    "    \n",
    "    epoch += 1\n",
    "    current_num_iters = _n_env_steps_total // (\n",
    "        num_rollouts_per_iter * max_trajectory_len\n",
    "    )\n",
    "    if (\n",
    "        current_num_iters != last_eval_num_iters\n",
    "        and current_num_iters % log_interval == 0\n",
    "    ):\n",
    "        last_eval_num_iters = current_num_iters\n",
    "        average_returns, std_returns = collect_rollouts(\n",
    "            num_rollouts=eval_num_rollouts,\n",
    "            train_mode=False,\n",
    "            random_actions=False,\n",
    "            deterministic=True,\n",
    "        )\n",
    "        learning_curve[\"x\"].append(_n_env_steps_total)\n",
    "        learning_curve[\"y\"].append(average_returns)\n",
    "        learning_curve[\"z\"].append(std_returns)\n",
    "        print(_n_env_steps_total, average_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, 85000, 90000, 95000, 100000, 105000, 110000, 115000, 120000, 125000, 130000, 135000, 140000, 145000, 150000, 155000, 160000, 165000, 170000, 175000, 180000, 185000, 190000, 195000, 200000, 205000, 210000, 215000, 220000, 225000, 230000, 235000, 240000, 245000, 250000, 255000, 260000, 265000, 270000, 275000, 280000, 285000, 290000, 295000, 300000, 305000, 310000, 315000, 320000, 325000, 330000, 335000, 340000, 345000, 350000, 355000, 360000, 365000, 370000, 375000, 380000, 385000, 390000, 395000, 400000, 405000, 410000, 415000, 420000, 425000, 430000, 435000, 440000, 445000, 450000, 455000, 460000, 465000, 470000, 475000, 480000, 485000, 490000, 495000, 500000], 'y': [-1430.881638908165, -1506.941090363264, -1404.9711316734551, -1537.2416670426726, -1544.933452437073, -1580.1394324719906, -1525.7515486329794, -1569.7409265607596, -1595.3889801528305, -1560.0010439167731, -1698.1990755043923, -1607.795566123724, -1608.1608733593428, -1533.5950775921344, -1532.1541730128229, -1564.936598700285, -1501.0305064643267, -1521.0048744887113, -1487.6040425726212, -1578.740789233148, -1591.614818315208, -1298.8379008661257, -980.3632917717565, -1343.2716301600449, -1360.0102463953197, -1092.974100885354, -1396.56254696548, -1195.6688508234918, -1277.4819591134788, -1007.5389938550536, -1044.5013395735994, -796.5725641830475, -921.982913844008, -1114.9126227878617, -618.6131632148754, -888.9577961557545, -947.1027326672687, -992.2774082815274, -1127.4989830470179, -776.2305617412552, -1196.022293239832, -734.5270020088763, -754.4206979262875, -553.7675836573069, -813.738997802441, -1168.355174193252, -631.5900871783917, -1062.316888770042, -874.1841631648597, -1165.151124949241, -693.3334166001539, -1058.8599714986863, -794.2479157429655, -1026.2300544075144, -1174.5806468393653, -1061.994686589623, -589.2859463069938, -512.6736411180289, -606.6065957317275, -1242.6195970748333, -828.1428512174986, -691.5420361521334, -616.93455341144, -803.2300273366651, -1050.951546267513, -650.0454755279206, -583.1747968565178, -514.2690101540763, -915.8555172057706, -648.1535861215204, -565.6076185525257, -873.3126072365461, -805.1303773219406, -717.5861008854117, -460.6659844858601, -559.7625306182075, -853.5636280104285, -669.6295004264532, -617.7487586261705, -546.0138496625909, -654.9290879295615, -487.6065248300516, -445.39745819049347, -539.700794701396, -413.05645559862313, -360.029927658262, -795.1200032620807, -640.8805918504147, -523.991685515223, -452.1806319406902, -394.81971048733976, -419.0487965810047, -398.4144540901558, -411.13415821197924, -388.2802269123087, -374.9131540865086, -335.984211055591, -343.5199275453477, -459.33062000356983, -491.6638621718288], 'z': [193.73127599702894, 152.19103021310804, 180.7688459276159, 163.169883794665, 134.47659890132462, 25.321643838933312, 146.7788410864153, 65.26215485510524, 75.19747015454041, 111.45511399784674, 128.20387049071135, 46.10604493652237, 111.14479557185811, 48.65635969375605, 49.50371277726835, 43.88870027364137, 122.38071376791167, 80.11279107676654, 111.7956050780687, 87.10132520658252, 85.21793608009871, 469.36880071250823, 547.1062573540611, 349.1133546772517, 198.37306624324285, 402.1323952855337, 216.71282087152173, 181.55503110091848, 231.40607593981977, 428.8713796964442, 400.63013946330113, 487.30457902500103, 378.62279265560056, 562.640006762477, 396.13497892398465, 506.4749088963808, 513.2269519353918, 453.32277764609535, 343.61797089765184, 452.85770843648504, 389.95327451159324, 481.56280053412706, 479.4159288129268, 450.052274159882, 398.5331956008504, 376.9338914046265, 565.8453258916862, 514.3193213642224, 479.1332318599693, 461.1412270007613, 540.2574806253959, 581.4520225668821, 529.7702815009566, 514.9034460561423, 394.46529779194225, 527.9117712113082, 630.7541505335406, 567.8941772941799, 550.2014859669288, 393.40481004451743, 529.0917520255502, 610.2003187007408, 506.7578559880566, 506.0129512397013, 444.4098947436624, 486.25966421717146, 481.4863682189724, 540.9940106105396, 535.3002059573412, 507.69368074721575, 425.92536545397434, 594.3777205838301, 461.4745638302667, 415.96208797275443, 481.6421975280239, 515.0217648278661, 485.711454913311, 342.23531636536245, 414.78925931455234, 492.0077065688867, 445.1180076772345, 445.8795338062249, 301.4949522809394, 459.80677344156186, 303.20545491213437, 351.4343779477204, 419.33884796385263, 329.19628165596686, 258.5819926193197, 330.1266026786697, 214.36524992040665, 231.78003413358337, 204.50099247400672, 227.779812904993, 172.74595706502475, 291.70406559951107, 121.0288441147561, 166.20032799344514, 298.7423055817299, 195.68600450166352]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(learning_curve)\n",
    "plt.plot(learning_curve[\"x\"], learning_curve[\"y\"])\n",
    "plt.fill_between(np.array(learning_curve[\"x\"]), np.array(learning_curve[\"y\"])-np.array(learning_curve[\"z\"]), np.array(learning_curve[\"y\"])+np.array(learning_curve[\"z\"]))\n",
    "plt.xlabel(\"env steps\")\n",
    "plt.ylabel(\"return\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaning_curve_ncde_64_rk4 = learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [5000,\n",
       "  10000,\n",
       "  15000,\n",
       "  20000,\n",
       "  25000,\n",
       "  30000,\n",
       "  35000,\n",
       "  40000,\n",
       "  45000,\n",
       "  50000,\n",
       "  55000,\n",
       "  60000,\n",
       "  65000,\n",
       "  70000,\n",
       "  75000,\n",
       "  80000,\n",
       "  85000,\n",
       "  90000,\n",
       "  95000,\n",
       "  100000,\n",
       "  105000,\n",
       "  110000,\n",
       "  115000,\n",
       "  120000,\n",
       "  125000,\n",
       "  130000,\n",
       "  135000,\n",
       "  140000,\n",
       "  145000,\n",
       "  150000,\n",
       "  155000,\n",
       "  160000,\n",
       "  165000,\n",
       "  170000,\n",
       "  175000,\n",
       "  180000,\n",
       "  185000,\n",
       "  190000,\n",
       "  195000,\n",
       "  200000,\n",
       "  205000,\n",
       "  210000,\n",
       "  215000,\n",
       "  220000,\n",
       "  225000,\n",
       "  230000,\n",
       "  235000,\n",
       "  240000,\n",
       "  245000,\n",
       "  250000,\n",
       "  255000,\n",
       "  260000,\n",
       "  265000,\n",
       "  270000,\n",
       "  275000,\n",
       "  280000,\n",
       "  285000,\n",
       "  290000,\n",
       "  295000,\n",
       "  300000,\n",
       "  305000,\n",
       "  310000,\n",
       "  315000,\n",
       "  320000,\n",
       "  325000,\n",
       "  330000,\n",
       "  335000,\n",
       "  340000,\n",
       "  345000,\n",
       "  350000,\n",
       "  355000,\n",
       "  360000,\n",
       "  365000,\n",
       "  370000,\n",
       "  375000,\n",
       "  380000,\n",
       "  385000,\n",
       "  390000,\n",
       "  395000,\n",
       "  400000,\n",
       "  405000,\n",
       "  410000,\n",
       "  415000,\n",
       "  420000,\n",
       "  425000,\n",
       "  430000,\n",
       "  435000,\n",
       "  440000,\n",
       "  445000,\n",
       "  450000,\n",
       "  455000,\n",
       "  460000,\n",
       "  465000,\n",
       "  470000,\n",
       "  475000,\n",
       "  480000,\n",
       "  485000,\n",
       "  490000,\n",
       "  495000,\n",
       "  500000],\n",
       " 'y': [-1430.881638908165,\n",
       "  -1506.941090363264,\n",
       "  -1404.9711316734551,\n",
       "  -1537.2416670426726,\n",
       "  -1544.933452437073,\n",
       "  -1580.1394324719906,\n",
       "  -1525.7515486329794,\n",
       "  -1569.7409265607596,\n",
       "  -1595.3889801528305,\n",
       "  -1560.0010439167731,\n",
       "  -1698.1990755043923,\n",
       "  -1607.795566123724,\n",
       "  -1608.1608733593428,\n",
       "  -1533.5950775921344,\n",
       "  -1532.1541730128229,\n",
       "  -1564.936598700285,\n",
       "  -1501.0305064643267,\n",
       "  -1521.0048744887113,\n",
       "  -1487.6040425726212,\n",
       "  -1578.740789233148,\n",
       "  -1591.614818315208,\n",
       "  -1298.8379008661257,\n",
       "  -980.3632917717565,\n",
       "  -1343.2716301600449,\n",
       "  -1360.0102463953197,\n",
       "  -1092.974100885354,\n",
       "  -1396.56254696548,\n",
       "  -1195.6688508234918,\n",
       "  -1277.4819591134788,\n",
       "  -1007.5389938550536,\n",
       "  -1044.5013395735994,\n",
       "  -796.5725641830475,\n",
       "  -921.982913844008,\n",
       "  -1114.9126227878617,\n",
       "  -618.6131632148754,\n",
       "  -888.9577961557545,\n",
       "  -947.1027326672687,\n",
       "  -992.2774082815274,\n",
       "  -1127.4989830470179,\n",
       "  -776.2305617412552,\n",
       "  -1196.022293239832,\n",
       "  -734.5270020088763,\n",
       "  -754.4206979262875,\n",
       "  -553.7675836573069,\n",
       "  -813.738997802441,\n",
       "  -1168.355174193252,\n",
       "  -631.5900871783917,\n",
       "  -1062.316888770042,\n",
       "  -874.1841631648597,\n",
       "  -1165.151124949241,\n",
       "  -693.3334166001539,\n",
       "  -1058.8599714986863,\n",
       "  -794.2479157429655,\n",
       "  -1026.2300544075144,\n",
       "  -1174.5806468393653,\n",
       "  -1061.994686589623,\n",
       "  -589.2859463069938,\n",
       "  -512.6736411180289,\n",
       "  -606.6065957317275,\n",
       "  -1242.6195970748333,\n",
       "  -828.1428512174986,\n",
       "  -691.5420361521334,\n",
       "  -616.93455341144,\n",
       "  -803.2300273366651,\n",
       "  -1050.951546267513,\n",
       "  -650.0454755279206,\n",
       "  -583.1747968565178,\n",
       "  -514.2690101540763,\n",
       "  -915.8555172057706,\n",
       "  -648.1535861215204,\n",
       "  -565.6076185525257,\n",
       "  -873.3126072365461,\n",
       "  -805.1303773219406,\n",
       "  -717.5861008854117,\n",
       "  -460.6659844858601,\n",
       "  -559.7625306182075,\n",
       "  -853.5636280104285,\n",
       "  -669.6295004264532,\n",
       "  -617.7487586261705,\n",
       "  -546.0138496625909,\n",
       "  -654.9290879295615,\n",
       "  -487.6065248300516,\n",
       "  -445.39745819049347,\n",
       "  -539.700794701396,\n",
       "  -413.05645559862313,\n",
       "  -360.029927658262,\n",
       "  -795.1200032620807,\n",
       "  -640.8805918504147,\n",
       "  -523.991685515223,\n",
       "  -452.1806319406902,\n",
       "  -394.81971048733976,\n",
       "  -419.0487965810047,\n",
       "  -398.4144540901558,\n",
       "  -411.13415821197924,\n",
       "  -388.2802269123087,\n",
       "  -374.9131540865086,\n",
       "  -335.984211055591,\n",
       "  -343.5199275453477,\n",
       "  -459.33062000356983,\n",
       "  -491.6638621718288],\n",
       " 'z': [193.73127599702894,\n",
       "  152.19103021310804,\n",
       "  180.7688459276159,\n",
       "  163.169883794665,\n",
       "  134.47659890132462,\n",
       "  25.321643838933312,\n",
       "  146.7788410864153,\n",
       "  65.26215485510524,\n",
       "  75.19747015454041,\n",
       "  111.45511399784674,\n",
       "  128.20387049071135,\n",
       "  46.10604493652237,\n",
       "  111.14479557185811,\n",
       "  48.65635969375605,\n",
       "  49.50371277726835,\n",
       "  43.88870027364137,\n",
       "  122.38071376791167,\n",
       "  80.11279107676654,\n",
       "  111.7956050780687,\n",
       "  87.10132520658252,\n",
       "  85.21793608009871,\n",
       "  469.36880071250823,\n",
       "  547.1062573540611,\n",
       "  349.1133546772517,\n",
       "  198.37306624324285,\n",
       "  402.1323952855337,\n",
       "  216.71282087152173,\n",
       "  181.55503110091848,\n",
       "  231.40607593981977,\n",
       "  428.8713796964442,\n",
       "  400.63013946330113,\n",
       "  487.30457902500103,\n",
       "  378.62279265560056,\n",
       "  562.640006762477,\n",
       "  396.13497892398465,\n",
       "  506.4749088963808,\n",
       "  513.2269519353918,\n",
       "  453.32277764609535,\n",
       "  343.61797089765184,\n",
       "  452.85770843648504,\n",
       "  389.95327451159324,\n",
       "  481.56280053412706,\n",
       "  479.4159288129268,\n",
       "  450.052274159882,\n",
       "  398.5331956008504,\n",
       "  376.9338914046265,\n",
       "  565.8453258916862,\n",
       "  514.3193213642224,\n",
       "  479.1332318599693,\n",
       "  461.1412270007613,\n",
       "  540.2574806253959,\n",
       "  581.4520225668821,\n",
       "  529.7702815009566,\n",
       "  514.9034460561423,\n",
       "  394.46529779194225,\n",
       "  527.9117712113082,\n",
       "  630.7541505335406,\n",
       "  567.8941772941799,\n",
       "  550.2014859669288,\n",
       "  393.40481004451743,\n",
       "  529.0917520255502,\n",
       "  610.2003187007408,\n",
       "  506.7578559880566,\n",
       "  506.0129512397013,\n",
       "  444.4098947436624,\n",
       "  486.25966421717146,\n",
       "  481.4863682189724,\n",
       "  540.9940106105396,\n",
       "  535.3002059573412,\n",
       "  507.69368074721575,\n",
       "  425.92536545397434,\n",
       "  594.3777205838301,\n",
       "  461.4745638302667,\n",
       "  415.96208797275443,\n",
       "  481.6421975280239,\n",
       "  515.0217648278661,\n",
       "  485.711454913311,\n",
       "  342.23531636536245,\n",
       "  414.78925931455234,\n",
       "  492.0077065688867,\n",
       "  445.1180076772345,\n",
       "  445.8795338062249,\n",
       "  301.4949522809394,\n",
       "  459.80677344156186,\n",
       "  303.20545491213437,\n",
       "  351.4343779477204,\n",
       "  419.33884796385263,\n",
       "  329.19628165596686,\n",
       "  258.5819926193197,\n",
       "  330.1266026786697,\n",
       "  214.36524992040665,\n",
       "  231.78003413358337,\n",
       "  204.50099247400672,\n",
       "  227.779812904993,\n",
       "  172.74595706502475,\n",
       "  291.70406559951107,\n",
       "  121.0288441147561,\n",
       "  166.20032799344514,\n",
       "  298.7423055817299,\n",
       "  195.68600450166352]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "timess=torch.linspace(0, 65-1, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open('config.txt', 'w')\n",
    "file1.write(str(conf))\n",
    "\n",
    "file1.close()\n",
    "file2 = open('results.txt', 'w')\n",
    "file2.write(str(learning_curve))\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5f49fb63f78fde0f27b95a7c8e14eeaa9af6d816174ff450f7bbbcd21c7c97c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
