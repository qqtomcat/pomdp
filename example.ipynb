{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchkit.pytorch_utils as ptu\n",
    "import torchsde\n",
    "from torch.nn import functional as F\n",
    "import random as rnd\n",
    "import copy as cp\n",
    "# import environments\n",
    "import envs.pomdp\n",
    "import pdb\n",
    "# import recurrent model-free RL (separate architecture)\n",
    "from policies.models.policy_rnn import ModelFreeOffPolicy_Separate_RNN as Policy_RNN\n",
    "from policies.models.policy_rnn_shared import ModelFreeOffPolicy_Shared_RNN as Policy_Shared_RNN\n",
    "from policies.models.policy_mlp import ModelFreeOffPolicy_MLP as Policy_MLP\n",
    "from tqdm import tqdm\n",
    "# import the replay buffer\n",
    "from buffers.seq_replay_buffer_vanilla import SeqReplayBuffer\n",
    "from buffers.simple_replay_buffer import SimpleReplayBuffer \n",
    "from utils import helpers as utl\n",
    "from typing import Sequence\n",
    "from read_ini import read_ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf =read_ini(\"C:/Users/alexander.vasilyev/pomdp-baselines-main/configfile.ini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a POMDP environment: Pendulum-V (only observe the velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelFreeOffPolicy_Separate_RNN(\n",
      "  (critic): Critic_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_shortcut_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=2, out_features=48, bias=True)\n",
      "    )\n",
      "    (qf1): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf2): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (critic_target): Critic_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_shortcut_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=2, out_features=48, bias=True)\n",
      "    )\n",
      "    (qf1): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "    (qf2): FlattenMlp(\n",
      "      (fc0): Linear(in_features=120, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (actor): Actor_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (policy): DeterministicPolicy(\n",
      "      (fc0): Linear(in_features=104, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (actor_target): Actor_RNN(\n",
      "    (observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (action_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (reward_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=8, bias=True)\n",
      "    )\n",
      "    (rnn): NeuralCDE(\n",
      "      (func): CDEFunc(\n",
      "        (linear0): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear1): Linear(in_features=72, out_features=72, bias=True)\n",
      "        (linear2): Linear(in_features=72, out_features=3528, bias=True)\n",
      "      )\n",
      "      (initial): Linear(in_features=49, out_features=72, bias=True)\n",
      "      (readout): Linear(in_features=72, out_features=72, bias=True)\n",
      "    )\n",
      "    (current_observ_embedder): FeatureExtractor(\n",
      "      (fc): Linear(in_features=1, out_features=32, bias=True)\n",
      "    )\n",
      "    (policy): DeterministicPolicy(\n",
      "      (fc0): Linear(in_features=104, out_features=128, bias=True)\n",
      "      (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (last_fc): Linear(in_features=128, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1.0  # training frequency'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17544\\3256960018.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0magent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mnum_updates_per_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"num_updates_per_iter\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# training frequency\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[0msampled_seq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sampled_seq_len\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# context length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"buffer_size\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '1.0  # training frequency'"
     ]
    }
   ],
   "source": [
    "cuda_id = 0  # -1 if using cpu\n",
    "ptu.set_gpu_mode(torch.cuda.is_available() and cuda_id >= 0, cuda_id)\n",
    "\n",
    "env = gym.make(conf[\"env_name\"])\n",
    "max_trajectory_len = env._max_episode_steps\n",
    "act_dim = env.action_space.shape[0]\n",
    "obs_dim = env.observation_space.shape[0]\n",
    "\n",
    "shared = False\n",
    "markov = False\n",
    "\n",
    "if markov:\n",
    "    agent = Policy_MLP(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=act_dim,\n",
    "        algo_name=conf[\"algo_name\"],\n",
    "        dqn_layers=[128, 128],\n",
    "        policy_layers=[128, 128],\n",
    "        lr=3e-4,\n",
    "        gamma=0.99,\n",
    "        tau=5e-3,\n",
    "    ).to(ptu.device)\n",
    "    encoder=\"Nan\"\n",
    "else:\n",
    "    if shared:\n",
    "        agent = Policy_Shared_RNN(\n",
    "            obs_dim=obs_dim,\n",
    "            action_dim=act_dim,\n",
    "            encoder=conf[\"encoder\"],\n",
    "            algo_name=conf[\"algo_name\"],\n",
    "            action_embedding_size=int(conf[\"action_embedding_size\"]),\n",
    "            observ_embedding_size=int(conf[\"observ_embedding_size\"]),\n",
    "            reward_embedding_size=int(conf[\"reward_embedding_size\"]),\n",
    "            rnn_hidden_size=int(conf[\"hidden_size\"]),\n",
    "            dqn_layers=[128, 128],\n",
    "            policy_layers=[128, 128],\n",
    "            lr=float(conf[\"lr\"]),\n",
    "            gamma=0.9,\n",
    "            tau=0.005,\n",
    "            embed=True,\n",
    "        ).to(ptu.device)\n",
    "    else: \n",
    "        agent = Policy_RNN(\n",
    "            obs_dim=obs_dim,\n",
    "            action_dim=act_dim,\n",
    "            encoder=conf[\"encoder\"],\n",
    "            algo_name=conf[\"algo_name\"],\n",
    "            action_embedding_size=int(conf[\"action_embedding_size\"]),\n",
    "            observ_embedding_size=int(conf[\"observ_embedding_size\"]),\n",
    "            reward_embedding_size=int(conf[\"reward_embedding_size\"]),\n",
    "            rnn_hidden_size=int(conf[\"hidden_size\"]),\n",
    "            dqn_layers=[128, 128],\n",
    "            policy_layers=[128, 128],\n",
    "            lr=float(conf[\"lr\"]),\n",
    "            gamma=0.9,\n",
    "            tau=0.005,\n",
    "            radii=60,\n",
    "            embed=True,\n",
    "            activation = conf[\"activation\"],\n",
    "        ).to(ptu.device)\n",
    "    \n",
    "print(agent)\n",
    "\n",
    "num_updates_per_iter = int(conf[\"num_updates_per_iter\"])  # training frequency\n",
    "sampled_seq_len = int(conf[\"sampled_seq_len\"])  # context length\n",
    "buffer_size = int(conf[\"buffer_size\"])\n",
    "batch_size = int(conf[\"batch_size\"])\n",
    "dropout_rate=float(conf[\"dropout_rate\"])\n",
    "num_iters = int(conf[\"num_iters\"])\n",
    "num_init_rollouts_pool = int(conf[\"num_init_rollouts_pool\"])\n",
    "num_rollouts_per_iter = int(conf[\"num_rollouts_pool\"])\n",
    "total_rollouts = num_init_rollouts_pool + num_iters * num_rollouts_per_iter\n",
    "n_env_steps_total = max_trajectory_len * total_rollouts\n",
    "_n_env_steps_total = 0\n",
    "print(\"total env episodes\", total_rollouts, \"total env steps\", n_env_steps_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a recurent model-free RL agent: separate architecture, `lstm` encoder, `oar` policy input space, `td3` RL algorithm (context length set later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define other training parameters such as context length and training frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define key functions: collect rollouts and policy update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ncde_row(obs, next_obs, prev_action, action, prev_reward, reward, steps,init):\n",
    "    \n",
    "    if init:\n",
    "        obs_row= obs\n",
    "        rew_row = prev_reward\n",
    "        act_row = prev_action\n",
    "    else:\n",
    "        obs_row=torch.cat((obs, next_obs),0)\n",
    "        rew_row=torch.cat((prev_reward, reward),0)\n",
    "        act_row=torch.cat((prev_action, action),0)\n",
    " \n",
    "    if shared: \n",
    "        obs_row=agent.observ_embedder(obs_row)\n",
    "        rew_row=agent.reward_embedder(rew_row)\n",
    "        act_row=agent.action_embedder(act_row)\n",
    "    else: \n",
    "        obs_row=agent.actor.observ_embedder(obs_row)\n",
    "        rew_row=agent.actor.reward_embedder(rew_row)\n",
    "        act_row=agent.actor.action_embedder(act_row)\n",
    "    \n",
    "    if init:\n",
    "        time_tensor=torch.tensor([[steps]]).to(ptu.device)\n",
    "    else:\n",
    "        time_tensor=torch.tensor([[steps],[steps+1]]).to(ptu.device)\n",
    "\n",
    "    ncde_row=torch.cat((time_tensor,act_row,obs_row,rew_row),1)\n",
    "    ncde_row=ncde_row[None,:]\n",
    "    \n",
    "    return ncde_row\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_rollouts(\n",
    "    num_rollouts, random_actions=False, deterministic=True, train_mode=True\n",
    "):\n",
    "    \"\"\"collect num_rollouts of trajectories in task and save into policy buffer\n",
    "    :param\n",
    "        random_actions: whether to use policy to sample actions, or randomly sample action space\n",
    "        deterministic: deterministic action selection?\n",
    "        train_mode: whether to train (stored to buffer) or test\n",
    "    \"\"\"\n",
    "    if not train_mode:\n",
    "        assert random_actions == False and deterministic == True\n",
    "\n",
    "    total_steps = 0\n",
    "    total_rewards = 0.0\n",
    "    trewards =[]\n",
    "    for idx in range(num_rollouts):\n",
    "        steps = 0\n",
    "        rewards = 0.0\n",
    "        energy = 0.0\n",
    "        print(env.reset())\n",
    "        obs = ptu.from_numpy(env.reset())\n",
    "        obs = obs.reshape(1, obs.shape[-1])\n",
    "        done_rollout = False\n",
    "        init=True\n",
    "        # get hidden state at timestep=0, None for mlp\n",
    "        \n",
    "        if not markov:\n",
    "            action, reward, internal_state = agent.get_initial_info()\n",
    "\n",
    "            if encoder == \"ncde\":\n",
    "                internal_state= None\n",
    "                ncde_row= create_ncde_row(obs, obs, action, action, reward, reward, steps,init)\n",
    "                prev_action= action.clone()\n",
    "                prev_reward= reward.clone()\n",
    "                next_obs= obs.clone()\n",
    "        \n",
    "        \n",
    "        if train_mode:\n",
    "            # temporary storage\n",
    "            obs_list, act_list, rew_list, next_obs_list, term_list = (\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "                [],\n",
    "            )\n",
    "                           \n",
    "\n",
    "        while not done_rollout:\n",
    "            if markov: \n",
    "                action = agent.act(obs=obs, deterministic=deterministic)[0]\n",
    "            else:\n",
    "                if encoder == \"ncde\":\n",
    "                    (action,_,_,_), internal_state= agent.ncde_act(ncde_row=ncde_row, prev_internal_state=internal_state, obs=obs,  deterministic=deterministic)\n",
    "                else:\n",
    "                    (action, _, _, _), internal_state = agent.act(\n",
    "                        prev_internal_state=internal_state,\n",
    "                        prev_action=action,\n",
    "                        reward=reward,\n",
    "                        obs=obs,\n",
    "                        deterministic=deterministic,\n",
    "                    )\n",
    "            # observe reward and next obs (B=1, dim)\n",
    "            #pdb.set_trace()\n",
    "        \n",
    "            #print(torch.norm(internal_state))\n",
    "            next_obs, reward, done, info = utl.env_step(env, action.squeeze(dim=0))\n",
    "            done_rollout = False if ptu.get_numpy(done[0][0]) == 0.0 else True\n",
    "            init=False\n",
    "            \n",
    "            if not markov:\n",
    "                if encoder == \"ncde\":\n",
    "   \n",
    "                    ncde_row= create_ncde_row(obs, next_obs, prev_action, action, prev_reward, reward, steps,init)\n",
    "            \n",
    "            #switch on/off dropouts\n",
    "            #drop_trigger=rnd.uniform(0,1)\n",
    "            #if drop_trigger<dropout_rate:\n",
    "            #    next_obs=cp.deepcopy(obs)\n",
    "            # update statistics\n",
    "           \n",
    "            rewards += reward.item()\n",
    "            energy += action*action\n",
    "           \n",
    "            # early stopping env: such as rmdp, pomdp, generalize tasks. term ignores timeout\n",
    "            term = (\n",
    "                False\n",
    "                if \"TimeLimit.truncated\" in info or steps >= max_trajectory_len\n",
    "                else done_rollout\n",
    "            )\n",
    "\n",
    "            if train_mode:\n",
    "                # append tensors to temporary storage\n",
    "                obs_list.append(obs)  # (1, dim)\n",
    "                act_list.append(action)  # (1, dim)\n",
    "                rew_list.append(reward)  # (1, dim)\n",
    "                term_list.append(term)  # bool\n",
    "                next_obs_list.append(next_obs)  # (1, dim)\n",
    "            steps += 1\n",
    "            # set: obs <- next_obs\n",
    "            obs = next_obs.clone()\n",
    "            prev_reward= reward.clone()\n",
    "            prev_action= action.clone()\n",
    "        if train_mode:\n",
    "            # add collected sequence to buffer\n",
    "            policy_storage.add_episode(\n",
    "                observations=ptu.get_numpy(torch.cat(obs_list, dim=0)),  # (L, dim)\n",
    "                actions=ptu.get_numpy(torch.cat(act_list, dim=0)),  # (L, dim)\n",
    "                rewards=ptu.get_numpy(torch.cat(rew_list, dim=0)),  # (L, dim)\n",
    "                terminals=np.array(term_list).reshape(-1, 1),  # (L, 1)\n",
    "                next_observations=ptu.get_numpy(\n",
    "                    torch.cat(next_obs_list, dim=0)\n",
    "                ),  # (L, dim)\n",
    "            )\n",
    "        print(\n",
    "            \"Mode:\",\n",
    "            \"Train\" if train_mode else \"Test\",\n",
    "            \"env_steps\",\n",
    "            steps,\n",
    "            \"total rewards\",\n",
    "            rewards,\n",
    "            \"total energy\",\n",
    "            energy,\n",
    "        )\n",
    "        total_steps += steps\n",
    "        total_rewards += rewards\n",
    "        trewards.append(rewards)\n",
    "    if train_mode:\n",
    "        return total_steps\n",
    "    else:\n",
    "        return total_rewards / num_rollouts, np.std(trewards)\n",
    "\n",
    "\n",
    "def update(num_updates, factor):\n",
    "    rl_losses_agg = {}\n",
    "    # print(num_updates)\n",
    "    for update in tqdm(range(num_updates), leave=True):\n",
    "        # sample random RL batch: in transitions\n",
    "        batch = ptu.np_to_pytorch_batch(policy_storage.random_episodes(batch_size))\n",
    "        # RL update\n",
    "        \n",
    "        rl_losses = agent.update(batch, factor)\n",
    "\n",
    "        for k, v in rl_losses.items():\n",
    "            if update == 0:  # first iterate - create list\n",
    "                rl_losses_agg[k] = [v]\n",
    "            else:  # append values\n",
    "                rl_losses_agg[k].append(v)\n",
    "    # statistics\n",
    "    for k in rl_losses_agg:\n",
    "        rl_losses_agg[k] = np.mean(rl_losses_agg[k])\n",
    "    return rl_losses_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the agent: only costs < 20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buffer RAM usage: 0.02 GB\n",
      "[-0.8886556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexander.vasilyev\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Train env_steps 200 total rewards -752.1514814943075 total energy tensor([[0.0011]])\n",
      "[-0.38494992]\n",
      "Mode: Train env_steps 200 total rewards -966.8167201280594 total energy tensor([[0.0012]])\n",
      "[-0.28952718]\n",
      "Mode: Train env_steps 200 total rewards -1733.3318209648132 total energy tensor([[0.0002]])\n",
      "[-0.27561712]\n",
      "Mode: Train env_steps 200 total rewards -1808.0275964736938 total energy tensor([[0.0003]])\n",
      "[0.47383732]\n",
      "Mode: Train env_steps 200 total rewards -1069.4560034275055 total energy tensor([[0.0006]])\n",
      "[0.56014025]\n",
      "Mode: Train env_steps 200 total rewards -1398.5331158638 total energy tensor([[0.0005]])\n",
      "[0.81298447]\n",
      "Mode: Train env_steps 200 total rewards -930.098480373621 total energy tensor([[0.0011]])\n",
      "[-0.64982426]\n",
      "Mode: Train env_steps 200 total rewards -1519.8661150932312 total energy tensor([[0.0003]])\n",
      "[0.65959096]\n",
      "Mode: Train env_steps 200 total rewards -1195.3857116699219 total energy tensor([[0.0008]])\n",
      "[0.09396754]\n",
      "Mode: Train env_steps 200 total rewards -767.0736628770828 total energy tensor([[0.0012]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]C:\\Users\\alexander.vasilyev\\pomdp-baselines-main\\torchkit\\pytorch_utils.py:73: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if v.dtype == np.bool:\n",
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.858687]\n",
      "Mode: Train env_steps 200 total rewards -1295.2701272964478 total energy tensor([[30.6150]])\n",
      "[-0.74713135]\n",
      "Mode: Train env_steps 200 total rewards -1048.4881656412035 total energy tensor([[22.1755]])\n",
      "[-0.7619818]\n",
      "Mode: Train env_steps 200 total rewards -1271.372799396515 total energy tensor([[30.5758]])\n",
      "[-0.36253005]\n",
      "Mode: Train env_steps 200 total rewards -1276.2459196448326 total energy tensor([[28.2103]])\n",
      "[-0.05145149]\n",
      "Mode: Train env_steps 200 total rewards -1314.0028107762337 total energy tensor([[33.6320]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:22<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14335765]\n",
      "Mode: Train env_steps 200 total rewards -1120.2623265981674 total energy tensor([[35.5294]])\n",
      "[0.6701961]\n",
      "Mode: Train env_steps 200 total rewards -1591.5501455068588 total energy tensor([[158.6436]])\n",
      "[-0.00273333]\n",
      "Mode: Train env_steps 200 total rewards -1056.361417926848 total energy tensor([[8.8136]])\n",
      "[-0.02744618]\n",
      "Mode: Train env_steps 200 total rewards -1064.608354628086 total energy tensor([[8.8970]])\n",
      "[-0.85559857]\n",
      "Mode: Train env_steps 200 total rewards -1512.8443417549133 total energy tensor([[144.8969]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32944614]\n",
      "Mode: Train env_steps 200 total rewards -1518.9321229457855 total energy tensor([[180.8153]])\n",
      "[0.80315]\n",
      "Mode: Train env_steps 200 total rewards -1599.4976488351822 total energy tensor([[197.0690]])\n",
      "[-0.01288414]\n",
      "Mode: Train env_steps 200 total rewards -1585.3629476428032 total energy tensor([[190.9108]])\n",
      "[0.51239884]\n",
      "Mode: Train env_steps 200 total rewards -1592.1129640340805 total energy tensor([[195.9822]])\n",
      "[0.9548604]\n",
      "Mode: Train env_steps 200 total rewards -1668.9528556466103 total energy tensor([[197.3090]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:23<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08940437]\n",
      "Mode: Test env_steps 200 total rewards -1607.857881784439 total energy tensor([[197.8901]])\n",
      "[0.66710234]\n",
      "Mode: Test env_steps 200 total rewards -1589.3124179691076 total energy tensor([[162.9896]])\n",
      "[-0.661121]\n",
      "Mode: Test env_steps 200 total rewards -1552.285821557045 total energy tensor([[181.3358]])\n",
      "[0.8457368]\n",
      "Mode: Test env_steps 200 total rewards -1601.5158936977386 total energy tensor([[162.9564]])\n",
      "[0.6620378]\n",
      "Mode: Test env_steps 200 total rewards -1621.9524097442627 total energy tensor([[195.8973]])\n",
      "[-0.8592356]\n",
      "Mode: Test env_steps 200 total rewards -1639.1513495445251 total energy tensor([[196.1042]])\n",
      "[0.61828035]\n",
      "Mode: Test env_steps 200 total rewards -1598.1391351222992 total energy tensor([[162.4919]])\n",
      "[-0.3983485]\n",
      "Mode: Test env_steps 200 total rewards -1539.5067472457886 total energy tensor([[150.5256]])\n",
      "[0.2871818]\n",
      "Mode: Test env_steps 200 total rewards -1637.6776406764984 total energy tensor([[196.3320]])\n",
      "[-0.17173512]\n",
      "Mode: Test env_steps 200 total rewards -1668.4916159510612 total energy tensor([[196.8997]])\n",
      "5000 -1605.5890913292765\n",
      "[-0.7711482]\n",
      "Mode: Train env_steps 200 total rewards -1477.7334720641375 total energy tensor([[152.8307]])\n",
      "[0.05917877]\n",
      "Mode: Train env_steps 200 total rewards -1573.2328768968582 total energy tensor([[182.3716]])\n",
      "[-0.99660677]\n",
      "Mode: Train env_steps 200 total rewards -1674.2989577054977 total energy tensor([[197.0537]])\n",
      "[-0.9308452]\n",
      "Mode: Train env_steps 200 total rewards -1614.2798476219177 total energy tensor([[165.5935]])\n",
      "[0.50268817]\n",
      "Mode: Train env_steps 200 total rewards -1547.8767864704132 total energy tensor([[165.8400]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:21<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28340778]\n",
      "Mode: Train env_steps 200 total rewards -1654.3732580840588 total energy tensor([[197.5732]])\n",
      "[0.56440574]\n",
      "Mode: Train env_steps 200 total rewards -1491.920791298151 total energy tensor([[195.7487]])\n",
      "[0.37301147]\n",
      "Mode: Train env_steps 200 total rewards -1450.8777207434177 total energy tensor([[96.0278]])\n",
      "[0.04825671]\n",
      "Mode: Train env_steps 200 total rewards -1556.8730249404907 total energy tensor([[167.4206]])\n",
      "[-0.39566275]\n",
      "Mode: Train env_steps 200 total rewards -1464.4997664690018 total energy tensor([[96.7820]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.468584]\n",
      "Mode: Train env_steps 200 total rewards -1566.1647394895554 total energy tensor([[180.9668]])\n",
      "[0.6060268]\n",
      "Mode: Train env_steps 200 total rewards -1576.5005668401718 total energy tensor([[179.4009]])\n",
      "[-0.27715367]\n",
      "Mode: Train env_steps 200 total rewards -1567.2340968437493 total energy tensor([[191.5202]])\n",
      "[0.09094619]\n",
      "Mode: Train env_steps 200 total rewards -1462.5780569314957 total energy tensor([[156.8570]])\n",
      "[0.1791181]\n",
      "Mode: Train env_steps 200 total rewards -1665.4520778656006 total energy tensor([[197.8974]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10549574]\n",
      "Mode: Train env_steps 200 total rewards -1441.8246710300446 total energy tensor([[145.9231]])\n",
      "[-0.4412097]\n",
      "Mode: Train env_steps 200 total rewards -1269.498694241047 total energy tensor([[101.3393]])\n",
      "[0.20150857]\n",
      "Mode: Train env_steps 200 total rewards -1620.7714780569077 total energy tensor([[197.9225]])\n",
      "[0.05938006]\n",
      "Mode: Train env_steps 200 total rewards -1581.7588157653809 total energy tensor([[155.2766]])\n",
      "[0.9462109]\n",
      "Mode: Train env_steps 200 total rewards -1553.4361013174057 total energy tensor([[179.7221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26702952]\n",
      "Mode: Train env_steps 200 total rewards -1388.5798643231392 total energy tensor([[107.2132]])\n",
      "[-0.21855314]\n",
      "Mode: Train env_steps 200 total rewards -1669.5719021558762 total energy tensor([[198.0732]])\n",
      "[-0.5116922]\n",
      "Mode: Train env_steps 200 total rewards -1531.4821821451187 total energy tensor([[177.3932]])\n",
      "[-0.7697862]\n",
      "Mode: Train env_steps 200 total rewards -1355.8116801977158 total energy tensor([[136.1817]])\n",
      "[0.07242046]\n",
      "Mode: Train env_steps 200 total rewards -1591.2902893349528 total energy tensor([[194.3598]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68643975]\n",
      "Mode: Test env_steps 200 total rewards -1663.1783969402313 total energy tensor([[197.1986]])\n",
      "[-0.11880929]\n",
      "Mode: Test env_steps 200 total rewards -1639.7531274855137 total energy tensor([[197.1665]])\n",
      "[0.21209826]\n",
      "Mode: Test env_steps 200 total rewards -1620.156452551484 total energy tensor([[197.1371]])\n",
      "[0.79303765]\n",
      "Mode: Test env_steps 200 total rewards -1657.708726644516 total energy tensor([[198.5486]])\n",
      "[-0.80944717]\n",
      "Mode: Test env_steps 200 total rewards -1523.0374238491058 total energy tensor([[123.6869]])\n",
      "[0.7429964]\n",
      "Mode: Test env_steps 200 total rewards -1681.8883618116379 total energy tensor([[198.5155]])\n",
      "[0.23669176]\n",
      "Mode: Test env_steps 200 total rewards -1303.9781349897385 total energy tensor([[54.8596]])\n",
      "[0.45159876]\n",
      "Mode: Test env_steps 200 total rewards -1683.4652537107468 total energy tensor([[198.7360]])\n",
      "[-0.45005524]\n",
      "Mode: Test env_steps 200 total rewards -1212.7184725254774 total energy tensor([[51.4650]])\n",
      "[-0.9762479]\n",
      "Mode: Test env_steps 200 total rewards -1478.158506989479 total energy tensor([[159.8749]])\n",
      "10000 -1546.404285749793\n",
      "[-0.28380683]\n",
      "Mode: Train env_steps 200 total rewards -1426.0189800262451 total energy tensor([[113.9524]])\n",
      "[-0.83196115]\n",
      "Mode: Train env_steps 200 total rewards -1488.0203351974487 total energy tensor([[120.7424]])\n",
      "[0.5928115]\n",
      "Mode: Train env_steps 200 total rewards -1607.312331199646 total energy tensor([[182.1427]])\n",
      "[-0.6357538]\n",
      "Mode: Train env_steps 200 total rewards -1249.9456915855408 total energy tensor([[95.8311]])\n",
      "[-0.25864768]\n",
      "Mode: Train env_steps 200 total rewards -1664.7660991549492 total energy tensor([[198.3268]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05514707]\n",
      "Mode: Train env_steps 200 total rewards -1511.6335730552673 total energy tensor([[133.6277]])\n",
      "[-0.4249418]\n",
      "Mode: Train env_steps 200 total rewards -1423.0311388224363 total energy tensor([[154.6380]])\n",
      "[0.2821492]\n",
      "Mode: Train env_steps 200 total rewards -1575.4776340723038 total energy tensor([[179.3314]])\n",
      "[-0.18138371]\n",
      "Mode: Train env_steps 200 total rewards -1490.9190320074558 total energy tensor([[169.4773]])\n",
      "[-0.79665977]\n",
      "Mode: Train env_steps 200 total rewards -1518.236276090145 total energy tensor([[171.5504]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12856114]\n",
      "Mode: Train env_steps 200 total rewards -1594.0777274370193 total energy tensor([[197.0187]])\n",
      "[-0.61626536]\n",
      "Mode: Train env_steps 200 total rewards -1580.4536082744598 total energy tensor([[181.9970]])\n",
      "[-0.4498045]\n",
      "Mode: Train env_steps 200 total rewards -1461.4335803985596 total energy tensor([[149.0363]])\n",
      "[-0.41982755]\n",
      "Mode: Train env_steps 200 total rewards -1582.5638538599014 total energy tensor([[198.2268]])\n",
      "[0.00596505]\n",
      "Mode: Train env_steps 200 total rewards -1660.6161291599274 total energy tensor([[197.0781]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9916251]\n",
      "Mode: Train env_steps 200 total rewards -1137.1252669990063 total energy tensor([[144.3685]])\n",
      "[0.87306577]\n",
      "Mode: Train env_steps 200 total rewards -1560.7073482871056 total energy tensor([[197.7095]])\n",
      "[0.2601602]\n",
      "Mode: Train env_steps 200 total rewards -1658.6483783721924 total energy tensor([[93.8980]])\n",
      "[-0.25281265]\n",
      "Mode: Train env_steps 200 total rewards -1598.3188386075199 total energy tensor([[194.8746]])\n",
      "[0.04381427]\n",
      "Mode: Train env_steps 200 total rewards -1325.663595288992 total energy tensor([[162.8040]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.61162835]\n",
      "Mode: Train env_steps 200 total rewards -1064.574658036232 total energy tensor([[162.8461]])\n",
      "[-0.54648316]\n",
      "Mode: Train env_steps 200 total rewards -1639.078022480011 total energy tensor([[197.1891]])\n",
      "[-0.37693858]\n",
      "Mode: Train env_steps 200 total rewards -1637.974437236786 total energy tensor([[102.8557]])\n",
      "[0.44704857]\n",
      "Mode: Train env_steps 200 total rewards -1639.1627192795277 total energy tensor([[196.7615]])\n",
      "[0.06190012]\n",
      "Mode: Train env_steps 200 total rewards -1593.4381895018741 total energy tensor([[193.6655]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19856276]\n",
      "Mode: Test env_steps 200 total rewards -1558.7838100790977 total energy tensor([[185.9258]])\n",
      "[-0.46259004]\n",
      "Mode: Test env_steps 200 total rewards -1652.8194279670715 total energy tensor([[197.2667]])\n",
      "[0.51202244]\n",
      "Mode: Test env_steps 200 total rewards -1646.7389194965363 total energy tensor([[196.8095]])\n",
      "[-0.99267215]\n",
      "Mode: Test env_steps 200 total rewards -1623.0284423828125 total energy tensor([[197.5533]])\n",
      "[-0.9835662]\n",
      "Mode: Test env_steps 200 total rewards -1160.0269780009985 total energy tensor([[171.2023]])\n",
      "[0.8761411]\n",
      "Mode: Test env_steps 200 total rewards -1658.7121770977974 total energy tensor([[197.9822]])\n",
      "[0.71222323]\n",
      "Mode: Test env_steps 200 total rewards -1678.8091340065002 total energy tensor([[79.1993]])\n",
      "[0.28300482]\n",
      "Mode: Test env_steps 200 total rewards -1595.4567369092256 total energy tensor([[194.2208]])\n",
      "[0.5738858]\n",
      "Mode: Test env_steps 200 total rewards -1631.7184518873692 total energy tensor([[196.3295]])\n",
      "[0.05658745]\n",
      "Mode: Test env_steps 200 total rewards -1431.9624586105347 total energy tensor([[152.4229]])\n",
      "15000 -1563.8056536437944\n",
      "[-0.95625776]\n",
      "Mode: Train env_steps 200 total rewards -1363.949636220932 total energy tensor([[155.5048]])\n",
      "[-0.9334106]\n",
      "Mode: Train env_steps 200 total rewards -1292.958647966385 total energy tensor([[163.4848]])\n",
      "[-0.01033134]\n",
      "Mode: Train env_steps 200 total rewards -1229.1360084712505 total energy tensor([[170.4113]])\n",
      "[-0.13701978]\n",
      "Mode: Train env_steps 200 total rewards -1223.1872304528952 total energy tensor([[172.5569]])\n",
      "[-0.02565294]\n",
      "Mode: Train env_steps 200 total rewards -1370.5728468894958 total energy tensor([[148.2155]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1688311]\n",
      "Mode: Train env_steps 200 total rewards -1691.1204371452332 total energy tensor([[77.3855]])\n",
      "[0.20729162]\n",
      "Mode: Train env_steps 200 total rewards -1674.4110909700394 total energy tensor([[197.4805]])\n",
      "[-0.7967331]\n",
      "Mode: Train env_steps 200 total rewards -1589.6518931388855 total energy tensor([[113.2803]])\n",
      "[0.3281569]\n",
      "Mode: Train env_steps 200 total rewards -1251.0619357824326 total energy tensor([[160.7177]])\n",
      "[-0.0875378]\n",
      "Mode: Train env_steps 200 total rewards -1506.62060213089 total energy tensor([[137.1347]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8531968]\n",
      "Mode: Train env_steps 200 total rewards -940.0575885623693 total energy tensor([[151.2728]])\n",
      "[0.83862215]\n",
      "Mode: Train env_steps 200 total rewards -1593.8789845705032 total energy tensor([[197.1957]])\n",
      "[-0.95827335]\n",
      "Mode: Train env_steps 200 total rewards -879.2019010353833 total energy tensor([[147.6180]])\n",
      "[0.17698486]\n",
      "Mode: Train env_steps 200 total rewards -1667.437343597412 total energy tensor([[68.4814]])\n",
      "[0.92877173]\n",
      "Mode: Train env_steps 200 total rewards -1648.3085558116436 total energy tensor([[197.0393]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:15<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29681242]\n",
      "Mode: Train env_steps 200 total rewards -1320.4375139921904 total energy tensor([[170.9009]])\n",
      "[0.6437486]\n",
      "Mode: Train env_steps 200 total rewards -1681.0117646455765 total energy tensor([[198.1692]])\n",
      "[0.17037009]\n",
      "Mode: Train env_steps 200 total rewards -1652.0389288067818 total energy tensor([[197.4946]])\n",
      "[0.10340584]\n",
      "Mode: Train env_steps 200 total rewards -1426.287214577198 total energy tensor([[177.5428]])\n",
      "[0.85649604]\n",
      "Mode: Train env_steps 200 total rewards -1645.9136362075806 total energy tensor([[78.1175]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5342671]\n",
      "Mode: Train env_steps 200 total rewards -1528.0001196861267 total energy tensor([[118.9550]])\n",
      "[-0.27586964]\n",
      "Mode: Train env_steps 200 total rewards -1649.5544066429138 total energy tensor([[87.9531]])\n",
      "[0.1567585]\n",
      "Mode: Train env_steps 200 total rewards -1562.625263273716 total energy tensor([[186.0691]])\n",
      "[0.45899191]\n",
      "Mode: Train env_steps 200 total rewards -1601.0387711524963 total energy tensor([[101.4216]])\n",
      "[0.30301774]\n",
      "Mode: Train env_steps 200 total rewards -1573.689479646273 total energy tensor([[188.4900]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18407904]\n",
      "Mode: Test env_steps 200 total rewards -1627.1858673095703 total energy tensor([[197.0502]])\n",
      "[0.04663866]\n",
      "Mode: Test env_steps 200 total rewards -1634.7392826080322 total energy tensor([[196.8489]])\n",
      "[0.65552515]\n",
      "Mode: Test env_steps 200 total rewards -1554.6583242416382 total energy tensor([[113.9051]])\n",
      "[-0.4413971]\n",
      "Mode: Test env_steps 200 total rewards -1099.2445214614272 total energy tensor([[165.6458]])\n",
      "[-0.33236593]\n",
      "Mode: Test env_steps 200 total rewards -1207.9398112297058 total energy tensor([[149.5655]])\n",
      "[0.34228906]\n",
      "Mode: Test env_steps 200 total rewards -1222.316172838211 total energy tensor([[145.4882]])\n",
      "[-0.48092443]\n",
      "Mode: Test env_steps 200 total rewards -1522.7037711143494 total energy tensor([[118.2448]])\n",
      "[-0.15318108]\n",
      "Mode: Test env_steps 200 total rewards -1186.1281859874725 total energy tensor([[157.9502]])\n",
      "[0.7864453]\n",
      "Mode: Test env_steps 200 total rewards -1592.4669737815857 total energy tensor([[105.5289]])\n",
      "[0.8072383]\n",
      "Mode: Test env_steps 200 total rewards -1455.7543272972107 total energy tensor([[132.8615]])\n",
      "20000 -1410.3137237869203\n",
      "[0.76093096]\n",
      "Mode: Train env_steps 200 total rewards -1562.5957427024841 total energy tensor([[112.1226]])\n",
      "[-0.4033576]\n",
      "Mode: Train env_steps 200 total rewards -1685.8952671289444 total energy tensor([[198.1669]])\n",
      "[0.6613982]\n",
      "Mode: Train env_steps 200 total rewards -839.1026694327593 total energy tensor([[143.7921]])\n",
      "[-0.5904008]\n",
      "Mode: Train env_steps 200 total rewards -1593.0764300320297 total energy tensor([[191.9837]])\n",
      "[0.82132065]\n",
      "Mode: Train env_steps 200 total rewards -1214.2943994998932 total energy tensor([[144.3033]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51231605]\n",
      "Mode: Train env_steps 200 total rewards -1047.362741470337 total energy tensor([[157.4782]])\n",
      "[-0.3240449]\n",
      "Mode: Train env_steps 200 total rewards -1498.11381483078 total energy tensor([[136.1948]])\n",
      "[-0.12689486]\n",
      "Mode: Train env_steps 200 total rewards -1579.7703351974487 total energy tensor([[116.9624]])\n",
      "[-0.31849337]\n",
      "Mode: Train env_steps 200 total rewards -1639.1937858462334 total energy tensor([[196.2933]])\n",
      "[-0.2732297]\n",
      "Mode: Train env_steps 200 total rewards -1678.6246256828308 total energy tensor([[85.2952]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72749263]\n",
      "Mode: Train env_steps 200 total rewards -1016.6953981518745 total energy tensor([[153.7266]])\n",
      "[-0.81037456]\n",
      "Mode: Train env_steps 200 total rewards -1100.7578583955765 total energy tensor([[155.9032]])\n",
      "[-0.434285]\n",
      "Mode: Train env_steps 200 total rewards -1657.5319638252258 total energy tensor([[66.7446]])\n",
      "[0.7600738]\n",
      "Mode: Train env_steps 200 total rewards -1701.2732605934143 total energy tensor([[52.4605]])\n",
      "[0.2172821]\n",
      "Mode: Train env_steps 200 total rewards -1577.7454910874367 total energy tensor([[196.5495]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9607622]\n",
      "Mode: Train env_steps 200 total rewards -1256.633870601654 total energy tensor([[147.7773]])\n",
      "[0.7872059]\n",
      "Mode: Train env_steps 200 total rewards -1276.0607880353928 total energy tensor([[143.5062]])\n",
      "[-0.44850275]\n",
      "Mode: Train env_steps 200 total rewards -1175.945036649704 total energy tensor([[156.3306]])\n",
      "[0.7174265]\n",
      "Mode: Train env_steps 200 total rewards -1204.156628370285 total energy tensor([[149.8753]])\n",
      "[0.07554498]\n",
      "Mode: Train env_steps 200 total rewards -1583.4576997756958 total energy tensor([[98.2830]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8110845]\n",
      "Mode: Train env_steps 200 total rewards -1568.3676635026932 total energy tensor([[193.6685]])\n",
      "[-0.4932092]\n",
      "Mode: Train env_steps 200 total rewards -1678.4158664345741 total energy tensor([[196.9405]])\n",
      "[0.85717547]\n",
      "Mode: Train env_steps 200 total rewards -1660.058364868164 total energy tensor([[196.9716]])\n",
      "[-0.9801364]\n",
      "Mode: Train env_steps 200 total rewards -1673.5632773637772 total energy tensor([[196.9634]])\n",
      "[-0.22562674]\n",
      "Mode: Train env_steps 200 total rewards -1345.755366563797 total energy tensor([[145.4490]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25282055]\n",
      "Mode: Test env_steps 200 total rewards -1028.5551876276731 total energy tensor([[149.8976]])\n",
      "[-0.9220733]\n",
      "Mode: Test env_steps 200 total rewards -1590.876937866211 total energy tensor([[99.2205]])\n",
      "[-0.44962513]\n",
      "Mode: Test env_steps 200 total rewards -1658.6396320462227 total energy tensor([[194.6008]])\n",
      "[-0.10550698]\n",
      "Mode: Test env_steps 200 total rewards -1406.3578915596008 total energy tensor([[133.9886]])\n",
      "[-0.8261432]\n",
      "Mode: Test env_steps 200 total rewards -1191.256664276123 total energy tensor([[152.2628]])\n",
      "[-0.3519334]\n",
      "Mode: Test env_steps 200 total rewards -950.4177068202407 total energy tensor([[139.1216]])\n",
      "[0.5390684]\n",
      "Mode: Test env_steps 200 total rewards -1476.3787503242493 total energy tensor([[122.2986]])\n",
      "[0.6038431]\n",
      "Mode: Test env_steps 200 total rewards -1190.535343170166 total energy tensor([[152.6937]])\n",
      "[0.16016173]\n",
      "Mode: Test env_steps 200 total rewards -1609.1035985946655 total energy tensor([[96.0187]])\n",
      "[0.22480753]\n",
      "Mode: Test env_steps 200 total rewards -1590.3485798835754 total energy tensor([[97.6707]])\n",
      "25000 -1369.2470292168728\n",
      "[-0.0277885]\n",
      "Mode: Train env_steps 200 total rewards -1244.454621553421 total energy tensor([[151.5206]])\n",
      "[0.458812]\n",
      "Mode: Train env_steps 200 total rewards -995.346246547997 total energy tensor([[147.8528]])\n",
      "[-0.59045213]\n",
      "Mode: Train env_steps 200 total rewards -1397.8596470355988 total energy tensor([[135.0294]])\n",
      "[0.5944986]\n",
      "Mode: Train env_steps 200 total rewards -1646.2742261886597 total energy tensor([[196.1669]])\n",
      "[-0.04253095]\n",
      "Mode: Train env_steps 200 total rewards -1672.7504521608353 total energy tensor([[196.1988]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5838573]\n",
      "Mode: Train env_steps 200 total rewards -1664.7786269187927 total energy tensor([[67.2159]])\n",
      "[-0.14379673]\n",
      "Mode: Train env_steps 200 total rewards -1060.6336004287004 total energy tensor([[150.5088]])\n",
      "[0.03651941]\n",
      "Mode: Train env_steps 200 total rewards -1609.695854485035 total energy tensor([[189.3847]])\n",
      "[-0.67572904]\n",
      "Mode: Train env_steps 200 total rewards -1614.2888588905334 total energy tensor([[88.7196]])\n",
      "[0.7748109]\n",
      "Mode: Train env_steps 200 total rewards -1649.9591588974 total energy tensor([[68.1378]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0997638]\n",
      "Mode: Train env_steps 200 total rewards -950.9438453032635 total energy tensor([[143.2769]])\n",
      "[-0.9702241]\n",
      "Mode: Train env_steps 200 total rewards -1321.8798687458038 total energy tensor([[147.9050]])\n",
      "[-0.7099387]\n",
      "Mode: Train env_steps 200 total rewards -1640.4539954066277 total energy tensor([[194.8592]])\n",
      "[0.5314935]\n",
      "Mode: Train env_steps 200 total rewards -1411.5437767505646 total energy tensor([[136.9857]])\n",
      "[-0.08066726]\n",
      "Mode: Train env_steps 200 total rewards -1076.0543462634087 total energy tensor([[149.1994]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4151028]\n",
      "Mode: Train env_steps 200 total rewards -1640.5483875274658 total energy tensor([[192.3581]])\n",
      "[0.91212]\n",
      "Mode: Train env_steps 200 total rewards -1356.907291650772 total energy tensor([[144.7324]])\n",
      "[0.753751]\n",
      "Mode: Train env_steps 200 total rewards -1183.6185775995255 total energy tensor([[157.3662]])\n",
      "[-0.25274345]\n",
      "Mode: Train env_steps 200 total rewards -1582.7703928947449 total energy tensor([[105.6429]])\n",
      "[-0.27768677]\n",
      "Mode: Train env_steps 200 total rewards -1649.1753227114677 total energy tensor([[191.6302]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9612275]\n",
      "Mode: Train env_steps 200 total rewards -1640.0775653719902 total energy tensor([[190.4737]])\n",
      "[0.9381484]\n",
      "Mode: Train env_steps 200 total rewards -1088.0357125401497 total energy tensor([[150.4463]])\n",
      "[0.12328967]\n",
      "Mode: Train env_steps 200 total rewards -1594.9684187024832 total energy tensor([[186.0648]])\n",
      "[-0.39407682]\n",
      "Mode: Train env_steps 200 total rewards -1621.2571950554848 total energy tensor([[188.7025]])\n",
      "[0.9437378]\n",
      "Mode: Train env_steps 200 total rewards -1635.1832567453384 total energy tensor([[191.0791]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23193654]\n",
      "Mode: Test env_steps 200 total rewards -1605.4243097305298 total energy tensor([[102.3423]])\n",
      "[-0.4074571]\n",
      "Mode: Test env_steps 200 total rewards -1566.8748998641968 total energy tensor([[104.1086]])\n",
      "[-0.08189262]\n",
      "Mode: Test env_steps 200 total rewards -1612.512531220913 total energy tensor([[189.4130]])\n",
      "[-0.60591114]\n",
      "Mode: Test env_steps 200 total rewards -1552.854054927826 total energy tensor([[105.7522]])\n",
      "[0.59445274]\n",
      "Mode: Test env_steps 200 total rewards -1185.5437812805176 total energy tensor([[148.2385]])\n",
      "[-0.6755462]\n",
      "Mode: Test env_steps 200 total rewards -1444.7988212108612 total energy tensor([[124.5493]])\n",
      "[0.14197484]\n",
      "Mode: Test env_steps 200 total rewards -1423.144459247589 total energy tensor([[126.9862]])\n",
      "[-0.73295677]\n",
      "Mode: Test env_steps 200 total rewards -1216.338381767273 total energy tensor([[146.2991]])\n",
      "[0.3432534]\n",
      "Mode: Test env_steps 200 total rewards -1169.369375705719 total energy tensor([[148.6403]])\n",
      "[-0.4984633]\n",
      "Mode: Test env_steps 200 total rewards -1594.0787282288074 total energy tensor([[188.7575]])\n",
      "30000 -1437.0939343184232\n",
      "[0.2276678]\n",
      "Mode: Train env_steps 200 total rewards -1139.1202874779701 total energy tensor([[148.5510]])\n",
      "[0.04086019]\n",
      "Mode: Train env_steps 200 total rewards -1594.4914368391037 total energy tensor([[188.8842]])\n",
      "[0.66955566]\n",
      "Mode: Train env_steps 200 total rewards -1182.8491418361664 total energy tensor([[147.8798]])\n",
      "[0.12268492]\n",
      "Mode: Train env_steps 200 total rewards -1180.9232568740845 total energy tensor([[149.9842]])\n",
      "[0.4339053]\n",
      "Mode: Train env_steps 200 total rewards -1489.5181188583374 total energy tensor([[113.2367]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6255919]\n",
      "Mode: Train env_steps 200 total rewards -1628.2943887710571 total energy tensor([[115.6249]])\n",
      "[-0.6815311]\n",
      "Mode: Train env_steps 200 total rewards -1619.8364696502686 total energy tensor([[107.8470]])\n",
      "[0.7248604]\n",
      "Mode: Train env_steps 200 total rewards -1229.0219222307205 total energy tensor([[157.1725]])\n",
      "[0.34617367]\n",
      "Mode: Train env_steps 200 total rewards -1594.2998132705688 total energy tensor([[112.7871]])\n",
      "[0.4824609]\n",
      "Mode: Train env_steps 200 total rewards -1382.7821023464203 total energy tensor([[130.3713]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8885382]\n",
      "Mode: Train env_steps 200 total rewards -1340.8930706977844 total energy tensor([[137.6122]])\n",
      "[0.23946428]\n",
      "Mode: Train env_steps 200 total rewards -1560.1125192642212 total energy tensor([[117.7870]])\n",
      "[0.4090564]\n",
      "Mode: Train env_steps 200 total rewards -1582.809599429369 total energy tensor([[189.2019]])\n",
      "[0.00529426]\n",
      "Mode: Train env_steps 200 total rewards -1689.4971270561218 total energy tensor([[73.6756]])\n",
      "[-0.09986453]\n",
      "Mode: Train env_steps 200 total rewards -1119.6707942523062 total energy tensor([[153.8560]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1419636]\n",
      "Mode: Train env_steps 200 total rewards -1190.8645241260529 total energy tensor([[158.8239]])\n",
      "[0.8148476]\n",
      "Mode: Train env_steps 200 total rewards -1582.0319065749645 total energy tensor([[192.2234]])\n",
      "[0.3938469]\n",
      "Mode: Train env_steps 200 total rewards -1232.012431025505 total energy tensor([[160.0744]])\n",
      "[-0.45035934]\n",
      "Mode: Train env_steps 200 total rewards -974.507330276072 total energy tensor([[145.7191]])\n",
      "[0.4427659]\n",
      "Mode: Train env_steps 200 total rewards -1219.1678813695908 total energy tensor([[159.6906]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44044182]\n",
      "Mode: Train env_steps 200 total rewards -1205.7822383642197 total energy tensor([[151.8714]])\n",
      "[-0.7990358]\n",
      "Mode: Train env_steps 200 total rewards -1426.794104628265 total energy tensor([[174.1602]])\n",
      "[0.47817352]\n",
      "Mode: Train env_steps 200 total rewards -1282.3267036676407 total energy tensor([[129.6542]])\n",
      "[-0.5867326]\n",
      "Mode: Train env_steps 200 total rewards -1621.3162660598755 total energy tensor([[87.5573]])\n",
      "[0.0778032]\n",
      "Mode: Train env_steps 200 total rewards -1451.8019680976868 total energy tensor([[112.1479]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3752008]\n",
      "Mode: Test env_steps 200 total rewards -1228.5714565627277 total energy tensor([[137.5395]])\n",
      "[-0.6952367]\n",
      "Mode: Test env_steps 200 total rewards -1579.7023168206215 total energy tensor([[189.3338]])\n",
      "[0.10181808]\n",
      "Mode: Test env_steps 200 total rewards -1355.388479590416 total energy tensor([[137.3795]])\n",
      "[-0.66498375]\n",
      "Mode: Test env_steps 200 total rewards -1676.8508248329163 total energy tensor([[83.2647]])\n",
      "[-0.3562426]\n",
      "Mode: Test env_steps 200 total rewards -1314.8360689878464 total energy tensor([[143.8326]])\n",
      "[-0.36620975]\n",
      "Mode: Test env_steps 200 total rewards -1711.821605682373 total energy tensor([[74.5061]])\n",
      "[-0.92365557]\n",
      "Mode: Test env_steps 200 total rewards -1370.7240649461746 total energy tensor([[138.5932]])\n",
      "[-0.946969]\n",
      "Mode: Test env_steps 200 total rewards -1239.3339373394847 total energy tensor([[138.5390]])\n",
      "[0.972485]\n",
      "Mode: Test env_steps 200 total rewards -1190.563144005835 total energy tensor([[131.4012]])\n",
      "[0.98609567]\n",
      "Mode: Test env_steps 200 total rewards -1351.8575811386108 total energy tensor([[140.5892]])\n",
      "35000 -1401.9649479907007\n",
      "[0.3863057]\n",
      "Mode: Train env_steps 200 total rewards -1342.0897147655487 total energy tensor([[132.3758]])\n",
      "[-0.50337696]\n",
      "Mode: Train env_steps 200 total rewards -1589.9987415075302 total energy tensor([[191.9282]])\n",
      "[-0.29224557]\n",
      "Mode: Train env_steps 200 total rewards -1565.136024236679 total energy tensor([[96.7692]])\n",
      "[0.9255313]\n",
      "Mode: Train env_steps 200 total rewards -1302.489449262619 total energy tensor([[140.6416]])\n",
      "[-0.65372753]\n",
      "Mode: Train env_steps 200 total rewards -1574.1629651933908 total energy tensor([[191.8480]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.64902157]\n",
      "Mode: Train env_steps 200 total rewards -1349.8233859539032 total energy tensor([[148.9671]])\n",
      "[-0.08104455]\n",
      "Mode: Train env_steps 200 total rewards -1292.7043099999428 total energy tensor([[144.4267]])\n",
      "[0.01012092]\n",
      "Mode: Train env_steps 200 total rewards -1311.113211363554 total energy tensor([[138.1328]])\n",
      "[0.00285308]\n",
      "Mode: Train env_steps 200 total rewards -1303.2299238443375 total energy tensor([[148.1871]])\n",
      "[0.47602317]\n",
      "Mode: Train env_steps 200 total rewards -1312.0333922803402 total energy tensor([[139.0013]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14236727]\n",
      "Mode: Train env_steps 200 total rewards -1500.3281280994415 total energy tensor([[102.5722]])\n",
      "[0.35869166]\n",
      "Mode: Train env_steps 200 total rewards -1628.5156197547913 total energy tensor([[62.2404]])\n",
      "[0.6147647]\n",
      "Mode: Train env_steps 200 total rewards -1644.0358986854553 total energy tensor([[77.6909]])\n",
      "[-0.741834]\n",
      "Mode: Train env_steps 200 total rewards -1691.0056552886963 total energy tensor([[49.4895]])\n",
      "[-0.48387256]\n",
      "Mode: Train env_steps 200 total rewards -1724.635419845581 total energy tensor([[57.3038]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.669544]\n",
      "Mode: Train env_steps 200 total rewards -1579.7273297309875 total energy tensor([[132.5314]])\n",
      "[0.96761405]\n",
      "Mode: Train env_steps 200 total rewards -1545.8024867773056 total energy tensor([[88.3725]])\n",
      "[-0.35183412]\n",
      "Mode: Train env_steps 200 total rewards -1566.4303803443909 total energy tensor([[115.6359]])\n",
      "[-0.3127329]\n",
      "Mode: Train env_steps 200 total rewards -1401.2589222490788 total energy tensor([[101.4924]])\n",
      "[0.2696829]\n",
      "Mode: Train env_steps 200 total rewards -1547.2593159675598 total energy tensor([[114.5455]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55359447]\n",
      "Mode: Train env_steps 200 total rewards -1474.464877460152 total energy tensor([[80.8933]])\n",
      "[-0.53521633]\n",
      "Mode: Train env_steps 200 total rewards -1497.5985741764307 total energy tensor([[82.3540]])\n",
      "[-0.93118024]\n",
      "Mode: Train env_steps 200 total rewards -1555.723449230194 total energy tensor([[107.4378]])\n",
      "[-0.61792386]\n",
      "Mode: Train env_steps 200 total rewards -1572.490974187851 total energy tensor([[104.9576]])\n",
      "[-0.7915279]\n",
      "Mode: Train env_steps 200 total rewards -1569.4620279073715 total energy tensor([[101.8980]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.932779]\n",
      "Mode: Test env_steps 200 total rewards -1596.8380074501038 total energy tensor([[91.6733]])\n",
      "[-0.6953293]\n",
      "Mode: Test env_steps 200 total rewards -1545.2238683700562 total energy tensor([[91.7337]])\n",
      "[-0.81117165]\n",
      "Mode: Test env_steps 200 total rewards -1460.5389788746834 total energy tensor([[81.4401]])\n",
      "[-0.8291029]\n",
      "Mode: Test env_steps 200 total rewards -1530.0838755369186 total energy tensor([[80.1223]])\n",
      "[0.08983357]\n",
      "Mode: Test env_steps 200 total rewards -1338.736712448299 total energy tensor([[79.1903]])\n",
      "[0.12074569]\n",
      "Mode: Test env_steps 200 total rewards -1379.6099487543106 total energy tensor([[87.4164]])\n",
      "[-0.7066704]\n",
      "Mode: Test env_steps 200 total rewards -1626.5265126228333 total energy tensor([[112.3302]])\n",
      "[-0.59197885]\n",
      "Mode: Test env_steps 200 total rewards -1536.6294979453087 total energy tensor([[83.3545]])\n",
      "[-0.81437594]\n",
      "Mode: Test env_steps 200 total rewards -1581.6764345169067 total energy tensor([[86.0727]])\n",
      "[0.6764365]\n",
      "Mode: Test env_steps 200 total rewards -1539.961377620697 total energy tensor([[92.3558]])\n",
      "40000 -1513.5825214140118\n",
      "[-0.89014316]\n",
      "Mode: Train env_steps 200 total rewards -1519.5132133960724 total energy tensor([[79.5543]])\n",
      "[0.7017759]\n",
      "Mode: Train env_steps 200 total rewards -1573.8549609184265 total energy tensor([[106.2591]])\n",
      "[-0.4704607]\n",
      "Mode: Train env_steps 200 total rewards -1486.9984142556787 total energy tensor([[79.7372]])\n",
      "[0.13995968]\n",
      "Mode: Train env_steps 200 total rewards -1461.852822497487 total energy tensor([[77.4765]])\n",
      "[0.62456256]\n",
      "Mode: Train env_steps 200 total rewards -1643.0623979568481 total energy tensor([[99.4379]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9598903]\n",
      "Mode: Train env_steps 200 total rewards -1493.884992968291 total energy tensor([[81.3418]])\n",
      "[0.3170804]\n",
      "Mode: Train env_steps 200 total rewards -1494.4223322793841 total energy tensor([[81.5005]])\n",
      "[-0.66840535]\n",
      "Mode: Train env_steps 200 total rewards -1558.7083523273468 total energy tensor([[94.9082]])\n",
      "[-0.15064617]\n",
      "Mode: Train env_steps 200 total rewards -1505.3087840676308 total energy tensor([[81.2532]])\n",
      "[-0.33920366]\n",
      "Mode: Train env_steps 200 total rewards -1651.494472503662 total energy tensor([[102.2508]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95243675]\n",
      "Mode: Train env_steps 200 total rewards -1451.9232320617884 total energy tensor([[95.9751]])\n",
      "[-0.16527942]\n",
      "Mode: Train env_steps 200 total rewards -1507.5826573371887 total energy tensor([[94.9299]])\n",
      "[0.7135411]\n",
      "Mode: Train env_steps 200 total rewards -1569.913666009903 total energy tensor([[106.0101]])\n",
      "[-0.69839466]\n",
      "Mode: Train env_steps 200 total rewards -1584.6066627502441 total energy tensor([[96.1457]])\n",
      "[0.5605612]\n",
      "Mode: Train env_steps 200 total rewards -1610.6477389335632 total energy tensor([[112.9287]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21651368]\n",
      "Mode: Train env_steps 200 total rewards -1634.6693572998047 total energy tensor([[70.7420]])\n",
      "[-0.33887833]\n",
      "Mode: Train env_steps 200 total rewards -1625.0718235969543 total energy tensor([[53.9993]])\n",
      "[0.27232495]\n",
      "Mode: Train env_steps 200 total rewards -1644.386480808258 total energy tensor([[121.6481]])\n",
      "[0.5733048]\n",
      "Mode: Train env_steps 200 total rewards -1599.1344225406647 total energy tensor([[53.1274]])\n",
      "[-0.4090872]\n",
      "Mode: Train env_steps 200 total rewards -1506.7727219779044 total energy tensor([[63.3520]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.59964406]\n",
      "Mode: Train env_steps 200 total rewards -1524.0454325079918 total energy tensor([[92.3466]])\n",
      "[-0.2985586]\n",
      "Mode: Train env_steps 200 total rewards -1568.9849736690521 total energy tensor([[107.0812]])\n",
      "[-0.9775416]\n",
      "Mode: Train env_steps 200 total rewards -1572.959600687027 total energy tensor([[97.9583]])\n",
      "[-0.93534577]\n",
      "Mode: Train env_steps 200 total rewards -1608.137924671173 total energy tensor([[103.7980]])\n",
      "[-0.3847276]\n",
      "Mode: Train env_steps 200 total rewards -1561.5603885650635 total energy tensor([[98.0877]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.21071813]\n",
      "Mode: Test env_steps 200 total rewards -1492.785144224763 total energy tensor([[105.0560]])\n",
      "[-0.36475748]\n",
      "Mode: Test env_steps 200 total rewards -1527.8071746826172 total energy tensor([[113.1608]])\n",
      "[0.2617131]\n",
      "Mode: Test env_steps 200 total rewards -1562.1057214736938 total energy tensor([[125.1373]])\n",
      "[-0.6761197]\n",
      "Mode: Test env_steps 200 total rewards -1592.9711322784424 total energy tensor([[129.1067]])\n",
      "[0.47123137]\n",
      "Mode: Test env_steps 200 total rewards -1580.3715176582336 total energy tensor([[146.6259]])\n",
      "[-0.94215614]\n",
      "Mode: Test env_steps 200 total rewards -1576.9372606277466 total energy tensor([[148.8133]])\n",
      "[0.86570495]\n",
      "Mode: Test env_steps 200 total rewards -1581.068823814392 total energy tensor([[130.6676]])\n",
      "[0.16230296]\n",
      "Mode: Test env_steps 200 total rewards -1532.3393737077713 total energy tensor([[109.9848]])\n",
      "[-0.45695528]\n",
      "Mode: Test env_steps 200 total rewards -1526.040292263031 total energy tensor([[113.6261]])\n",
      "[-0.90086013]\n",
      "Mode: Test env_steps 200 total rewards -1597.6295657157898 total energy tensor([[125.1406]])\n",
      "45000 -1557.005600644648\n",
      "[-0.7487127]\n",
      "Mode: Train env_steps 200 total rewards -1597.986490726471 total energy tensor([[125.0856]])\n",
      "[-0.45870516]\n",
      "Mode: Train env_steps 200 total rewards -1418.4694802612066 total energy tensor([[107.0081]])\n",
      "[0.31969982]\n",
      "Mode: Train env_steps 200 total rewards -1413.715729678981 total energy tensor([[99.6002]])\n",
      "[0.49439588]\n",
      "Mode: Train env_steps 200 total rewards -1537.2974820137024 total energy tensor([[108.9021]])\n",
      "[-0.14379889]\n",
      "Mode: Train env_steps 200 total rewards -1583.6209497451782 total energy tensor([[148.1198]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18286867]\n",
      "Mode: Train env_steps 200 total rewards -1558.9655413031578 total energy tensor([[86.1076]])\n",
      "[0.6112259]\n",
      "Mode: Train env_steps 200 total rewards -1566.3543506264687 total energy tensor([[87.7688]])\n",
      "[0.25386396]\n",
      "Mode: Train env_steps 200 total rewards -1598.0281326770782 total energy tensor([[105.6560]])\n",
      "[0.2605028]\n",
      "Mode: Train env_steps 200 total rewards -1651.527994632721 total energy tensor([[115.6899]])\n",
      "[0.48745784]\n",
      "Mode: Train env_steps 200 total rewards -1568.0885659456253 total energy tensor([[93.6512]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61765224]\n",
      "Mode: Train env_steps 200 total rewards -1585.6487035751343 total energy tensor([[132.4806]])\n",
      "[-0.5710328]\n",
      "Mode: Train env_steps 200 total rewards -1457.5565436780453 total energy tensor([[91.1478]])\n",
      "[0.2766935]\n",
      "Mode: Train env_steps 200 total rewards -1591.6268863677979 total energy tensor([[117.2186]])\n",
      "[0.07363406]\n",
      "Mode: Train env_steps 200 total rewards -1572.1332902908325 total energy tensor([[111.2175]])\n",
      "[0.09336831]\n",
      "Mode: Train env_steps 200 total rewards -1468.0289918519557 total energy tensor([[91.4044]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05628547]\n",
      "Mode: Train env_steps 200 total rewards -1527.6585158407688 total energy tensor([[81.7875]])\n",
      "[-0.91462046]\n",
      "Mode: Train env_steps 200 total rewards -1497.6485370248556 total energy tensor([[82.0594]])\n",
      "[-0.345767]\n",
      "Mode: Train env_steps 200 total rewards -1454.7222293317318 total energy tensor([[82.4562]])\n",
      "[0.16650896]\n",
      "Mode: Train env_steps 200 total rewards -1626.2812213897705 total energy tensor([[91.4400]])\n",
      "[0.9184041]\n",
      "Mode: Train env_steps 200 total rewards -1609.4879717826843 total energy tensor([[74.7793]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6601095]\n",
      "Mode: Train env_steps 200 total rewards -1613.2994074821472 total energy tensor([[122.0180]])\n",
      "[0.72166526]\n",
      "Mode: Train env_steps 200 total rewards -1594.7147274017334 total energy tensor([[130.6637]])\n",
      "[-0.03123991]\n",
      "Mode: Train env_steps 200 total rewards -1546.1361442804337 total energy tensor([[118.0557]])\n",
      "[0.7037312]\n",
      "Mode: Train env_steps 200 total rewards -1569.2788226604462 total energy tensor([[111.8568]])\n",
      "[0.36121753]\n",
      "Mode: Train env_steps 200 total rewards -1480.171074345708 total energy tensor([[98.8403]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19131725]\n",
      "Mode: Test env_steps 200 total rewards -1593.7543988227844 total energy tensor([[103.7907]])\n",
      "[-0.87164664]\n",
      "Mode: Test env_steps 200 total rewards -1612.3434853553772 total energy tensor([[98.9101]])\n",
      "[0.8850962]\n",
      "Mode: Test env_steps 200 total rewards -1629.3872199058533 total energy tensor([[100.1024]])\n",
      "[-0.9256767]\n",
      "Mode: Test env_steps 200 total rewards -1574.312976181507 total energy tensor([[90.4291]])\n",
      "[0.14492032]\n",
      "Mode: Test env_steps 200 total rewards -1554.045947521925 total energy tensor([[83.9032]])\n",
      "[0.6990464]\n",
      "Mode: Test env_steps 200 total rewards -1542.8796007037163 total energy tensor([[90.4485]])\n",
      "[0.6324604]\n",
      "Mode: Test env_steps 200 total rewards -1652.5311751365662 total energy tensor([[104.2294]])\n",
      "[0.9237158]\n",
      "Mode: Test env_steps 200 total rewards -1640.7448830604553 total energy tensor([[117.4051]])\n",
      "[-0.611309]\n",
      "Mode: Test env_steps 200 total rewards -1604.8506813049316 total energy tensor([[101.3613]])\n",
      "[0.6812043]\n",
      "Mode: Test env_steps 200 total rewards -1602.5375430583954 total energy tensor([[90.8137]])\n",
      "50000 -1600.7387911051512\n",
      "[-0.17952251]\n",
      "Mode: Train env_steps 200 total rewards -1629.784704208374 total energy tensor([[92.5351]])\n",
      "[-0.16349679]\n",
      "Mode: Train env_steps 200 total rewards -1646.8648834228516 total energy tensor([[107.1347]])\n",
      "[-0.807075]\n",
      "Mode: Train env_steps 200 total rewards -1619.6708781719208 total energy tensor([[91.2211]])\n",
      "[-0.9621771]\n",
      "Mode: Train env_steps 200 total rewards -1630.1122336387634 total energy tensor([[116.2886]])\n",
      "[0.2184872]\n",
      "Mode: Train env_steps 200 total rewards -1632.9259116649628 total energy tensor([[81.5028]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8300311]\n",
      "Mode: Train env_steps 200 total rewards -1660.3285126686096 total energy tensor([[90.7259]])\n",
      "[-0.33649036]\n",
      "Mode: Train env_steps 200 total rewards -1657.5461535453796 total energy tensor([[75.5367]])\n",
      "[0.13365997]\n",
      "Mode: Train env_steps 200 total rewards -1480.5009229928255 total energy tensor([[85.7502]])\n",
      "[0.7646087]\n",
      "Mode: Train env_steps 200 total rewards -1650.3062009811401 total energy tensor([[76.0559]])\n",
      "[-0.03756456]\n",
      "Mode: Train env_steps 200 total rewards -1643.7952771186829 total energy tensor([[92.4794]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9771837]\n",
      "Mode: Train env_steps 200 total rewards -1623.4904705286026 total energy tensor([[79.1862]])\n",
      "[0.3796727]\n",
      "Mode: Train env_steps 200 total rewards -1442.025982633233 total energy tensor([[90.3494]])\n",
      "[-0.638001]\n",
      "Mode: Train env_steps 200 total rewards -1563.485655874014 total energy tensor([[86.7094]])\n",
      "[-0.17611237]\n",
      "Mode: Train env_steps 200 total rewards -1637.0454919338226 total energy tensor([[73.2788]])\n",
      "[-0.1645342]\n",
      "Mode: Train env_steps 200 total rewards -1641.1950180530548 total energy tensor([[69.7108]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69395244]\n",
      "Mode: Train env_steps 200 total rewards -1715.7276730537415 total energy tensor([[72.1415]])\n",
      "[0.8017406]\n",
      "Mode: Train env_steps 200 total rewards -1528.123187072575 total energy tensor([[74.5757]])\n",
      "[-0.41445133]\n",
      "Mode: Train env_steps 200 total rewards -1685.1437611579895 total energy tensor([[73.2317]])\n",
      "[0.19115084]\n",
      "Mode: Train env_steps 200 total rewards -1675.765501499176 total energy tensor([[63.5027]])\n",
      "[-0.46866778]\n",
      "Mode: Train env_steps 200 total rewards -1516.8106460943818 total energy tensor([[75.4882]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81836045]\n",
      "Mode: Train env_steps 200 total rewards -1604.0558815598488 total energy tensor([[72.5603]])\n",
      "[-0.2685056]\n",
      "Mode: Train env_steps 200 total rewards -1637.6577956676483 total energy tensor([[66.6531]])\n",
      "[0.19657001]\n",
      "Mode: Train env_steps 200 total rewards -1703.4543690681458 total energy tensor([[62.2004]])\n",
      "[0.3951282]\n",
      "Mode: Train env_steps 200 total rewards -1707.4777693748474 total energy tensor([[63.1679]])\n",
      "[-0.34905583]\n",
      "Mode: Train env_steps 200 total rewards -1674.0405299663544 total energy tensor([[62.5849]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4175927]\n",
      "Mode: Test env_steps 200 total rewards -1729.3823409080505 total energy tensor([[54.4253]])\n",
      "[0.32217547]\n",
      "Mode: Test env_steps 200 total rewards -1641.1720284223557 total energy tensor([[57.9025]])\n",
      "[0.79605275]\n",
      "Mode: Test env_steps 200 total rewards -1741.0160655975342 total energy tensor([[49.7125]])\n",
      "[0.85740644]\n",
      "Mode: Test env_steps 200 total rewards -1738.523579120636 total energy tensor([[48.1136]])\n",
      "[-0.14138535]\n",
      "Mode: Test env_steps 200 total rewards -1721.1164321899414 total energy tensor([[54.4033]])\n",
      "[0.27813604]\n",
      "Mode: Test env_steps 200 total rewards -1658.4393566846848 total energy tensor([[57.1573]])\n",
      "[-0.7223594]\n",
      "Mode: Test env_steps 200 total rewards -1704.1482348442078 total energy tensor([[49.5224]])\n",
      "[0.35764226]\n",
      "Mode: Test env_steps 200 total rewards -1625.104554951191 total energy tensor([[59.8787]])\n",
      "[-0.00154584]\n",
      "Mode: Test env_steps 200 total rewards -1616.8825717270374 total energy tensor([[69.1720]])\n",
      "[-0.8040026]\n",
      "Mode: Test env_steps 200 total rewards -1668.623060464859 total energy tensor([[56.9468]])\n",
      "55000 -1684.4408224910499\n",
      "[0.7304746]\n",
      "Mode: Train env_steps 200 total rewards -1723.952275276184 total energy tensor([[53.5891]])\n",
      "[0.10815364]\n",
      "Mode: Train env_steps 200 total rewards -1719.9640407562256 total energy tensor([[54.6141]])\n",
      "[-0.06833515]\n",
      "Mode: Train env_steps 200 total rewards -1643.7780075073242 total energy tensor([[62.8057]])\n",
      "[-0.3240909]\n",
      "Mode: Train env_steps 200 total rewards -1458.2268535206094 total energy tensor([[69.4581]])\n",
      "[0.79864824]\n",
      "Mode: Train env_steps 200 total rewards -1547.7279239296913 total energy tensor([[74.9176]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8844283]\n",
      "Mode: Train env_steps 200 total rewards -1558.5395624116063 total energy tensor([[84.9182]])\n",
      "[0.0861307]\n",
      "Mode: Train env_steps 200 total rewards -1696.5316286087036 total energy tensor([[77.6574]])\n",
      "[-0.10026399]\n",
      "Mode: Train env_steps 200 total rewards -1673.572702884674 total energy tensor([[75.4468]])\n",
      "[0.07109617]\n",
      "Mode: Train env_steps 200 total rewards -1515.4459129292518 total energy tensor([[88.6576]])\n",
      "[-0.2235789]\n",
      "Mode: Train env_steps 200 total rewards -1614.3898675441742 total energy tensor([[79.9018]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5596624]\n",
      "Mode: Train env_steps 200 total rewards -1446.8696408607066 total energy tensor([[82.3898]])\n",
      "[-0.8611975]\n",
      "Mode: Train env_steps 200 total rewards -1502.4039055891335 total energy tensor([[79.8563]])\n",
      "[0.6304254]\n",
      "Mode: Train env_steps 200 total rewards -1725.051218509674 total energy tensor([[55.7155]])\n",
      "[-0.02501112]\n",
      "Mode: Train env_steps 200 total rewards -1615.8378911018372 total energy tensor([[66.4242]])\n",
      "[0.20809177]\n",
      "Mode: Train env_steps 200 total rewards -1633.8969756364822 total energy tensor([[69.7482]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25879443]\n",
      "Mode: Train env_steps 200 total rewards -1656.5703642368317 total energy tensor([[71.2263]])\n",
      "[-0.44802412]\n",
      "Mode: Train env_steps 200 total rewards -1632.8783711194992 total energy tensor([[73.6663]])\n",
      "[0.11737511]\n",
      "Mode: Train env_steps 200 total rewards -1714.8018889427185 total energy tensor([[69.4117]])\n",
      "[0.08341375]\n",
      "Mode: Train env_steps 200 total rewards -1540.6373638361692 total energy tensor([[86.2393]])\n",
      "[0.23555209]\n",
      "Mode: Train env_steps 200 total rewards -1676.3238492012024 total energy tensor([[84.9625]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45179117]\n",
      "Mode: Train env_steps 200 total rewards -1718.4351682662964 total energy tensor([[51.6275]])\n",
      "[0.56846476]\n",
      "Mode: Train env_steps 200 total rewards -1613.3409497141838 total energy tensor([[54.6197]])\n",
      "[0.7523711]\n",
      "Mode: Train env_steps 200 total rewards -1712.4794845581055 total energy tensor([[54.6953]])\n",
      "[-0.8504243]\n",
      "Mode: Train env_steps 200 total rewards -1621.3480298519135 total energy tensor([[56.3994]])\n",
      "[0.7326531]\n",
      "Mode: Train env_steps 200 total rewards -1545.8431691005826 total energy tensor([[54.3847]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3913126]\n",
      "Mode: Test env_steps 200 total rewards -1485.7520279176533 total energy tensor([[74.4942]])\n",
      "[-0.26774094]\n",
      "Mode: Test env_steps 200 total rewards -1771.4154868125916 total energy tensor([[41.7535]])\n",
      "[0.21614225]\n",
      "Mode: Test env_steps 200 total rewards -1636.2861341834068 total energy tensor([[62.8006]])\n",
      "[-0.48681298]\n",
      "Mode: Test env_steps 200 total rewards -1718.0419845581055 total energy tensor([[47.7925]])\n",
      "[0.37503985]\n",
      "Mode: Test env_steps 200 total rewards -1745.4997444152832 total energy tensor([[43.5388]])\n",
      "[-0.39897]\n",
      "Mode: Test env_steps 200 total rewards -1652.153896510601 total energy tensor([[61.5362]])\n",
      "[0.09762455]\n",
      "Mode: Test env_steps 200 total rewards -1563.8490040376782 total energy tensor([[69.5686]])\n",
      "[-0.33964217]\n",
      "Mode: Test env_steps 200 total rewards -1630.7484939992428 total energy tensor([[64.0290]])\n",
      "[0.48450837]\n",
      "Mode: Test env_steps 200 total rewards -1683.5662956237793 total energy tensor([[55.8603]])\n",
      "[0.07379565]\n",
      "Mode: Test env_steps 200 total rewards -1593.787788271904 total energy tensor([[66.1079]])\n",
      "60000 -1648.1100856330245\n",
      "[-0.3398457]\n",
      "Mode: Train env_steps 200 total rewards -1518.404617300257 total energy tensor([[72.1411]])\n",
      "[0.25621644]\n",
      "Mode: Train env_steps 200 total rewards -1763.8239979743958 total energy tensor([[38.1153]])\n",
      "[-0.47434455]\n",
      "Mode: Train env_steps 200 total rewards -1469.484597319737 total energy tensor([[76.1985]])\n",
      "[-0.36788577]\n",
      "Mode: Train env_steps 200 total rewards -1616.1620140075684 total energy tensor([[63.0064]])\n",
      "[0.63378197]\n",
      "Mode: Train env_steps 200 total rewards -1764.2960195541382 total energy tensor([[46.0326]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63005936]\n",
      "Mode: Train env_steps 200 total rewards -1736.0115613937378 total energy tensor([[40.1316]])\n",
      "[-0.14342766]\n",
      "Mode: Train env_steps 200 total rewards -1765.0001797676086 total energy tensor([[41.9214]])\n",
      "[0.16886011]\n",
      "Mode: Train env_steps 200 total rewards -1708.7469218969345 total energy tensor([[51.1268]])\n",
      "[0.01877291]\n",
      "Mode: Train env_steps 200 total rewards -1747.5078873634338 total energy tensor([[40.7926]])\n",
      "[-0.99765927]\n",
      "Mode: Train env_steps 200 total rewards -1568.8759548813105 total energy tensor([[65.1193]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.33774492]\n",
      "Mode: Train env_steps 200 total rewards -1723.2677468061447 total energy tensor([[46.1319]])\n",
      "[0.7641953]\n",
      "Mode: Train env_steps 200 total rewards -1813.8888568878174 total energy tensor([[27.3481]])\n",
      "[-0.49183843]\n",
      "Mode: Train env_steps 200 total rewards -1800.949360370636 total energy tensor([[26.3681]])\n",
      "[0.41999307]\n",
      "Mode: Train env_steps 200 total rewards -1722.731983423233 total energy tensor([[41.5471]])\n",
      "[-0.558792]\n",
      "Mode: Train env_steps 200 total rewards -1804.2351412773132 total energy tensor([[30.3218]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01188261]\n",
      "Mode: Train env_steps 200 total rewards -1723.8709154129028 total energy tensor([[42.5133]])\n",
      "[-0.39605752]\n",
      "Mode: Train env_steps 200 total rewards -1766.4260096549988 total energy tensor([[38.7584]])\n",
      "[-0.31707886]\n",
      "Mode: Train env_steps 200 total rewards -1516.0781676070765 total energy tensor([[66.4827]])\n",
      "[0.28502843]\n",
      "Mode: Train env_steps 200 total rewards -1725.6644496917725 total energy tensor([[41.5839]])\n",
      "[-0.57975745]\n",
      "Mode: Train env_steps 200 total rewards -1800.9641828536987 total energy tensor([[26.0997]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42999977]\n",
      "Mode: Train env_steps 200 total rewards -1643.8172810077667 total energy tensor([[61.5478]])\n",
      "[-0.14167885]\n",
      "Mode: Train env_steps 200 total rewards -1657.5652942061424 total energy tensor([[55.5534]])\n",
      "[-0.29839215]\n",
      "Mode: Train env_steps 200 total rewards -1715.7599289417267 total energy tensor([[46.9952]])\n",
      "[-0.43191716]\n",
      "Mode: Train env_steps 200 total rewards -1751.749665260315 total energy tensor([[41.0033]])\n",
      "[-0.17715858]\n",
      "Mode: Train env_steps 200 total rewards -1687.9843754768372 total energy tensor([[51.4048]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12012281]\n",
      "Mode: Test env_steps 200 total rewards -1655.6283683776855 total energy tensor([[71.0417]])\n",
      "[-0.04728873]\n",
      "Mode: Test env_steps 200 total rewards -1693.3631601333618 total energy tensor([[63.6577]])\n",
      "[0.30583706]\n",
      "Mode: Test env_steps 200 total rewards -1667.9232318401337 total energy tensor([[71.7760]])\n",
      "[0.01729341]\n",
      "Mode: Test env_steps 200 total rewards -1641.6828618049622 total energy tensor([[71.2641]])\n",
      "[0.20341456]\n",
      "Mode: Test env_steps 200 total rewards -1546.901073768735 total energy tensor([[84.4957]])\n",
      "[0.00745316]\n",
      "Mode: Test env_steps 200 total rewards -1168.9221812784672 total energy tensor([[112.7683]])\n",
      "[0.40824547]\n",
      "Mode: Test env_steps 200 total rewards -1665.0245158672333 total energy tensor([[72.9650]])\n",
      "[-0.19317414]\n",
      "Mode: Test env_steps 200 total rewards -1620.3429766893387 total energy tensor([[75.8133]])\n",
      "[0.48838228]\n",
      "Mode: Test env_steps 200 total rewards -1696.8317947387695 total energy tensor([[62.9765]])\n",
      "[-0.706045]\n",
      "Mode: Test env_steps 200 total rewards -1693.1466937065125 total energy tensor([[63.4606]])\n",
      "65000 -1604.9766858205198\n",
      "[-0.9628406]\n",
      "Mode: Train env_steps 200 total rewards -1708.3413186073303 total energy tensor([[61.3233]])\n",
      "[-0.6653097]\n",
      "Mode: Train env_steps 200 total rewards -1633.5024230480194 total energy tensor([[73.7000]])\n",
      "[0.07079369]\n",
      "Mode: Train env_steps 200 total rewards -1640.3973115682602 total energy tensor([[73.5540]])\n",
      "[-0.37245077]\n",
      "Mode: Train env_steps 200 total rewards -1594.4512450695038 total energy tensor([[81.0792]])\n",
      "[-0.80829734]\n",
      "Mode: Train env_steps 200 total rewards -1679.7038671970367 total energy tensor([[71.7713]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7519004]\n",
      "Mode: Train env_steps 200 total rewards -1649.062741458416 total energy tensor([[78.0435]])\n",
      "[-0.04151597]\n",
      "Mode: Train env_steps 200 total rewards -1679.7571294307709 total energy tensor([[86.2277]])\n",
      "[0.22316153]\n",
      "Mode: Train env_steps 200 total rewards -1563.480488628149 total energy tensor([[78.5320]])\n",
      "[-0.1993961]\n",
      "Mode: Train env_steps 200 total rewards -1512.7563616596162 total energy tensor([[73.4411]])\n",
      "[0.35231113]\n",
      "Mode: Train env_steps 200 total rewards -1665.2569432258606 total energy tensor([[86.4103]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.634805]\n",
      "Mode: Train env_steps 200 total rewards -1717.9692402482033 total energy tensor([[43.0756]])\n",
      "[-0.13381948]\n",
      "Mode: Train env_steps 200 total rewards -1627.6562731452286 total energy tensor([[51.8788]])\n",
      "[-0.04502617]\n",
      "Mode: Train env_steps 200 total rewards -1849.1773285865784 total energy tensor([[13.0181]])\n",
      "[-0.69162875]\n",
      "Mode: Train env_steps 200 total rewards -1751.9110915660858 total energy tensor([[36.6731]])\n",
      "[0.87996846]\n",
      "Mode: Train env_steps 200 total rewards -1791.5625672340393 total energy tensor([[24.1556]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.54973626]\n",
      "Mode: Train env_steps 200 total rewards -1682.4879750311375 total energy tensor([[52.4882]])\n",
      "[0.7835409]\n",
      "Mode: Train env_steps 200 total rewards -1601.5394667834044 total energy tensor([[56.7747]])\n",
      "[-0.45787275]\n",
      "Mode: Train env_steps 200 total rewards -1622.4977192431688 total energy tensor([[58.0724]])\n",
      "[0.23108399]\n",
      "Mode: Train env_steps 200 total rewards -1734.0211852788925 total energy tensor([[59.9258]])\n",
      "[-0.4954932]\n",
      "Mode: Train env_steps 200 total rewards -1758.2904686927795 total energy tensor([[56.1785]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8429902]\n",
      "Mode: Train env_steps 200 total rewards -1762.884102344513 total energy tensor([[59.4290]])\n",
      "[0.27661633]\n",
      "Mode: Train env_steps 200 total rewards -1778.047902584076 total energy tensor([[35.0687]])\n",
      "[-0.5436886]\n",
      "Mode: Train env_steps 200 total rewards -1757.6898612976074 total energy tensor([[43.4771]])\n",
      "[-0.8165986]\n",
      "Mode: Train env_steps 200 total rewards -1688.7158001065254 total energy tensor([[47.2932]])\n",
      "[-0.5507254]\n",
      "Mode: Train env_steps 200 total rewards -1587.5551071837544 total energy tensor([[57.5271]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84584415]\n",
      "Mode: Test env_steps 200 total rewards -1673.6735748648643 total energy tensor([[47.6386]])\n",
      "[0.905705]\n",
      "Mode: Test env_steps 200 total rewards -1784.5289793014526 total energy tensor([[31.9232]])\n",
      "[-0.30968606]\n",
      "Mode: Test env_steps 200 total rewards -1740.9558584690094 total energy tensor([[38.8615]])\n",
      "[0.28788313]\n",
      "Mode: Test env_steps 200 total rewards -1656.6032802462578 total energy tensor([[49.4723]])\n",
      "[-0.56717896]\n",
      "Mode: Test env_steps 200 total rewards -1770.4036302566528 total energy tensor([[30.5101]])\n",
      "[-0.06147353]\n",
      "Mode: Test env_steps 200 total rewards -1670.1540220975876 total energy tensor([[47.7730]])\n",
      "[-0.10345003]\n",
      "Mode: Test env_steps 200 total rewards -1705.1394842863083 total energy tensor([[42.9456]])\n",
      "[-0.5686483]\n",
      "Mode: Test env_steps 200 total rewards -1783.5025000572205 total energy tensor([[31.9387]])\n",
      "[0.48869947]\n",
      "Mode: Test env_steps 200 total rewards -1759.661877632141 total energy tensor([[33.3157]])\n",
      "[0.61274725]\n",
      "Mode: Test env_steps 200 total rewards -1711.4488669633865 total energy tensor([[43.9821]])\n",
      "70000 -1725.607207417488\n",
      "[-0.19078107]\n",
      "Mode: Train env_steps 200 total rewards -1667.7132223844528 total energy tensor([[49.1234]])\n",
      "[-0.98420876]\n",
      "Mode: Train env_steps 200 total rewards -1771.3209190368652 total energy tensor([[29.7463]])\n",
      "[-0.5923139]\n",
      "Mode: Train env_steps 200 total rewards -1380.5003387592733 total energy tensor([[74.2756]])\n",
      "[0.48198104]\n",
      "Mode: Train env_steps 200 total rewards -1654.8682010769844 total energy tensor([[50.0180]])\n",
      "[0.36010364]\n",
      "Mode: Train env_steps 200 total rewards -1797.4262108802795 total energy tensor([[30.2609]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:31<00:00,  3.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28346917]\n",
      "Mode: Train env_steps 200 total rewards -1650.4147345423698 total energy tensor([[53.1656]])\n",
      "[0.5954837]\n",
      "Mode: Train env_steps 200 total rewards -1757.5387287139893 total energy tensor([[31.8456]])\n",
      "[0.9616921]\n",
      "Mode: Train env_steps 200 total rewards -1786.981327533722 total energy tensor([[31.0780]])\n",
      "[0.02081827]\n",
      "Mode: Train env_steps 200 total rewards -1752.7505178451538 total energy tensor([[32.9496]])\n",
      "[0.7996064]\n",
      "Mode: Train env_steps 200 total rewards -1761.001224040985 total energy tensor([[31.1850]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:47<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68920296]\n",
      "Mode: Train env_steps 200 total rewards -1645.7397146821022 total energy tensor([[49.4892]])\n",
      "[0.31202835]\n",
      "Mode: Train env_steps 200 total rewards -1758.5002455711365 total energy tensor([[38.3367]])\n",
      "[-0.5037602]\n",
      "Mode: Train env_steps 200 total rewards -1622.5375982448459 total energy tensor([[51.7656]])\n",
      "[-0.60481673]\n",
      "Mode: Train env_steps 200 total rewards -1433.2164258692355 total energy tensor([[65.7419]])\n",
      "[-0.1881884]\n",
      "Mode: Train env_steps 200 total rewards -1660.8421958386898 total energy tensor([[47.6224]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:21<00:00,  3.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46045867]\n",
      "Mode: Train env_steps 200 total rewards -1760.674421787262 total energy tensor([[33.1887]])\n",
      "[-0.8240151]\n",
      "Mode: Train env_steps 200 total rewards -1758.049199104309 total energy tensor([[40.2619]])\n",
      "[-0.08583247]\n",
      "Mode: Train env_steps 200 total rewards -1580.2321877032518 total energy tensor([[58.6205]])\n",
      "[0.17543586]\n",
      "Mode: Train env_steps 200 total rewards -1766.5998277664185 total energy tensor([[30.8834]])\n",
      "[0.7121091]\n",
      "Mode: Train env_steps 200 total rewards -1781.0184888839722 total energy tensor([[30.5681]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01310052]\n",
      "Mode: Train env_steps 200 total rewards -1831.2635641098022 total energy tensor([[16.6556]])\n",
      "[-0.6443148]\n",
      "Mode: Train env_steps 200 total rewards -1666.618995308876 total energy tensor([[44.8599]])\n",
      "[0.82734776]\n",
      "Mode: Train env_steps 200 total rewards -1611.6408206587657 total energy tensor([[49.9649]])\n",
      "[-0.6069802]\n",
      "Mode: Train env_steps 200 total rewards -1708.3520175218582 total energy tensor([[37.1565]])\n",
      "[0.12220237]\n",
      "Mode: Train env_steps 200 total rewards -1865.715087890625 total energy tensor([[9.9137]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41480392]\n",
      "Mode: Test env_steps 200 total rewards -1813.2313141822815 total energy tensor([[19.8229]])\n",
      "[-0.83079726]\n",
      "Mode: Test env_steps 200 total rewards -1806.7635836601257 total energy tensor([[21.4787]])\n",
      "[0.42076984]\n",
      "Mode: Test env_steps 200 total rewards -1830.1153450012207 total energy tensor([[16.4848]])\n",
      "[0.9192533]\n",
      "Mode: Test env_steps 200 total rewards -1836.017321586609 total energy tensor([[14.3734]])\n",
      "[0.32038102]\n",
      "Mode: Test env_steps 200 total rewards -1857.344081401825 total energy tensor([[11.4948]])\n",
      "[-0.9981624]\n",
      "Mode: Test env_steps 200 total rewards -1798.8997526168823 total energy tensor([[24.7776]])\n",
      "[0.679771]\n",
      "Mode: Test env_steps 200 total rewards -1793.0490834712982 total energy tensor([[25.5175]])\n",
      "[-0.47146216]\n",
      "Mode: Test env_steps 200 total rewards -1825.535509109497 total energy tensor([[17.2479]])\n",
      "[-0.10355677]\n",
      "Mode: Test env_steps 200 total rewards -1584.7919726669788 total energy tensor([[48.6211]])\n",
      "[0.32849193]\n",
      "Mode: Test env_steps 200 total rewards -1498.6746212719008 total energy tensor([[51.6374]])\n",
      "75000 -1764.442258496862\n",
      "[-0.97047025]\n",
      "Mode: Train env_steps 200 total rewards -1806.9417662620544 total energy tensor([[23.7570]])\n",
      "[-0.12765463]\n",
      "Mode: Train env_steps 200 total rewards -1788.695398569107 total energy tensor([[28.8193]])\n",
      "[-0.35424864]\n",
      "Mode: Train env_steps 200 total rewards -1862.727484703064 total energy tensor([[10.8258]])\n",
      "[0.18874949]\n",
      "Mode: Train env_steps 200 total rewards -1750.831043958664 total energy tensor([[30.8015]])\n",
      "[0.49662733]\n",
      "Mode: Train env_steps 200 total rewards -1826.026840686798 total energy tensor([[21.6085]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4100547]\n",
      "Mode: Train env_steps 200 total rewards -1159.6273914449848 total energy tensor([[78.6634]])\n",
      "[-0.07763471]\n",
      "Mode: Train env_steps 200 total rewards -1823.9071180820465 total energy tensor([[26.2383]])\n",
      "[-0.18978891]\n",
      "Mode: Train env_steps 200 total rewards -1847.4647603034973 total energy tensor([[14.8343]])\n",
      "[0.13421158]\n",
      "Mode: Train env_steps 200 total rewards -1879.4493327140808 total energy tensor([[7.8022]])\n",
      "[-0.5089984]\n",
      "Mode: Train env_steps 200 total rewards -1766.3920905590057 total energy tensor([[35.8996]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3158832]\n",
      "Mode: Train env_steps 200 total rewards -1759.2222908139229 total energy tensor([[27.9956]])\n",
      "[0.31427327]\n",
      "Mode: Train env_steps 200 total rewards -1903.1241493225098 total energy tensor([[5.1979]])\n",
      "[0.75453806]\n",
      "Mode: Train env_steps 200 total rewards -1839.4008536338806 total energy tensor([[15.2991]])\n",
      "[0.26510322]\n",
      "Mode: Train env_steps 200 total rewards -1664.6991249360144 total energy tensor([[39.0248]])\n",
      "[-0.329983]\n",
      "Mode: Train env_steps 200 total rewards -1884.9600801467896 total energy tensor([[14.0204]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02794242]\n",
      "Mode: Train env_steps 200 total rewards -1785.5344619750977 total energy tensor([[27.0486]])\n",
      "[0.51487875]\n",
      "Mode: Train env_steps 200 total rewards -1165.9797826390713 total energy tensor([[64.5148]])\n",
      "[0.4331078]\n",
      "Mode: Train env_steps 200 total rewards -1861.4422726631165 total energy tensor([[11.2470]])\n",
      "[-0.77521956]\n",
      "Mode: Train env_steps 200 total rewards -1839.869701385498 total energy tensor([[12.9626]])\n",
      "[-0.981373]\n",
      "Mode: Train env_steps 200 total rewards -1858.1068086624146 total energy tensor([[18.5341]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3395952]\n",
      "Mode: Train env_steps 200 total rewards -1792.7593955993652 total energy tensor([[25.7243]])\n",
      "[-0.6683363]\n",
      "Mode: Train env_steps 200 total rewards -1654.19669932127 total energy tensor([[43.4179]])\n",
      "[0.4474801]\n",
      "Mode: Train env_steps 200 total rewards -1819.242908000946 total energy tensor([[20.2441]])\n",
      "[-0.40082973]\n",
      "Mode: Train env_steps 200 total rewards -1736.4969382286072 total energy tensor([[37.2863]])\n",
      "[-0.35177252]\n",
      "Mode: Train env_steps 200 total rewards -1649.140524417162 total energy tensor([[46.4076]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7483772]\n",
      "Mode: Test env_steps 200 total rewards -1853.2974681854248 total energy tensor([[17.3037]])\n",
      "[-0.71055204]\n",
      "Mode: Test env_steps 200 total rewards -1867.8850920200348 total energy tensor([[20.0363]])\n",
      "[0.16806959]\n",
      "Mode: Test env_steps 200 total rewards -1833.1672415733337 total energy tensor([[23.9142]])\n",
      "[-0.11365513]\n",
      "Mode: Test env_steps 200 total rewards -1900.0351166725159 total energy tensor([[13.2693]])\n",
      "[0.41702276]\n",
      "Mode: Test env_steps 200 total rewards -1753.8359835743904 total energy tensor([[34.0845]])\n",
      "[-0.9133856]\n",
      "Mode: Test env_steps 200 total rewards -1795.7229726314545 total energy tensor([[30.8272]])\n",
      "[-0.52847457]\n",
      "Mode: Test env_steps 200 total rewards -1733.5338573157787 total energy tensor([[37.3955]])\n",
      "[-0.67593914]\n",
      "Mode: Test env_steps 200 total rewards -1774.5504804849625 total energy tensor([[34.3814]])\n",
      "[-0.9893652]\n",
      "Mode: Test env_steps 200 total rewards -1868.0570378303528 total energy tensor([[19.7751]])\n",
      "[0.3486159]\n",
      "Mode: Test env_steps 200 total rewards -1796.6776695251465 total energy tensor([[30.6123]])\n",
      "80000 -1817.6762919813395\n",
      "[-0.26918823]\n",
      "Mode: Train env_steps 200 total rewards -1759.041040301323 total energy tensor([[36.4118]])\n",
      "[-0.7034515]\n",
      "Mode: Train env_steps 200 total rewards -1915.663477897644 total energy tensor([[5.1098]])\n",
      "[-0.5289404]\n",
      "Mode: Train env_steps 200 total rewards -1878.380286693573 total energy tensor([[12.3540]])\n",
      "[0.1834095]\n",
      "Mode: Train env_steps 200 total rewards -1862.922324180603 total energy tensor([[20.4630]])\n",
      "[0.27633455]\n",
      "Mode: Train env_steps 200 total rewards -1724.5671175718307 total energy tensor([[39.9262]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:34<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6980303]\n",
      "Mode: Train env_steps 200 total rewards -1551.590087890625 total energy tensor([[146.6744]])\n",
      "[-0.31344593]\n",
      "Mode: Train env_steps 200 total rewards -1820.0386986732483 total energy tensor([[43.0428]])\n",
      "[-0.69278115]\n",
      "Mode: Train env_steps 200 total rewards -1718.6145284175873 total energy tensor([[52.9595]])\n",
      "[-0.12954861]\n",
      "Mode: Train env_steps 200 total rewards -1837.9859156608582 total energy tensor([[39.6868]])\n",
      "[0.6945796]\n",
      "Mode: Train env_steps 200 total rewards -1361.2291514202952 total energy tensor([[72.7286]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:28<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7657971]\n",
      "Mode: Train env_steps 200 total rewards -1808.5256298780441 total energy tensor([[25.7640]])\n",
      "[-0.69709545]\n",
      "Mode: Train env_steps 200 total rewards -1932.2494659423828 total energy tensor([[2.9677]])\n",
      "[-0.3148796]\n",
      "Mode: Train env_steps 200 total rewards -1871.7754573822021 total energy tensor([[12.9492]])\n",
      "[-0.44520462]\n",
      "Mode: Train env_steps 200 total rewards -1800.9132733345032 total energy tensor([[30.5242]])\n",
      "[0.47947046]\n",
      "Mode: Train env_steps 200 total rewards -1510.198951387778 total energy tensor([[55.4982]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:18<00:00,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.46494162]\n",
      "Mode: Train env_steps 200 total rewards -1769.2854729890823 total energy tensor([[32.1295]])\n",
      "[0.60151803]\n",
      "Mode: Train env_steps 200 total rewards -1692.2008800655603 total energy tensor([[41.6297]])\n",
      "[0.15073533]\n",
      "Mode: Train env_steps 200 total rewards -1769.1293201446533 total energy tensor([[29.7095]])\n",
      "[-0.81802905]\n",
      "Mode: Train env_steps 200 total rewards -1581.9043815806508 total energy tensor([[54.6294]])\n",
      "[-0.96341586]\n",
      "Mode: Train env_steps 200 total rewards -1804.9257669448853 total energy tensor([[25.2956]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:19<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7083095]\n",
      "Mode: Train env_steps 200 total rewards -1631.2574907541275 total energy tensor([[49.2132]])\n",
      "[-0.8469938]\n",
      "Mode: Train env_steps 200 total rewards -1872.4221787452698 total energy tensor([[15.4278]])\n",
      "[0.36332318]\n",
      "Mode: Train env_steps 200 total rewards -1699.447149604559 total energy tensor([[38.6411]])\n",
      "[0.2616746]\n",
      "Mode: Train env_steps 200 total rewards -1867.8306460380554 total energy tensor([[16.5375]])\n",
      "[-0.6776149]\n",
      "Mode: Train env_steps 200 total rewards -1764.297303557396 total energy tensor([[30.6509]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:21<00:00,  3.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19839875]\n",
      "Mode: Test env_steps 200 total rewards -1690.7172099351883 total energy tensor([[47.8211]])\n",
      "[-0.75799304]\n",
      "Mode: Test env_steps 200 total rewards -1790.0853850841522 total energy tensor([[29.8311]])\n",
      "[-0.81176335]\n",
      "Mode: Test env_steps 200 total rewards -1712.8937828540802 total energy tensor([[45.0955]])\n",
      "[0.6168593]\n",
      "Mode: Test env_steps 200 total rewards -1795.0682153701782 total energy tensor([[26.1938]])\n",
      "[0.06759853]\n",
      "Mode: Test env_steps 200 total rewards -1505.1087377667427 total energy tensor([[64.4091]])\n",
      "[0.9729774]\n",
      "Mode: Test env_steps 200 total rewards -1810.4754300117493 total energy tensor([[22.2772]])\n",
      "[0.9105484]\n",
      "Mode: Test env_steps 200 total rewards -1826.2336926460266 total energy tensor([[18.2704]])\n",
      "[-0.14062412]\n",
      "Mode: Test env_steps 200 total rewards -1691.8469814062119 total energy tensor([[47.6886]])\n",
      "[-0.8822774]\n",
      "Mode: Test env_steps 200 total rewards -1837.9129753112793 total energy tensor([[16.0618]])\n",
      "[-0.19321239]\n",
      "Mode: Test env_steps 200 total rewards -1780.2209141254425 total energy tensor([[30.0410]])\n",
      "85000 -1744.0563324511052\n",
      "[0.77934194]\n",
      "Mode: Train env_steps 200 total rewards -1809.1256518363953 total energy tensor([[22.5624]])\n",
      "[-0.4191193]\n",
      "Mode: Train env_steps 200 total rewards -1745.7423808574677 total energy tensor([[39.8672]])\n",
      "[-0.57501984]\n",
      "Mode: Train env_steps 200 total rewards -1549.840607136488 total energy tensor([[60.8420]])\n",
      "[0.81045145]\n",
      "Mode: Train env_steps 200 total rewards -1765.522236585617 total energy tensor([[34.9236]])\n",
      "[-0.41248035]\n",
      "Mode: Train env_steps 200 total rewards -1821.9590797424316 total energy tensor([[18.6844]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2540975]\n",
      "Mode: Train env_steps 200 total rewards -1810.1604752540588 total energy tensor([[22.2070]])\n",
      "[-0.9825944]\n",
      "Mode: Train env_steps 200 total rewards -1728.4711116552353 total energy tensor([[37.5771]])\n",
      "[-0.62012595]\n",
      "Mode: Train env_steps 200 total rewards -1708.4532759785652 total energy tensor([[43.4270]])\n",
      "[-0.7655556]\n",
      "Mode: Train env_steps 200 total rewards -1746.359310388565 total energy tensor([[37.6577]])\n",
      "[-0.18546931]\n",
      "Mode: Train env_steps 200 total rewards -1785.630794286728 total energy tensor([[32.8019]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:20<00:00,  3.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24911535]\n",
      "Mode: Train env_steps 200 total rewards -1714.8095828592777 total energy tensor([[41.0706]])\n",
      "[0.797738]\n",
      "Mode: Train env_steps 200 total rewards -1724.2469860315323 total energy tensor([[40.1475]])\n",
      "[0.57785934]\n",
      "Mode: Train env_steps 200 total rewards -1759.7433741092682 total energy tensor([[35.4791]])\n",
      "[-0.8332052]\n",
      "Mode: Train env_steps 200 total rewards -1844.4675507545471 total energy tensor([[15.2092]])\n",
      "[-0.16676791]\n",
      "Mode: Train env_steps 200 total rewards -1811.1717309951782 total energy tensor([[15.9591]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3724618]\n",
      "Mode: Train env_steps 200 total rewards -1835.186396598816 total energy tensor([[18.2898]])\n",
      "[-0.2568727]\n",
      "Mode: Train env_steps 200 total rewards -1804.1433191299438 total energy tensor([[25.8736]])\n",
      "[0.49395502]\n",
      "Mode: Train env_steps 200 total rewards -1779.5623381137848 total energy tensor([[32.5770]])\n",
      "[-0.54221946]\n",
      "Mode: Train env_steps 200 total rewards -1463.2891600504518 total energy tensor([[67.6294]])\n",
      "[-0.33794776]\n",
      "Mode: Train env_steps 200 total rewards -1772.935112953186 total energy tensor([[34.1030]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3625019]\n",
      "Mode: Train env_steps 200 total rewards -1756.4538795948029 total energy tensor([[30.9909]])\n",
      "[-0.41328764]\n",
      "Mode: Train env_steps 200 total rewards -1733.2521172761917 total energy tensor([[42.0806]])\n",
      "[0.07806952]\n",
      "Mode: Train env_steps 200 total rewards -1829.150737285614 total energy tensor([[18.9958]])\n",
      "[0.6312852]\n",
      "Mode: Train env_steps 200 total rewards -1788.1283440589905 total energy tensor([[29.2582]])\n",
      "[-0.16485938]\n",
      "Mode: Train env_steps 200 total rewards -1505.731885438785 total energy tensor([[64.8135]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.65592253]\n",
      "Mode: Test env_steps 200 total rewards -1827.3924589157104 total energy tensor([[17.7141]])\n",
      "[0.42324963]\n",
      "Mode: Test env_steps 200 total rewards -1803.5102462768555 total energy tensor([[28.6026]])\n",
      "[0.55762386]\n",
      "Mode: Test env_steps 200 total rewards -1677.8762072771788 total energy tensor([[47.2052]])\n",
      "[0.991222]\n",
      "Mode: Test env_steps 200 total rewards -1685.6446435153484 total energy tensor([[46.2281]])\n",
      "[0.6724055]\n",
      "Mode: Test env_steps 200 total rewards -1713.905132472515 total energy tensor([[43.4053]])\n",
      "[0.42699125]\n",
      "Mode: Test env_steps 200 total rewards -1733.5506366491318 total energy tensor([[40.6996]])\n",
      "[-0.06298887]\n",
      "Mode: Test env_steps 200 total rewards -1171.3062611133792 total energy tensor([[84.1305]])\n",
      "[-0.154724]\n",
      "Mode: Test env_steps 200 total rewards -1829.53316116333 total energy tensor([[19.4960]])\n",
      "[0.14859906]\n",
      "Mode: Test env_steps 200 total rewards -1828.8713512420654 total energy tensor([[18.1881]])\n",
      "[0.88187563]\n",
      "Mode: Test env_steps 200 total rewards -1653.8394927680492 total energy tensor([[47.9354]])\n",
      "90000 -1692.5429591393563\n",
      "[0.11340039]\n",
      "Mode: Train env_steps 200 total rewards -1738.9741764068604 total energy tensor([[39.1586]])\n",
      "[0.42458406]\n",
      "Mode: Train env_steps 200 total rewards -1756.0484628677368 total energy tensor([[36.1280]])\n",
      "[-0.6828647]\n",
      "Mode: Train env_steps 200 total rewards -1711.6138414144516 total energy tensor([[43.1221]])\n",
      "[-0.86271334]\n",
      "Mode: Train env_steps 200 total rewards -1824.7642798423767 total energy tensor([[18.2812]])\n",
      "[0.26390705]\n",
      "Mode: Train env_steps 200 total rewards -1704.0663919448853 total energy tensor([[43.9568]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22853062]\n",
      "Mode: Train env_steps 200 total rewards -1733.1601066589355 total energy tensor([[46.6438]])\n",
      "[-0.814427]\n",
      "Mode: Train env_steps 200 total rewards -1685.50439620018 total energy tensor([[52.5736]])\n",
      "[-0.7419358]\n",
      "Mode: Train env_steps 200 total rewards -1757.2941036224365 total energy tensor([[38.5038]])\n",
      "[0.0844434]\n",
      "Mode: Train env_steps 200 total rewards -1670.7072085142136 total energy tensor([[56.8643]])\n",
      "[-0.5072264]\n",
      "Mode: Train env_steps 200 total rewards -1748.0427618026733 total energy tensor([[41.4052]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33869708]\n",
      "Mode: Train env_steps 200 total rewards -1646.8181272149086 total energy tensor([[56.0645]])\n",
      "[0.3351624]\n",
      "Mode: Train env_steps 200 total rewards -1724.5297718048096 total energy tensor([[44.9002]])\n",
      "[0.7272615]\n",
      "Mode: Train env_steps 200 total rewards -1648.8346183300018 total energy tensor([[55.5581]])\n",
      "[-0.08391078]\n",
      "Mode: Train env_steps 200 total rewards -1624.131315857172 total energy tensor([[57.6414]])\n",
      "[-0.76930815]\n",
      "Mode: Train env_steps 200 total rewards -1715.166806936264 total energy tensor([[47.0083]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:19<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55478764]\n",
      "Mode: Train env_steps 200 total rewards -1780.5020716190338 total energy tensor([[30.8358]])\n",
      "[-0.8522818]\n",
      "Mode: Train env_steps 200 total rewards -1534.7148980908096 total energy tensor([[60.1852]])\n",
      "[-0.9422296]\n",
      "Mode: Train env_steps 200 total rewards -1738.1247562170029 total energy tensor([[38.4962]])\n",
      "[-0.85186523]\n",
      "Mode: Train env_steps 200 total rewards -1818.5286784172058 total energy tensor([[21.9203]])\n",
      "[0.966208]\n",
      "Mode: Train env_steps 200 total rewards -1688.7103004455566 total energy tensor([[45.0937]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:25<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10208637]\n",
      "Mode: Train env_steps 200 total rewards -1748.2832248210907 total energy tensor([[37.7049]])\n",
      "[0.7843738]\n",
      "Mode: Train env_steps 200 total rewards -1762.9637837409973 total energy tensor([[34.8134]])\n",
      "[-0.52504075]\n",
      "Mode: Train env_steps 200 total rewards -1680.339630305767 total energy tensor([[48.9977]])\n",
      "[-0.6564112]\n",
      "Mode: Train env_steps 200 total rewards -1597.1865363270044 total energy tensor([[58.0606]])\n",
      "[0.49475327]\n",
      "Mode: Train env_steps 200 total rewards -1754.740569114685 total energy tensor([[37.3611]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5967267]\n",
      "Mode: Test env_steps 200 total rewards -1822.8320751190186 total energy tensor([[20.0507]])\n",
      "[-0.6613004]\n",
      "Mode: Test env_steps 200 total rewards -1739.575737953186 total energy tensor([[34.7337]])\n",
      "[0.47678965]\n",
      "Mode: Test env_steps 200 total rewards -1723.4320496320724 total energy tensor([[43.8435]])\n",
      "[-0.82724524]\n",
      "Mode: Test env_steps 200 total rewards -1715.2128505706787 total energy tensor([[42.2696]])\n",
      "[0.99359554]\n",
      "Mode: Test env_steps 200 total rewards -1265.9008924621157 total energy tensor([[75.8516]])\n",
      "[-0.3269448]\n",
      "Mode: Test env_steps 200 total rewards -1764.381620645523 total energy tensor([[33.9789]])\n",
      "[-0.5531381]\n",
      "Mode: Test env_steps 200 total rewards -1649.0779334306717 total energy tensor([[50.3646]])\n",
      "[-0.3795253]\n",
      "Mode: Test env_steps 200 total rewards -1803.4300909042358 total energy tensor([[28.1136]])\n",
      "[0.47528434]\n",
      "Mode: Test env_steps 200 total rewards -1646.055931583047 total energy tensor([[52.8307]])\n",
      "[-0.27023268]\n",
      "Mode: Test env_steps 200 total rewards -1529.691380083561 total energy tensor([[62.7730]])\n",
      "95000 -1665.959056238411\n",
      "[-0.18569745]\n",
      "Mode: Train env_steps 200 total rewards -1718.4677030444145 total energy tensor([[44.8467]])\n",
      "[-0.8431215]\n",
      "Mode: Train env_steps 200 total rewards -1328.220313784026 total energy tensor([[68.2251]])\n",
      "[-0.44440308]\n",
      "Mode: Train env_steps 200 total rewards -1729.1125926971436 total energy tensor([[39.9655]])\n",
      "[0.07074527]\n",
      "Mode: Train env_steps 200 total rewards -1795.787910938263 total energy tensor([[20.2786]])\n",
      "[0.23791079]\n",
      "Mode: Train env_steps 200 total rewards -1827.9682664871216 total energy tensor([[17.6786]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.17418839]\n",
      "Mode: Train env_steps 200 total rewards -1772.5677297115326 total energy tensor([[29.2274]])\n",
      "[-0.04456655]\n",
      "Mode: Train env_steps 200 total rewards -1724.5030403137207 total energy tensor([[40.9020]])\n",
      "[0.11658713]\n",
      "Mode: Train env_steps 200 total rewards -1800.5041584968567 total energy tensor([[22.1916]])\n",
      "[0.80069315]\n",
      "Mode: Train env_steps 200 total rewards -1754.7590464353561 total energy tensor([[36.4794]])\n",
      "[0.68512475]\n",
      "Mode: Train env_steps 200 total rewards -1805.995322227478 total energy tensor([[27.4283]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:24<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2512213]\n",
      "Mode: Train env_steps 200 total rewards -1773.6586439609528 total energy tensor([[29.2844]])\n",
      "[-0.8147292]\n",
      "Mode: Train env_steps 200 total rewards -1753.1610553264618 total energy tensor([[32.1979]])\n",
      "[-0.04193668]\n",
      "Mode: Train env_steps 200 total rewards -1748.8977526426315 total energy tensor([[34.2480]])\n",
      "[0.36729035]\n",
      "Mode: Train env_steps 200 total rewards -1730.236405134201 total energy tensor([[40.1653]])\n",
      "[-0.816975]\n",
      "Mode: Train env_steps 200 total rewards -1768.5368359088898 total energy tensor([[30.2763]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5666312]\n",
      "Mode: Train env_steps 200 total rewards -1717.6973313093185 total energy tensor([[40.0249]])\n",
      "[0.55737436]\n",
      "Mode: Train env_steps 200 total rewards -1623.0068090334535 total energy tensor([[53.4780]])\n",
      "[0.526092]\n",
      "Mode: Train env_steps 200 total rewards -1817.0762615203857 total energy tensor([[21.0487]])\n",
      "[0.72317344]\n",
      "Mode: Train env_steps 200 total rewards -1665.3251841068268 total energy tensor([[48.7435]])\n",
      "[-0.44452676]\n",
      "Mode: Train env_steps 200 total rewards -1576.2461121231318 total energy tensor([[58.2422]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8904129]\n",
      "Mode: Train env_steps 200 total rewards -1639.873489484191 total energy tensor([[51.0070]])\n",
      "[0.21776973]\n",
      "Mode: Train env_steps 200 total rewards -1752.748474597931 total energy tensor([[35.4260]])\n",
      "[-0.5951707]\n",
      "Mode: Train env_steps 200 total rewards -1578.086653277278 total energy tensor([[57.3794]])\n",
      "[0.20315586]\n",
      "Mode: Train env_steps 200 total rewards -1762.7294626235962 total energy tensor([[34.2275]])\n",
      "[0.8633404]\n",
      "Mode: Train env_steps 200 total rewards -1702.0108805894852 total energy tensor([[44.5400]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8013533]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Test env_steps 200 total rewards -1639.3457137048244 total energy tensor([[54.7633]])\n",
      "[-0.7472571]\n",
      "Mode: Test env_steps 200 total rewards -1754.2215857505798 total energy tensor([[36.8193]])\n",
      "[0.9345576]\n",
      "Mode: Test env_steps 200 total rewards -1729.9155983924866 total energy tensor([[43.7324]])\n",
      "[-0.15045764]\n",
      "Mode: Test env_steps 200 total rewards -1799.6356706619263 total energy tensor([[25.8931]])\n",
      "[0.03144328]\n",
      "Mode: Test env_steps 200 total rewards -1687.5405193567276 total energy tensor([[50.0860]])\n",
      "[0.6365138]\n",
      "Mode: Test env_steps 200 total rewards -1386.5323139671236 total energy tensor([[65.5420]])\n",
      "[-0.37892407]\n",
      "Mode: Test env_steps 200 total rewards -1545.4960767552257 total energy tensor([[62.1272]])\n",
      "[0.96879107]\n",
      "Mode: Test env_steps 200 total rewards -1788.5936040878296 total energy tensor([[26.2162]])\n",
      "[0.45028478]\n",
      "Mode: Test env_steps 200 total rewards -1783.3538565635681 total energy tensor([[29.2962]])\n",
      "[0.3012462]\n",
      "Mode: Test env_steps 200 total rewards -1779.502682209015 total energy tensor([[28.1208]])\n",
      "100000 -1689.4137621449306\n",
      "[0.7740916]\n",
      "Mode: Train env_steps 200 total rewards -1719.7829208374023 total energy tensor([[46.7133]])\n",
      "[0.09612996]\n",
      "Mode: Train env_steps 200 total rewards -1763.047738313675 total energy tensor([[34.8135]])\n",
      "[-0.22117567]\n",
      "Mode: Train env_steps 200 total rewards -1681.947967916727 total energy tensor([[50.9870]])\n",
      "[-0.12985897]\n",
      "Mode: Train env_steps 200 total rewards -1809.1828861236572 total energy tensor([[24.8316]])\n",
      "[-0.96180165]\n",
      "Mode: Train env_steps 200 total rewards -1793.6039867401123 total energy tensor([[25.2470]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92970395]\n",
      "Mode: Train env_steps 200 total rewards -1682.3509868383408 total energy tensor([[50.0959]])\n",
      "[-0.18914482]\n",
      "Mode: Train env_steps 200 total rewards -1788.8262491226196 total energy tensor([[28.2307]])\n",
      "[-0.08771414]\n",
      "Mode: Train env_steps 200 total rewards -1686.0874945521355 total energy tensor([[51.0755]])\n",
      "[0.35423812]\n",
      "Mode: Train env_steps 200 total rewards -1700.318474650383 total energy tensor([[46.1348]])\n",
      "[-0.07051066]\n",
      "Mode: Train env_steps 200 total rewards -1588.8438350372016 total energy tensor([[60.6362]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.95550215]\n",
      "Mode: Train env_steps 200 total rewards -1790.5416173934937 total energy tensor([[23.3402]])\n",
      "[-0.69064504]\n",
      "Mode: Train env_steps 200 total rewards -1709.4460886716843 total energy tensor([[41.8581]])\n",
      "[-0.7068776]\n",
      "Mode: Train env_steps 200 total rewards -1838.1335830688477 total energy tensor([[14.4113]])\n",
      "[-0.88224435]\n",
      "Mode: Train env_steps 200 total rewards -1456.0608207136393 total energy tensor([[66.9696]])\n",
      "[-0.69875425]\n",
      "Mode: Train env_steps 200 total rewards -1789.5285396575928 total energy tensor([[29.3691]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19590037]\n",
      "Mode: Train env_steps 200 total rewards -1794.6960434913635 total energy tensor([[26.6438]])\n",
      "[-0.36526656]\n",
      "Mode: Train env_steps 200 total rewards -1752.255749464035 total energy tensor([[33.0277]])\n",
      "[-0.74797267]\n",
      "Mode: Train env_steps 200 total rewards -1797.6227631568909 total energy tensor([[24.5670]])\n",
      "[0.18319407]\n",
      "Mode: Train env_steps 200 total rewards -1608.544158026576 total energy tensor([[52.8891]])\n",
      "[-0.13320969]\n",
      "Mode: Train env_steps 200 total rewards -1832.2161169052124 total energy tensor([[17.4105]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8826886]\n",
      "Mode: Train env_steps 200 total rewards -1709.4967836141586 total energy tensor([[42.1476]])\n",
      "[-0.77292424]\n",
      "Mode: Train env_steps 200 total rewards -1785.1455578804016 total energy tensor([[26.4735]])\n",
      "[-0.7895929]\n",
      "Mode: Train env_steps 200 total rewards -1802.3650369644165 total energy tensor([[23.6936]])\n",
      "[0.3614384]\n",
      "Mode: Train env_steps 200 total rewards -1699.1761414408684 total energy tensor([[44.7066]])\n",
      "[0.08241381]\n",
      "Mode: Train env_steps 200 total rewards -1747.7444792985916 total energy tensor([[35.4576]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.96793807]\n",
      "Mode: Test env_steps 200 total rewards -1817.0635361671448 total energy tensor([[13.8612]])\n",
      "[-0.8669307]\n",
      "Mode: Test env_steps 200 total rewards -1848.754032611847 total energy tensor([[13.8616]])\n",
      "[-0.7414994]\n",
      "Mode: Test env_steps 200 total rewards -1812.712773323059 total energy tensor([[19.3555]])\n",
      "[-0.00940485]\n",
      "Mode: Test env_steps 200 total rewards -1219.0748955165036 total energy tensor([[68.1219]])\n",
      "[-0.5937409]\n",
      "Mode: Test env_steps 200 total rewards -1708.328679382801 total energy tensor([[37.5197]])\n",
      "[0.44189283]\n",
      "Mode: Test env_steps 200 total rewards -1348.8880107793957 total energy tensor([[64.4219]])\n",
      "[-0.87503856]\n",
      "Mode: Test env_steps 200 total rewards -1824.3496265411377 total energy tensor([[15.5673]])\n",
      "[0.775516]\n",
      "Mode: Test env_steps 200 total rewards -1858.096604347229 total energy tensor([[11.9703]])\n",
      "[-0.8976769]\n",
      "Mode: Test env_steps 200 total rewards -1799.3777327537537 total energy tensor([[18.5185]])\n",
      "[0.5967054]\n",
      "Mode: Test env_steps 200 total rewards -1749.1749192476273 total energy tensor([[34.9712]])\n",
      "105000 -1698.5820810670498\n",
      "[-0.85754263]\n",
      "Mode: Train env_steps 200 total rewards -1825.196406364441 total energy tensor([[16.0672]])\n",
      "[-0.5715741]\n",
      "Mode: Train env_steps 200 total rewards -1792.9992673397064 total energy tensor([[23.0159]])\n",
      "[0.8883588]\n",
      "Mode: Train env_steps 200 total rewards -1844.726887702942 total energy tensor([[14.6801]])\n",
      "[-0.20526144]\n",
      "Mode: Train env_steps 200 total rewards -1722.1609793305397 total energy tensor([[35.9016]])\n",
      "[-0.97303104]\n",
      "Mode: Train env_steps 200 total rewards -1479.239279633388 total energy tensor([[61.2449]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54634875]\n",
      "Mode: Train env_steps 200 total rewards -1787.3406465053558 total energy tensor([[25.8547]])\n",
      "[-0.23203427]\n",
      "Mode: Train env_steps 200 total rewards -1781.9628641605377 total energy tensor([[29.7191]])\n",
      "[-0.94983053]\n",
      "Mode: Train env_steps 200 total rewards -1792.603238582611 total energy tensor([[27.2191]])\n",
      "[-0.6101728]\n",
      "Mode: Train env_steps 200 total rewards -1761.2023079395294 total energy tensor([[33.5628]])\n",
      "[0.29916075]\n",
      "Mode: Train env_steps 200 total rewards -1781.7621307373047 total energy tensor([[29.7498]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40093237]\n",
      "Mode: Train env_steps 200 total rewards -1848.5109729766846 total energy tensor([[13.8630]])\n",
      "[0.9548393]\n",
      "Mode: Train env_steps 200 total rewards -1761.8305106163025 total energy tensor([[29.1351]])\n",
      "[0.08207173]\n",
      "Mode: Train env_steps 200 total rewards -1787.633204460144 total energy tensor([[24.5917]])\n",
      "[0.6196755]\n",
      "Mode: Train env_steps 200 total rewards -1638.6325135231018 total energy tensor([[45.7523]])\n",
      "[0.59757316]\n",
      "Mode: Train env_steps 200 total rewards -1760.780484676361 total energy tensor([[34.2996]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8891008]\n",
      "Mode: Train env_steps 200 total rewards -1691.1801826655865 total energy tensor([[45.1932]])\n",
      "[0.85832024]\n",
      "Mode: Train env_steps 200 total rewards -1774.873902797699 total energy tensor([[27.0482]])\n",
      "[0.18072633]\n",
      "Mode: Train env_steps 200 total rewards -1802.2178673744202 total energy tensor([[21.7032]])\n",
      "[0.7462045]\n",
      "Mode: Train env_steps 200 total rewards -1624.7482356727123 total energy tensor([[51.0289]])\n",
      "[-0.8365541]\n",
      "Mode: Train env_steps 200 total rewards -1698.0575159788132 total energy tensor([[40.4965]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8306896]\n",
      "Mode: Train env_steps 200 total rewards -1765.2486834526062 total energy tensor([[28.9767]])\n",
      "[-0.0549842]\n",
      "Mode: Train env_steps 200 total rewards -1653.309327289462 total energy tensor([[51.8730]])\n",
      "[-0.6575535]\n",
      "Mode: Train env_steps 200 total rewards -1736.6800782680511 total energy tensor([[37.3468]])\n",
      "[0.23811722]\n",
      "Mode: Train env_steps 200 total rewards -1316.5032744202763 total energy tensor([[62.9194]])\n",
      "[0.15746018]\n",
      "Mode: Train env_steps 200 total rewards -1732.138420343399 total energy tensor([[40.7051]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8506908]\n",
      "Mode: Test env_steps 200 total rewards -1844.1699867248535 total energy tensor([[12.6726]])\n",
      "[0.50378996]\n",
      "Mode: Test env_steps 200 total rewards -1716.2346227765083 total energy tensor([[35.9020]])\n",
      "[-0.5333714]\n",
      "Mode: Test env_steps 200 total rewards -1686.0091161429882 total energy tensor([[40.4845]])\n",
      "[0.65723765]\n",
      "Mode: Test env_steps 200 total rewards -1806.3757271766663 total energy tensor([[20.4279]])\n",
      "[0.6340364]\n",
      "Mode: Test env_steps 200 total rewards -1798.4280092716217 total energy tensor([[25.9715]])\n",
      "[-0.5096617]\n",
      "Mode: Test env_steps 200 total rewards -1830.9017009735107 total energy tensor([[15.0905]])\n",
      "[-0.02467621]\n",
      "Mode: Test env_steps 200 total rewards -1737.0529745817184 total energy tensor([[32.3490]])\n",
      "[-0.4347897]\n",
      "Mode: Test env_steps 200 total rewards -1779.2523086071014 total energy tensor([[29.8687]])\n",
      "[-0.8183092]\n",
      "Mode: Test env_steps 200 total rewards -1626.2428653389215 total energy tensor([[45.4600]])\n",
      "[0.7121384]\n",
      "Mode: Test env_steps 200 total rewards -1876.789451599121 total energy tensor([[9.2211]])\n",
      "110000 -1770.1456763193012\n",
      "[0.50484854]\n",
      "Mode: Train env_steps 200 total rewards -1613.2371151447296 total energy tensor([[47.1075]])\n",
      "[0.46310452]\n",
      "Mode: Train env_steps 200 total rewards -1775.255884885788 total energy tensor([[25.8624]])\n",
      "[0.81266195]\n",
      "Mode: Train env_steps 200 total rewards -1699.6131692826748 total energy tensor([[37.6825]])\n",
      "[-0.89295757]\n",
      "Mode: Train env_steps 200 total rewards -1670.7690910696983 total energy tensor([[40.3553]])\n",
      "[0.45242405]\n",
      "Mode: Train env_steps 200 total rewards -1830.7113218307495 total energy tensor([[11.6540]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6624638]\n",
      "Mode: Train env_steps 200 total rewards -1812.05819272995 total energy tensor([[18.1641]])\n",
      "[-0.83505934]\n",
      "Mode: Train env_steps 200 total rewards -1695.5418498516083 total energy tensor([[37.4571]])\n",
      "[-0.47586632]\n",
      "Mode: Train env_steps 200 total rewards -1817.8703351020813 total energy tensor([[21.8036]])\n",
      "[-0.65947545]\n",
      "Mode: Train env_steps 200 total rewards -1770.7471297979355 total energy tensor([[28.6540]])\n",
      "[-0.550522]\n",
      "Mode: Train env_steps 200 total rewards -1745.9406150579453 total energy tensor([[32.1834]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.15276068]\n",
      "Mode: Train env_steps 200 total rewards -1547.9534931480885 total energy tensor([[51.5662]])\n",
      "[-0.00185193]\n",
      "Mode: Train env_steps 200 total rewards -1704.107511460781 total energy tensor([[42.0798]])\n",
      "[0.24629259]\n",
      "Mode: Train env_steps 200 total rewards -1803.5834407806396 total energy tensor([[21.9228]])\n",
      "[0.26266804]\n",
      "Mode: Train env_steps 200 total rewards -1816.1877784729004 total energy tensor([[17.2300]])\n",
      "[0.16092475]\n",
      "Mode: Train env_steps 200 total rewards -1357.0453797425143 total energy tensor([[67.3939]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5618587]\n",
      "Mode: Train env_steps 200 total rewards -1602.6847048774362 total energy tensor([[49.5709]])\n",
      "[0.02006542]\n",
      "Mode: Train env_steps 200 total rewards -1792.9986925125122 total energy tensor([[23.1962]])\n",
      "[0.70705545]\n",
      "Mode: Train env_steps 200 total rewards -1638.4456141591072 total energy tensor([[42.9317]])\n",
      "[-0.691989]\n",
      "Mode: Train env_steps 200 total rewards -1840.0103883743286 total energy tensor([[13.9524]])\n",
      "[0.7907352]\n",
      "Mode: Train env_steps 200 total rewards -1181.385132001713 total energy tensor([[82.9941]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9228619]\n",
      "Mode: Train env_steps 200 total rewards -1778.2962293624878 total energy tensor([[23.6398]])\n",
      "[0.22708343]\n",
      "Mode: Train env_steps 200 total rewards -1782.761779308319 total energy tensor([[26.3540]])\n",
      "[-0.02524368]\n",
      "Mode: Train env_steps 200 total rewards -1764.3558990955353 total energy tensor([[32.9712]])\n",
      "[-0.57755506]\n",
      "Mode: Train env_steps 200 total rewards -1507.9277501553297 total energy tensor([[56.9979]])\n",
      "[0.08502112]\n",
      "Mode: Train env_steps 200 total rewards -1764.135052204132 total energy tensor([[29.1615]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6911072]\n",
      "Mode: Test env_steps 200 total rewards -1792.4209942817688 total energy tensor([[22.9968]])\n",
      "[0.23467395]\n",
      "Mode: Test env_steps 200 total rewards -1786.3797526359558 total energy tensor([[22.2269]])\n",
      "[0.5191868]\n",
      "Mode: Test env_steps 200 total rewards -1761.3270626068115 total energy tensor([[22.7744]])\n",
      "[0.40541485]\n",
      "Mode: Test env_steps 200 total rewards -1287.9157851764467 total energy tensor([[68.7794]])\n",
      "[0.23037101]\n",
      "Mode: Test env_steps 200 total rewards -1758.5550162792206 total energy tensor([[33.7138]])\n",
      "[-0.93646955]\n",
      "Mode: Test env_steps 200 total rewards -1489.1692395061255 total energy tensor([[57.6864]])\n",
      "[0.48807725]\n",
      "Mode: Test env_steps 200 total rewards -1809.949818611145 total energy tensor([[19.6681]])\n",
      "[0.8036011]\n",
      "Mode: Test env_steps 200 total rewards -1761.4471669197083 total energy tensor([[24.1022]])\n",
      "[0.83150715]\n",
      "Mode: Test env_steps 200 total rewards -1628.761430427432 total energy tensor([[48.9796]])\n",
      "[-0.76064396]\n",
      "Mode: Test env_steps 200 total rewards -1625.0985709130764 total energy tensor([[44.8024]])\n",
      "115000 -1670.102483735769\n",
      "[-0.10336436]\n",
      "Mode: Train env_steps 200 total rewards -1699.8496224284172 total energy tensor([[41.9833]])\n",
      "[0.7910002]\n",
      "Mode: Train env_steps 200 total rewards -1827.5794734954834 total energy tensor([[17.9977]])\n",
      "[-0.51537496]\n",
      "Mode: Train env_steps 200 total rewards -1661.980674982071 total energy tensor([[39.9977]])\n",
      "[-0.46711665]\n",
      "Mode: Train env_steps 200 total rewards -1772.2214426994324 total energy tensor([[26.1861]])\n",
      "[0.05720608]\n",
      "Mode: Train env_steps 200 total rewards -1756.9690465927124 total energy tensor([[33.9699]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.787647]\n",
      "Mode: Train env_steps 200 total rewards -1258.3671228438616 total energy tensor([[75.2282]])\n",
      "[0.34014592]\n",
      "Mode: Train env_steps 200 total rewards -1753.6789898872375 total energy tensor([[25.0545]])\n",
      "[0.570834]\n",
      "Mode: Train env_steps 200 total rewards -1686.6740573048592 total energy tensor([[45.4550]])\n",
      "[-0.11432929]\n",
      "Mode: Train env_steps 200 total rewards -1611.27319945395 total energy tensor([[53.2989]])\n",
      "[0.989263]\n",
      "Mode: Train env_steps 200 total rewards -1815.7418184280396 total energy tensor([[21.0105]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9519092]\n",
      "Mode: Train env_steps 200 total rewards -1746.6325924396515 total energy tensor([[28.0486]])\n",
      "[-0.6178342]\n",
      "Mode: Train env_steps 200 total rewards -1808.282172203064 total energy tensor([[16.3907]])\n",
      "[0.6256006]\n",
      "Mode: Train env_steps 200 total rewards -1609.2587093561888 total energy tensor([[45.7832]])\n",
      "[-0.6160037]\n",
      "Mode: Train env_steps 200 total rewards -1806.40314245224 total energy tensor([[16.4706]])\n",
      "[-0.68794954]\n",
      "Mode: Train env_steps 200 total rewards -1761.1505851745605 total energy tensor([[22.7883]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.048918]\n",
      "Mode: Train env_steps 200 total rewards -1448.8981181755662 total energy tensor([[61.6089]])\n",
      "[0.6547137]\n",
      "Mode: Train env_steps 200 total rewards -1724.0574061870575 total energy tensor([[34.3500]])\n",
      "[0.8632988]\n",
      "Mode: Train env_steps 200 total rewards -1628.0335163474083 total energy tensor([[45.4527]])\n",
      "[-0.9872335]\n",
      "Mode: Train env_steps 200 total rewards -1678.8475997447968 total energy tensor([[39.3156]])\n",
      "[-0.6155019]\n",
      "Mode: Train env_steps 200 total rewards -1655.212539434433 total energy tensor([[42.2708]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9719636]\n",
      "Mode: Train env_steps 200 total rewards -1812.3758687973022 total energy tensor([[13.6350]])\n",
      "[-0.02642805]\n",
      "Mode: Train env_steps 200 total rewards -1711.656167626381 total energy tensor([[34.0887]])\n",
      "[-0.825638]\n",
      "Mode: Train env_steps 200 total rewards -1817.459110736847 total energy tensor([[15.8679]])\n",
      "[-0.1794492]\n",
      "Mode: Train env_steps 200 total rewards -1698.9151442050934 total energy tensor([[37.8787]])\n",
      "[-0.8544256]\n",
      "Mode: Train env_steps 200 total rewards -1669.63554880023 total energy tensor([[42.5395]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90791506]\n",
      "Mode: Test env_steps 200 total rewards -1377.749898057431 total energy tensor([[65.9938]])\n",
      "[-0.26256076]\n",
      "Mode: Test env_steps 200 total rewards -1259.8652827958576 total energy tensor([[60.1921]])\n",
      "[-0.95311403]\n",
      "Mode: Test env_steps 200 total rewards -1670.4097938537598 total energy tensor([[35.2540]])\n",
      "[0.75191987]\n",
      "Mode: Test env_steps 200 total rewards -1782.0035800933838 total energy tensor([[20.0273]])\n",
      "[-0.14802694]\n",
      "Mode: Test env_steps 200 total rewards -1765.1540293693542 total energy tensor([[20.4049]])\n",
      "[0.48117882]\n",
      "Mode: Test env_steps 200 total rewards -1601.7676555514336 total energy tensor([[46.4250]])\n",
      "[-0.6894884]\n",
      "Mode: Test env_steps 200 total rewards -1733.5956227779388 total energy tensor([[27.8331]])\n",
      "[0.680199]\n",
      "Mode: Test env_steps 200 total rewards -1576.394552335143 total energy tensor([[50.3616]])\n",
      "[-0.6471877]\n",
      "Mode: Test env_steps 200 total rewards -1697.7939143180847 total energy tensor([[33.2145]])\n",
      "[-0.7888604]\n",
      "Mode: Test env_steps 200 total rewards -1756.8971848487854 total energy tensor([[20.3299]])\n",
      "120000 -1622.1631514001172\n",
      "[0.25343868]\n",
      "Mode: Train env_steps 200 total rewards -1577.3448637127876 total energy tensor([[47.7754]])\n",
      "[0.3742256]\n",
      "Mode: Train env_steps 200 total rewards -1608.9452716112137 total energy tensor([[44.6762]])\n",
      "[0.15140662]\n",
      "Mode: Train env_steps 200 total rewards -1556.2584135234356 total energy tensor([[52.8272]])\n",
      "[0.77648383]\n",
      "Mode: Train env_steps 200 total rewards -1828.6220655441284 total energy tensor([[18.0613]])\n",
      "[-0.7182472]\n",
      "Mode: Train env_steps 200 total rewards -1722.6419129371643 total energy tensor([[25.6794]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22304258]\n",
      "Mode: Train env_steps 200 total rewards -1704.7918846607208 total energy tensor([[40.9237]])\n",
      "[0.5597459]\n",
      "Mode: Train env_steps 200 total rewards -1583.8460073769093 total energy tensor([[55.7143]])\n",
      "[-0.16289428]\n",
      "Mode: Train env_steps 200 total rewards -1633.8248665332794 total energy tensor([[43.3069]])\n",
      "[-0.10899362]\n",
      "Mode: Train env_steps 200 total rewards -1301.79703242518 total energy tensor([[73.7100]])\n",
      "[-0.9158333]\n",
      "Mode: Train env_steps 200 total rewards -1621.405589222908 total energy tensor([[47.2246]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77868754]\n",
      "Mode: Train env_steps 200 total rewards -1339.1913603628054 total energy tensor([[70.8641]])\n",
      "[-0.4383498]\n",
      "Mode: Train env_steps 200 total rewards -1605.2609649896622 total energy tensor([[45.6488]])\n",
      "[-0.41177917]\n",
      "Mode: Train env_steps 200 total rewards -1782.6826729774475 total energy tensor([[17.5811]])\n",
      "[0.20626503]\n",
      "Mode: Train env_steps 200 total rewards -1734.1036503314972 total energy tensor([[29.3164]])\n",
      "[0.11131134]\n",
      "Mode: Train env_steps 200 total rewards -1614.8965292572975 total energy tensor([[44.6158]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7676539]\n",
      "Mode: Train env_steps 200 total rewards -1748.8240427970886 total energy tensor([[22.3457]])\n",
      "[0.07441244]\n",
      "Mode: Train env_steps 200 total rewards -1606.2815150022507 total energy tensor([[42.1387]])\n",
      "[-0.3936406]\n",
      "Mode: Train env_steps 200 total rewards -1802.6320629119873 total energy tensor([[12.2335]])\n",
      "[-0.5794075]\n",
      "Mode: Train env_steps 200 total rewards -1794.9343967437744 total energy tensor([[13.3953]])\n",
      "[0.21522427]\n",
      "Mode: Train env_steps 200 total rewards -1726.876781463623 total energy tensor([[19.7666]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05287893]\n",
      "Mode: Train env_steps 200 total rewards -1097.4761343114078 total energy tensor([[94.5440]])\n",
      "[0.9532672]\n",
      "Mode: Train env_steps 200 total rewards -1762.0324001312256 total energy tensor([[20.3876]])\n",
      "[-0.62981975]\n",
      "Mode: Train env_steps 200 total rewards -1802.366819858551 total energy tensor([[16.7445]])\n",
      "[0.9369734]\n",
      "Mode: Train env_steps 200 total rewards -1223.3340976200998 total energy tensor([[85.3004]])\n",
      "[-0.07921962]\n",
      "Mode: Train env_steps 200 total rewards -1602.9792246818542 total energy tensor([[42.8374]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69882447]\n",
      "Mode: Test env_steps 200 total rewards -1572.2110694646835 total energy tensor([[40.8663]])\n",
      "[0.6203088]\n",
      "Mode: Test env_steps 200 total rewards -1809.1042909622192 total energy tensor([[17.7274]])\n",
      "[-0.8305478]\n",
      "Mode: Test env_steps 200 total rewards -1768.4454157352448 total energy tensor([[17.4841]])\n",
      "[0.35778058]\n",
      "Mode: Test env_steps 200 total rewards -1278.4658372323029 total energy tensor([[70.3317]])\n",
      "[0.30530515]\n",
      "Mode: Test env_steps 200 total rewards -1840.5736856460571 total energy tensor([[10.5543]])\n",
      "[-0.99962085]\n",
      "Mode: Test env_steps 200 total rewards -1841.795000553131 total energy tensor([[11.2727]])\n",
      "[0.9571655]\n",
      "Mode: Test env_steps 200 total rewards -1741.8985419273376 total energy tensor([[19.1743]])\n",
      "[0.9179416]\n",
      "Mode: Test env_steps 200 total rewards -1877.4209308624268 total energy tensor([[8.5332]])\n",
      "[-0.2855872]\n",
      "Mode: Test env_steps 200 total rewards -1769.8260579109192 total energy tensor([[24.0570]])\n",
      "[0.47232655]\n",
      "Mode: Test env_steps 200 total rewards -1651.7343572378159 total energy tensor([[34.5107]])\n",
      "125000 -1715.1475187532137\n",
      "[0.70004404]\n",
      "Mode: Train env_steps 200 total rewards -1819.8407764434814 total energy tensor([[16.3456]])\n",
      "[0.7095134]\n",
      "Mode: Train env_steps 200 total rewards -1766.4797954559326 total energy tensor([[24.0075]])\n",
      "[0.3676753]\n",
      "Mode: Train env_steps 200 total rewards -1790.1679425239563 total energy tensor([[15.4244]])\n",
      "[-0.08861812]\n",
      "Mode: Train env_steps 200 total rewards -1599.6485061645508 total energy tensor([[45.2917]])\n",
      "[-0.89061713]\n",
      "Mode: Train env_steps 200 total rewards -1679.1213337182999 total energy tensor([[35.8681]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9147702]\n",
      "Mode: Train env_steps 200 total rewards -1149.7110908478498 total energy tensor([[82.9115]])\n",
      "[0.19684036]\n",
      "Mode: Train env_steps 200 total rewards -1793.1397275924683 total energy tensor([[15.3659]])\n",
      "[0.14666964]\n",
      "Mode: Train env_steps 200 total rewards -1533.9933573007584 total energy tensor([[42.5741]])\n",
      "[-0.73497576]\n",
      "Mode: Train env_steps 200 total rewards -1774.8164567947388 total energy tensor([[18.3259]])\n",
      "[-0.93663406]\n",
      "Mode: Train env_steps 200 total rewards -1703.7949032783508 total energy tensor([[22.4786]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.655429]\n",
      "Mode: Train env_steps 200 total rewards -1482.7900263220072 total energy tensor([[49.6703]])\n",
      "[-0.80616033]\n",
      "Mode: Train env_steps 200 total rewards -1439.0981141328812 total energy tensor([[47.9274]])\n",
      "[0.11522982]\n",
      "Mode: Train env_steps 200 total rewards -1799.486617565155 total energy tensor([[16.8666]])\n",
      "[0.3019798]\n",
      "Mode: Train env_steps 200 total rewards -1725.6287999153137 total energy tensor([[20.6272]])\n",
      "[-0.78991956]\n",
      "Mode: Train env_steps 200 total rewards -1764.7411270141602 total energy tensor([[20.5799]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2650282]\n",
      "Mode: Train env_steps 200 total rewards -1286.3921358585358 total energy tensor([[63.6123]])\n",
      "[0.6889344]\n",
      "Mode: Train env_steps 200 total rewards -1067.7858864068985 total energy tensor([[84.3306]])\n",
      "[-0.721267]\n",
      "Mode: Train env_steps 200 total rewards -1210.6685320734978 total energy tensor([[77.4572]])\n",
      "[0.52225804]\n",
      "Mode: Train env_steps 200 total rewards -1747.2686066627502 total energy tensor([[14.9956]])\n",
      "[0.11919494]\n",
      "Mode: Train env_steps 200 total rewards -1690.6379961967468 total energy tensor([[17.4541]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6299318]\n",
      "Mode: Train env_steps 200 total rewards -1803.8913679122925 total energy tensor([[12.3310]])\n",
      "[0.6853102]\n",
      "Mode: Train env_steps 200 total rewards -737.8803463261575 total energy tensor([[111.5643]])\n",
      "[-0.74115187]\n",
      "Mode: Train env_steps 200 total rewards -1023.8359575420618 total energy tensor([[93.1269]])\n",
      "[-0.5423002]\n",
      "Mode: Train env_steps 200 total rewards -1779.9857921600342 total energy tensor([[13.9070]])\n",
      "[-0.8632649]\n",
      "Mode: Train env_steps 200 total rewards -885.3938456326723 total energy tensor([[105.3580]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.19871892]\n",
      "Mode: Test env_steps 200 total rewards -1138.095772266388 total energy tensor([[87.3821]])\n",
      "[-0.59962696]\n",
      "Mode: Test env_steps 200 total rewards -1142.612743139267 total energy tensor([[92.1408]])\n",
      "[-0.526484]\n",
      "Mode: Test env_steps 200 total rewards -1568.9024538993835 total energy tensor([[15.0399]])\n",
      "[0.8757635]\n",
      "Mode: Test env_steps 200 total rewards -1129.2272646427155 total energy tensor([[89.4982]])\n",
      "[0.7635775]\n",
      "Mode: Test env_steps 200 total rewards -1414.5167248249054 total energy tensor([[43.6133]])\n",
      "[0.68788606]\n",
      "Mode: Test env_steps 200 total rewards -1184.5986477136612 total energy tensor([[85.5640]])\n",
      "[0.99289596]\n",
      "Mode: Test env_steps 200 total rewards -1114.9982434511185 total energy tensor([[97.0976]])\n",
      "[0.58927304]\n",
      "Mode: Test env_steps 200 total rewards -1562.1332478523254 total energy tensor([[16.8115]])\n",
      "[-0.4744659]\n",
      "Mode: Test env_steps 200 total rewards -1025.576138228178 total energy tensor([[105.9750]])\n",
      "[0.14538898]\n",
      "Mode: Test env_steps 200 total rewards -1128.7547290325165 total energy tensor([[97.3630]])\n",
      "130000 -1240.941596505046\n",
      "[0.04533854]\n",
      "Mode: Train env_steps 200 total rewards -1127.1803271770477 total energy tensor([[90.5574]])\n",
      "[-0.48591885]\n",
      "Mode: Train env_steps 200 total rewards -1573.9291968345642 total energy tensor([[15.1537]])\n",
      "[0.12605315]\n",
      "Mode: Train env_steps 200 total rewards -863.5084486678243 total energy tensor([[116.6554]])\n",
      "[-0.3672223]\n",
      "Mode: Train env_steps 200 total rewards -1033.4765605852008 total energy tensor([[102.9700]])\n",
      "[0.21992818]\n",
      "Mode: Train env_steps 200 total rewards -1544.1681623458862 total energy tensor([[18.7541]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5111337]\n",
      "Mode: Train env_steps 200 total rewards -1005.1734428405762 total energy tensor([[93.8644]])\n",
      "[0.13340339]\n",
      "Mode: Train env_steps 200 total rewards -1562.9152455329895 total energy tensor([[16.2860]])\n",
      "[-0.79274786]\n",
      "Mode: Train env_steps 200 total rewards -896.5652039386332 total energy tensor([[103.0105]])\n",
      "[-0.80872726]\n",
      "Mode: Train env_steps 200 total rewards -1017.6840016841888 total energy tensor([[94.3008]])\n",
      "[0.8081801]\n",
      "Mode: Train env_steps 200 total rewards -1011.961884200573 total energy tensor([[97.0517]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36530212]\n",
      "Mode: Train env_steps 200 total rewards -1014.0664935112 total energy tensor([[96.9304]])\n",
      "[0.6719557]\n",
      "Mode: Train env_steps 200 total rewards -1007.0622470974922 total energy tensor([[105.6058]])\n",
      "[-0.13792904]\n",
      "Mode: Train env_steps 200 total rewards -891.3126409947872 total energy tensor([[108.1844]])\n",
      "[-0.7813588]\n",
      "Mode: Train env_steps 200 total rewards -1315.0516595244408 total energy tensor([[62.2620]])\n",
      "[-0.2764311]\n",
      "Mode: Train env_steps 200 total rewards -1009.4689347743988 total energy tensor([[96.5280]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1572955]\n",
      "Mode: Train env_steps 200 total rewards -1013.0520235598087 total energy tensor([[102.5241]])\n",
      "[-0.43057197]\n",
      "Mode: Train env_steps 200 total rewards -1025.0723430514336 total energy tensor([[103.3611]])\n",
      "[0.3854377]\n",
      "Mode: Train env_steps 200 total rewards -1298.8195444345474 total energy tensor([[59.2799]])\n",
      "[0.70202655]\n",
      "Mode: Train env_steps 200 total rewards -1051.074892103672 total energy tensor([[97.8961]])\n",
      "[-0.83375394]\n",
      "Mode: Train env_steps 200 total rewards -1022.3574624657631 total energy tensor([[106.2606]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5549596]\n",
      "Mode: Train env_steps 200 total rewards -997.8615802526474 total energy tensor([[98.7546]])\n",
      "[-0.8935285]\n",
      "Mode: Train env_steps 200 total rewards -1002.1687493920326 total energy tensor([[97.5151]])\n",
      "[-0.20605592]\n",
      "Mode: Train env_steps 200 total rewards -1005.8916311860085 total energy tensor([[96.6056]])\n",
      "[0.3047177]\n",
      "Mode: Train env_steps 200 total rewards -998.9125073552132 total energy tensor([[92.3204]])\n",
      "[-0.12084033]\n",
      "Mode: Train env_steps 200 total rewards -1004.0272731781006 total energy tensor([[98.7968]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18319093]\n",
      "Mode: Test env_steps 200 total rewards -867.714071854949 total energy tensor([[91.2522]])\n",
      "[-0.7064675]\n",
      "Mode: Test env_steps 200 total rewards -1451.1131681203842 total energy tensor([[44.3757]])\n",
      "[-0.05363831]\n",
      "Mode: Test env_steps 200 total rewards -626.9070174209774 total energy tensor([[77.4125]])\n",
      "[0.445405]\n",
      "Mode: Test env_steps 200 total rewards -628.4923278298229 total energy tensor([[95.0789]])\n",
      "[-0.93017447]\n",
      "Mode: Test env_steps 200 total rewards -765.4024569001049 total energy tensor([[73.1431]])\n",
      "[-0.45646086]\n",
      "Mode: Test env_steps 200 total rewards -752.6504028830677 total energy tensor([[76.3734]])\n",
      "[0.3629091]\n",
      "Mode: Test env_steps 200 total rewards -668.1299307662994 total energy tensor([[89.1379]])\n",
      "[-0.5838081]\n",
      "Mode: Test env_steps 200 total rewards -753.5977467522025 total energy tensor([[100.9510]])\n",
      "[-0.2306942]\n",
      "Mode: Test env_steps 200 total rewards -753.8726886771619 total energy tensor([[101.2616]])\n",
      "[-0.31604835]\n",
      "Mode: Test env_steps 200 total rewards -640.6586662521586 total energy tensor([[109.4717]])\n",
      "135000 -790.8538477457129\n",
      "[0.08039527]\n",
      "Mode: Train env_steps 200 total rewards -963.1136866211891 total energy tensor([[82.6277]])\n",
      "[-0.03831029]\n",
      "Mode: Train env_steps 200 total rewards -791.1473821029067 total energy tensor([[107.8779]])\n",
      "[0.90529555]\n",
      "Mode: Train env_steps 200 total rewards -727.6328314188868 total energy tensor([[78.1217]])\n",
      "[0.72009975]\n",
      "Mode: Train env_steps 200 total rewards -869.3433410152793 total energy tensor([[103.3935]])\n",
      "[-0.4749718]\n",
      "Mode: Train env_steps 200 total rewards -872.609110545367 total energy tensor([[95.3248]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86175746]\n",
      "Mode: Train env_steps 200 total rewards -1053.853982977569 total energy tensor([[65.7039]])\n",
      "[0.37848157]\n",
      "Mode: Train env_steps 200 total rewards -1060.9972404837608 total energy tensor([[93.5230]])\n",
      "[0.62182564]\n",
      "Mode: Train env_steps 200 total rewards -910.0351114273071 total energy tensor([[124.3008]])\n",
      "[0.44142148]\n",
      "Mode: Train env_steps 200 total rewards -845.3809044286609 total energy tensor([[103.2878]])\n",
      "[0.12190245]\n",
      "Mode: Train env_steps 200 total rewards -1054.0757637023926 total energy tensor([[100.9177]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.78117526]\n",
      "Mode: Train env_steps 200 total rewards -898.3934733569622 total energy tensor([[116.4186]])\n",
      "[0.23959582]\n",
      "Mode: Train env_steps 200 total rewards -882.219470500946 total energy tensor([[100.2158]])\n",
      "[-0.493714]\n",
      "Mode: Train env_steps 200 total rewards -1124.926794975996 total energy tensor([[84.3936]])\n",
      "[-0.41498256]\n",
      "Mode: Train env_steps 200 total rewards -774.2208632947877 total energy tensor([[110.8834]])\n",
      "[0.43395105]\n",
      "Mode: Train env_steps 200 total rewards -873.2462344840169 total energy tensor([[104.8510]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00381316]\n",
      "Mode: Train env_steps 200 total rewards -648.4867271482944 total energy tensor([[95.1273]])\n",
      "[-0.9137432]\n",
      "Mode: Train env_steps 200 total rewards -756.7886835187674 total energy tensor([[96.7452]])\n",
      "[-0.678879]\n",
      "Mode: Train env_steps 200 total rewards -760.6278819069266 total energy tensor([[95.4248]])\n",
      "[0.55227983]\n",
      "Mode: Train env_steps 200 total rewards -780.7242187336087 total energy tensor([[97.4432]])\n",
      "[-0.93859196]\n",
      "Mode: Train env_steps 200 total rewards -777.7628744766116 total energy tensor([[92.0780]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8138913]\n",
      "Mode: Train env_steps 200 total rewards -985.0620725899935 total energy tensor([[87.8273]])\n",
      "[0.8857739]\n",
      "Mode: Train env_steps 200 total rewards -636.4277762137353 total energy tensor([[95.0620]])\n",
      "[0.28480616]\n",
      "Mode: Train env_steps 200 total rewards -531.1925519071519 total energy tensor([[99.5523]])\n",
      "[-0.22987503]\n",
      "Mode: Train env_steps 200 total rewards -393.92128704860806 total energy tensor([[94.2640]])\n",
      "[-0.5753997]\n",
      "Mode: Train env_steps 200 total rewards -396.79568868875504 total energy tensor([[92.0868]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:21<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9423504]\n",
      "Mode: Test env_steps 200 total rewards -768.2218938469887 total energy tensor([[102.5382]])\n",
      "[0.7052111]\n",
      "Mode: Test env_steps 200 total rewards -770.4773885309696 total energy tensor([[115.9322]])\n",
      "[-0.7578195]\n",
      "Mode: Test env_steps 200 total rewards -773.4375541582704 total energy tensor([[90.9036]])\n",
      "[0.12428638]\n",
      "Mode: Test env_steps 200 total rewards -516.9455651566386 total energy tensor([[134.4170]])\n",
      "[-0.6402459]\n",
      "Mode: Test env_steps 200 total rewards -639.0276455804706 total energy tensor([[106.2588]])\n",
      "[-0.28966498]\n",
      "Mode: Test env_steps 200 total rewards -1092.1215946376324 total energy tensor([[84.4275]])\n",
      "[-0.85026973]\n",
      "Mode: Test env_steps 200 total rewards -643.5878614485264 total energy tensor([[101.4194]])\n",
      "[0.02760233]\n",
      "Mode: Test env_steps 200 total rewards -1155.6631166264415 total energy tensor([[70.6504]])\n",
      "[0.64760596]\n",
      "Mode: Test env_steps 200 total rewards -673.7788485884666 total energy tensor([[106.9363]])\n",
      "[-0.83038145]\n",
      "Mode: Test env_steps 200 total rewards -770.911808423698 total energy tensor([[96.5462]])\n",
      "140000 -780.4173276998102\n",
      "[0.8618939]\n",
      "Mode: Train env_steps 200 total rewards -1425.403019040823 total energy tensor([[62.3457]])\n",
      "[-0.84723604]\n",
      "Mode: Train env_steps 200 total rewards -646.5879665091634 total energy tensor([[106.1196]])\n",
      "[0.3471036]\n",
      "Mode: Train env_steps 200 total rewards -636.530263622757 total energy tensor([[122.4297]])\n",
      "[0.25132108]\n",
      "Mode: Train env_steps 200 total rewards -644.8895306661725 total energy tensor([[104.7305]])\n",
      "[0.7136642]\n",
      "Mode: Train env_steps 200 total rewards -685.011396445334 total energy tensor([[104.7363]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:49<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9510634]\n",
      "Mode: Train env_steps 200 total rewards -633.4008211810142 total energy tensor([[92.6764]])\n",
      "[-0.11253265]\n",
      "Mode: Train env_steps 200 total rewards -510.8789633256383 total energy tensor([[82.2796]])\n",
      "[-0.49961355]\n",
      "Mode: Train env_steps 200 total rewards -764.2751932926476 total energy tensor([[107.4172]])\n",
      "[-0.83480227]\n",
      "Mode: Train env_steps 200 total rewards -512.8383126141271 total energy tensor([[85.2747]])\n",
      "[0.33909342]\n",
      "Mode: Train env_steps 200 total rewards -765.3757984116673 total energy tensor([[99.9617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86783934]\n",
      "Mode: Train env_steps 200 total rewards -877.3639507889748 total energy tensor([[96.7472]])\n",
      "[-0.9797608]\n",
      "Mode: Train env_steps 200 total rewards -1033.9504709094763 total energy tensor([[81.3478]])\n",
      "[0.13419886]\n",
      "Mode: Train env_steps 200 total rewards -881.8340022265911 total energy tensor([[93.9397]])\n",
      "[0.38378042]\n",
      "Mode: Train env_steps 200 total rewards -614.3426165711135 total energy tensor([[125.1607]])\n",
      "[-0.33877122]\n",
      "Mode: Train env_steps 200 total rewards -883.9487107917666 total energy tensor([[96.5591]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1743333]\n",
      "Mode: Train env_steps 200 total rewards -1031.5412577688694 total energy tensor([[59.8900]])\n",
      "[0.20090716]\n",
      "Mode: Train env_steps 200 total rewards -910.6399791240692 total energy tensor([[58.8153]])\n",
      "[-0.58397305]\n",
      "Mode: Train env_steps 200 total rewards -1034.7072223126888 total energy tensor([[54.8335]])\n",
      "[0.33647206]\n",
      "Mode: Train env_steps 200 total rewards -1051.028072655201 total energy tensor([[76.1737]])\n",
      "[-0.8397689]\n",
      "Mode: Train env_steps 200 total rewards -1045.6381558775902 total energy tensor([[54.0432]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10600348]\n",
      "Mode: Train env_steps 200 total rewards -1015.1655799150467 total energy tensor([[69.2387]])\n",
      "[0.5430561]\n",
      "Mode: Train env_steps 200 total rewards -1205.6388591825962 total energy tensor([[71.6016]])\n",
      "[0.6833364]\n",
      "Mode: Train env_steps 200 total rewards -1138.2513455152512 total energy tensor([[80.0427]])\n",
      "[-0.283109]\n",
      "Mode: Train env_steps 200 total rewards -987.2849201411009 total energy tensor([[76.4414]])\n",
      "[-0.6861528]\n",
      "Mode: Train env_steps 200 total rewards -920.4093223959208 total energy tensor([[80.1081]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53109896]\n",
      "Mode: Test env_steps 200 total rewards -1074.2340815663338 total energy tensor([[61.4503]])\n",
      "[-0.448494]\n",
      "Mode: Test env_steps 200 total rewards -1049.068882867694 total energy tensor([[57.9148]])\n",
      "[-0.7438595]\n",
      "Mode: Test env_steps 200 total rewards -1007.3945337980986 total energy tensor([[73.3432]])\n",
      "[-0.21282968]\n",
      "Mode: Test env_steps 200 total rewards -1100.7479364871979 total energy tensor([[61.6229]])\n",
      "[0.25852993]\n",
      "Mode: Test env_steps 200 total rewards -1028.101586997509 total energy tensor([[64.5944]])\n",
      "[0.91580945]\n",
      "Mode: Test env_steps 200 total rewards -1096.1121395230293 total energy tensor([[66.4035]])\n",
      "[0.7627827]\n",
      "Mode: Test env_steps 200 total rewards -677.4895832252223 total energy tensor([[94.3959]])\n",
      "[-0.28665292]\n",
      "Mode: Test env_steps 200 total rewards -1153.7805756926537 total energy tensor([[69.5107]])\n",
      "[-0.47241732]\n",
      "Mode: Test env_steps 200 total rewards -658.8130878312513 total energy tensor([[91.8843]])\n",
      "[0.80492204]\n",
      "Mode: Test env_steps 200 total rewards -1081.0040537714958 total energy tensor([[65.7935]])\n",
      "145000 -992.6746461760486\n",
      "[0.7163008]\n",
      "Mode: Train env_steps 200 total rewards -1052.2633863389492 total energy tensor([[67.2142]])\n",
      "[0.9647809]\n",
      "Mode: Train env_steps 200 total rewards -1063.3815236613154 total energy tensor([[74.0298]])\n",
      "[-0.26908678]\n",
      "Mode: Train env_steps 200 total rewards -1078.1158658266068 total energy tensor([[63.6152]])\n",
      "[-0.38526338]\n",
      "Mode: Train env_steps 200 total rewards -1060.4161991477013 total energy tensor([[65.7803]])\n",
      "[-0.9557769]\n",
      "Mode: Train env_steps 200 total rewards -1049.32948204875 total energy tensor([[79.7741]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11809554]\n",
      "Mode: Train env_steps 200 total rewards -1048.441738024354 total energy tensor([[53.9941]])\n",
      "[0.94284254]\n",
      "Mode: Train env_steps 200 total rewards -1055.6026580035686 total energy tensor([[48.3555]])\n",
      "[-0.403249]\n",
      "Mode: Train env_steps 200 total rewards -1054.993079483509 total energy tensor([[50.4019]])\n",
      "[-0.48489103]\n",
      "Mode: Train env_steps 200 total rewards -1095.9105020165443 total energy tensor([[56.4382]])\n",
      "[-0.82500905]\n",
      "Mode: Train env_steps 200 total rewards -1164.0533627867699 total energy tensor([[56.8395]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33053276]\n",
      "Mode: Train env_steps 200 total rewards -1082.8024730980396 total energy tensor([[70.3450]])\n",
      "[0.35845682]\n",
      "Mode: Train env_steps 200 total rewards -1132.4589943289757 total energy tensor([[65.9539]])\n",
      "[0.11671204]\n",
      "Mode: Train env_steps 200 total rewards -1183.771929115057 total energy tensor([[56.7901]])\n",
      "[-0.04795986]\n",
      "Mode: Train env_steps 200 total rewards -1079.9806782081723 total energy tensor([[57.2589]])\n",
      "[0.6882827]\n",
      "Mode: Train env_steps 200 total rewards -1081.9598416090012 total energy tensor([[54.6957]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0827255]\n",
      "Mode: Train env_steps 200 total rewards -1033.569001197815 total energy tensor([[61.2056]])\n",
      "[-0.17074776]\n",
      "Mode: Train env_steps 200 total rewards -953.4236050471663 total energy tensor([[59.3765]])\n",
      "[0.6572224]\n",
      "Mode: Train env_steps 200 total rewards -1034.8768629133701 total energy tensor([[74.7566]])\n",
      "[0.94666195]\n",
      "Mode: Train env_steps 200 total rewards -973.3928875923157 total energy tensor([[59.1136]])\n",
      "[0.9261084]\n",
      "Mode: Train env_steps 200 total rewards -971.6410499215126 total energy tensor([[68.7121]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6044213]\n",
      "Mode: Train env_steps 200 total rewards -910.6737809479237 total energy tensor([[72.5638]])\n",
      "[0.9771761]\n",
      "Mode: Train env_steps 200 total rewards -1035.6003927588463 total energy tensor([[56.1239]])\n",
      "[-0.8171655]\n",
      "Mode: Train env_steps 200 total rewards -1037.5270984768867 total energy tensor([[60.8828]])\n",
      "[-0.65377736]\n",
      "Mode: Train env_steps 200 total rewards -1102.844763815403 total energy tensor([[68.3567]])\n",
      "[0.30353585]\n",
      "Mode: Train env_steps 200 total rewards -1025.6517202556133 total energy tensor([[61.1679]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13051729]\n",
      "Mode: Test env_steps 200 total rewards -1023.5385058522224 total energy tensor([[67.4007]])\n",
      "[0.2424727]\n",
      "Mode: Test env_steps 200 total rewards -934.5772943198681 total energy tensor([[54.0805]])\n",
      "[-0.25117257]\n",
      "Mode: Test env_steps 200 total rewards -897.5258884876966 total energy tensor([[63.5469]])\n",
      "[-0.91205585]\n",
      "Mode: Test env_steps 200 total rewards -898.85529948771 total energy tensor([[63.4812]])\n",
      "[0.33442116]\n",
      "Mode: Test env_steps 200 total rewards -905.2535471022129 total energy tensor([[50.2593]])\n",
      "[0.31330442]\n",
      "Mode: Test env_steps 200 total rewards -981.7779684364796 total energy tensor([[53.4418]])\n",
      "[-0.01410507]\n",
      "Mode: Test env_steps 200 total rewards -922.2568025588989 total energy tensor([[92.3186]])\n",
      "[-0.8187702]\n",
      "Mode: Test env_steps 200 total rewards -905.8786341398954 total energy tensor([[52.7280]])\n",
      "[0.09086227]\n",
      "Mode: Test env_steps 200 total rewards -1139.640507876873 total energy tensor([[60.2222]])\n",
      "[0.01968635]\n",
      "Mode: Test env_steps 200 total rewards -924.2175801992416 total energy tensor([[68.5070]])\n",
      "150000 -953.3522028461099\n",
      "[0.07637305]\n",
      "Mode: Train env_steps 200 total rewards -1002.8024905472994 total energy tensor([[61.0410]])\n",
      "[0.6793502]\n",
      "Mode: Train env_steps 200 total rewards -1015.9661935865879 total energy tensor([[59.1735]])\n",
      "[-0.5626573]\n",
      "Mode: Train env_steps 200 total rewards -918.1322872340679 total energy tensor([[58.0749]])\n",
      "[0.8965267]\n",
      "Mode: Train env_steps 200 total rewards -901.8037642985582 total energy tensor([[49.9515]])\n",
      "[0.90608615]\n",
      "Mode: Train env_steps 200 total rewards -1016.0894068777561 total energy tensor([[58.3415]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.88042945]\n",
      "Mode: Train env_steps 200 total rewards -958.9289791882038 total energy tensor([[88.9544]])\n",
      "[-0.7534096]\n",
      "Mode: Train env_steps 200 total rewards -902.656876116991 total energy tensor([[60.7420]])\n",
      "[0.6154928]\n",
      "Mode: Train env_steps 200 total rewards -919.6639468073845 total energy tensor([[58.5659]])\n",
      "[0.01491699]\n",
      "Mode: Train env_steps 200 total rewards -946.9114752411842 total energy tensor([[65.6414]])\n",
      "[0.19948964]\n",
      "Mode: Train env_steps 200 total rewards -897.2552340775728 total energy tensor([[55.8088]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1661607]\n",
      "Mode: Train env_steps 200 total rewards -1115.7924171686172 total energy tensor([[71.2566]])\n",
      "[-0.5168028]\n",
      "Mode: Train env_steps 200 total rewards -1036.039437353611 total energy tensor([[56.4718]])\n",
      "[0.40915295]\n",
      "Mode: Train env_steps 200 total rewards -1031.5122337043285 total energy tensor([[53.9084]])\n",
      "[0.6066834]\n",
      "Mode: Train env_steps 200 total rewards -1035.0616429150105 total energy tensor([[74.7662]])\n",
      "[0.7838878]\n",
      "Mode: Train env_steps 200 total rewards -1010.6161581873894 total energy tensor([[63.0650]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59833306]\n",
      "Mode: Train env_steps 200 total rewards -1046.1073256134987 total energy tensor([[76.3389]])\n",
      "[0.25517765]\n",
      "Mode: Train env_steps 200 total rewards -997.6825685799122 total energy tensor([[65.3723]])\n",
      "[0.20244168]\n",
      "Mode: Train env_steps 200 total rewards -960.0648329854012 total energy tensor([[70.7221]])\n",
      "[0.23640612]\n",
      "Mode: Train env_steps 200 total rewards -807.4258062741719 total energy tensor([[85.0902]])\n",
      "[-0.1682199]\n",
      "Mode: Train env_steps 200 total rewards -784.1741764692488 total energy tensor([[83.7842]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18281248]\n",
      "Mode: Train env_steps 200 total rewards -909.1608241200447 total energy tensor([[64.5968]])\n",
      "[-0.8602358]\n",
      "Mode: Train env_steps 200 total rewards -903.0439937710762 total energy tensor([[62.8439]])\n",
      "[0.12858512]\n",
      "Mode: Train env_steps 200 total rewards -913.2152551710606 total energy tensor([[66.3471]])\n",
      "[0.82111865]\n",
      "Mode: Train env_steps 200 total rewards -882.5282496511936 total energy tensor([[66.0307]])\n",
      "[0.46175486]\n",
      "Mode: Train env_steps 200 total rewards -886.2295441478491 total energy tensor([[58.3003]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6610239]\n",
      "Mode: Test env_steps 200 total rewards -645.6639642994851 total energy tensor([[92.4733]])\n",
      "[0.12902486]\n",
      "Mode: Test env_steps 200 total rewards -938.877209186554 total energy tensor([[76.9765]])\n",
      "[0.00532367]\n",
      "Mode: Test env_steps 200 total rewards -903.417559415102 total energy tensor([[69.9107]])\n",
      "[0.26851067]\n",
      "Mode: Test env_steps 200 total rewards -895.9381611943245 total energy tensor([[73.6211]])\n",
      "[-0.6380188]\n",
      "Mode: Test env_steps 200 total rewards -978.490874171257 total energy tensor([[76.3917]])\n",
      "[-0.66140026]\n",
      "Mode: Test env_steps 200 total rewards -899.9534957408905 total energy tensor([[78.0427]])\n",
      "[-0.39888]\n",
      "Mode: Test env_steps 200 total rewards -879.1910410821438 total energy tensor([[82.3817]])\n",
      "[0.8045473]\n",
      "Mode: Test env_steps 200 total rewards -903.812795817852 total energy tensor([[71.2763]])\n",
      "[0.36020473]\n",
      "Mode: Test env_steps 200 total rewards -935.0955034792423 total energy tensor([[76.4277]])\n",
      "[-0.48035106]\n",
      "Mode: Test env_steps 200 total rewards -916.6966822445393 total energy tensor([[81.8528]])\n",
      "155000 -889.713728663139\n",
      "[0.5378535]\n",
      "Mode: Train env_steps 200 total rewards -895.0304997563362 total energy tensor([[73.7610]])\n",
      "[-0.06785168]\n",
      "Mode: Train env_steps 200 total rewards -749.8605848886073 total energy tensor([[87.8103]])\n",
      "[-0.45751187]\n",
      "Mode: Train env_steps 200 total rewards -875.6869339495897 total energy tensor([[68.3457]])\n",
      "[-0.8813058]\n",
      "Mode: Train env_steps 200 total rewards -899.2479537129402 total energy tensor([[77.6157]])\n",
      "[-0.45744452]\n",
      "Mode: Train env_steps 200 total rewards -903.4030651301146 total energy tensor([[81.3233]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:22<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71470994]\n",
      "Mode: Train env_steps 200 total rewards -891.1572124958038 total energy tensor([[62.1854]])\n",
      "[-0.9166259]\n",
      "Mode: Train env_steps 200 total rewards -888.6921856850386 total energy tensor([[57.5893]])\n",
      "[-0.93467695]\n",
      "Mode: Train env_steps 200 total rewards -839.702872030437 total energy tensor([[63.9143]])\n",
      "[0.23620936]\n",
      "Mode: Train env_steps 200 total rewards -880.1227056086063 total energy tensor([[61.0114]])\n",
      "[0.69725114]\n",
      "Mode: Train env_steps 200 total rewards -898.7783834934235 total energy tensor([[61.5847]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:28<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79889673]\n",
      "Mode: Train env_steps 200 total rewards -884.0342961214483 total energy tensor([[63.9302]])\n",
      "[-0.9077495]\n",
      "Mode: Train env_steps 200 total rewards -898.8661203384399 total energy tensor([[52.1201]])\n",
      "[-0.1909735]\n",
      "Mode: Train env_steps 200 total rewards -882.6819967627525 total energy tensor([[70.6932]])\n",
      "[-0.33277902]\n",
      "Mode: Train env_steps 200 total rewards -897.2331307679415 total energy tensor([[58.9580]])\n",
      "[-0.571813]\n",
      "Mode: Train env_steps 200 total rewards -893.6478572636843 total energy tensor([[57.2279]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99801266]\n",
      "Mode: Train env_steps 200 total rewards -777.2780772149563 total energy tensor([[54.6761]])\n",
      "[0.7708263]\n",
      "Mode: Train env_steps 200 total rewards -893.2304760813713 total energy tensor([[60.1746]])\n",
      "[0.95324117]\n",
      "Mode: Train env_steps 200 total rewards -981.1087944805622 total energy tensor([[69.3578]])\n",
      "[-0.7063972]\n",
      "Mode: Train env_steps 200 total rewards -1036.887088984251 total energy tensor([[65.2315]])\n",
      "[-0.4196484]\n",
      "Mode: Train env_steps 200 total rewards -922.9669099897146 total energy tensor([[70.8799]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04988314]\n",
      "Mode: Train env_steps 200 total rewards -854.1836522966623 total energy tensor([[76.6539]])\n",
      "[-0.28443033]\n",
      "Mode: Train env_steps 200 total rewards -893.0638906359673 total energy tensor([[76.3918]])\n",
      "[0.80571836]\n",
      "Mode: Train env_steps 200 total rewards -898.8163633346558 total energy tensor([[80.3946]])\n",
      "[-0.43629768]\n",
      "Mode: Train env_steps 200 total rewards -845.49527785182 total energy tensor([[74.6154]])\n",
      "[-0.36525655]\n",
      "Mode: Train env_steps 200 total rewards -664.745668053627 total energy tensor([[83.2634]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8532731]\n",
      "Mode: Test env_steps 200 total rewards -891.7596629858017 total energy tensor([[81.4171]])\n",
      "[0.71471435]\n",
      "Mode: Test env_steps 200 total rewards -769.2791009545326 total energy tensor([[68.9417]])\n",
      "[0.18533097]\n",
      "Mode: Test env_steps 200 total rewards -755.8023763298988 total energy tensor([[114.3180]])\n",
      "[-0.05122532]\n",
      "Mode: Test env_steps 200 total rewards -886.083515971899 total energy tensor([[83.2611]])\n",
      "[0.28468463]\n",
      "Mode: Test env_steps 200 total rewards -763.4614178426564 total energy tensor([[82.4696]])\n",
      "[-0.4898272]\n",
      "Mode: Test env_steps 200 total rewards -765.9676527827978 total energy tensor([[72.4217]])\n",
      "[0.04726994]\n",
      "Mode: Test env_steps 200 total rewards -774.6107450574636 total energy tensor([[69.2025]])\n",
      "[0.04657681]\n",
      "Mode: Test env_steps 200 total rewards -879.3925114572048 total energy tensor([[75.2822]])\n",
      "[-0.01942021]\n",
      "Mode: Test env_steps 200 total rewards -873.3620903491974 total energy tensor([[74.3707]])\n",
      "[-0.21983527]\n",
      "Mode: Test env_steps 200 total rewards -757.5961074028164 total energy tensor([[82.7746]])\n",
      "160000 -811.7315181134269\n",
      "[0.325213]\n",
      "Mode: Train env_steps 200 total rewards -782.0809976160526 total energy tensor([[88.2402]])\n",
      "[0.21096854]\n",
      "Mode: Train env_steps 200 total rewards -856.6549877822399 total energy tensor([[82.8425]])\n",
      "[0.35224822]\n",
      "Mode: Train env_steps 200 total rewards -918.5479439795017 total energy tensor([[81.0897]])\n",
      "[0.54860026]\n",
      "Mode: Train env_steps 200 total rewards -796.0044508576393 total energy tensor([[87.3622]])\n",
      "[0.6135968]\n",
      "Mode: Train env_steps 200 total rewards -894.6343540549278 total energy tensor([[88.5614]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33906776]\n",
      "Mode: Train env_steps 200 total rewards -858.0134993717074 total energy tensor([[85.8786]])\n",
      "[0.7899054]\n",
      "Mode: Train env_steps 200 total rewards -758.388421792537 total energy tensor([[88.2682]])\n",
      "[-0.03077029]\n",
      "Mode: Train env_steps 200 total rewards -1008.9982880353928 total energy tensor([[122.1654]])\n",
      "[0.12117483]\n",
      "Mode: Train env_steps 200 total rewards -1246.2452405691147 total energy tensor([[118.7187]])\n",
      "[0.8406636]\n",
      "Mode: Train env_steps 200 total rewards -516.4536159513518 total energy tensor([[73.9337]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.61884934]\n",
      "Mode: Train env_steps 200 total rewards -671.0758059155196 total energy tensor([[81.2552]])\n",
      "[-0.31459588]\n",
      "Mode: Train env_steps 200 total rewards -758.5636978894472 total energy tensor([[65.2893]])\n",
      "[0.27873313]\n",
      "Mode: Train env_steps 200 total rewards -522.5963585600257 total energy tensor([[135.7167]])\n",
      "[-0.8184939]\n",
      "Mode: Train env_steps 200 total rewards -844.4951649457216 total energy tensor([[80.4205]])\n",
      "[0.10077386]\n",
      "Mode: Train env_steps 200 total rewards -751.8686980754137 total energy tensor([[70.1654]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05074226]\n",
      "Mode: Train env_steps 200 total rewards -744.4285965487361 total energy tensor([[85.2912]])\n",
      "[0.42948535]\n",
      "Mode: Train env_steps 200 total rewards -615.6989120543003 total energy tensor([[77.7889]])\n",
      "[0.61684555]\n",
      "Mode: Train env_steps 200 total rewards -762.4467376023531 total energy tensor([[82.1789]])\n",
      "[0.0938387]\n",
      "Mode: Train env_steps 200 total rewards -721.492021875456 total energy tensor([[77.1340]])\n",
      "[-0.99868476]\n",
      "Mode: Train env_steps 200 total rewards -807.1613259315491 total energy tensor([[85.6298]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16310583]\n",
      "Mode: Train env_steps 200 total rewards -1272.917632073164 total energy tensor([[139.7842]])\n",
      "[-0.7794054]\n",
      "Mode: Train env_steps 200 total rewards -754.7104398682714 total energy tensor([[80.2492]])\n",
      "[-0.7899962]\n",
      "Mode: Train env_steps 200 total rewards -1417.383053779602 total energy tensor([[145.7208]])\n",
      "[-0.9668489]\n",
      "Mode: Train env_steps 200 total rewards -1263.2514539659023 total energy tensor([[137.5093]])\n",
      "[-0.0911645]\n",
      "Mode: Train env_steps 200 total rewards -1281.8450102806091 total energy tensor([[134.2852]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22721112]\n",
      "Mode: Test env_steps 200 total rewards -774.0158514380455 total energy tensor([[74.3317]])\n",
      "[0.9356651]\n",
      "Mode: Test env_steps 200 total rewards -631.3568095415831 total energy tensor([[93.8540]])\n",
      "[-0.965132]\n",
      "Mode: Test env_steps 200 total rewards -1393.7003735899925 total energy tensor([[164.5418]])\n",
      "[0.36402062]\n",
      "Mode: Test env_steps 200 total rewards -770.5541043952107 total energy tensor([[72.9570]])\n",
      "[-0.920899]\n",
      "Mode: Test env_steps 200 total rewards -882.927964091301 total energy tensor([[97.0556]])\n",
      "[0.09970667]\n",
      "Mode: Test env_steps 200 total rewards -1406.592619895935 total energy tensor([[166.8201]])\n",
      "[-0.6826848]\n",
      "Mode: Test env_steps 200 total rewards -1402.2956882715225 total energy tensor([[168.7099]])\n",
      "[-0.39172736]\n",
      "Mode: Test env_steps 200 total rewards -1431.3438837826252 total energy tensor([[172.0742]])\n",
      "[0.67022216]\n",
      "Mode: Test env_steps 200 total rewards -769.6585619971156 total energy tensor([[78.1297]])\n",
      "[-0.85745186]\n",
      "Mode: Test env_steps 200 total rewards -764.7991792336106 total energy tensor([[80.4470]])\n",
      "165000 -1022.7245036236942\n",
      "[0.05669483]\n",
      "Mode: Train env_steps 200 total rewards -1317.6131458580494 total energy tensor([[174.5762]])\n",
      "[0.99252576]\n",
      "Mode: Train env_steps 200 total rewards -1386.7778686732054 total energy tensor([[166.1737]])\n",
      "[0.22080576]\n",
      "Mode: Train env_steps 200 total rewards -784.3753119260073 total energy tensor([[69.9562]])\n",
      "[-0.45457074]\n",
      "Mode: Train env_steps 200 total rewards -656.602485479787 total energy tensor([[89.4653]])\n",
      "[-0.12052096]\n",
      "Mode: Train env_steps 200 total rewards -772.3715298771858 total energy tensor([[71.8617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10536411]\n",
      "Mode: Train env_steps 200 total rewards -514.0441205073148 total energy tensor([[102.9932]])\n",
      "[0.77810925]\n",
      "Mode: Train env_steps 200 total rewards -737.6419622004032 total energy tensor([[101.9627]])\n",
      "[-0.17153487]\n",
      "Mode: Train env_steps 200 total rewards -754.1215035021305 total energy tensor([[96.0827]])\n",
      "[-0.09628763]\n",
      "Mode: Train env_steps 200 total rewards -510.5867513651028 total energy tensor([[88.1222]])\n",
      "[0.573714]\n",
      "Mode: Train env_steps 200 total rewards -738.5879543498158 total energy tensor([[80.5572]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3043449]\n",
      "Mode: Train env_steps 200 total rewards -710.5825951909646 total energy tensor([[113.3865]])\n",
      "[0.4669146]\n",
      "Mode: Train env_steps 200 total rewards -632.3091835901141 total energy tensor([[122.9729]])\n",
      "[0.830135]\n",
      "Mode: Train env_steps 200 total rewards -977.3186693787575 total energy tensor([[119.8353]])\n",
      "[-0.66777104]\n",
      "Mode: Train env_steps 200 total rewards -817.3915694355965 total energy tensor([[124.0089]])\n",
      "[-0.6874231]\n",
      "Mode: Train env_steps 200 total rewards -630.0096595138311 total energy tensor([[114.1581]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.28613064]\n",
      "Mode: Train env_steps 200 total rewards -786.7589960247278 total energy tensor([[100.6310]])\n",
      "[0.20965517]\n",
      "Mode: Train env_steps 200 total rewards -1330.4927227795124 total energy tensor([[162.6740]])\n",
      "[-0.78481984]\n",
      "Mode: Train env_steps 200 total rewards -1558.2941926121712 total energy tensor([[180.7729]])\n",
      "[0.95371765]\n",
      "Mode: Train env_steps 200 total rewards -1436.9859457612038 total energy tensor([[173.1073]])\n",
      "[0.88055575]\n",
      "Mode: Train env_steps 200 total rewards -723.040731549263 total energy tensor([[89.3197]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22783662]\n",
      "Mode: Train env_steps 200 total rewards -776.7387028932571 total energy tensor([[69.6138]])\n",
      "[-0.8246261]\n",
      "Mode: Train env_steps 200 total rewards -767.9113270193338 total energy tensor([[70.9794]])\n",
      "[-0.00341883]\n",
      "Mode: Train env_steps 200 total rewards -501.1849164098967 total energy tensor([[119.6871]])\n",
      "[0.55249745]\n",
      "Mode: Train env_steps 200 total rewards -380.6373181096278 total energy tensor([[139.1933]])\n",
      "[0.69030315]\n",
      "Mode: Train env_steps 200 total rewards -761.4739598929882 total energy tensor([[77.0776]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21590623]\n",
      "Mode: Test env_steps 200 total rewards -777.6973901689053 total energy tensor([[85.7692]])\n",
      "[0.31964678]\n",
      "Mode: Test env_steps 200 total rewards -786.591479126364 total energy tensor([[127.7617]])\n",
      "[0.7947553]\n",
      "Mode: Test env_steps 200 total rewards -504.5611912185559 total energy tensor([[112.2100]])\n",
      "[-0.256507]\n",
      "Mode: Test env_steps 200 total rewards -879.8178871423006 total energy tensor([[120.3212]])\n",
      "[0.6115274]\n",
      "Mode: Test env_steps 200 total rewards -778.3517639245838 total energy tensor([[117.9115]])\n",
      "[-0.4228163]\n",
      "Mode: Test env_steps 200 total rewards -635.7475118432194 total energy tensor([[92.6157]])\n",
      "[0.86527926]\n",
      "Mode: Test env_steps 200 total rewards -906.773725181818 total energy tensor([[87.7226]])\n",
      "[0.54829365]\n",
      "Mode: Test env_steps 200 total rewards -789.6314248740673 total energy tensor([[123.2648]])\n",
      "[-0.7845099]\n",
      "Mode: Test env_steps 200 total rewards -895.7486606836319 total energy tensor([[125.4119]])\n",
      "[-0.62068933]\n",
      "Mode: Test env_steps 200 total rewards -628.094950010578 total energy tensor([[96.4677]])\n",
      "170000 -758.3015984174024\n",
      "[0.606349]\n",
      "Mode: Train env_steps 200 total rewards -782.5893529206514 total energy tensor([[120.3094]])\n",
      "[-0.99288714]\n",
      "Mode: Train env_steps 200 total rewards -519.088195215445 total energy tensor([[103.8407]])\n",
      "[-0.5363493]\n",
      "Mode: Train env_steps 200 total rewards -750.7413078732789 total energy tensor([[102.6066]])\n",
      "[0.5027116]\n",
      "Mode: Train env_steps 200 total rewards -616.4891671906225 total energy tensor([[92.3601]])\n",
      "[0.1388469]\n",
      "Mode: Train env_steps 200 total rewards -755.4289934150875 total energy tensor([[118.3417]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8965343]\n",
      "Mode: Train env_steps 200 total rewards -722.7198226824403 total energy tensor([[97.0493]])\n",
      "[-0.8264744]\n",
      "Mode: Train env_steps 200 total rewards -1133.0707914233208 total energy tensor([[116.0269]])\n",
      "[-0.38715506]\n",
      "Mode: Train env_steps 200 total rewards -668.9071766957641 total energy tensor([[95.4941]])\n",
      "[0.03179397]\n",
      "Mode: Train env_steps 200 total rewards -1066.8867496848106 total energy tensor([[118.8534]])\n",
      "[-0.55548424]\n",
      "Mode: Train env_steps 200 total rewards -635.8122595697641 total energy tensor([[81.4411]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83479524]\n",
      "Mode: Train env_steps 200 total rewards -763.7446866035461 total energy tensor([[77.9724]])\n",
      "[-0.0466114]\n",
      "Mode: Train env_steps 200 total rewards -639.6297332514077 total energy tensor([[98.8216]])\n",
      "[0.521536]\n",
      "Mode: Train env_steps 200 total rewards -665.7160871783271 total energy tensor([[85.2151]])\n",
      "[-0.8474949]\n",
      "Mode: Train env_steps 200 total rewards -837.7364303767681 total energy tensor([[87.5931]])\n",
      "[0.45986953]\n",
      "Mode: Train env_steps 200 total rewards -640.3390783788636 total energy tensor([[90.0374]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18233685]\n",
      "Mode: Train env_steps 200 total rewards -828.882188424468 total energy tensor([[82.6108]])\n",
      "[0.72600657]\n",
      "Mode: Train env_steps 200 total rewards -509.75672552455217 total energy tensor([[114.6491]])\n",
      "[0.6025214]\n",
      "Mode: Train env_steps 200 total rewards -757.9953259155154 total energy tensor([[111.0897]])\n",
      "[0.69191253]\n",
      "Mode: Train env_steps 200 total rewards -760.3756394386292 total energy tensor([[88.4777]])\n",
      "[-0.30964872]\n",
      "Mode: Train env_steps 200 total rewards -662.7782574556768 total energy tensor([[123.4189]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5509397]\n",
      "Mode: Train env_steps 200 total rewards -629.6901982743293 total energy tensor([[124.3461]])\n",
      "[0.6920361]\n",
      "Mode: Train env_steps 200 total rewards -626.5272481963038 total energy tensor([[110.3419]])\n",
      "[-0.5852284]\n",
      "Mode: Train env_steps 200 total rewards -636.9394475854933 total energy tensor([[100.5424]])\n",
      "[-0.51942307]\n",
      "Mode: Train env_steps 200 total rewards -626.6946851909161 total energy tensor([[109.9016]])\n",
      "[-0.42613292]\n",
      "Mode: Train env_steps 200 total rewards -512.425311377272 total energy tensor([[103.2998]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14114211]\n",
      "Mode: Test env_steps 200 total rewards -511.163544312818 total energy tensor([[108.5320]])\n",
      "[0.72714955]\n",
      "Mode: Test env_steps 200 total rewards -638.0905747041106 total energy tensor([[128.3689]])\n",
      "[0.6550252]\n",
      "Mode: Test env_steps 200 total rewards -625.1247432082891 total energy tensor([[127.9779]])\n",
      "[0.20064166]\n",
      "Mode: Test env_steps 200 total rewards -620.4064092263579 total energy tensor([[125.0052]])\n",
      "[-0.12370524]\n",
      "Mode: Test env_steps 200 total rewards -618.5499607399106 total energy tensor([[100.8805]])\n",
      "[0.02833235]\n",
      "Mode: Test env_steps 200 total rewards -520.6401855703443 total energy tensor([[137.0418]])\n",
      "[0.43997306]\n",
      "Mode: Test env_steps 200 total rewards -751.7829091772437 total energy tensor([[111.5916]])\n",
      "[0.26275462]\n",
      "Mode: Test env_steps 200 total rewards -623.994247010909 total energy tensor([[100.8934]])\n",
      "[-0.5246901]\n",
      "Mode: Test env_steps 200 total rewards -522.1879342868924 total energy tensor([[149.1888]])\n",
      "[-0.78179574]\n",
      "Mode: Test env_steps 200 total rewards -655.5260966569185 total energy tensor([[110.5507]])\n",
      "175000 -608.7466604893795\n",
      "[-0.27776846]\n",
      "Mode: Train env_steps 200 total rewards -633.4976137578487 total energy tensor([[127.7196]])\n",
      "[-0.15052328]\n",
      "Mode: Train env_steps 200 total rewards -511.10622820444405 total energy tensor([[118.9048]])\n",
      "[0.2539549]\n",
      "Mode: Train env_steps 200 total rewards -842.1953792870045 total energy tensor([[123.2692]])\n",
      "[-0.2336256]\n",
      "Mode: Train env_steps 200 total rewards -514.9455964080989 total energy tensor([[118.0256]])\n",
      "[0.7729896]\n",
      "Mode: Train env_steps 200 total rewards -617.9278404070064 total energy tensor([[106.0051]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21705401]\n",
      "Mode: Train env_steps 200 total rewards -766.6417829021811 total energy tensor([[75.3747]])\n",
      "[-0.9727104]\n",
      "Mode: Train env_steps 200 total rewards -552.5454553738236 total energy tensor([[130.1089]])\n",
      "[0.35934222]\n",
      "Mode: Train env_steps 200 total rewards -775.1481336131692 total energy tensor([[75.7896]])\n",
      "[0.95694596]\n",
      "Mode: Train env_steps 200 total rewards -749.5756496931426 total energy tensor([[91.4570]])\n",
      "[0.80910134]\n",
      "Mode: Train env_steps 200 total rewards -779.1149756610394 total energy tensor([[74.3519]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06252328]\n",
      "Mode: Train env_steps 200 total rewards -742.3475562036037 total energy tensor([[106.0915]])\n",
      "[-0.645755]\n",
      "Mode: Train env_steps 200 total rewards -805.7188160540536 total energy tensor([[111.3197]])\n",
      "[0.01629998]\n",
      "Mode: Train env_steps 200 total rewards -650.5072121582925 total energy tensor([[100.3671]])\n",
      "[0.12203994]\n",
      "Mode: Train env_steps 200 total rewards -755.4771089851856 total energy tensor([[102.8414]])\n",
      "[-0.21794789]\n",
      "Mode: Train env_steps 200 total rewards -685.9119082987309 total energy tensor([[103.8790]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6215735]\n",
      "Mode: Train env_steps 200 total rewards -785.0439935997128 total energy tensor([[126.2690]])\n",
      "[0.8274786]\n",
      "Mode: Train env_steps 200 total rewards -633.8549594022334 total energy tensor([[131.6698]])\n",
      "[0.23292868]\n",
      "Mode: Train env_steps 200 total rewards -768.9902113974094 total energy tensor([[105.5203]])\n",
      "[-0.629435]\n",
      "Mode: Train env_steps 200 total rewards -762.9791854172945 total energy tensor([[81.4575]])\n",
      "[0.9072]\n",
      "Mode: Train env_steps 200 total rewards -635.5298702642322 total energy tensor([[95.6539]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5897993]\n",
      "Mode: Train env_steps 200 total rewards -736.3886882867664 total energy tensor([[101.7371]])\n",
      "[-0.58123684]\n",
      "Mode: Train env_steps 200 total rewards -708.8601155690849 total energy tensor([[99.1969]])\n",
      "[-0.9151146]\n",
      "Mode: Train env_steps 200 total rewards -766.9437915831804 total energy tensor([[68.1430]])\n",
      "[-0.76601285]\n",
      "Mode: Train env_steps 200 total rewards -771.884906116873 total energy tensor([[104.4759]])\n",
      "[0.8214159]\n",
      "Mode: Train env_steps 200 total rewards -642.0204786080867 total energy tensor([[87.3766]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9133329]\n",
      "Mode: Test env_steps 200 total rewards -513.9449291368946 total energy tensor([[122.4334]])\n",
      "[-0.06321272]\n",
      "Mode: Test env_steps 200 total rewards -388.2817286923528 total energy tensor([[117.0732]])\n",
      "[-0.99641085]\n",
      "Mode: Test env_steps 200 total rewards -512.2527440013364 total energy tensor([[110.9604]])\n",
      "[-0.4077193]\n",
      "Mode: Test env_steps 200 total rewards -542.3185001313686 total energy tensor([[116.6524]])\n",
      "[-0.19655558]\n",
      "Mode: Test env_steps 200 total rewards -754.2492109052837 total energy tensor([[119.9028]])\n",
      "[0.1537885]\n",
      "Mode: Test env_steps 200 total rewards -512.4372767703608 total energy tensor([[115.9496]])\n",
      "[-0.552976]\n",
      "Mode: Test env_steps 200 total rewards -512.6825717757456 total energy tensor([[119.2029]])\n",
      "[-0.22893189]\n",
      "Mode: Test env_steps 200 total rewards -513.4446774274111 total energy tensor([[127.0929]])\n",
      "[-0.19144335]\n",
      "Mode: Test env_steps 200 total rewards -498.36986563532264 total energy tensor([[117.6625]])\n",
      "[0.34362665]\n",
      "Mode: Test env_steps 200 total rewards -632.1727751642466 total energy tensor([[130.0695]])\n",
      "180000 -538.0154279640323\n",
      "[0.70789456]\n",
      "Mode: Train env_steps 200 total rewards -630.4631265923381 total energy tensor([[119.7233]])\n",
      "[0.36713585]\n",
      "Mode: Train env_steps 200 total rewards -635.9146325066686 total energy tensor([[120.9658]])\n",
      "[0.6390093]\n",
      "Mode: Train env_steps 200 total rewards -514.0144015103579 total energy tensor([[125.9638]])\n",
      "[-0.18516101]\n",
      "Mode: Train env_steps 200 total rewards -644.8204884887673 total energy tensor([[124.7232]])\n",
      "[0.76352364]\n",
      "Mode: Train env_steps 200 total rewards -627.6629755171016 total energy tensor([[115.8909]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6724626]\n",
      "Mode: Train env_steps 200 total rewards -623.0467984899879 total energy tensor([[112.1285]])\n",
      "[-0.58992654]\n",
      "Mode: Train env_steps 200 total rewards -515.1316147312755 total energy tensor([[119.5229]])\n",
      "[0.42446098]\n",
      "Mode: Train env_steps 200 total rewards -552.2883192226291 total energy tensor([[117.5422]])\n",
      "[-0.09072038]\n",
      "Mode: Train env_steps 200 total rewards -651.4340283051133 total energy tensor([[102.0391]])\n",
      "[-0.13514984]\n",
      "Mode: Train env_steps 200 total rewards -734.5744257047772 total energy tensor([[96.9010]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51766104]\n",
      "Mode: Train env_steps 200 total rewards -857.1690663695335 total energy tensor([[97.7462]])\n",
      "[-0.22729896]\n",
      "Mode: Train env_steps 200 total rewards -758.2206186652184 total energy tensor([[71.2800]])\n",
      "[-0.98496974]\n",
      "Mode: Train env_steps 200 total rewards -751.6888368278742 total energy tensor([[89.9638]])\n",
      "[-0.6265757]\n",
      "Mode: Train env_steps 200 total rewards -760.4787911176682 total energy tensor([[76.6301]])\n",
      "[-0.05134276]\n",
      "Mode: Train env_steps 200 total rewards -755.1271594762802 total energy tensor([[89.5133]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1406744]\n",
      "Mode: Train env_steps 200 total rewards -516.2592515947763 total energy tensor([[94.3823]])\n",
      "[0.33165348]\n",
      "Mode: Train env_steps 200 total rewards -515.2364915078506 total energy tensor([[95.5765]])\n",
      "[0.20465542]\n",
      "Mode: Train env_steps 200 total rewards -640.95762052387 total energy tensor([[133.2877]])\n",
      "[0.6483018]\n",
      "Mode: Train env_steps 200 total rewards -539.8354332242161 total energy tensor([[142.5541]])\n",
      "[0.37753582]\n",
      "Mode: Train env_steps 200 total rewards -770.0945842862129 total energy tensor([[128.8093]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66011107]\n",
      "Mode: Train env_steps 200 total rewards -722.6401811125106 total energy tensor([[108.5735]])\n",
      "[0.3859848]\n",
      "Mode: Train env_steps 200 total rewards -629.4024461116642 total energy tensor([[101.5704]])\n",
      "[-0.55982286]\n",
      "Mode: Train env_steps 200 total rewards -631.1232053339481 total energy tensor([[100.9373]])\n",
      "[0.99176234]\n",
      "Mode: Train env_steps 200 total rewards -630.9874355290085 total energy tensor([[102.0558]])\n",
      "[0.64294666]\n",
      "Mode: Train env_steps 200 total rewards -648.3458162397146 total energy tensor([[114.4358]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02548931]\n",
      "Mode: Test env_steps 200 total rewards -661.5557940304279 total energy tensor([[98.7364]])\n",
      "[-0.04492145]\n",
      "Mode: Test env_steps 200 total rewards -748.1227183043957 total energy tensor([[97.3540]])\n",
      "[-0.58954537]\n",
      "Mode: Test env_steps 200 total rewards -919.0133944004774 total energy tensor([[133.7987]])\n",
      "[0.22654186]\n",
      "Mode: Test env_steps 200 total rewards -802.093367792666 total energy tensor([[139.9407]])\n",
      "[0.38547522]\n",
      "Mode: Test env_steps 200 total rewards -918.0401799976826 total energy tensor([[132.1052]])\n",
      "[-0.25729477]\n",
      "Mode: Test env_steps 200 total rewards -526.410668252036 total energy tensor([[101.6539]])\n",
      "[0.7252465]\n",
      "Mode: Test env_steps 200 total rewards -924.4441112279892 total energy tensor([[129.5300]])\n",
      "[-0.75393254]\n",
      "Mode: Test env_steps 200 total rewards -753.1250560581684 total energy tensor([[95.7866]])\n",
      "[0.100625]\n",
      "Mode: Test env_steps 200 total rewards -821.2260099351406 total energy tensor([[136.2129]])\n",
      "[0.68370426]\n",
      "Mode: Test env_steps 200 total rewards -632.6637729108334 total energy tensor([[109.8120]])\n",
      "185000 -770.6695072909818\n",
      "[0.6538392]\n",
      "Mode: Train env_steps 200 total rewards -520.9270350243896 total energy tensor([[92.2988]])\n",
      "[0.89346653]\n",
      "Mode: Train env_steps 200 total rewards -917.920953810215 total energy tensor([[135.6426]])\n",
      "[0.10272665]\n",
      "Mode: Train env_steps 200 total rewards -634.1353524178267 total energy tensor([[86.5117]])\n",
      "[-0.43374223]\n",
      "Mode: Train env_steps 200 total rewards -1030.5880960524082 total energy tensor([[131.6134]])\n",
      "[0.5416333]\n",
      "Mode: Train env_steps 200 total rewards -783.5665735881776 total energy tensor([[142.7757]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92293173]\n",
      "Mode: Train env_steps 200 total rewards -505.03994343674276 total energy tensor([[109.2997]])\n",
      "[0.76321715]\n",
      "Mode: Train env_steps 200 total rewards -674.5800754874945 total energy tensor([[104.0301]])\n",
      "[0.7291304]\n",
      "Mode: Train env_steps 200 total rewards -656.7541655413806 total energy tensor([[106.4295]])\n",
      "[-0.43867144]\n",
      "Mode: Train env_steps 200 total rewards -842.081895172596 total energy tensor([[132.9039]])\n",
      "[0.7584902]\n",
      "Mode: Train env_steps 200 total rewards -504.31405947729945 total energy tensor([[105.8900]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09855974]\n",
      "Mode: Train env_steps 200 total rewards -494.6080193761736 total energy tensor([[124.3009]])\n",
      "[0.37005517]\n",
      "Mode: Train env_steps 200 total rewards -502.47344107180834 total energy tensor([[115.7665]])\n",
      "[-0.9675848]\n",
      "Mode: Train env_steps 200 total rewards -549.799231801182 total energy tensor([[121.0783]])\n",
      "[-0.661356]\n",
      "Mode: Train env_steps 200 total rewards -390.635534344241 total energy tensor([[119.5258]])\n",
      "[-0.54038984]\n",
      "Mode: Train env_steps 200 total rewards -281.89615729264915 total energy tensor([[124.9567]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29815847]\n",
      "Mode: Train env_steps 200 total rewards -584.8242986630648 total energy tensor([[119.1136]])\n",
      "[-0.6862336]\n",
      "Mode: Train env_steps 200 total rewards -399.59230287745595 total energy tensor([[133.0010]])\n",
      "[0.7567377]\n",
      "Mode: Train env_steps 200 total rewards -895.0548870712519 total energy tensor([[133.4906]])\n",
      "[-0.3221956]\n",
      "Mode: Train env_steps 200 total rewards -395.3734845640138 total energy tensor([[134.9268]])\n",
      "[0.06630406]\n",
      "Mode: Train env_steps 200 total rewards -961.6413717865944 total energy tensor([[127.2991]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69700843]\n",
      "Mode: Train env_steps 200 total rewards -638.844237960875 total energy tensor([[133.0201]])\n",
      "[-0.5701121]\n",
      "Mode: Train env_steps 200 total rewards -521.5125495970715 total energy tensor([[128.5913]])\n",
      "[0.29534328]\n",
      "Mode: Train env_steps 200 total rewards -520.8050762955099 total energy tensor([[123.5420]])\n",
      "[-0.17518285]\n",
      "Mode: Train env_steps 200 total rewards -518.1400332795456 total energy tensor([[123.1848]])\n",
      "[-0.7874588]\n",
      "Mode: Train env_steps 200 total rewards -570.2561148051172 total energy tensor([[123.2996]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:54<00:00,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01576847]\n",
      "Mode: Test env_steps 200 total rewards -621.7307073175907 total energy tensor([[101.3972]])\n",
      "[0.47412202]\n",
      "Mode: Test env_steps 200 total rewards -511.7145774848759 total energy tensor([[121.3588]])\n",
      "[-0.06829616]\n",
      "Mode: Test env_steps 200 total rewards -612.7814125269651 total energy tensor([[102.4950]])\n",
      "[-0.9277332]\n",
      "Mode: Test env_steps 200 total rewards -895.0471507459879 total energy tensor([[130.4547]])\n",
      "[-0.47900108]\n",
      "Mode: Test env_steps 200 total rewards -821.2695176154375 total energy tensor([[139.0833]])\n",
      "[0.55669856]\n",
      "Mode: Test env_steps 200 total rewards -476.13589378260076 total energy tensor([[115.4964]])\n",
      "[-0.5532606]\n",
      "Mode: Test env_steps 200 total rewards -414.02761044725776 total energy tensor([[113.9962]])\n",
      "[-0.37887105]\n",
      "Mode: Test env_steps 200 total rewards -642.7965140454471 total energy tensor([[112.6608]])\n",
      "[-0.80542356]\n",
      "Mode: Test env_steps 200 total rewards -617.173765655607 total energy tensor([[116.9922]])\n",
      "[0.33228108]\n",
      "Mode: Test env_steps 200 total rewards -501.8117747390643 total energy tensor([[114.4321]])\n",
      "190000 -611.4488924360834\n",
      "[0.71403253]\n",
      "Mode: Train env_steps 200 total rewards -398.7490488367621 total energy tensor([[117.3600]])\n",
      "[-0.894964]\n",
      "Mode: Train env_steps 200 total rewards -617.4262822102755 total energy tensor([[119.3734]])\n",
      "[-0.45142686]\n",
      "Mode: Train env_steps 200 total rewards -386.99271479365416 total energy tensor([[116.8468]])\n",
      "[0.36217198]\n",
      "Mode: Train env_steps 200 total rewards -496.7112204693258 total energy tensor([[118.5350]])\n",
      "[0.94916636]\n",
      "Mode: Train env_steps 200 total rewards -510.36506301444024 total energy tensor([[117.2913]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7145533]\n",
      "Mode: Train env_steps 200 total rewards -771.8653916120529 total energy tensor([[138.0038]])\n",
      "[0.6800948]\n",
      "Mode: Train env_steps 200 total rewards -498.3283014341723 total energy tensor([[113.1325]])\n",
      "[0.01282049]\n",
      "Mode: Train env_steps 200 total rewards -744.2826077640057 total energy tensor([[112.6415]])\n",
      "[0.6754589]\n",
      "Mode: Train env_steps 200 total rewards -667.2487076185644 total energy tensor([[114.0851]])\n",
      "[-0.4422257]\n",
      "Mode: Train env_steps 200 total rewards -774.7791358679533 total energy tensor([[136.7988]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:16<00:00,  3.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12286732]\n",
      "Mode: Train env_steps 200 total rewards -628.7588387951255 total energy tensor([[107.0053]])\n",
      "[0.71252394]\n",
      "Mode: Train env_steps 200 total rewards -532.8814103417099 total energy tensor([[116.0665]])\n",
      "[-0.05448439]\n",
      "Mode: Train env_steps 200 total rewards -574.5148289743811 total energy tensor([[104.5772]])\n",
      "[0.81520414]\n",
      "Mode: Train env_steps 200 total rewards -510.3333410602063 total energy tensor([[109.3153]])\n",
      "[0.56771415]\n",
      "Mode: Train env_steps 200 total rewards -637.8929408043623 total energy tensor([[86.5637]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75109154]\n",
      "Mode: Train env_steps 200 total rewards -646.8447316475213 total energy tensor([[146.5438]])\n",
      "[0.7444576]\n",
      "Mode: Train env_steps 200 total rewards -509.4300762861967 total energy tensor([[102.7139]])\n",
      "[0.92358756]\n",
      "Mode: Train env_steps 200 total rewards -887.7344371750951 total energy tensor([[134.2894]])\n",
      "[0.19098589]\n",
      "Mode: Train env_steps 200 total rewards -776.0367798656225 total energy tensor([[134.6414]])\n",
      "[0.1093667]\n",
      "Mode: Train env_steps 200 total rewards -505.61641441762913 total energy tensor([[119.7480]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0266281]\n",
      "Mode: Train env_steps 200 total rewards -677.253890552558 total energy tensor([[115.8862]])\n",
      "[0.42407888]\n",
      "Mode: Train env_steps 200 total rewards -746.7579812444746 total energy tensor([[116.2382]])\n",
      "[-0.03209778]\n",
      "Mode: Train env_steps 200 total rewards -770.420209094882 total energy tensor([[108.3666]])\n",
      "[0.3169948]\n",
      "Mode: Train env_steps 200 total rewards -648.4571864530444 total energy tensor([[116.2020]])\n",
      "[0.99116427]\n",
      "Mode: Train env_steps 200 total rewards -634.7773325145245 total energy tensor([[87.0815]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59231514]\n",
      "Mode: Test env_steps 200 total rewards -616.0235662162304 total energy tensor([[118.0371]])\n",
      "[0.17436585]\n",
      "Mode: Test env_steps 200 total rewards -800.903752475977 total energy tensor([[113.0817]])\n",
      "[-0.47752258]\n",
      "Mode: Test env_steps 200 total rewards -520.9511341005564 total energy tensor([[112.1042]])\n",
      "[0.73820686]\n",
      "Mode: Test env_steps 200 total rewards -702.2436106950045 total energy tensor([[128.4557]])\n",
      "[-0.6697958]\n",
      "Mode: Test env_steps 200 total rewards -743.4174842089415 total energy tensor([[116.1332]])\n",
      "[0.4611719]\n",
      "Mode: Test env_steps 200 total rewards -518.4703070111573 total energy tensor([[101.3469]])\n",
      "[-0.78649]\n",
      "Mode: Test env_steps 200 total rewards -629.3592835441232 total energy tensor([[92.6704]])\n",
      "[0.29530153]\n",
      "Mode: Test env_steps 200 total rewards -622.9251876994967 total energy tensor([[116.4609]])\n",
      "[0.26169923]\n",
      "Mode: Test env_steps 200 total rewards -635.2476511374116 total energy tensor([[104.6416]])\n",
      "[-0.44229075]\n",
      "Mode: Test env_steps 200 total rewards -512.957514969632 total energy tensor([[112.6416]])\n",
      "195000 -630.249949205853\n",
      "[-0.74092597]\n",
      "Mode: Train env_steps 200 total rewards -629.223843164742 total energy tensor([[108.1238]])\n",
      "[0.00375221]\n",
      "Mode: Train env_steps 200 total rewards -535.0128047913313 total energy tensor([[108.1784]])\n",
      "[-0.8936272]\n",
      "Mode: Train env_steps 200 total rewards -626.2021129503846 total energy tensor([[94.8208]])\n",
      "[-0.37091875]\n",
      "Mode: Train env_steps 200 total rewards -559.1958566829562 total energy tensor([[120.8329]])\n",
      "[-0.86265445]\n",
      "Mode: Train env_steps 200 total rewards -717.2921112850308 total energy tensor([[122.0455]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63389164]\n",
      "Mode: Train env_steps 200 total rewards -386.263949329732 total energy tensor([[106.5364]])\n",
      "[0.1374383]\n",
      "Mode: Train env_steps 200 total rewards -506.4355332199484 total energy tensor([[108.3120]])\n",
      "[-0.19563855]\n",
      "Mode: Train env_steps 200 total rewards -389.37155065871775 total energy tensor([[105.9469]])\n",
      "[-0.28024384]\n",
      "Mode: Train env_steps 200 total rewards -384.7410411313176 total energy tensor([[110.0516]])\n",
      "[-0.33076873]\n",
      "Mode: Train env_steps 200 total rewards -532.0970010980964 total energy tensor([[108.2994]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.683343]\n",
      "Mode: Train env_steps 200 total rewards -808.1406339406967 total energy tensor([[134.3984]])\n",
      "[0.8344204]\n",
      "Mode: Train env_steps 200 total rewards -501.9087305702269 total energy tensor([[111.9828]])\n",
      "[0.20799676]\n",
      "Mode: Train env_steps 200 total rewards -788.6232422888279 total energy tensor([[140.7414]])\n",
      "[0.27083412]\n",
      "Mode: Train env_steps 200 total rewards -801.4851604774594 total energy tensor([[128.8820]])\n",
      "[-0.2690883]\n",
      "Mode: Train env_steps 200 total rewards -511.21586881089024 total energy tensor([[111.6180]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.49619868]\n",
      "Mode: Train env_steps 200 total rewards -566.7917960952036 total energy tensor([[133.9547]])\n",
      "[0.7463945]\n",
      "Mode: Train env_steps 200 total rewards -382.42137832776643 total energy tensor([[140.3934]])\n",
      "[-0.20205685]\n",
      "Mode: Train env_steps 200 total rewards -375.72600240504835 total energy tensor([[133.6478]])\n",
      "[0.35096115]\n",
      "Mode: Train env_steps 200 total rewards -259.7470637462102 total energy tensor([[132.0199]])\n",
      "[0.50354123]\n",
      "Mode: Train env_steps 200 total rewards -655.701288305223 total energy tensor([[147.4271]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77031404]\n",
      "Mode: Train env_steps 200 total rewards -515.8269624300301 total energy tensor([[113.2591]])\n",
      "[-0.30924386]\n",
      "Mode: Train env_steps 200 total rewards -526.7116748490371 total energy tensor([[116.2408]])\n",
      "[0.9261269]\n",
      "Mode: Train env_steps 200 total rewards -505.0637279296061 total energy tensor([[103.4555]])\n",
      "[0.9987722]\n",
      "Mode: Train env_steps 200 total rewards -621.2670992957428 total energy tensor([[117.7334]])\n",
      "[0.54457694]\n",
      "Mode: Train env_steps 200 total rewards -747.1014850363135 total energy tensor([[110.9075]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6346982]\n",
      "Mode: Test env_steps 200 total rewards -701.4581443937495 total energy tensor([[111.1049]])\n",
      "[-0.19432604]\n",
      "Mode: Test env_steps 200 total rewards -618.1706136520952 total energy tensor([[114.8928]])\n",
      "[-0.35968864]\n",
      "Mode: Test env_steps 200 total rewards -626.4756818637252 total energy tensor([[94.8470]])\n",
      "[-0.03349494]\n",
      "Mode: Test env_steps 200 total rewards -508.75160899036564 total energy tensor([[102.3872]])\n",
      "[-0.79972696]\n",
      "Mode: Test env_steps 200 total rewards -628.4748690202832 total energy tensor([[93.2126]])\n",
      "[-0.82632464]\n",
      "Mode: Test env_steps 200 total rewards -647.3930569142103 total energy tensor([[141.1350]])\n",
      "[0.52358234]\n",
      "Mode: Test env_steps 200 total rewards -504.84916824288666 total energy tensor([[123.4729]])\n",
      "[0.5957813]\n",
      "Mode: Test env_steps 200 total rewards -518.6878773276694 total energy tensor([[106.0198]])\n",
      "[-0.47766212]\n",
      "Mode: Test env_steps 200 total rewards -512.6245997026563 total energy tensor([[104.7575]])\n",
      "[-0.14472316]\n",
      "Mode: Test env_steps 200 total rewards -506.02744123199955 total energy tensor([[109.3089]])\n",
      "200000 -577.2913061339641\n",
      "[-0.41484693]\n",
      "Mode: Train env_steps 200 total rewards -583.0477423463017 total energy tensor([[114.4812]])\n",
      "[-0.9995567]\n",
      "Mode: Train env_steps 200 total rewards -456.85844860738143 total energy tensor([[112.7258]])\n",
      "[-0.962356]\n",
      "Mode: Train env_steps 200 total rewards -296.80220729112625 total energy tensor([[141.8855]])\n",
      "[-0.22494276]\n",
      "Mode: Train env_steps 200 total rewards -513.514163456508 total energy tensor([[124.0498]])\n",
      "[0.12323809]\n",
      "Mode: Train env_steps 200 total rewards -660.3056530952454 total energy tensor([[142.3345]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57041067]\n",
      "Mode: Train env_steps 200 total rewards -651.1103309430182 total energy tensor([[148.3225]])\n",
      "[-0.5452448]\n",
      "Mode: Train env_steps 200 total rewards -546.0632295167306 total energy tensor([[125.9206]])\n",
      "[-0.92998105]\n",
      "Mode: Train env_steps 200 total rewards -392.7553581688553 total energy tensor([[117.5253]])\n",
      "[-0.79289186]\n",
      "Mode: Train env_steps 200 total rewards -609.9683495610952 total energy tensor([[125.7575]])\n",
      "[-0.2343049]\n",
      "Mode: Train env_steps 200 total rewards -506.1193753872067 total energy tensor([[111.9793]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09622253]\n",
      "Mode: Train env_steps 200 total rewards -452.98261485947296 total energy tensor([[123.6127]])\n",
      "[0.4751256]\n",
      "Mode: Train env_steps 200 total rewards -479.44093708577566 total energy tensor([[122.0147]])\n",
      "[-0.2806087]\n",
      "Mode: Train env_steps 200 total rewards -615.8245056942105 total energy tensor([[124.4873]])\n",
      "[-0.7326771]\n",
      "Mode: Train env_steps 200 total rewards -513.291747641284 total energy tensor([[119.6642]])\n",
      "[0.16699602]\n",
      "Mode: Train env_steps 200 total rewards -502.8754719385179 total energy tensor([[109.2493]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6938012]\n",
      "Mode: Train env_steps 200 total rewards -382.9861465211725 total energy tensor([[133.2630]])\n",
      "[0.87100095]\n",
      "Mode: Train env_steps 200 total rewards -624.2903045043349 total energy tensor([[132.6232]])\n",
      "[-0.40328667]\n",
      "Mode: Train env_steps 200 total rewards -500.73955660988577 total energy tensor([[131.3974]])\n",
      "[-0.59853953]\n",
      "Mode: Train env_steps 200 total rewards -715.9267714433372 total energy tensor([[138.5475]])\n",
      "[-0.42806733]\n",
      "Mode: Train env_steps 200 total rewards -386.8693832885474 total energy tensor([[126.0621]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9725147]\n",
      "Mode: Train env_steps 200 total rewards -612.1498088818043 total energy tensor([[132.9765]])\n",
      "[0.86310166]\n",
      "Mode: Train env_steps 200 total rewards -485.85559603892034 total energy tensor([[123.1960]])\n",
      "[0.7223119]\n",
      "Mode: Train env_steps 200 total rewards -614.5525652393699 total energy tensor([[120.9482]])\n",
      "[-0.70321375]\n",
      "Mode: Train env_steps 200 total rewards -683.8796720746905 total energy tensor([[119.9650]])\n",
      "[0.16058941]\n",
      "Mode: Train env_steps 200 total rewards -623.2439118027687 total energy tensor([[115.1373]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03879989]\n",
      "Mode: Test env_steps 200 total rewards -632.4233992397785 total energy tensor([[86.0888]])\n",
      "[0.41346002]\n",
      "Mode: Test env_steps 200 total rewards -631.5025746077299 total energy tensor([[97.3852]])\n",
      "[0.39734653]\n",
      "Mode: Test env_steps 200 total rewards -512.8285051360726 total energy tensor([[105.8580]])\n",
      "[-0.9054487]\n",
      "Mode: Test env_steps 200 total rewards -536.4210260871332 total energy tensor([[126.3496]])\n",
      "[0.02678359]\n",
      "Mode: Test env_steps 200 total rewards -698.1676845550537 total energy tensor([[143.6316]])\n",
      "[-0.71982867]\n",
      "Mode: Test env_steps 200 total rewards -642.1201073341072 total energy tensor([[149.5912]])\n",
      "[0.3722941]\n",
      "Mode: Test env_steps 200 total rewards -759.97625156492 total energy tensor([[146.4184]])\n",
      "[-0.49490833]\n",
      "Mode: Test env_steps 200 total rewards -521.0742906108499 total energy tensor([[151.5023]])\n",
      "[-0.91494006]\n",
      "Mode: Test env_steps 200 total rewards -744.6260205581784 total energy tensor([[144.0641]])\n",
      "[0.28364116]\n",
      "Mode: Test env_steps 200 total rewards -726.7999838292599 total energy tensor([[147.5999]])\n",
      "205000 -640.5939843523083\n",
      "[0.98242664]\n",
      "Mode: Train env_steps 200 total rewards -507.9074349538423 total energy tensor([[105.4436]])\n",
      "[0.549016]\n",
      "Mode: Train env_steps 200 total rewards -639.1648632101715 total energy tensor([[147.4189]])\n",
      "[0.00215427]\n",
      "Mode: Train env_steps 200 total rewards -566.2519845832139 total energy tensor([[123.3580]])\n",
      "[-0.3443977]\n",
      "Mode: Train env_steps 200 total rewards -678.9061749354005 total energy tensor([[142.4525]])\n",
      "[0.16595048]\n",
      "Mode: Train env_steps 200 total rewards -762.2602446973324 total energy tensor([[145.7817]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0965583]\n",
      "Mode: Train env_steps 200 total rewards -458.89716212969506 total energy tensor([[113.8204]])\n",
      "[0.72886467]\n",
      "Mode: Train env_steps 200 total rewards -641.6415726691484 total energy tensor([[101.4515]])\n",
      "[-0.5175357]\n",
      "Mode: Train env_steps 200 total rewards -631.1723565161228 total energy tensor([[88.3757]])\n",
      "[-0.6865707]\n",
      "Mode: Train env_steps 200 total rewards -503.8231713952264 total energy tensor([[122.6783]])\n",
      "[-0.16146377]\n",
      "Mode: Train env_steps 200 total rewards -506.84467459470034 total energy tensor([[116.6661]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.50269926]\n",
      "Mode: Train env_steps 200 total rewards -586.8779921196401 total energy tensor([[126.2651]])\n",
      "[0.7773421]\n",
      "Mode: Train env_steps 200 total rewards -522.0706071332097 total energy tensor([[107.0370]])\n",
      "[-0.75510836]\n",
      "Mode: Train env_steps 200 total rewards -539.3219543192536 total energy tensor([[123.4915]])\n",
      "[-0.8954351]\n",
      "Mode: Train env_steps 200 total rewards -512.465617492795 total energy tensor([[132.4868]])\n",
      "[-0.99960935]\n",
      "Mode: Train env_steps 200 total rewards -438.21533215767704 total energy tensor([[123.0488]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.47752914]\n",
      "Mode: Train env_steps 200 total rewards -418.16085751727223 total energy tensor([[135.0478]])\n",
      "[0.02887427]\n",
      "Mode: Train env_steps 200 total rewards -534.0326274912804 total energy tensor([[139.8170]])\n",
      "[0.35978705]\n",
      "Mode: Train env_steps 200 total rewards -419.72365465108305 total energy tensor([[136.1655]])\n",
      "[-0.71874535]\n",
      "Mode: Train env_steps 200 total rewards -417.76085979805794 total energy tensor([[133.1772]])\n",
      "[-0.9355069]\n",
      "Mode: Train env_steps 200 total rewards -388.6815972607583 total energy tensor([[126.8230]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90148795]\n",
      "Mode: Train env_steps 200 total rewards -258.94557040299696 total energy tensor([[131.1743]])\n",
      "[0.7695463]\n",
      "Mode: Train env_steps 200 total rewards -275.8115802988177 total energy tensor([[130.8514]])\n",
      "[-0.91378456]\n",
      "Mode: Train env_steps 200 total rewards -759.8667858466506 total energy tensor([[137.4384]])\n",
      "[0.6878439]\n",
      "Mode: Train env_steps 200 total rewards -258.72612771819695 total energy tensor([[125.4508]])\n",
      "[0.80544156]\n",
      "Mode: Train env_steps 200 total rewards -629.5133330821991 total energy tensor([[92.7349]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05574393]\n",
      "Mode: Test env_steps 200 total rewards -629.3839106485248 total energy tensor([[83.4881]])\n",
      "[0.27670673]\n",
      "Mode: Test env_steps 200 total rewards -631.6105783730745 total energy tensor([[86.8284]])\n",
      "[0.26929167]\n",
      "Mode: Test env_steps 200 total rewards -630.546830419451 total energy tensor([[140.6654]])\n",
      "[0.87255275]\n",
      "Mode: Test env_steps 200 total rewards -509.6026450578356 total energy tensor([[116.9071]])\n",
      "[-0.10151792]\n",
      "Mode: Test env_steps 200 total rewards -493.1020046022022 total energy tensor([[113.8296]])\n",
      "[0.4857323]\n",
      "Mode: Test env_steps 200 total rewards -503.3053070041351 total energy tensor([[117.3204]])\n",
      "[0.33962104]\n",
      "Mode: Test env_steps 200 total rewards -663.9782656952739 total energy tensor([[146.5394]])\n",
      "[0.8280371]\n",
      "Mode: Test env_steps 200 total rewards -539.7031238116324 total energy tensor([[101.8586]])\n",
      "[-0.02363995]\n",
      "Mode: Test env_steps 200 total rewards -634.1035679280758 total energy tensor([[145.3643]])\n",
      "[-0.05677638]\n",
      "Mode: Test env_steps 200 total rewards -631.6308972984552 total energy tensor([[89.1388]])\n",
      "210000 -586.696713083866\n",
      "[0.5350186]\n",
      "Mode: Train env_steps 200 total rewards -637.1793271005154 total energy tensor([[143.7217]])\n",
      "[-0.61600405]\n",
      "Mode: Train env_steps 200 total rewards -565.2672247029841 total energy tensor([[146.8389]])\n",
      "[-0.17287618]\n",
      "Mode: Train env_steps 200 total rewards -453.83388978848234 total energy tensor([[112.3648]])\n",
      "[-0.818268]\n",
      "Mode: Train env_steps 200 total rewards -638.3523214831948 total energy tensor([[138.1925]])\n",
      "[-0.53724474]\n",
      "Mode: Train env_steps 200 total rewards -641.7238635271788 total energy tensor([[103.8462]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40575832]\n",
      "Mode: Train env_steps 200 total rewards -544.8490900807083 total energy tensor([[116.4101]])\n",
      "[-0.72836924]\n",
      "Mode: Train env_steps 200 total rewards -663.0866594575346 total energy tensor([[140.4734]])\n",
      "[-0.833047]\n",
      "Mode: Train env_steps 200 total rewards -640.9534922502935 total energy tensor([[151.1431]])\n",
      "[-0.2992629]\n",
      "Mode: Train env_steps 200 total rewards -350.3852507658303 total energy tensor([[134.1551]])\n",
      "[0.16493362]\n",
      "Mode: Train env_steps 200 total rewards -644.0845021605492 total energy tensor([[149.1510]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7138246]\n",
      "Mode: Train env_steps 200 total rewards -637.2076733708382 total energy tensor([[146.9846]])\n",
      "[0.76174974]\n",
      "Mode: Train env_steps 200 total rewards -556.4151981174946 total energy tensor([[157.7674]])\n",
      "[-0.13309394]\n",
      "Mode: Train env_steps 200 total rewards -507.34497625008225 total energy tensor([[119.1710]])\n",
      "[-0.45005313]\n",
      "Mode: Train env_steps 200 total rewards -391.79400261491537 total energy tensor([[122.6926]])\n",
      "[0.310392]\n",
      "Mode: Train env_steps 200 total rewards -628.8717738240957 total energy tensor([[89.0188]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.72588414]\n",
      "Mode: Train env_steps 200 total rewards -428.2216060869396 total energy tensor([[115.1756]])\n",
      "[-0.76068896]\n",
      "Mode: Train env_steps 200 total rewards -519.4509125798941 total energy tensor([[147.2102]])\n",
      "[0.01088011]\n",
      "Mode: Train env_steps 200 total rewards -401.81827223248547 total energy tensor([[111.0958]])\n",
      "[-0.22393711]\n",
      "Mode: Train env_steps 200 total rewards -629.8287891745567 total energy tensor([[86.9983]])\n",
      "[-0.42407954]\n",
      "Mode: Train env_steps 200 total rewards -407.1226356626721 total energy tensor([[110.8423]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7296823]\n",
      "Mode: Train env_steps 200 total rewards -527.2957002336043 total energy tensor([[139.9020]])\n",
      "[-0.651135]\n",
      "Mode: Train env_steps 200 total rewards -512.4794601053 total energy tensor([[134.8294]])\n",
      "[0.03244577]\n",
      "Mode: Train env_steps 200 total rewards -631.7282853871584 total energy tensor([[91.7517]])\n",
      "[0.99880475]\n",
      "Mode: Train env_steps 200 total rewards -503.3458881138358 total energy tensor([[118.6535]])\n",
      "[-0.00096533]\n",
      "Mode: Train env_steps 200 total rewards -500.4473542954074 total energy tensor([[118.8386]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09969195]\n",
      "Mode: Test env_steps 200 total rewards -770.1459825374186 total energy tensor([[143.0474]])\n",
      "[0.9890167]\n",
      "Mode: Test env_steps 200 total rewards -905.8302227407694 total energy tensor([[142.4212]])\n",
      "[0.75575393]\n",
      "Mode: Test env_steps 200 total rewards -489.9233682062477 total energy tensor([[116.3821]])\n",
      "[-0.92122173]\n",
      "Mode: Test env_steps 200 total rewards -765.7999498434365 total energy tensor([[140.3098]])\n",
      "[0.11633509]\n",
      "Mode: Test env_steps 200 total rewards -504.27422176487744 total energy tensor([[122.3642]])\n",
      "[0.02803273]\n",
      "Mode: Test env_steps 200 total rewards -505.1195164397359 total energy tensor([[125.6099]])\n",
      "[-0.81216294]\n",
      "Mode: Test env_steps 200 total rewards -508.93561793118715 total energy tensor([[113.8755]])\n",
      "[-0.3662068]\n",
      "Mode: Test env_steps 200 total rewards -373.00778999284375 total energy tensor([[126.6518]])\n",
      "[0.3751893]\n",
      "Mode: Test env_steps 200 total rewards -713.5928294211626 total energy tensor([[148.4983]])\n",
      "[2.2667158e-05]\n",
      "Mode: Test env_steps 200 total rewards -389.23276851396076 total energy tensor([[124.3254]])\n",
      "215000 -592.586226739164\n",
      "[0.2048419]\n",
      "Mode: Train env_steps 200 total rewards -777.7110211849213 total energy tensor([[141.2281]])\n",
      "[-0.90982]\n",
      "Mode: Train env_steps 200 total rewards -445.60860664979555 total energy tensor([[128.2146]])\n",
      "[0.151647]\n",
      "Mode: Train env_steps 200 total rewards -773.2596707865596 total energy tensor([[146.8587]])\n",
      "[0.77014655]\n",
      "Mode: Train env_steps 200 total rewards -772.6316996067762 total energy tensor([[139.4695]])\n",
      "[-0.28338528]\n",
      "Mode: Train env_steps 200 total rewards -651.80696131289 total energy tensor([[152.1040]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9214384]\n",
      "Mode: Train env_steps 200 total rewards -505.1981164701283 total energy tensor([[114.4916]])\n",
      "[0.7545171]\n",
      "Mode: Train env_steps 200 total rewards -730.1225534901023 total energy tensor([[134.4546]])\n",
      "[-0.9838444]\n",
      "Mode: Train env_steps 200 total rewards -656.3260067030787 total energy tensor([[141.6801]])\n",
      "[0.87687004]\n",
      "Mode: Train env_steps 200 total rewards -647.6072745993733 total energy tensor([[141.4017]])\n",
      "[0.9177082]\n",
      "Mode: Train env_steps 200 total rewards -638.9240673296154 total energy tensor([[147.1340]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.26874653]\n",
      "Mode: Train env_steps 200 total rewards -617.9609435541788 total energy tensor([[144.7871]])\n",
      "[-0.56232136]\n",
      "Mode: Train env_steps 200 total rewards -6.19380807550624 total energy tensor([[148.6408]])\n",
      "[0.31985047]\n",
      "Mode: Train env_steps 200 total rewards -463.9488035548711 total energy tensor([[153.5943]])\n",
      "[0.8432802]\n",
      "Mode: Train env_steps 200 total rewards -383.44846900040284 total energy tensor([[154.5833]])\n",
      "[-0.76214397]\n",
      "Mode: Train env_steps 200 total rewards -611.9925345107913 total energy tensor([[95.6681]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48214647]\n",
      "Mode: Train env_steps 200 total rewards -511.00289771705866 total energy tensor([[99.0526]])\n",
      "[-0.4432074]\n",
      "Mode: Train env_steps 200 total rewards -383.79389937827364 total energy tensor([[119.9681]])\n",
      "[-0.1344482]\n",
      "Mode: Train env_steps 200 total rewards -602.4804643690586 total energy tensor([[130.0874]])\n",
      "[0.13522479]\n",
      "Mode: Train env_steps 200 total rewards -532.8791771940887 total energy tensor([[151.5763]])\n",
      "[-0.8129404]\n",
      "Mode: Train env_steps 200 total rewards -628.2947808876634 total energy tensor([[87.0304]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8357784]\n",
      "Mode: Train env_steps 200 total rewards -636.9123221561313 total energy tensor([[97.5128]])\n",
      "[0.07604013]\n",
      "Mode: Train env_steps 200 total rewards -500.7843833081424 total energy tensor([[128.7661]])\n",
      "[-0.41521403]\n",
      "Mode: Train env_steps 200 total rewards -563.3883901014924 total energy tensor([[135.8300]])\n",
      "[0.840214]\n",
      "Mode: Train env_steps 200 total rewards -387.3706545950263 total energy tensor([[133.9254]])\n",
      "[-0.40967807]\n",
      "Mode: Train env_steps 200 total rewards -810.5098551660776 total energy tensor([[105.4753]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11462141]\n",
      "Mode: Test env_steps 200 total rewards -627.6492491066456 total energy tensor([[111.3259]])\n",
      "[0.44434425]\n",
      "Mode: Test env_steps 200 total rewards -599.4302353709936 total energy tensor([[149.8571]])\n",
      "[0.91871864]\n",
      "Mode: Test env_steps 200 total rewards -744.8408156037331 total energy tensor([[120.4584]])\n",
      "[-0.08467849]\n",
      "Mode: Test env_steps 200 total rewards -636.1222632825375 total energy tensor([[147.2309]])\n",
      "[0.9876077]\n",
      "Mode: Test env_steps 200 total rewards -563.869445502758 total energy tensor([[151.3912]])\n",
      "[0.8736749]\n",
      "Mode: Test env_steps 200 total rewards -521.10038286075 total energy tensor([[159.6172]])\n",
      "[0.39212388]\n",
      "Mode: Test env_steps 200 total rewards -649.2578633092344 total energy tensor([[153.9701]])\n",
      "[-0.4799354]\n",
      "Mode: Test env_steps 200 total rewards -530.6893001785502 total energy tensor([[132.5042]])\n",
      "[-0.00760542]\n",
      "Mode: Test env_steps 200 total rewards -497.5238396752975 total energy tensor([[140.7068]])\n",
      "[0.3515613]\n",
      "Mode: Test env_steps 200 total rewards -631.0039611160755 total energy tensor([[107.3073]])\n",
      "220000 -600.1487356006576\n",
      "[-0.75177664]\n",
      "Mode: Train env_steps 200 total rewards -410.3905248467345 total energy tensor([[135.5962]])\n",
      "[0.9086216]\n",
      "Mode: Train env_steps 200 total rewards -635.6496098004282 total energy tensor([[149.1524]])\n",
      "[-0.29744503]\n",
      "Mode: Train env_steps 200 total rewards -510.6319093471393 total energy tensor([[141.6230]])\n",
      "[0.2820723]\n",
      "Mode: Train env_steps 200 total rewards -631.0100204199553 total energy tensor([[106.9586]])\n",
      "[0.1626814]\n",
      "Mode: Train env_steps 200 total rewards -510.0454441215843 total energy tensor([[116.1125]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6695113]\n",
      "Mode: Train env_steps 200 total rewards -637.5417143516243 total energy tensor([[144.5186]])\n",
      "[0.6531395]\n",
      "Mode: Train env_steps 200 total rewards -7.953480954980478 total energy tensor([[170.6097]])\n",
      "[0.7271002]\n",
      "Mode: Train env_steps 200 total rewards -637.5739761181176 total energy tensor([[147.2733]])\n",
      "[0.7448809]\n",
      "Mode: Train env_steps 200 total rewards -640.0470652841032 total energy tensor([[146.8728]])\n",
      "[-0.98760855]\n",
      "Mode: Train env_steps 200 total rewards -5.184096658369526 total energy tensor([[163.4204]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73402864]\n",
      "Mode: Train env_steps 200 total rewards -633.4376046285033 total energy tensor([[89.9632]])\n",
      "[-0.47393128]\n",
      "Mode: Train env_steps 200 total rewards -409.7245136415586 total energy tensor([[141.4715]])\n",
      "[-0.46856424]\n",
      "Mode: Train env_steps 200 total rewards -585.5299135260284 total energy tensor([[139.2243]])\n",
      "[-0.86989146]\n",
      "Mode: Train env_steps 200 total rewards -734.4078500382602 total energy tensor([[140.2844]])\n",
      "[-0.55975014]\n",
      "Mode: Train env_steps 200 total rewards -723.6688393354416 total energy tensor([[100.8381]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8287724]\n",
      "Mode: Train env_steps 200 total rewards -504.2731820605695 total energy tensor([[128.4496]])\n",
      "[-0.4524402]\n",
      "Mode: Train env_steps 200 total rewards -508.84313075616956 total energy tensor([[119.8111]])\n",
      "[0.19000514]\n",
      "Mode: Train env_steps 200 total rewards -508.0328269265592 total energy tensor([[112.5883]])\n",
      "[-0.5376106]\n",
      "Mode: Train env_steps 200 total rewards -652.918646812439 total energy tensor([[112.2062]])\n",
      "[0.5884041]\n",
      "Mode: Train env_steps 200 total rewards -629.9208693243563 total energy tensor([[146.0642]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02482577]\n",
      "Mode: Train env_steps 200 total rewards -628.4335920214653 total energy tensor([[85.3288]])\n",
      "[-0.7543236]\n",
      "Mode: Train env_steps 200 total rewards -622.3383515998721 total energy tensor([[148.6529]])\n",
      "[0.20334734]\n",
      "Mode: Train env_steps 200 total rewards -631.6104093715549 total energy tensor([[90.5301]])\n",
      "[-0.8479405]\n",
      "Mode: Train env_steps 200 total rewards -645.9858840182424 total energy tensor([[135.7694]])\n",
      "[0.58676225]\n",
      "Mode: Train env_steps 200 total rewards -384.5354080677498 total energy tensor([[125.8467]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66904694]\n",
      "Mode: Test env_steps 200 total rewards -629.3619810193777 total energy tensor([[97.8397]])\n",
      "[-0.65541416]\n",
      "Mode: Test env_steps 200 total rewards -766.2585995048285 total energy tensor([[105.2808]])\n",
      "[0.77262396]\n",
      "Mode: Test env_steps 200 total rewards -617.4624231187627 total energy tensor([[124.7896]])\n",
      "[-0.10666028]\n",
      "Mode: Test env_steps 200 total rewards -615.4639460272156 total energy tensor([[125.6435]])\n",
      "[-0.95319355]\n",
      "Mode: Test env_steps 200 total rewards -626.4710388686508 total energy tensor([[118.5742]])\n",
      "[-0.59209096]\n",
      "Mode: Test env_steps 200 total rewards -505.54363730270416 total energy tensor([[122.6638]])\n",
      "[0.20948498]\n",
      "Mode: Test env_steps 200 total rewards -742.440059915185 total energy tensor([[95.1943]])\n",
      "[-0.9147656]\n",
      "Mode: Test env_steps 200 total rewards -524.4645833596587 total energy tensor([[123.8602]])\n",
      "[0.47828144]\n",
      "Mode: Test env_steps 200 total rewards -675.546153485775 total energy tensor([[95.7979]])\n",
      "[0.0655188]\n",
      "Mode: Test env_steps 200 total rewards -668.5107768289745 total energy tensor([[126.3479]])\n",
      "225000 -637.1523199431133\n",
      "[-0.5899796]\n",
      "Mode: Train env_steps 200 total rewards -631.2051614602096 total energy tensor([[120.4567]])\n",
      "[-0.08631344]\n",
      "Mode: Train env_steps 200 total rewards -514.6775829317048 total energy tensor([[131.7161]])\n",
      "[-0.68945724]\n",
      "Mode: Train env_steps 200 total rewards -619.1945477961563 total energy tensor([[121.8764]])\n",
      "[-0.0509649]\n",
      "Mode: Train env_steps 200 total rewards -744.3828915506601 total energy tensor([[95.5092]])\n",
      "[-0.14090985]\n",
      "Mode: Train env_steps 200 total rewards -524.346635133028 total energy tensor([[124.0476]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9193077]\n",
      "Mode: Train env_steps 200 total rewards -730.6814327985048 total energy tensor([[98.4085]])\n",
      "[-0.8484233]\n",
      "Mode: Train env_steps 200 total rewards -511.90322665311396 total energy tensor([[120.6991]])\n",
      "[-0.46974906]\n",
      "Mode: Train env_steps 200 total rewards -625.0629816646688 total energy tensor([[115.5420]])\n",
      "[0.14335278]\n",
      "Mode: Train env_steps 200 total rewards -638.5913789607584 total energy tensor([[138.4704]])\n",
      "[0.42616415]\n",
      "Mode: Train env_steps 200 total rewards -510.5979689043015 total energy tensor([[105.6236]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15246554]\n",
      "Mode: Train env_steps 200 total rewards -637.4432673491538 total energy tensor([[144.8667]])\n",
      "[-0.5271311]\n",
      "Mode: Train env_steps 200 total rewards -637.5137876011431 total energy tensor([[146.2428]])\n",
      "[-0.58385193]\n",
      "Mode: Train env_steps 200 total rewards -670.6029879748821 total energy tensor([[124.1801]])\n",
      "[0.9255419]\n",
      "Mode: Train env_steps 200 total rewards -627.4543974325061 total energy tensor([[98.3551]])\n",
      "[0.6411313]\n",
      "Mode: Train env_steps 200 total rewards -511.2591532766819 total energy tensor([[120.9428]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35052326]\n",
      "Mode: Train env_steps 200 total rewards -388.3060490190983 total energy tensor([[129.0643]])\n",
      "[0.12626997]\n",
      "Mode: Train env_steps 200 total rewards -633.7446853742003 total energy tensor([[88.7409]])\n",
      "[0.9584332]\n",
      "Mode: Train env_steps 200 total rewards -771.2794533632696 total energy tensor([[140.4938]])\n",
      "[-0.83421123]\n",
      "Mode: Train env_steps 200 total rewards -654.9135349094868 total energy tensor([[147.5167]])\n",
      "[-0.28201017]\n",
      "Mode: Train env_steps 200 total rewards -736.9232494458556 total energy tensor([[99.9799]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6733727]\n",
      "Mode: Train env_steps 200 total rewards -502.9675610943232 total energy tensor([[117.2326]])\n",
      "[0.7026789]\n",
      "Mode: Train env_steps 200 total rewards -613.5297474095132 total energy tensor([[121.4541]])\n",
      "[0.4698731]\n",
      "Mode: Train env_steps 200 total rewards -500.745797192445 total energy tensor([[115.2083]])\n",
      "[0.36899254]\n",
      "Mode: Train env_steps 200 total rewards -526.21700350233 total energy tensor([[142.1147]])\n",
      "[0.27026638]\n",
      "Mode: Train env_steps 200 total rewards -645.083203330636 total energy tensor([[104.0988]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0867701]\n",
      "Mode: Test env_steps 200 total rewards -623.4049712121487 total energy tensor([[119.5696]])\n",
      "[-0.80470455]\n",
      "Mode: Test env_steps 200 total rewards -808.6336597204208 total energy tensor([[102.0571]])\n",
      "[0.39639938]\n",
      "Mode: Test env_steps 200 total rewards -631.6461721509695 total energy tensor([[93.2958]])\n",
      "[-0.6875962]\n",
      "Mode: Test env_steps 200 total rewards -519.0057357028127 total energy tensor([[153.6005]])\n",
      "[0.7133152]\n",
      "Mode: Test env_steps 200 total rewards -631.1271214820445 total energy tensor([[145.0522]])\n",
      "[-0.12061265]\n",
      "Mode: Test env_steps 200 total rewards -561.4776675589383 total energy tensor([[105.1198]])\n",
      "[0.22115846]\n",
      "Mode: Test env_steps 200 total rewards -514.7369692921638 total energy tensor([[119.9516]])\n",
      "[0.30550233]\n",
      "Mode: Test env_steps 200 total rewards -520.0070334970951 total energy tensor([[104.7440]])\n",
      "[-0.9900276]\n",
      "Mode: Test env_steps 200 total rewards -631.374768063426 total energy tensor([[94.2204]])\n",
      "[-0.67402864]\n",
      "Mode: Test env_steps 200 total rewards -606.7829971536994 total energy tensor([[140.9772]])\n",
      "230000 -604.8197095833718\n",
      "[-0.07261145]\n",
      "Mode: Train env_steps 200 total rewards -631.5893533155322 total energy tensor([[127.6159]])\n",
      "[-0.705632]\n",
      "Mode: Train env_steps 200 total rewards -626.9204524159431 total energy tensor([[87.3901]])\n",
      "[0.45740807]\n",
      "Mode: Train env_steps 200 total rewards -627.9939121827483 total energy tensor([[95.7999]])\n",
      "[-0.25805658]\n",
      "Mode: Train env_steps 200 total rewards -649.6875377446413 total energy tensor([[103.1547]])\n",
      "[-0.12487278]\n",
      "Mode: Train env_steps 200 total rewards -628.7728509679437 total energy tensor([[88.2854]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6842345]\n",
      "Mode: Train env_steps 200 total rewards -581.8876999095082 total energy tensor([[148.8959]])\n",
      "[-0.5263431]\n",
      "Mode: Train env_steps 200 total rewards -646.3857993222773 total energy tensor([[149.8066]])\n",
      "[0.625809]\n",
      "Mode: Train env_steps 200 total rewards -516.8188448213041 total energy tensor([[119.0684]])\n",
      "[-0.49499416]\n",
      "Mode: Train env_steps 200 total rewards -613.4028115607798 total energy tensor([[116.3642]])\n",
      "[-0.28154865]\n",
      "Mode: Train env_steps 200 total rewards -649.6810580920428 total energy tensor([[132.2945]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43031195]\n",
      "Mode: Train env_steps 200 total rewards -780.0532803982496 total energy tensor([[103.2850]])\n",
      "[0.34917277]\n",
      "Mode: Train env_steps 200 total rewards -519.4563720581355 total energy tensor([[114.1311]])\n",
      "[-0.32903737]\n",
      "Mode: Train env_steps 200 total rewards -626.649116024375 total energy tensor([[105.2881]])\n",
      "[0.9961612]\n",
      "Mode: Train env_steps 200 total rewards -659.2731665021274 total energy tensor([[130.3525]])\n",
      "[-0.17521663]\n",
      "Mode: Train env_steps 200 total rewards -666.836579312745 total energy tensor([[122.3193]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5155173]\n",
      "Mode: Train env_steps 200 total rewards -619.5194027293473 total energy tensor([[106.6068]])\n",
      "[-0.0155195]\n",
      "Mode: Train env_steps 200 total rewards -636.1769402548671 total energy tensor([[105.5384]])\n",
      "[0.16968186]\n",
      "Mode: Train env_steps 200 total rewards -633.350348263979 total energy tensor([[94.1633]])\n",
      "[0.9971697]\n",
      "Mode: Train env_steps 200 total rewards -86.80895933695138 total energy tensor([[155.1373]])\n",
      "[-0.06838285]\n",
      "Mode: Train env_steps 200 total rewards -624.3238951936364 total energy tensor([[102.0927]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57186025]\n",
      "Mode: Train env_steps 200 total rewards -796.1710204184055 total energy tensor([[106.0807]])\n",
      "[0.22386672]\n",
      "Mode: Train env_steps 200 total rewards -795.1336764544249 total energy tensor([[130.1403]])\n",
      "[-0.6517403]\n",
      "Mode: Train env_steps 200 total rewards -644.1133543178439 total energy tensor([[132.2429]])\n",
      "[-0.65029746]\n",
      "Mode: Train env_steps 200 total rewards -566.9716936945915 total energy tensor([[100.4736]])\n",
      "[-0.66265637]\n",
      "Mode: Train env_steps 200 total rewards -570.0689401887357 total energy tensor([[102.2866]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4979794]\n",
      "Mode: Test env_steps 200 total rewards -565.1136684753001 total energy tensor([[128.3062]])\n",
      "[0.90198463]\n",
      "Mode: Test env_steps 200 total rewards -395.6341610189993 total energy tensor([[146.8681]])\n",
      "[0.04949149]\n",
      "Mode: Test env_steps 200 total rewards -638.7576466724277 total energy tensor([[139.6455]])\n",
      "[0.582476]\n",
      "Mode: Test env_steps 200 total rewards -715.5265821926296 total energy tensor([[125.8195]])\n",
      "[0.8510706]\n",
      "Mode: Test env_steps 200 total rewards -742.3525184839964 total energy tensor([[139.9203]])\n",
      "[-0.09017811]\n",
      "Mode: Test env_steps 200 total rewards -518.5995370969176 total energy tensor([[130.4462]])\n",
      "[0.84619474]\n",
      "Mode: Test env_steps 200 total rewards -770.9693468995392 total energy tensor([[144.3598]])\n",
      "[0.6784578]\n",
      "Mode: Test env_steps 200 total rewards -520.000507324934 total energy tensor([[133.7037]])\n",
      "[0.83221483]\n",
      "Mode: Test env_steps 200 total rewards -742.0454256758094 total energy tensor([[141.9126]])\n",
      "[-0.8456864]\n",
      "Mode: Test env_steps 200 total rewards -517.4796818904579 total energy tensor([[135.6918]])\n",
      "235000 -612.6479075731011\n",
      "[-0.49949694]\n",
      "Mode: Train env_steps 200 total rewards -653.1270694546402 total energy tensor([[152.2313]])\n",
      "[-0.4134421]\n",
      "Mode: Train env_steps 200 total rewards -646.3209241740406 total energy tensor([[142.4452]])\n",
      "[-0.9714189]\n",
      "Mode: Train env_steps 200 total rewards -820.1254996545613 total energy tensor([[138.3744]])\n",
      "[-0.62116534]\n",
      "Mode: Train env_steps 200 total rewards -515.2255593314767 total energy tensor([[96.6029]])\n",
      "[-0.76704794]\n",
      "Mode: Train env_steps 200 total rewards -645.2298791371286 total energy tensor([[140.4415]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37186536]\n",
      "Mode: Train env_steps 200 total rewards -650.5939520448446 total energy tensor([[93.9235]])\n",
      "[0.58203423]\n",
      "Mode: Train env_steps 200 total rewards -921.4129341691732 total energy tensor([[132.8833]])\n",
      "[-0.04582571]\n",
      "Mode: Train env_steps 200 total rewards -632.7855608016253 total energy tensor([[94.2020]])\n",
      "[0.31004786]\n",
      "Mode: Train env_steps 200 total rewards -665.9306967034936 total energy tensor([[144.8764]])\n",
      "[0.4673107]\n",
      "Mode: Train env_steps 200 total rewards -1199.214110672474 total energy tensor([[129.8426]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:54<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5251653]\n",
      "Mode: Train env_steps 200 total rewards -762.9603176265955 total energy tensor([[104.4361]])\n",
      "[0.10647198]\n",
      "Mode: Train env_steps 200 total rewards -633.6781952753663 total energy tensor([[95.2035]])\n",
      "[0.3311637]\n",
      "Mode: Train env_steps 200 total rewards -627.7117095403373 total energy tensor([[102.4893]])\n",
      "[-0.9499053]\n",
      "Mode: Train env_steps 200 total rewards -630.8939807116985 total energy tensor([[94.4325]])\n",
      "[0.83978206]\n",
      "Mode: Train env_steps 200 total rewards -624.6262404303998 total energy tensor([[108.6164]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83181083]\n",
      "Mode: Train env_steps 200 total rewards -507.68211429193616 total energy tensor([[118.0620]])\n",
      "[-0.82080173]\n",
      "Mode: Train env_steps 200 total rewards -654.1914218515158 total energy tensor([[135.9832]])\n",
      "[0.6194613]\n",
      "Mode: Train env_steps 200 total rewards -653.4926778078079 total energy tensor([[135.5113]])\n",
      "[-0.43099996]\n",
      "Mode: Train env_steps 200 total rewards -590.9364211447537 total energy tensor([[123.0655]])\n",
      "[0.6118141]\n",
      "Mode: Train env_steps 200 total rewards -660.6511083692312 total energy tensor([[134.4384]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5678417]\n",
      "Mode: Train env_steps 200 total rewards -630.8613482639194 total energy tensor([[102.3727]])\n",
      "[-0.20403329]\n",
      "Mode: Train env_steps 200 total rewards -726.5127562209964 total energy tensor([[128.1054]])\n",
      "[0.2665843]\n",
      "Mode: Train env_steps 200 total rewards -628.472639657557 total energy tensor([[104.0131]])\n",
      "[0.01857671]\n",
      "Mode: Train env_steps 200 total rewards -390.62051803804934 total energy tensor([[126.5313]])\n",
      "[-0.68750453]\n",
      "Mode: Train env_steps 200 total rewards -700.6496516391635 total energy tensor([[131.1465]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00993763]\n",
      "Mode: Test env_steps 200 total rewards -639.95486367587 total energy tensor([[106.6834]])\n",
      "[-0.38075194]\n",
      "Mode: Test env_steps 200 total rewards -620.2355601806194 total energy tensor([[110.2555]])\n",
      "[0.00499323]\n",
      "Mode: Test env_steps 200 total rewards -523.0001647267491 total energy tensor([[109.1331]])\n",
      "[-0.33235297]\n",
      "Mode: Test env_steps 200 total rewards -766.863019797951 total energy tensor([[112.5914]])\n",
      "[0.87604487]\n",
      "Mode: Test env_steps 200 total rewards -624.0115730864927 total energy tensor([[115.8261]])\n",
      "[-0.37639946]\n",
      "Mode: Test env_steps 200 total rewards -517.7606565468013 total energy tensor([[107.1414]])\n",
      "[-0.44705907]\n",
      "Mode: Test env_steps 200 total rewards -583.0022242050618 total energy tensor([[123.5820]])\n",
      "[-0.30192378]\n",
      "Mode: Test env_steps 200 total rewards -515.3273977153003 total energy tensor([[97.5484]])\n",
      "[-0.48402327]\n",
      "Mode: Test env_steps 200 total rewards -640.094647847116 total energy tensor([[93.7153]])\n",
      "[-0.7338545]\n",
      "Mode: Test env_steps 200 total rewards -596.9895847178996 total energy tensor([[117.7338]])\n",
      "240000 -602.7239692499861\n",
      "[0.71240914]\n",
      "Mode: Train env_steps 200 total rewards -525.2782687749714 total energy tensor([[116.9959]])\n",
      "[0.52889466]\n",
      "Mode: Train env_steps 200 total rewards -638.2877284511924 total energy tensor([[95.1406]])\n",
      "[0.28706303]\n",
      "Mode: Train env_steps 200 total rewards -511.90074835531414 total energy tensor([[123.6963]])\n",
      "[-0.10445267]\n",
      "Mode: Train env_steps 200 total rewards -690.835726082325 total energy tensor([[96.6119]])\n",
      "[0.77422106]\n",
      "Mode: Train env_steps 200 total rewards -685.4662188440561 total energy tensor([[96.4414]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5433538]\n",
      "Mode: Train env_steps 200 total rewards -648.6321363374591 total energy tensor([[136.7646]])\n",
      "[-0.6321502]\n",
      "Mode: Train env_steps 200 total rewards -659.2485580556095 total energy tensor([[151.0722]])\n",
      "[-0.9940003]\n",
      "Mode: Train env_steps 200 total rewards -620.3301488682628 total energy tensor([[140.5809]])\n",
      "[0.6513517]\n",
      "Mode: Train env_steps 200 total rewards -649.2007936313748 total energy tensor([[137.2219]])\n",
      "[0.1611049]\n",
      "Mode: Train env_steps 200 total rewards -641.9698476195335 total energy tensor([[149.9231]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04373604]\n",
      "Mode: Train env_steps 200 total rewards -518.3263371884823 total energy tensor([[138.3501]])\n",
      "[0.04093807]\n",
      "Mode: Train env_steps 200 total rewards -727.1479677632451 total energy tensor([[111.5341]])\n",
      "[-0.8477585]\n",
      "Mode: Train env_steps 200 total rewards -507.368945482187 total energy tensor([[105.2682]])\n",
      "[-0.72239614]\n",
      "Mode: Train env_steps 200 total rewards -519.3555286936462 total energy tensor([[107.0729]])\n",
      "[0.25827733]\n",
      "Mode: Train env_steps 200 total rewards -627.1043144240975 total energy tensor([[102.0024]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10371851]\n",
      "Mode: Train env_steps 200 total rewards -647.918891876936 total energy tensor([[139.6832]])\n",
      "[0.48397323]\n",
      "Mode: Train env_steps 200 total rewards -513.105502469698 total energy tensor([[94.6125]])\n",
      "[-0.5730086]\n",
      "Mode: Train env_steps 200 total rewards -545.8186140106991 total energy tensor([[97.3561]])\n",
      "[0.19644663]\n",
      "Mode: Train env_steps 200 total rewards -629.6706700026989 total energy tensor([[150.8716]])\n",
      "[0.72716266]\n",
      "Mode: Train env_steps 200 total rewards -800.9963601008058 total energy tensor([[141.5960]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15411863]\n",
      "Mode: Train env_steps 200 total rewards -620.6299516260624 total energy tensor([[108.2393]])\n",
      "[-0.4672136]\n",
      "Mode: Train env_steps 200 total rewards -633.9079914018512 total energy tensor([[94.1229]])\n",
      "[-0.42382878]\n",
      "Mode: Train env_steps 200 total rewards -521.1390494331717 total energy tensor([[146.6617]])\n",
      "[-0.54036367]\n",
      "Mode: Train env_steps 200 total rewards -502.2651005256921 total energy tensor([[131.3987]])\n",
      "[0.8802927]\n",
      "Mode: Train env_steps 200 total rewards -638.3051622658968 total energy tensor([[91.4129]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72531337]\n",
      "Mode: Test env_steps 200 total rewards -745.8529501259327 total energy tensor([[96.5133]])\n",
      "[0.27732825]\n",
      "Mode: Test env_steps 200 total rewards -1188.9683081954718 total energy tensor([[128.2998]])\n",
      "[0.7771415]\n",
      "Mode: Test env_steps 200 total rewards -1048.2833155989647 total energy tensor([[132.8709]])\n",
      "[-0.32007325]\n",
      "Mode: Test env_steps 200 total rewards -1159.5032720565796 total energy tensor([[128.5336]])\n",
      "[0.83720875]\n",
      "Mode: Test env_steps 200 total rewards -1451.265015244484 total energy tensor([[128.7991]])\n",
      "[-0.19882573]\n",
      "Mode: Test env_steps 200 total rewards -1277.7378389239311 total energy tensor([[126.1174]])\n",
      "[0.7255062]\n",
      "Mode: Test env_steps 200 total rewards -933.7593176960945 total energy tensor([[138.2897]])\n",
      "[-0.13093615]\n",
      "Mode: Test env_steps 200 total rewards -701.6070809401572 total energy tensor([[103.7573]])\n",
      "[-0.43957657]\n",
      "Mode: Test env_steps 200 total rewards -803.7062034010887 total energy tensor([[142.2855]])\n",
      "[0.8307599]\n",
      "Mode: Test env_steps 200 total rewards -892.3748706877232 total energy tensor([[138.8452]])\n",
      "245000 -1020.3058172870427\n",
      "[0.3082396]\n",
      "Mode: Train env_steps 200 total rewards -899.9696384072304 total energy tensor([[139.3102]])\n",
      "[-0.7484397]\n",
      "Mode: Train env_steps 200 total rewards -915.6123260557652 total energy tensor([[135.0295]])\n",
      "[-0.49706692]\n",
      "Mode: Train env_steps 200 total rewards -1063.97712251544 total energy tensor([[134.7666]])\n",
      "[-0.67878973]\n",
      "Mode: Train env_steps 200 total rewards -1066.2373561561108 total energy tensor([[132.9665]])\n",
      "[-0.48464483]\n",
      "Mode: Train env_steps 200 total rewards -909.7739899158478 total energy tensor([[133.9631]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10833599]\n",
      "Mode: Train env_steps 200 total rewards -10.427389536052942 total energy tensor([[157.1559]])\n",
      "[0.62523377]\n",
      "Mode: Train env_steps 200 total rewards -510.4548715893179 total energy tensor([[123.8810]])\n",
      "[-0.98557395]\n",
      "Mode: Train env_steps 200 total rewards -760.971089117229 total energy tensor([[109.4533]])\n",
      "[-0.56084734]\n",
      "Mode: Train env_steps 200 total rewards -501.0496255364269 total energy tensor([[102.3623]])\n",
      "[0.95719826]\n",
      "Mode: Train env_steps 200 total rewards -609.2204462736845 total energy tensor([[132.6850]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87688667]\n",
      "Mode: Train env_steps 200 total rewards -641.6900172531605 total energy tensor([[143.4189]])\n",
      "[0.78963256]\n",
      "Mode: Train env_steps 200 total rewards -540.8565539717674 total energy tensor([[148.8945]])\n",
      "[-0.54965824]\n",
      "Mode: Train env_steps 200 total rewards -518.4967847578228 total energy tensor([[128.3575]])\n",
      "[-0.8256353]\n",
      "Mode: Train env_steps 200 total rewards -626.4921999052167 total energy tensor([[125.9040]])\n",
      "[0.88118875]\n",
      "Mode: Train env_steps 200 total rewards -521.3975408896804 total energy tensor([[127.9482]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.68486345]\n",
      "Mode: Train env_steps 200 total rewards -1024.44453728199 total energy tensor([[137.2617]])\n",
      "[-0.5931448]\n",
      "Mode: Train env_steps 200 total rewards -596.5562283992767 total energy tensor([[107.3824]])\n",
      "[0.3683884]\n",
      "Mode: Train env_steps 200 total rewards -629.4151385463774 total energy tensor([[98.7528]])\n",
      "[0.43466076]\n",
      "Mode: Train env_steps 200 total rewards -1010.6810573339462 total energy tensor([[134.2499]])\n",
      "[0.8701652]\n",
      "Mode: Train env_steps 200 total rewards -634.9264088273048 total energy tensor([[96.9917]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10624247]\n",
      "Mode: Train env_steps 200 total rewards -653.4358077384531 total energy tensor([[152.9175]])\n",
      "[0.97413903]\n",
      "Mode: Train env_steps 200 total rewards -636.4862335342914 total energy tensor([[151.0146]])\n",
      "[0.12929405]\n",
      "Mode: Train env_steps 200 total rewards -509.17053075507283 total energy tensor([[123.1011]])\n",
      "[0.263562]\n",
      "Mode: Train env_steps 200 total rewards -630.7652121782303 total energy tensor([[98.8558]])\n",
      "[0.48339155]\n",
      "Mode: Train env_steps 200 total rewards -635.3242959976196 total energy tensor([[151.1078]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5588494]\n",
      "Mode: Test env_steps 200 total rewards -393.43323318008333 total energy tensor([[108.1288]])\n",
      "[0.2903253]\n",
      "Mode: Test env_steps 200 total rewards -543.9339078683406 total energy tensor([[114.8211]])\n",
      "[-0.0074514]\n",
      "Mode: Test env_steps 200 total rewards -645.0750700756907 total energy tensor([[123.9747]])\n",
      "[-0.10252833]\n",
      "Mode: Test env_steps 200 total rewards -513.558250979986 total energy tensor([[102.9664]])\n",
      "[0.08871357]\n",
      "Mode: Test env_steps 200 total rewards -664.6999492049217 total energy tensor([[150.2282]])\n",
      "[0.6641434]\n",
      "Mode: Test env_steps 200 total rewards -637.4576693251729 total energy tensor([[150.2300]])\n",
      "[-0.4567035]\n",
      "Mode: Test env_steps 200 total rewards -530.0344198718667 total energy tensor([[151.4687]])\n",
      "[0.4304064]\n",
      "Mode: Test env_steps 200 total rewards -508.3369973860681 total energy tensor([[103.2664]])\n",
      "[0.29548925]\n",
      "Mode: Test env_steps 200 total rewards -630.4273477420211 total energy tensor([[100.9674]])\n",
      "[-0.06615101]\n",
      "Mode: Test env_steps 200 total rewards -381.7075079213828 total energy tensor([[104.9758]])\n",
      "250000 -544.8664353555534\n",
      "[-0.00441766]\n",
      "Mode: Train env_steps 200 total rewards -516.150906547904 total energy tensor([[112.3408]])\n",
      "[0.27907896]\n",
      "Mode: Train env_steps 200 total rewards -517.9335252339952 total energy tensor([[104.8389]])\n",
      "[0.4886214]\n",
      "Mode: Train env_steps 200 total rewards -512.4024140946567 total energy tensor([[123.7607]])\n",
      "[-0.0568891]\n",
      "Mode: Train env_steps 200 total rewards -529.2060049846768 total energy tensor([[150.8456]])\n",
      "[0.65630084]\n",
      "Mode: Train env_steps 200 total rewards -526.0139052346349 total energy tensor([[152.8576]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36273947]\n",
      "Mode: Train env_steps 200 total rewards -518.1033706981689 total energy tensor([[100.9284]])\n",
      "[0.4493379]\n",
      "Mode: Train env_steps 200 total rewards -512.4265437498689 total energy tensor([[112.0453]])\n",
      "[-0.9810926]\n",
      "Mode: Train env_steps 200 total rewards -512.8853216320276 total energy tensor([[123.5567]])\n",
      "[-0.7327139]\n",
      "Mode: Train env_steps 200 total rewards -383.9355806708336 total energy tensor([[112.4992]])\n",
      "[0.22004205]\n",
      "Mode: Train env_steps 200 total rewards -520.7198557816446 total energy tensor([[153.2155]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6393847]\n",
      "Mode: Train env_steps 200 total rewards -490.67729996331036 total energy tensor([[107.2501]])\n",
      "[0.6055443]\n",
      "Mode: Train env_steps 200 total rewards -538.2976657226682 total energy tensor([[149.8725]])\n",
      "[0.3546033]\n",
      "Mode: Train env_steps 200 total rewards -612.7428228780627 total energy tensor([[99.0901]])\n",
      "[-0.5508242]\n",
      "Mode: Train env_steps 200 total rewards -584.1058777924627 total energy tensor([[107.2980]])\n",
      "[-0.12881103]\n",
      "Mode: Train env_steps 200 total rewards -628.0119851306081 total energy tensor([[116.5133]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09003355]\n",
      "Mode: Train env_steps 200 total rewards -645.6462011188269 total energy tensor([[149.4967]])\n",
      "[0.28290823]\n",
      "Mode: Train env_steps 200 total rewards -634.2829208597541 total energy tensor([[147.3061]])\n",
      "[0.79793686]\n",
      "Mode: Train env_steps 200 total rewards -637.3373888134956 total energy tensor([[87.7227]])\n",
      "[-0.33365825]\n",
      "Mode: Train env_steps 200 total rewards -629.4532683342695 total energy tensor([[144.5273]])\n",
      "[-0.4784333]\n",
      "Mode: Train env_steps 200 total rewards -637.5044674873352 total energy tensor([[87.3511]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.92168456]\n",
      "Mode: Train env_steps 200 total rewards -529.7459043003619 total energy tensor([[110.0540]])\n",
      "[-0.5662443]\n",
      "Mode: Train env_steps 200 total rewards -524.8872122522444 total energy tensor([[121.6266]])\n",
      "[0.5937491]\n",
      "Mode: Train env_steps 200 total rewards -631.6828765124083 total energy tensor([[91.0214]])\n",
      "[0.28996944]\n",
      "Mode: Train env_steps 200 total rewards -632.8546453863382 total energy tensor([[89.0149]])\n",
      "[0.9297975]\n",
      "Mode: Train env_steps 200 total rewards -755.7440676614642 total energy tensor([[148.4265]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9843756]\n",
      "Mode: Test env_steps 200 total rewards -629.4038273990154 total energy tensor([[91.8382]])\n",
      "[-0.98213184]\n",
      "Mode: Test env_steps 200 total rewards -750.1882479265332 total energy tensor([[148.7148]])\n",
      "[-0.7729819]\n",
      "Mode: Test env_steps 200 total rewards -643.3013588041067 total energy tensor([[147.5648]])\n",
      "[0.4270849]\n",
      "Mode: Test env_steps 200 total rewards -651.2319815084338 total energy tensor([[149.4677]])\n",
      "[-0.784949]\n",
      "Mode: Test env_steps 200 total rewards -626.8362821117043 total energy tensor([[94.7963]])\n",
      "[-0.04308875]\n",
      "Mode: Test env_steps 200 total rewards -629.0735402628779 total energy tensor([[91.0798]])\n",
      "[0.8609897]\n",
      "Mode: Test env_steps 200 total rewards -652.9274459630251 total energy tensor([[149.9764]])\n",
      "[0.60447586]\n",
      "Mode: Test env_steps 200 total rewards -778.9884568080306 total energy tensor([[147.3648]])\n",
      "[-0.13786098]\n",
      "Mode: Test env_steps 200 total rewards -382.9059375550132 total energy tensor([[116.1392]])\n",
      "[0.7937739]\n",
      "Mode: Test env_steps 200 total rewards -644.5876147672534 total energy tensor([[106.2326]])\n",
      "255000 -638.9444693105994\n",
      "[-0.99134576]\n",
      "Mode: Train env_steps 200 total rewards -554.674334153533 total energy tensor([[150.4775]])\n",
      "[-0.8803964]\n",
      "Mode: Train env_steps 200 total rewards -765.6648623161018 total energy tensor([[150.6102]])\n",
      "[-0.03595411]\n",
      "Mode: Train env_steps 200 total rewards -631.0493398532271 total energy tensor([[95.4831]])\n",
      "[-0.8452314]\n",
      "Mode: Train env_steps 200 total rewards -649.070614695549 total energy tensor([[150.0692]])\n",
      "[-0.8702895]\n",
      "Mode: Train env_steps 200 total rewards -633.923565518111 total energy tensor([[128.6030]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32346708]\n",
      "Mode: Train env_steps 200 total rewards -632.2511588651687 total energy tensor([[89.1668]])\n",
      "[0.5156346]\n",
      "Mode: Train env_steps 200 total rewards -440.99798615369946 total energy tensor([[115.1597]])\n",
      "[0.3437847]\n",
      "Mode: Train env_steps 200 total rewards -886.538844563067 total energy tensor([[142.4031]])\n",
      "[0.64473563]\n",
      "Mode: Train env_steps 200 total rewards -559.4008997008204 total energy tensor([[113.9967]])\n",
      "[-0.29784492]\n",
      "Mode: Train env_steps 200 total rewards -803.5571730211377 total energy tensor([[100.0057]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54210806]\n",
      "Mode: Train env_steps 200 total rewards -627.7228992003947 total energy tensor([[105.2201]])\n",
      "[0.09012812]\n",
      "Mode: Train env_steps 200 total rewards -630.6786620467901 total energy tensor([[98.1016]])\n",
      "[-0.0646558]\n",
      "Mode: Train env_steps 200 total rewards -628.9520006068051 total energy tensor([[115.9337]])\n",
      "[-0.62313324]\n",
      "Mode: Train env_steps 200 total rewards -723.8458922244608 total energy tensor([[117.6512]])\n",
      "[0.9282025]\n",
      "Mode: Train env_steps 200 total rewards -651.4089883342385 total energy tensor([[104.1467]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35738575]\n",
      "Mode: Train env_steps 200 total rewards -632.0508580431342 total energy tensor([[89.4324]])\n",
      "[0.3961243]\n",
      "Mode: Train env_steps 200 total rewards -615.8016083850234 total energy tensor([[95.5265]])\n",
      "[-0.8998663]\n",
      "Mode: Train env_steps 200 total rewards -634.0395780913532 total energy tensor([[114.6231]])\n",
      "[-0.5394896]\n",
      "Mode: Train env_steps 200 total rewards -720.3282428532839 total energy tensor([[102.2167]])\n",
      "[0.02374821]\n",
      "Mode: Train env_steps 200 total rewards -330.68738341575954 total energy tensor([[112.7772]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8789382]\n",
      "Mode: Train env_steps 200 total rewards -632.7965896427631 total energy tensor([[91.9856]])\n",
      "[-0.88351166]\n",
      "Mode: Train env_steps 200 total rewards -632.6547182127833 total energy tensor([[98.3633]])\n",
      "[0.8314605]\n",
      "Mode: Train env_steps 200 total rewards -437.1534117683768 total energy tensor([[133.3108]])\n",
      "[0.00211966]\n",
      "Mode: Train env_steps 200 total rewards -631.5699101313949 total energy tensor([[92.2421]])\n",
      "[0.3902931]\n",
      "Mode: Train env_steps 200 total rewards -515.4564750678837 total energy tensor([[119.4067]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98532116]\n",
      "Mode: Test env_steps 200 total rewards -644.468219101429 total energy tensor([[154.5723]])\n",
      "[0.05297368]\n",
      "Mode: Test env_steps 200 total rewards -636.3506264388561 total energy tensor([[81.4267]])\n",
      "[0.83791614]\n",
      "Mode: Test env_steps 200 total rewards -673.9683266226202 total energy tensor([[97.8523]])\n",
      "[0.535155]\n",
      "Mode: Test env_steps 200 total rewards -639.5819587558508 total energy tensor([[80.1165]])\n",
      "[-0.66087466]\n",
      "Mode: Test env_steps 200 total rewards -535.2957215812057 total energy tensor([[83.1919]])\n",
      "[-0.4056986]\n",
      "Mode: Test env_steps 200 total rewards -502.1491692890413 total energy tensor([[88.2433]])\n",
      "[-0.53509265]\n",
      "Mode: Test env_steps 200 total rewards -635.2352322265506 total energy tensor([[148.3646]])\n",
      "[-0.4179846]\n",
      "Mode: Test env_steps 200 total rewards -651.0602648258209 total energy tensor([[144.1223]])\n",
      "[-0.84782386]\n",
      "Mode: Test env_steps 200 total rewards -719.4436675906181 total energy tensor([[77.7321]])\n",
      "[-0.1098416]\n",
      "Mode: Test env_steps 200 total rewards -640.8795047421008 total energy tensor([[118.5691]])\n",
      "260000 -627.8432691174094\n",
      "[0.26886702]\n",
      "Mode: Train env_steps 200 total rewards -629.5062718186527 total energy tensor([[91.3568]])\n",
      "[-0.4592168]\n",
      "Mode: Train env_steps 200 total rewards -525.3527576429769 total energy tensor([[80.8325]])\n",
      "[0.9880322]\n",
      "Mode: Train env_steps 200 total rewards -641.7272020094097 total energy tensor([[145.2918]])\n",
      "[-0.01268177]\n",
      "Mode: Train env_steps 200 total rewards -639.753738572821 total energy tensor([[130.6207]])\n",
      "[0.41064274]\n",
      "Mode: Train env_steps 200 total rewards -773.292448528111 total energy tensor([[149.9165]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49029234]\n",
      "Mode: Train env_steps 200 total rewards -658.6691584140062 total energy tensor([[105.5367]])\n",
      "[-0.09078688]\n",
      "Mode: Train env_steps 200 total rewards -514.3030327428132 total energy tensor([[109.0968]])\n",
      "[-0.6584699]\n",
      "Mode: Train env_steps 200 total rewards -628.5713151525706 total energy tensor([[114.5192]])\n",
      "[-0.7693099]\n",
      "Mode: Train env_steps 200 total rewards -634.3678810670972 total energy tensor([[149.7209]])\n",
      "[0.31665438]\n",
      "Mode: Train env_steps 200 total rewards -628.0809253118932 total energy tensor([[100.0956]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6069544]\n",
      "Mode: Train env_steps 200 total rewards -700.1282713189721 total energy tensor([[131.1627]])\n",
      "[-0.92249745]\n",
      "Mode: Train env_steps 200 total rewards -376.8456631246954 total energy tensor([[108.6215]])\n",
      "[-0.4912322]\n",
      "Mode: Train env_steps 200 total rewards -643.737571079284 total energy tensor([[154.2386]])\n",
      "[-0.821635]\n",
      "Mode: Train env_steps 200 total rewards -559.8562908694148 total energy tensor([[147.5603]])\n",
      "[-0.69962287]\n",
      "Mode: Train env_steps 200 total rewards -531.364798411727 total energy tensor([[153.3919]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10399343]\n",
      "Mode: Train env_steps 200 total rewards -621.8317165654153 total energy tensor([[100.0244]])\n",
      "[-0.19691704]\n",
      "Mode: Train env_steps 200 total rewards -627.794683046639 total energy tensor([[81.8507]])\n",
      "[-0.64942354]\n",
      "Mode: Train env_steps 200 total rewards -275.50484642060474 total energy tensor([[132.3697]])\n",
      "[-0.5402818]\n",
      "Mode: Train env_steps 200 total rewards -514.500318871811 total energy tensor([[94.3564]])\n",
      "[0.43935362]\n",
      "Mode: Train env_steps 200 total rewards -616.4382690638304 total energy tensor([[101.0627]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25279516]\n",
      "Mode: Train env_steps 200 total rewards -873.910654142499 total energy tensor([[149.6534]])\n",
      "[0.56441724]\n",
      "Mode: Train env_steps 200 total rewards -894.2275540530682 total energy tensor([[144.5864]])\n",
      "[0.57839084]\n",
      "Mode: Train env_steps 200 total rewards -895.3048742115498 total energy tensor([[141.5211]])\n",
      "[-0.25789928]\n",
      "Mode: Train env_steps 200 total rewards -971.8609696626663 total energy tensor([[142.3608]])\n",
      "[-0.62446797]\n",
      "Mode: Train env_steps 200 total rewards -510.6309773847461 total energy tensor([[100.1134]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5743409]\n",
      "Mode: Test env_steps 200 total rewards -632.5463277045637 total energy tensor([[113.4522]])\n",
      "[-0.5355584]\n",
      "Mode: Test env_steps 200 total rewards -5.550836286507547 total energy tensor([[158.0942]])\n",
      "[-0.9200034]\n",
      "Mode: Test env_steps 200 total rewards -626.7994845062494 total energy tensor([[104.9610]])\n",
      "[0.25677648]\n",
      "Mode: Test env_steps 200 total rewards -510.24013168457896 total energy tensor([[94.0769]])\n",
      "[-0.42770782]\n",
      "Mode: Test env_steps 200 total rewards -621.0426228982396 total energy tensor([[108.8423]])\n",
      "[0.23277809]\n",
      "Mode: Test env_steps 200 total rewards -511.49826434254646 total energy tensor([[119.5664]])\n",
      "[-0.81329995]\n",
      "Mode: Test env_steps 200 total rewards -793.9814170077443 total energy tensor([[101.1959]])\n",
      "[0.31791583]\n",
      "Mode: Test env_steps 200 total rewards -626.1606844384223 total energy tensor([[110.1436]])\n",
      "[-0.988716]\n",
      "Mode: Test env_steps 200 total rewards -421.49044765299186 total energy tensor([[120.3985]])\n",
      "[-0.7494904]\n",
      "Mode: Test env_steps 200 total rewards -555.7366466224194 total energy tensor([[115.8100]])\n",
      "265000 -530.5046863144264\n",
      "[0.26066923]\n",
      "Mode: Train env_steps 200 total rewards -7.238185878144577 total energy tensor([[164.3962]])\n",
      "[-0.75730604]\n",
      "Mode: Train env_steps 200 total rewards -508.5620589181781 total energy tensor([[102.7137]])\n",
      "[0.34173614]\n",
      "Mode: Train env_steps 200 total rewards -252.56246573704993 total energy tensor([[125.7182]])\n",
      "[0.29027224]\n",
      "Mode: Train env_steps 200 total rewards -635.7258772719651 total energy tensor([[110.2054]])\n",
      "[0.6157338]\n",
      "Mode: Train env_steps 200 total rewards -592.3638142347336 total energy tensor([[119.6178]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8031915]\n",
      "Mode: Train env_steps 200 total rewards -513.8921782509424 total energy tensor([[94.4278]])\n",
      "[-0.66777796]\n",
      "Mode: Train env_steps 200 total rewards -525.7236158400774 total energy tensor([[155.6620]])\n",
      "[0.51574343]\n",
      "Mode: Train env_steps 200 total rewards -520.2188885882497 total energy tensor([[130.0327]])\n",
      "[0.53292567]\n",
      "Mode: Train env_steps 200 total rewards -678.868635321036 total energy tensor([[117.1004]])\n",
      "[-0.7027987]\n",
      "Mode: Train env_steps 200 total rewards -782.3109140768647 total energy tensor([[128.1653]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.44606316]\n",
      "Mode: Train env_steps 200 total rewards -786.2125129103661 total energy tensor([[152.6827]])\n",
      "[0.8598237]\n",
      "Mode: Train env_steps 200 total rewards -827.5578361302614 total energy tensor([[145.9132]])\n",
      "[-0.0535523]\n",
      "Mode: Train env_steps 200 total rewards -278.87280506128445 total energy tensor([[105.6654]])\n",
      "[-0.58307403]\n",
      "Mode: Train env_steps 200 total rewards -648.5760468093213 total energy tensor([[129.6034]])\n",
      "[0.05155027]\n",
      "Mode: Train env_steps 200 total rewards -756.180544257164 total energy tensor([[146.6999]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29274443]\n",
      "Mode: Train env_steps 200 total rewards -506.45695081725717 total energy tensor([[101.2168]])\n",
      "[0.12384752]\n",
      "Mode: Train env_steps 200 total rewards -646.5557133704424 total energy tensor([[81.9304]])\n",
      "[-0.45344853]\n",
      "Mode: Train env_steps 200 total rewards -515.7171469628811 total energy tensor([[100.8520]])\n",
      "[0.9801381]\n",
      "Mode: Train env_steps 200 total rewards -636.3613502681255 total energy tensor([[83.5589]])\n",
      "[-0.55343056]\n",
      "Mode: Train env_steps 200 total rewards -527.1217501349747 total energy tensor([[94.0336]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31652662]\n",
      "Mode: Train env_steps 200 total rewards -507.5098367445171 total energy tensor([[92.8877]])\n",
      "[0.5382251]\n",
      "Mode: Train env_steps 200 total rewards -508.0097379172221 total energy tensor([[95.5078]])\n",
      "[0.19912374]\n",
      "Mode: Train env_steps 200 total rewards -617.2034924924374 total energy tensor([[121.8055]])\n",
      "[0.31190002]\n",
      "Mode: Train env_steps 200 total rewards -598.056263718754 total energy tensor([[109.8870]])\n",
      "[-0.789934]\n",
      "Mode: Train env_steps 200 total rewards -537.3157611787319 total energy tensor([[153.8037]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2835141]\n",
      "Mode: Test env_steps 200 total rewards -258.07697010645643 total energy tensor([[112.4967]])\n",
      "[0.6208117]\n",
      "Mode: Test env_steps 200 total rewards -776.7227385118604 total energy tensor([[147.6463]])\n",
      "[-0.0609794]\n",
      "Mode: Test env_steps 200 total rewards -643.3906010836363 total energy tensor([[148.7016]])\n",
      "[-0.01264652]\n",
      "Mode: Test env_steps 200 total rewards -135.1558340706979 total energy tensor([[128.9097]])\n",
      "[0.84383994]\n",
      "Mode: Test env_steps 200 total rewards -133.2176514674211 total energy tensor([[139.9660]])\n",
      "[-0.05218188]\n",
      "Mode: Test env_steps 200 total rewards -525.0020306929946 total energy tensor([[93.4211]])\n",
      "[0.6890752]\n",
      "Mode: Test env_steps 200 total rewards -358.28675861191005 total energy tensor([[127.1499]])\n",
      "[0.07745761]\n",
      "Mode: Test env_steps 200 total rewards -391.91282107308507 total energy tensor([[129.4610]])\n",
      "[-0.35597622]\n",
      "Mode: Test env_steps 200 total rewards -641.1783588677645 total energy tensor([[147.6011]])\n",
      "[0.7646832]\n",
      "Mode: Test env_steps 200 total rewards -264.7514064507559 total energy tensor([[128.0677]])\n",
      "270000 -412.76951709365824\n",
      "[-0.04641083]\n",
      "Mode: Train env_steps 200 total rewards -515.7978016491979 total energy tensor([[131.2582]])\n",
      "[-0.9624719]\n",
      "Mode: Train env_steps 200 total rewards -627.6072710752487 total energy tensor([[87.2486]])\n",
      "[-0.9776464]\n",
      "Mode: Train env_steps 200 total rewards -683.2312390729785 total energy tensor([[146.8625]])\n",
      "[-0.3803344]\n",
      "Mode: Train env_steps 200 total rewards -644.8077657073736 total energy tensor([[149.4346]])\n",
      "[0.5203909]\n",
      "Mode: Train env_steps 200 total rewards -649.486716479063 total energy tensor([[146.1946]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45859763]\n",
      "Mode: Train env_steps 200 total rewards -132.99753858183976 total energy tensor([[122.4319]])\n",
      "[0.5093852]\n",
      "Mode: Train env_steps 200 total rewards -394.3492693733424 total energy tensor([[139.6013]])\n",
      "[-0.03771904]\n",
      "Mode: Train env_steps 200 total rewards -252.19795238692313 total energy tensor([[120.6865]])\n",
      "[-0.86056507]\n",
      "Mode: Train env_steps 200 total rewards -627.6292195729911 total energy tensor([[125.5346]])\n",
      "[-0.5259384]\n",
      "Mode: Train env_steps 200 total rewards -6.054674666840583 total energy tensor([[127.6482]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38970497]\n",
      "Mode: Train env_steps 200 total rewards -845.2984421253204 total energy tensor([[145.7673]])\n",
      "[-0.21798725]\n",
      "Mode: Train env_steps 200 total rewards -135.15488839824684 total energy tensor([[132.6664]])\n",
      "[-0.96008444]\n",
      "Mode: Train env_steps 200 total rewards -264.5194567106664 total energy tensor([[123.5697]])\n",
      "[0.6124303]\n",
      "Mode: Train env_steps 200 total rewards -545.2317145671695 total energy tensor([[126.6195]])\n",
      "[-0.6974812]\n",
      "Mode: Train env_steps 200 total rewards -136.83529981970787 total energy tensor([[137.8238]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.29404092]\n",
      "Mode: Train env_steps 200 total rewards -507.2108997832984 total energy tensor([[110.0517]])\n",
      "[0.2123021]\n",
      "Mode: Train env_steps 200 total rewards -391.3381992317736 total energy tensor([[125.4849]])\n",
      "[0.51856107]\n",
      "Mode: Train env_steps 200 total rewards -720.9711037278175 total energy tensor([[107.8990]])\n",
      "[0.14316429]\n",
      "Mode: Train env_steps 200 total rewards -681.7824031598866 total energy tensor([[139.7821]])\n",
      "[0.87964356]\n",
      "Mode: Train env_steps 200 total rewards -702.2530583515763 total energy tensor([[146.7796]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64018804]\n",
      "Mode: Train env_steps 200 total rewards -623.3883788064122 total energy tensor([[118.4201]])\n",
      "[-0.95434004]\n",
      "Mode: Train env_steps 200 total rewards -513.8417525179684 total energy tensor([[106.7397]])\n",
      "[-0.2641445]\n",
      "Mode: Train env_steps 200 total rewards -375.9266465418041 total energy tensor([[116.6385]])\n",
      "[-0.10536163]\n",
      "Mode: Train env_steps 200 total rewards -636.1481984108686 total energy tensor([[79.5923]])\n",
      "[0.56958115]\n",
      "Mode: Train env_steps 200 total rewards -417.61717396974564 total energy tensor([[136.9588]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41387615]\n",
      "Mode: Test env_steps 200 total rewards -135.40150332450867 total energy tensor([[123.4739]])\n",
      "[0.07196521]\n",
      "Mode: Test env_steps 200 total rewards -133.1587061099708 total energy tensor([[129.7541]])\n",
      "[0.28725237]\n",
      "Mode: Test env_steps 200 total rewards -691.4019943159074 total energy tensor([[128.7716]])\n",
      "[-0.72122246]\n",
      "Mode: Test env_steps 200 total rewards -134.01090919412673 total energy tensor([[124.8722]])\n",
      "[0.60822326]\n",
      "Mode: Test env_steps 200 total rewards -261.5592909157276 total energy tensor([[129.7144]])\n",
      "[-0.10834372]\n",
      "Mode: Test env_steps 200 total rewards -631.1824164390564 total energy tensor([[91.9835]])\n",
      "[-0.8022271]\n",
      "Mode: Test env_steps 200 total rewards -382.4333923779777 total energy tensor([[114.9568]])\n",
      "[0.15616414]\n",
      "Mode: Test env_steps 200 total rewards -130.53013490745798 total energy tensor([[115.0027]])\n",
      "[0.37286022]\n",
      "Mode: Test env_steps 200 total rewards -630.005279071629 total energy tensor([[91.1916]])\n",
      "[-0.94631225]\n",
      "Mode: Test env_steps 200 total rewards -638.3186319693923 total energy tensor([[155.1232]])\n",
      "275000 -376.8002258625755\n",
      "[-0.8665359]\n",
      "Mode: Train env_steps 200 total rewards -130.48571496084332 total energy tensor([[127.6096]])\n",
      "[-0.33426726]\n",
      "Mode: Train env_steps 200 total rewards -525.5021906681359 total energy tensor([[117.9318]])\n",
      "[0.05933823]\n",
      "Mode: Train env_steps 200 total rewards -514.8088668594137 total energy tensor([[114.0138]])\n",
      "[-0.85253745]\n",
      "Mode: Train env_steps 200 total rewards -555.8942214138806 total energy tensor([[121.6004]])\n",
      "[-0.27307898]\n",
      "Mode: Train env_steps 200 total rewards -266.9405913576484 total energy tensor([[150.3963]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4268423]\n",
      "Mode: Train env_steps 200 total rewards -631.7484436631203 total energy tensor([[89.3697]])\n",
      "[-0.587486]\n",
      "Mode: Train env_steps 200 total rewards -631.851258687675 total energy tensor([[91.6441]])\n",
      "[-0.27172628]\n",
      "Mode: Train env_steps 200 total rewards -608.1797173265368 total energy tensor([[125.1720]])\n",
      "[0.77777743]\n",
      "Mode: Train env_steps 200 total rewards -630.5052880253643 total energy tensor([[111.5387]])\n",
      "[0.11376516]\n",
      "Mode: Train env_steps 200 total rewards -506.99000098742545 total energy tensor([[105.3477]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24405041]\n",
      "Mode: Train env_steps 200 total rewards -613.3068960160017 total energy tensor([[97.8962]])\n",
      "[-0.70817566]\n",
      "Mode: Train env_steps 200 total rewards -611.3258496653289 total energy tensor([[100.4004]])\n",
      "[-0.19773199]\n",
      "Mode: Train env_steps 200 total rewards -521.9840890122578 total energy tensor([[95.3007]])\n",
      "[-0.36504182]\n",
      "Mode: Train env_steps 200 total rewards -667.297374881804 total energy tensor([[105.8414]])\n",
      "[-0.8247893]\n",
      "Mode: Train env_steps 200 total rewards -585.5209390539676 total energy tensor([[101.7420]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5168103]\n",
      "Mode: Train env_steps 200 total rewards -259.80717131402344 total energy tensor([[112.2385]])\n",
      "[-0.46601757]\n",
      "Mode: Train env_steps 200 total rewards -370.62924314662814 total energy tensor([[114.6696]])\n",
      "[-0.14293167]\n",
      "Mode: Train env_steps 200 total rewards -383.7735150465742 total energy tensor([[114.7129]])\n",
      "[0.03884736]\n",
      "Mode: Train env_steps 200 total rewards -138.80975880799815 total energy tensor([[128.5289]])\n",
      "[0.9041733]\n",
      "Mode: Train env_steps 200 total rewards -629.6726400107145 total energy tensor([[94.1937]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18560812]\n",
      "Mode: Train env_steps 200 total rewards -634.4896928071976 total energy tensor([[85.5872]])\n",
      "[-0.05228411]\n",
      "Mode: Train env_steps 200 total rewards -387.74153466150165 total energy tensor([[113.2354]])\n",
      "[0.6949542]\n",
      "Mode: Train env_steps 200 total rewards -268.6806336399168 total energy tensor([[121.8980]])\n",
      "[0.03413088]\n",
      "Mode: Train env_steps 200 total rewards -271.4033946041018 total energy tensor([[119.8525]])\n",
      "[0.3940291]\n",
      "Mode: Train env_steps 200 total rewards -367.20215218886733 total energy tensor([[114.6436]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00153622]\n",
      "Mode: Test env_steps 200 total rewards -133.1866287770681 total energy tensor([[100.0318]])\n",
      "[0.15164572]\n",
      "Mode: Test env_steps 200 total rewards -136.73110267147422 total energy tensor([[115.3078]])\n",
      "[0.38416967]\n",
      "Mode: Test env_steps 200 total rewards -133.3008827464655 total energy tensor([[114.3519]])\n",
      "[-0.8164089]\n",
      "Mode: Test env_steps 200 total rewards -134.0590511308983 total energy tensor([[104.8940]])\n",
      "[-0.4219499]\n",
      "Mode: Test env_steps 200 total rewards -386.8478608848527 total energy tensor([[124.3027]])\n",
      "[0.82580346]\n",
      "Mode: Test env_steps 200 total rewards -265.862909803167 total energy tensor([[119.8077]])\n",
      "[-0.00923496]\n",
      "Mode: Test env_steps 200 total rewards -261.3286800272763 total energy tensor([[108.1424]])\n",
      "[-0.44339225]\n",
      "Mode: Test env_steps 200 total rewards -257.7705132169649 total energy tensor([[107.4671]])\n",
      "[-0.48589697]\n",
      "Mode: Test env_steps 200 total rewards -513.54229083471 total energy tensor([[127.0336]])\n",
      "[0.4926961]\n",
      "Mode: Test env_steps 200 total rewards -632.1872781980783 total energy tensor([[121.2086]])\n",
      "280000 -285.48171982909554\n",
      "[-0.11912935]\n",
      "Mode: Train env_steps 200 total rewards -131.94530269596726 total energy tensor([[109.1016]])\n",
      "[0.79880816]\n",
      "Mode: Train env_steps 200 total rewards -510.41815137676895 total energy tensor([[125.7166]])\n",
      "[0.15178491]\n",
      "Mode: Train env_steps 200 total rewards -630.514684587717 total energy tensor([[86.7659]])\n",
      "[-0.8400084]\n",
      "Mode: Train env_steps 200 total rewards -260.4957519862801 total energy tensor([[111.4076]])\n",
      "[-0.6035285]\n",
      "Mode: Train env_steps 200 total rewards -503.1407151259482 total energy tensor([[122.8483]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7271302]\n",
      "Mode: Train env_steps 200 total rewards -391.00183238461614 total energy tensor([[114.8453]])\n",
      "[0.03745848]\n",
      "Mode: Train env_steps 200 total rewards -637.4230961129069 total energy tensor([[101.8540]])\n",
      "[-0.8983706]\n",
      "Mode: Train env_steps 200 total rewards -620.8615706190467 total energy tensor([[100.4614]])\n",
      "[0.3650868]\n",
      "Mode: Train env_steps 200 total rewards -636.7736087888479 total energy tensor([[77.9845]])\n",
      "[-0.3549608]\n",
      "Mode: Train env_steps 200 total rewards -659.1571765989065 total energy tensor([[98.2401]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00706919]\n",
      "Mode: Train env_steps 200 total rewards -387.3749152403325 total energy tensor([[108.4357]])\n",
      "[-0.5998042]\n",
      "Mode: Train env_steps 200 total rewards -390.34878866933286 total energy tensor([[108.8161]])\n",
      "[0.91756535]\n",
      "Mode: Train env_steps 200 total rewards -509.5457351952791 total energy tensor([[99.6025]])\n",
      "[-0.85627145]\n",
      "Mode: Train env_steps 200 total rewards -318.4577581291087 total energy tensor([[120.1683]])\n",
      "[-0.33953503]\n",
      "Mode: Train env_steps 200 total rewards -390.95071079954505 total energy tensor([[129.4886]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90263313]\n",
      "Mode: Train env_steps 200 total rewards -512.8043427839875 total energy tensor([[102.2214]])\n",
      "[-0.9940197]\n",
      "Mode: Train env_steps 200 total rewards -514.6300421077758 total energy tensor([[97.1097]])\n",
      "[0.3964208]\n",
      "Mode: Train env_steps 200 total rewards -333.96232922561467 total energy tensor([[116.4218]])\n",
      "[0.4449821]\n",
      "Mode: Train env_steps 200 total rewards -368.6255138795823 total energy tensor([[115.5056]])\n",
      "[-0.31332496]\n",
      "Mode: Train env_steps 200 total rewards -533.1655154963955 total energy tensor([[96.3887]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14315698]\n",
      "Mode: Train env_steps 200 total rewards -130.65975323179737 total energy tensor([[85.9422]])\n",
      "[-0.87842643]\n",
      "Mode: Train env_steps 200 total rewards -542.3720383197069 total energy tensor([[137.2017]])\n",
      "[-0.09732156]\n",
      "Mode: Train env_steps 200 total rewards -502.7214115187526 total energy tensor([[139.7064]])\n",
      "[-0.1216485]\n",
      "Mode: Train env_steps 200 total rewards -516.3092066682875 total energy tensor([[152.7993]])\n",
      "[0.5221911]\n",
      "Mode: Train env_steps 200 total rewards -513.4398149810731 total energy tensor([[125.7910]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23544914]\n",
      "Mode: Test env_steps 200 total rewards -515.4508387669921 total energy tensor([[144.6779]])\n",
      "[0.4479671]\n",
      "Mode: Test env_steps 200 total rewards -581.5051679679891 total energy tensor([[126.5177]])\n",
      "[-0.6566143]\n",
      "Mode: Test env_steps 200 total rewards -380.84723114664666 total energy tensor([[103.8463]])\n",
      "[0.5690116]\n",
      "Mode: Test env_steps 200 total rewards -377.2953146456275 total energy tensor([[96.2823]])\n",
      "[0.5267182]\n",
      "Mode: Test env_steps 200 total rewards -265.73545756877866 total energy tensor([[112.7242]])\n",
      "[0.8227394]\n",
      "Mode: Test env_steps 200 total rewards -259.8825244870968 total energy tensor([[92.6832]])\n",
      "[-0.22146122]\n",
      "Mode: Test env_steps 200 total rewards -385.5028942001518 total energy tensor([[91.6420]])\n",
      "[0.6831391]\n",
      "Mode: Test env_steps 200 total rewards -266.97030579485 total energy tensor([[110.6467]])\n",
      "[-0.49913934]\n",
      "Mode: Test env_steps 200 total rewards -386.6700541076716 total energy tensor([[91.6335]])\n",
      "[0.48943815]\n",
      "Mode: Test env_steps 200 total rewards -386.912394371815 total energy tensor([[100.1219]])\n",
      "285000 -380.6772183057619\n",
      "[0.603161]\n",
      "Mode: Train env_steps 200 total rewards -255.74096703575924 total energy tensor([[84.1208]])\n",
      "[0.5437606]\n",
      "Mode: Train env_steps 200 total rewards -381.6409689183347 total energy tensor([[104.2168]])\n",
      "[-0.2855319]\n",
      "Mode: Train env_steps 200 total rewards -398.93128872383386 total energy tensor([[112.4578]])\n",
      "[0.81873256]\n",
      "Mode: Train env_steps 200 total rewards -371.87360943685053 total energy tensor([[115.9266]])\n",
      "[-0.7996699]\n",
      "Mode: Train env_steps 200 total rewards -260.6133546366764 total energy tensor([[101.7674]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3395815]\n",
      "Mode: Train env_steps 200 total rewards -619.2772673107684 total energy tensor([[110.3441]])\n",
      "[0.66272634]\n",
      "Mode: Train env_steps 200 total rewards -641.5130680352449 total energy tensor([[79.7934]])\n",
      "[-0.5247222]\n",
      "Mode: Train env_steps 200 total rewards -262.5787944365293 total energy tensor([[122.3508]])\n",
      "[0.49901536]\n",
      "Mode: Train env_steps 200 total rewards -389.2378632836044 total energy tensor([[109.6225]])\n",
      "[-0.8177056]\n",
      "Mode: Train env_steps 200 total rewards -264.5131084881723 total energy tensor([[136.4985]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6994467]\n",
      "Mode: Train env_steps 200 total rewards -506.2123856730759 total energy tensor([[123.3626]])\n",
      "[0.7073474]\n",
      "Mode: Train env_steps 200 total rewards -265.5251650996506 total energy tensor([[125.4317]])\n",
      "[0.20015688]\n",
      "Mode: Train env_steps 200 total rewards -385.98878358490765 total energy tensor([[120.5239]])\n",
      "[0.70724136]\n",
      "Mode: Train env_steps 200 total rewards -380.3954522330314 total energy tensor([[122.7680]])\n",
      "[0.8723694]\n",
      "Mode: Train env_steps 200 total rewards -258.90145754255354 total energy tensor([[117.4279]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32525116]\n",
      "Mode: Train env_steps 200 total rewards -510.3631287124008 total energy tensor([[124.6607]])\n",
      "[-0.96907884]\n",
      "Mode: Train env_steps 200 total rewards -260.381624890957 total energy tensor([[125.9249]])\n",
      "[0.8636082]\n",
      "Mode: Train env_steps 200 total rewards -259.7254808358848 total energy tensor([[123.3509]])\n",
      "[-0.48723102]\n",
      "Mode: Train env_steps 200 total rewards -508.6890300437808 total energy tensor([[103.3354]])\n",
      "[-0.05576271]\n",
      "Mode: Train env_steps 200 total rewards -387.23590242117643 total energy tensor([[110.7934]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03158713]\n",
      "Mode: Train env_steps 200 total rewards -263.2194646857679 total energy tensor([[131.7185]])\n",
      "[0.0238111]\n",
      "Mode: Train env_steps 200 total rewards -467.1417306512594 total energy tensor([[123.2893]])\n",
      "[-0.26085487]\n",
      "Mode: Train env_steps 200 total rewards -381.4314636364579 total energy tensor([[122.5299]])\n",
      "[0.502039]\n",
      "Mode: Train env_steps 200 total rewards -534.1904054954648 total energy tensor([[124.1916]])\n",
      "[0.6057088]\n",
      "Mode: Train env_steps 200 total rewards -605.1261887084693 total energy tensor([[125.4587]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1447068]\n",
      "Mode: Test env_steps 200 total rewards -267.35043478384614 total energy tensor([[136.3477]])\n",
      "[-0.12922738]\n",
      "Mode: Test env_steps 200 total rewards -141.0294674905017 total energy tensor([[137.7800]])\n",
      "[-0.7203912]\n",
      "Mode: Test env_steps 200 total rewards -383.6997844390571 total energy tensor([[121.6304]])\n",
      "[-0.25661516]\n",
      "Mode: Test env_steps 200 total rewards -386.53969475999475 total energy tensor([[115.4651]])\n",
      "[-0.11814117]\n",
      "Mode: Test env_steps 200 total rewards -263.1557977916673 total energy tensor([[120.2833]])\n",
      "[-0.44466752]\n",
      "Mode: Test env_steps 200 total rewards -383.0407468266785 total energy tensor([[130.3374]])\n",
      "[-0.07383416]\n",
      "Mode: Test env_steps 200 total rewards -263.9672337435186 total energy tensor([[121.6910]])\n",
      "[-0.554729]\n",
      "Mode: Test env_steps 200 total rewards -265.00708572007716 total energy tensor([[132.3410]])\n",
      "[0.36329886]\n",
      "Mode: Test env_steps 200 total rewards -260.5569227654487 total energy tensor([[116.4210]])\n",
      "[-0.21330592]\n",
      "Mode: Test env_steps 200 total rewards -265.0035393219441 total energy tensor([[134.4298]])\n",
      "290000 -287.9350707642734\n",
      "[0.5249137]\n",
      "Mode: Train env_steps 200 total rewards -138.8694027736783 total energy tensor([[126.7452]])\n",
      "[-0.47949398]\n",
      "Mode: Train env_steps 200 total rewards -380.0665249414742 total energy tensor([[124.1213]])\n",
      "[-0.99821943]\n",
      "Mode: Train env_steps 200 total rewards -265.6897088342812 total energy tensor([[118.8360]])\n",
      "[0.8703517]\n",
      "Mode: Train env_steps 200 total rewards -263.0360670145601 total energy tensor([[121.7132]])\n",
      "[-0.60962826]\n",
      "Mode: Train env_steps 200 total rewards -260.02934367768466 total energy tensor([[134.4889]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8442468]\n",
      "Mode: Train env_steps 200 total rewards -383.5691986354068 total energy tensor([[124.7483]])\n",
      "[0.6842888]\n",
      "Mode: Train env_steps 200 total rewards -382.20345668680966 total energy tensor([[122.0047]])\n",
      "[-0.4390852]\n",
      "Mode: Train env_steps 200 total rewards -257.6949609005824 total energy tensor([[121.1209]])\n",
      "[0.7064784]\n",
      "Mode: Train env_steps 200 total rewards -263.47592971101403 total energy tensor([[115.4532]])\n",
      "[0.25853476]\n",
      "Mode: Train env_steps 200 total rewards -496.2138679251075 total energy tensor([[111.9788]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05794483]\n",
      "Mode: Train env_steps 200 total rewards -266.40708550438285 total energy tensor([[136.1048]])\n",
      "[0.33429384]\n",
      "Mode: Train env_steps 200 total rewards -266.84220802411437 total energy tensor([[125.2549]])\n",
      "[-0.46613795]\n",
      "Mode: Train env_steps 200 total rewards -273.31491882074624 total energy tensor([[142.7959]])\n",
      "[-0.5003748]\n",
      "Mode: Train env_steps 200 total rewards -514.0265203583986 total energy tensor([[131.4843]])\n",
      "[0.61894524]\n",
      "Mode: Train env_steps 200 total rewards -381.4990459224209 total energy tensor([[134.9770]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.64659584]\n",
      "Mode: Train env_steps 200 total rewards -267.10084607463796 total energy tensor([[114.9913]])\n",
      "[0.01841835]\n",
      "Mode: Train env_steps 200 total rewards -389.1698129978031 total energy tensor([[112.6575]])\n",
      "[-0.9908818]\n",
      "Mode: Train env_steps 200 total rewards -386.22899229079485 total energy tensor([[107.7702]])\n",
      "[0.39794967]\n",
      "Mode: Train env_steps 200 total rewards -388.88481193222106 total energy tensor([[109.0355]])\n",
      "[0.09692444]\n",
      "Mode: Train env_steps 200 total rewards -508.0687867850065 total energy tensor([[103.2712]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37897015]\n",
      "Mode: Train env_steps 200 total rewards -356.178882105276 total energy tensor([[105.5642]])\n",
      "[0.38843867]\n",
      "Mode: Train env_steps 200 total rewards -258.0523433946073 total energy tensor([[110.9507]])\n",
      "[-0.22189452]\n",
      "Mode: Train env_steps 200 total rewards -391.5325139090419 total energy tensor([[133.0484]])\n",
      "[0.45873985]\n",
      "Mode: Train env_steps 200 total rewards -138.1927706003189 total energy tensor([[128.6373]])\n",
      "[-0.848759]\n",
      "Mode: Train env_steps 200 total rewards -142.04277937486768 total energy tensor([[129.0306]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87004983]\n",
      "Mode: Test env_steps 200 total rewards -494.7192270513624 total energy tensor([[107.7263]])\n",
      "[0.11750561]\n",
      "Mode: Test env_steps 200 total rewards -386.9357684869319 total energy tensor([[105.7417]])\n",
      "[-0.6621716]\n",
      "Mode: Test env_steps 200 total rewards -387.4496550112963 total energy tensor([[112.9133]])\n",
      "[-0.34340736]\n",
      "Mode: Test env_steps 200 total rewards -501.706625232473 total energy tensor([[111.9254]])\n",
      "[0.17440891]\n",
      "Mode: Test env_steps 200 total rewards -388.2979083172977 total energy tensor([[111.8278]])\n",
      "[0.8341194]\n",
      "Mode: Test env_steps 200 total rewards -519.8731138156727 total energy tensor([[105.7382]])\n",
      "[0.40101436]\n",
      "Mode: Test env_steps 200 total rewards -389.8792740771023 total energy tensor([[108.2059]])\n",
      "[-0.22380121]\n",
      "Mode: Test env_steps 200 total rewards -269.96380984643474 total energy tensor([[112.3442]])\n",
      "[0.49387503]\n",
      "Mode: Test env_steps 200 total rewards -390.57015499519184 total energy tensor([[107.2031]])\n",
      "[0.16396971]\n",
      "Mode: Test env_steps 200 total rewards -617.000352466479 total energy tensor([[115.2396]])\n",
      "295000 -434.63958893002416\n",
      "[0.02700342]\n",
      "Mode: Train env_steps 200 total rewards -384.92179113905877 total energy tensor([[105.5955]])\n",
      "[0.62454176]\n",
      "Mode: Train env_steps 200 total rewards -263.037193702301 total energy tensor([[114.0053]])\n",
      "[0.15209566]\n",
      "Mode: Train env_steps 200 total rewards -382.29634051490575 total energy tensor([[109.5375]])\n",
      "[-0.5050432]\n",
      "Mode: Train env_steps 200 total rewards -513.3210957776755 total energy tensor([[114.9599]])\n",
      "[-0.75678676]\n",
      "Mode: Train env_steps 200 total rewards -387.7528850939125 total energy tensor([[114.1269]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9466752]\n",
      "Mode: Train env_steps 200 total rewards -385.77475155703723 total energy tensor([[103.0672]])\n",
      "[0.06063822]\n",
      "Mode: Train env_steps 200 total rewards -520.2902530459687 total energy tensor([[118.8928]])\n",
      "[-0.64767957]\n",
      "Mode: Train env_steps 200 total rewards -389.1272493880242 total energy tensor([[100.8540]])\n",
      "[-0.8384401]\n",
      "Mode: Train env_steps 200 total rewards -504.23343893140554 total energy tensor([[105.2112]])\n",
      "[0.03081583]\n",
      "Mode: Train env_steps 200 total rewards -283.5547431074083 total energy tensor([[133.6298]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1006625]\n",
      "Mode: Train env_steps 200 total rewards -499.2010988108814 total energy tensor([[128.7645]])\n",
      "[-0.85215384]\n",
      "Mode: Train env_steps 200 total rewards -569.873103832826 total energy tensor([[123.0485]])\n",
      "[-0.29268292]\n",
      "Mode: Train env_steps 200 total rewards -530.5203847792 total energy tensor([[111.5932]])\n",
      "[0.81682837]\n",
      "Mode: Train env_steps 200 total rewards -260.03968537040055 total energy tensor([[116.9417]])\n",
      "[0.93254983]\n",
      "Mode: Train env_steps 200 total rewards -491.06452415138483 total energy tensor([[128.7705]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14947008]\n",
      "Mode: Train env_steps 200 total rewards -153.82728325971402 total energy tensor([[127.7185]])\n",
      "[-0.5581663]\n",
      "Mode: Train env_steps 200 total rewards -257.8036156729213 total energy tensor([[119.2400]])\n",
      "[0.2169682]\n",
      "Mode: Train env_steps 200 total rewards -400.7847491612192 total energy tensor([[137.2356]])\n",
      "[-0.9241758]\n",
      "Mode: Train env_steps 200 total rewards -130.66159727680497 total energy tensor([[123.0712]])\n",
      "[-0.15991952]\n",
      "Mode: Train env_steps 200 total rewards -260.73607842903584 total energy tensor([[108.6569]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28638217]\n",
      "Mode: Train env_steps 200 total rewards -569.8177546877414 total energy tensor([[118.5719]])\n",
      "[-0.42358643]\n",
      "Mode: Train env_steps 200 total rewards -386.61020336672664 total energy tensor([[105.9360]])\n",
      "[-0.24966748]\n",
      "Mode: Train env_steps 200 total rewards -215.20995168865193 total energy tensor([[142.9544]])\n",
      "[0.25279966]\n",
      "Mode: Train env_steps 200 total rewards -385.8728362247348 total energy tensor([[120.2379]])\n",
      "[0.47237137]\n",
      "Mode: Train env_steps 200 total rewards -388.3164975345135 total energy tensor([[121.2249]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20992906]\n",
      "Mode: Test env_steps 200 total rewards -261.63704316783696 total energy tensor([[103.0182]])\n",
      "[-0.08267395]\n",
      "Mode: Test env_steps 200 total rewards -500.4020269382745 total energy tensor([[119.2318]])\n",
      "[-0.41378835]\n",
      "Mode: Test env_steps 200 total rewards -276.45143967680633 total energy tensor([[115.2564]])\n",
      "[-0.39453173]\n",
      "Mode: Test env_steps 200 total rewards -413.7733060643077 total energy tensor([[134.1050]])\n",
      "[0.05601001]\n",
      "Mode: Test env_steps 200 total rewards -375.1880668438971 total energy tensor([[118.9922]])\n",
      "[0.9161253]\n",
      "Mode: Test env_steps 200 total rewards -10.393497982586268 total energy tensor([[95.8000]])\n",
      "[0.04536035]\n",
      "Mode: Test env_steps 200 total rewards -388.8307739458978 total energy tensor([[116.4673]])\n",
      "[0.71244454]\n",
      "Mode: Test env_steps 200 total rewards -8.86879832658451 total energy tensor([[98.9728]])\n",
      "[0.51488376]\n",
      "Mode: Test env_steps 200 total rewards -388.95222432538867 total energy tensor([[113.0976]])\n",
      "[0.6120155]\n",
      "Mode: Test env_steps 200 total rewards -508.68170366995037 total energy tensor([[118.8813]])\n",
      "300000 -313.31788809415303\n",
      "[-0.8765236]\n",
      "Mode: Train env_steps 200 total rewards -371.92247897479683 total energy tensor([[109.7640]])\n",
      "[0.5792276]\n",
      "Mode: Train env_steps 200 total rewards -380.3688703356311 total energy tensor([[111.8695]])\n",
      "[0.79631454]\n",
      "Mode: Train env_steps 200 total rewards -252.8299949108623 total energy tensor([[104.3497]])\n",
      "[0.3721155]\n",
      "Mode: Train env_steps 200 total rewards -389.30583827290684 total energy tensor([[111.7282]])\n",
      "[0.11655398]\n",
      "Mode: Train env_steps 200 total rewards -490.88534463196993 total energy tensor([[123.0580]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01481629]\n",
      "Mode: Train env_steps 200 total rewards -252.86220802972093 total energy tensor([[104.2658]])\n",
      "[-0.3114717]\n",
      "Mode: Train env_steps 200 total rewards -675.4286565352231 total energy tensor([[115.6629]])\n",
      "[-0.93555766]\n",
      "Mode: Train env_steps 200 total rewards -482.362577104941 total energy tensor([[117.4111]])\n",
      "[-0.18422079]\n",
      "Mode: Train env_steps 200 total rewards -256.12661169841886 total energy tensor([[121.8803]])\n",
      "[0.3602043]\n",
      "Mode: Train env_steps 200 total rewards -8.717700355686247 total energy tensor([[96.5121]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20326649]\n",
      "Mode: Train env_steps 200 total rewards -134.85825932119042 total energy tensor([[107.0734]])\n",
      "[0.6419115]\n",
      "Mode: Train env_steps 200 total rewards -384.2617376111448 total energy tensor([[110.1658]])\n",
      "[-0.13771963]\n",
      "Mode: Train env_steps 200 total rewards -377.766285514459 total energy tensor([[109.6845]])\n",
      "[0.03787157]\n",
      "Mode: Train env_steps 200 total rewards -259.9728600308299 total energy tensor([[93.4655]])\n",
      "[-0.29261118]\n",
      "Mode: Train env_steps 200 total rewards -250.9202361460775 total energy tensor([[88.6108]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.79196566]\n",
      "Mode: Train env_steps 200 total rewards -263.13181581906974 total energy tensor([[110.5423]])\n",
      "[0.93574256]\n",
      "Mode: Train env_steps 200 total rewards -130.75314921047539 total energy tensor([[89.1237]])\n",
      "[0.10078408]\n",
      "Mode: Train env_steps 200 total rewards -135.67208404187113 total energy tensor([[96.2093]])\n",
      "[-0.63403994]\n",
      "Mode: Train env_steps 200 total rewards -526.0879605859518 total energy tensor([[142.8681]])\n",
      "[0.15720011]\n",
      "Mode: Train env_steps 200 total rewards -6.3487704164290335 total energy tensor([[77.4884]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35969508]\n",
      "Mode: Train env_steps 200 total rewards -263.05484659795184 total energy tensor([[107.1532]])\n",
      "[-0.6926717]\n",
      "Mode: Train env_steps 200 total rewards -386.5499632060528 total energy tensor([[110.4856]])\n",
      "[0.0967169]\n",
      "Mode: Train env_steps 200 total rewards -388.5810667797923 total energy tensor([[109.2766]])\n",
      "[-0.14931124]\n",
      "Mode: Train env_steps 200 total rewards -388.5736910495907 total energy tensor([[110.1215]])\n",
      "[0.63333297]\n",
      "Mode: Train env_steps 200 total rewards -388.44932537179557 total energy tensor([[111.4147]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7885784]\n",
      "Mode: Test env_steps 200 total rewards -133.85100793057063 total energy tensor([[105.7539]])\n",
      "[-0.61251974]\n",
      "Mode: Test env_steps 200 total rewards -384.7335101580247 total energy tensor([[107.5402]])\n",
      "[-0.86418927]\n",
      "Mode: Test env_steps 200 total rewards -256.6406799881952 total energy tensor([[124.5341]])\n",
      "[0.00477451]\n",
      "Mode: Test env_steps 200 total rewards -260.1978649329394 total energy tensor([[113.8386]])\n",
      "[0.24331392]\n",
      "Mode: Test env_steps 200 total rewards -262.13639082718873 total energy tensor([[115.9148]])\n",
      "[0.43371144]\n",
      "Mode: Test env_steps 200 total rewards -257.2438339116052 total energy tensor([[106.6083]])\n",
      "[0.2519137]\n",
      "Mode: Test env_steps 200 total rewards -384.6817931840196 total energy tensor([[108.0314]])\n",
      "[-0.1437381]\n",
      "Mode: Test env_steps 200 total rewards -379.6189563568769 total energy tensor([[110.9996]])\n",
      "[0.8147438]\n",
      "Mode: Test env_steps 200 total rewards -503.40394670143723 total energy tensor([[126.1621]])\n",
      "[-0.00729191]\n",
      "Mode: Test env_steps 200 total rewards -126.20287757576443 total energy tensor([[95.5342]])\n",
      "305000 -294.8710861566622\n",
      "[-0.69544715]\n",
      "Mode: Train env_steps 200 total rewards -258.9848641753197 total energy tensor([[108.5885]])\n",
      "[-0.10592139]\n",
      "Mode: Train env_steps 200 total rewards -138.5365848869551 total energy tensor([[118.9627]])\n",
      "[0.52195525]\n",
      "Mode: Train env_steps 200 total rewards -127.07172949943924 total energy tensor([[113.0707]])\n",
      "[-0.45186955]\n",
      "Mode: Train env_steps 200 total rewards -255.58174757752568 total energy tensor([[123.0221]])\n",
      "[0.41392285]\n",
      "Mode: Train env_steps 200 total rewards -389.5597774591297 total energy tensor([[105.9312]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45164576]\n",
      "Mode: Train env_steps 200 total rewards -123.81616031250451 total energy tensor([[77.0793]])\n",
      "[0.10143963]\n",
      "Mode: Train env_steps 200 total rewards -256.73569929227233 total energy tensor([[104.7932]])\n",
      "[-0.19290753]\n",
      "Mode: Train env_steps 200 total rewards -130.77459110226482 total energy tensor([[88.1808]])\n",
      "[0.5197022]\n",
      "Mode: Train env_steps 200 total rewards -126.1098363394849 total energy tensor([[80.1366]])\n",
      "[-0.5355674]\n",
      "Mode: Train env_steps 200 total rewards -336.24601429281756 total energy tensor([[107.7426]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5213581]\n",
      "Mode: Train env_steps 200 total rewards -509.5172053128481 total energy tensor([[107.0630]])\n",
      "[-0.73075]\n",
      "Mode: Train env_steps 200 total rewards -390.28593164961785 total energy tensor([[111.5736]])\n",
      "[0.12494221]\n",
      "Mode: Train env_steps 200 total rewards -379.9961674939841 total energy tensor([[120.4897]])\n",
      "[0.25413483]\n",
      "Mode: Train env_steps 200 total rewards -7.690862524439581 total energy tensor([[100.1251]])\n",
      "[-0.88444006]\n",
      "Mode: Train env_steps 200 total rewards -299.43797224015 total energy tensor([[116.0413]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10852627]\n",
      "Mode: Train env_steps 200 total rewards -414.0861933210472 total energy tensor([[91.4928]])\n",
      "[0.9244988]\n",
      "Mode: Train env_steps 200 total rewards -258.21738025546074 total energy tensor([[109.6481]])\n",
      "[-0.42312086]\n",
      "Mode: Train env_steps 200 total rewards -228.61886876806966 total energy tensor([[75.9910]])\n",
      "[0.22445369]\n",
      "Mode: Train env_steps 200 total rewards -391.3001015786722 total energy tensor([[112.9837]])\n",
      "[0.60515934]\n",
      "Mode: Train env_steps 200 total rewards -375.7376047602156 total energy tensor([[106.0355]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7959979]\n",
      "Mode: Train env_steps 200 total rewards -386.4937406722456 total energy tensor([[120.3792]])\n",
      "[-0.7449664]\n",
      "Mode: Train env_steps 200 total rewards -376.46311598690227 total energy tensor([[115.1297]])\n",
      "[0.3794608]\n",
      "Mode: Train env_steps 200 total rewards -257.4815001562238 total energy tensor([[109.9573]])\n",
      "[0.423987]\n",
      "Mode: Train env_steps 200 total rewards -260.601663724985 total energy tensor([[110.6866]])\n",
      "[0.06874198]\n",
      "Mode: Train env_steps 200 total rewards -270.40787948062643 total energy tensor([[106.3686]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64650387]\n",
      "Mode: Test env_steps 200 total rewards -396.75331776216626 total energy tensor([[113.7195]])\n",
      "[0.83344996]\n",
      "Mode: Test env_steps 200 total rewards -130.70745856687427 total energy tensor([[109.0050]])\n",
      "[0.38210696]\n",
      "Mode: Test env_steps 200 total rewards -505.17779739946127 total energy tensor([[109.8389]])\n",
      "[-0.21977927]\n",
      "Mode: Test env_steps 200 total rewards -394.8598633352667 total energy tensor([[108.2402]])\n",
      "[0.64887136]\n",
      "Mode: Test env_steps 200 total rewards -506.9461647644639 total energy tensor([[121.7422]])\n",
      "[-0.40364623]\n",
      "Mode: Test env_steps 200 total rewards -508.60653387755156 total energy tensor([[109.8705]])\n",
      "[0.28150275]\n",
      "Mode: Test env_steps 200 total rewards -659.5202409438789 total energy tensor([[104.6130]])\n",
      "[-0.25578928]\n",
      "Mode: Test env_steps 200 total rewards -410.91848160512745 total energy tensor([[109.6500]])\n",
      "[0.07031383]\n",
      "Mode: Test env_steps 200 total rewards -391.2722796946764 total energy tensor([[108.8517]])\n",
      "[-0.16112204]\n",
      "Mode: Test env_steps 200 total rewards -394.26803961768746 total energy tensor([[106.3506]])\n",
      "310000 -429.9030177567154\n",
      "[0.6354534]\n",
      "Mode: Train env_steps 200 total rewards -389.9257666449994 total energy tensor([[118.8595]])\n",
      "[-0.66586703]\n",
      "Mode: Train env_steps 200 total rewards -444.77008456364274 total energy tensor([[107.8767]])\n",
      "[0.07155047]\n",
      "Mode: Train env_steps 200 total rewards -386.5493405293673 total energy tensor([[102.9714]])\n",
      "[-0.08314592]\n",
      "Mode: Train env_steps 200 total rewards -402.6440276661888 total energy tensor([[102.3952]])\n",
      "[-0.7967058]\n",
      "Mode: Train env_steps 200 total rewards -6.4502736469730735 total energy tensor([[94.5543]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5069982]\n",
      "Mode: Train env_steps 200 total rewards -131.2492287911591 total energy tensor([[76.9066]])\n",
      "[-0.7863432]\n",
      "Mode: Train env_steps 200 total rewards -496.8721513338387 total energy tensor([[135.9827]])\n",
      "[0.9843941]\n",
      "Mode: Train env_steps 200 total rewards -246.42372149484072 total energy tensor([[108.3132]])\n",
      "[0.37033993]\n",
      "Mode: Train env_steps 200 total rewards -316.2990431599319 total energy tensor([[128.7237]])\n",
      "[0.34125444]\n",
      "Mode: Train env_steps 200 total rewards -258.93000104196835 total energy tensor([[92.0841]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.53426284]\n",
      "Mode: Train env_steps 200 total rewards -135.72838400211185 total energy tensor([[100.2756]])\n",
      "[0.96036613]\n",
      "Mode: Train env_steps 200 total rewards -133.72334776166826 total energy tensor([[115.1804]])\n",
      "[-0.7589151]\n",
      "Mode: Train env_steps 200 total rewards -343.9337934721261 total energy tensor([[120.0908]])\n",
      "[-0.18570969]\n",
      "Mode: Train env_steps 200 total rewards -123.19613872718764 total energy tensor([[84.5195]])\n",
      "[-0.25832328]\n",
      "Mode: Train env_steps 200 total rewards -131.6918210014701 total energy tensor([[100.3283]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7322882]\n",
      "Mode: Train env_steps 200 total rewards -268.57214513700455 total energy tensor([[119.0302]])\n",
      "[0.99990654]\n",
      "Mode: Train env_steps 200 total rewards -559.0057418942451 total energy tensor([[142.7997]])\n",
      "[0.89404297]\n",
      "Mode: Train env_steps 200 total rewards -262.0634757243097 total energy tensor([[93.3253]])\n",
      "[-0.46824822]\n",
      "Mode: Train env_steps 200 total rewards -368.03767645033076 total energy tensor([[122.0201]])\n",
      "[0.5350372]\n",
      "Mode: Train env_steps 200 total rewards -260.85092489700764 total energy tensor([[103.8218]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43846262]\n",
      "Mode: Train env_steps 200 total rewards -509.2087900619954 total energy tensor([[118.0436]])\n",
      "[-0.45943806]\n",
      "Mode: Train env_steps 200 total rewards -509.6467629149556 total energy tensor([[120.9770]])\n",
      "[-0.26597902]\n",
      "Mode: Train env_steps 200 total rewards -387.3003266006708 total energy tensor([[114.1963]])\n",
      "[0.31562996]\n",
      "Mode: Train env_steps 200 total rewards -506.7760767005384 total energy tensor([[111.7779]])\n",
      "[-0.35539478]\n",
      "Mode: Train env_steps 200 total rewards -386.992516156286 total energy tensor([[110.2729]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60912085]\n",
      "Mode: Test env_steps 200 total rewards -366.635221792385 total energy tensor([[134.1895]])\n",
      "[-0.23864166]\n",
      "Mode: Test env_steps 200 total rewards -263.5153734665364 total energy tensor([[118.4987]])\n",
      "[-0.06365956]\n",
      "Mode: Test env_steps 200 total rewards -10.701655380427837 total energy tensor([[106.1902]])\n",
      "[0.32241654]\n",
      "Mode: Test env_steps 200 total rewards -126.99383997358382 total energy tensor([[101.7463]])\n",
      "[0.36898363]\n",
      "Mode: Test env_steps 200 total rewards -261.6376767102629 total energy tensor([[118.3218]])\n",
      "[0.74876636]\n",
      "Mode: Test env_steps 200 total rewards -260.80827299132943 total energy tensor([[114.8899]])\n",
      "[0.7726529]\n",
      "Mode: Test env_steps 200 total rewards -365.0711326515302 total energy tensor([[117.1625]])\n",
      "[0.55205137]\n",
      "Mode: Test env_steps 200 total rewards -136.74315434508026 total energy tensor([[111.7441]])\n",
      "[0.38850123]\n",
      "Mode: Test env_steps 200 total rewards -264.1936262026429 total energy tensor([[116.7048]])\n",
      "[0.05055583]\n",
      "Mode: Test env_steps 200 total rewards -261.1851524449885 total energy tensor([[115.1172]])\n",
      "315000 -231.74851059587672\n",
      "[0.10715852]\n",
      "Mode: Train env_steps 200 total rewards -263.34433594346046 total energy tensor([[119.9355]])\n",
      "[-0.77050805]\n",
      "Mode: Train env_steps 200 total rewards -130.2267896886915 total energy tensor([[104.1435]])\n",
      "[-0.21188529]\n",
      "Mode: Train env_steps 200 total rewards -263.1968944808468 total energy tensor([[118.2577]])\n",
      "[-0.34927705]\n",
      "Mode: Train env_steps 200 total rewards -402.73884572833776 total energy tensor([[123.4584]])\n",
      "[0.28012428]\n",
      "Mode: Train env_steps 200 total rewards -137.48968479363248 total energy tensor([[112.3606]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11688565]\n",
      "Mode: Train env_steps 200 total rewards -254.75866423361003 total energy tensor([[129.8706]])\n",
      "[-0.9926622]\n",
      "Mode: Train env_steps 200 total rewards -385.72160679474473 total energy tensor([[142.8009]])\n",
      "[0.42023176]\n",
      "Mode: Train env_steps 200 total rewards -133.70817765407264 total energy tensor([[108.9991]])\n",
      "[-0.2426323]\n",
      "Mode: Train env_steps 200 total rewards -369.67357887141407 total energy tensor([[126.1748]])\n",
      "[0.34439778]\n",
      "Mode: Train env_steps 200 total rewards -11.152745912782848 total energy tensor([[105.6778]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62719643]\n",
      "Mode: Train env_steps 200 total rewards -6.473162659298396 total energy tensor([[82.5884]])\n",
      "[-0.9046844]\n",
      "Mode: Train env_steps 200 total rewards -371.1132217645645 total energy tensor([[106.3839]])\n",
      "[-0.5366379]\n",
      "Mode: Train env_steps 200 total rewards -258.1705099698156 total energy tensor([[110.2852]])\n",
      "[0.48967957]\n",
      "Mode: Train env_steps 200 total rewards -269.0012691859156 total energy tensor([[109.8055]])\n",
      "[-0.8797903]\n",
      "Mode: Train env_steps 200 total rewards -5.079878579359502 total energy tensor([[68.4591]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6862233]\n",
      "Mode: Train env_steps 200 total rewards -256.95123570552096 total energy tensor([[93.5311]])\n",
      "[-0.6854946]\n",
      "Mode: Train env_steps 200 total rewards -258.3563277531648 total energy tensor([[98.1401]])\n",
      "[0.620859]\n",
      "Mode: Train env_steps 200 total rewards -127.00294943992049 total energy tensor([[77.3839]])\n",
      "[0.68181616]\n",
      "Mode: Train env_steps 200 total rewards -249.88687119213864 total energy tensor([[80.8709]])\n",
      "[0.658765]\n",
      "Mode: Train env_steps 200 total rewards -129.1372218709439 total energy tensor([[72.9448]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91637635]\n",
      "Mode: Train env_steps 200 total rewards -252.05056776897982 total energy tensor([[87.8860]])\n",
      "[-0.5469526]\n",
      "Mode: Train env_steps 200 total rewards -370.79415223468095 total energy tensor([[110.2076]])\n",
      "[0.04188216]\n",
      "Mode: Train env_steps 200 total rewards -400.95635073725134 total energy tensor([[99.3706]])\n",
      "[-0.9646188]\n",
      "Mode: Train env_steps 200 total rewards -371.3674700688571 total energy tensor([[107.7574]])\n",
      "[0.84853625]\n",
      "Mode: Train env_steps 200 total rewards -136.23484349995852 total energy tensor([[96.1483]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7920087]\n",
      "Mode: Test env_steps 200 total rewards -130.4354180218652 total energy tensor([[67.6691]])\n",
      "[-0.41366407]\n",
      "Mode: Test env_steps 200 total rewards -370.87964355247095 total energy tensor([[89.5522]])\n",
      "[0.8847461]\n",
      "Mode: Test env_steps 200 total rewards -251.3245295798406 total energy tensor([[82.8023]])\n",
      "[-0.44548285]\n",
      "Mode: Test env_steps 200 total rewards -379.60758321452886 total energy tensor([[94.0767]])\n",
      "[-0.83183694]\n",
      "Mode: Test env_steps 200 total rewards -383.810237349011 total energy tensor([[94.6022]])\n",
      "[0.23500091]\n",
      "Mode: Test env_steps 200 total rewards -8.407195640727878 total energy tensor([[80.1029]])\n",
      "[0.17780848]\n",
      "Mode: Test env_steps 200 total rewards -6.026407957309857 total energy tensor([[69.4133]])\n",
      "[0.14323026]\n",
      "Mode: Test env_steps 200 total rewards -130.97046634275466 total energy tensor([[74.0583]])\n",
      "[-0.02410098]\n",
      "Mode: Test env_steps 200 total rewards -249.01571027189493 total energy tensor([[82.1772]])\n",
      "[-0.69557124]\n",
      "Mode: Test env_steps 200 total rewards -127.20109319547191 total energy tensor([[65.0075]])\n",
      "320000 -203.76782851258758\n",
      "[0.7655102]\n",
      "Mode: Train env_steps 200 total rewards -371.8202958032489 total energy tensor([[98.1300]])\n",
      "[-0.6321763]\n",
      "Mode: Train env_steps 200 total rewards -593.665869991295 total energy tensor([[106.5828]])\n",
      "[0.01317632]\n",
      "Mode: Train env_steps 200 total rewards -134.35584778245538 total energy tensor([[93.5005]])\n",
      "[-0.00899999]\n",
      "Mode: Train env_steps 200 total rewards -283.11212463723496 total energy tensor([[76.5367]])\n",
      "[0.02338205]\n",
      "Mode: Train env_steps 200 total rewards -262.9266304494813 total energy tensor([[95.1740]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.692499]\n",
      "Mode: Train env_steps 200 total rewards -138.14399925991893 total energy tensor([[128.7194]])\n",
      "[0.9511584]\n",
      "Mode: Train env_steps 200 total rewards -503.4693715455942 total energy tensor([[117.7335]])\n",
      "[0.7748354]\n",
      "Mode: Train env_steps 200 total rewards -125.73593972530216 total energy tensor([[90.8983]])\n",
      "[-0.21914135]\n",
      "Mode: Train env_steps 200 total rewards -513.4374422803521 total energy tensor([[109.0070]])\n",
      "[-0.00952167]\n",
      "Mode: Train env_steps 200 total rewards -268.31079533317825 total energy tensor([[127.4503]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47868267]\n",
      "Mode: Train env_steps 200 total rewards -264.5690198474331 total energy tensor([[111.6722]])\n",
      "[0.9740029]\n",
      "Mode: Train env_steps 200 total rewards -3.9584907919634134 total energy tensor([[59.1006]])\n",
      "[0.540447]\n",
      "Mode: Train env_steps 200 total rewards -518.4687396520749 total energy tensor([[117.5644]])\n",
      "[0.6066137]\n",
      "Mode: Train env_steps 200 total rewards -257.68906909041107 total energy tensor([[91.6246]])\n",
      "[0.37083465]\n",
      "Mode: Train env_steps 200 total rewards -288.60511987900827 total energy tensor([[84.5294]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97226167]\n",
      "Mode: Train env_steps 200 total rewards -487.6348957642913 total energy tensor([[119.8531]])\n",
      "[-0.18501264]\n",
      "Mode: Train env_steps 200 total rewards -304.0837963060476 total energy tensor([[75.4452]])\n",
      "[0.57649195]\n",
      "Mode: Train env_steps 200 total rewards -309.0964273218997 total energy tensor([[92.2299]])\n",
      "[0.8980341]\n",
      "Mode: Train env_steps 200 total rewards -353.2120657945052 total energy tensor([[75.9205]])\n",
      "[-0.30217078]\n",
      "Mode: Train env_steps 200 total rewards -346.96140922326595 total energy tensor([[81.3438]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.51793605]\n",
      "Mode: Train env_steps 200 total rewards -260.1416386566125 total energy tensor([[82.0105]])\n",
      "[0.02434538]\n",
      "Mode: Train env_steps 200 total rewards -379.3633789084852 total energy tensor([[91.6838]])\n",
      "[-0.8117769]\n",
      "Mode: Train env_steps 200 total rewards -262.5923949354328 total energy tensor([[96.6351]])\n",
      "[-0.20405707]\n",
      "Mode: Train env_steps 200 total rewards -385.4184638825245 total energy tensor([[97.3149]])\n",
      "[0.28323075]\n",
      "Mode: Train env_steps 200 total rewards -355.73425461235456 total energy tensor([[83.9324]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6217131]\n",
      "Mode: Test env_steps 200 total rewards -261.842593211215 total energy tensor([[101.6491]])\n",
      "[0.9187126]\n",
      "Mode: Test env_steps 200 total rewards -366.0086784581654 total energy tensor([[111.6944]])\n",
      "[-0.7677906]\n",
      "Mode: Test env_steps 200 total rewards -377.53517974494025 total energy tensor([[112.0274]])\n",
      "[-0.69041556]\n",
      "Mode: Test env_steps 200 total rewards -3.9751871721236967 total energy tensor([[50.3673]])\n",
      "[0.17774355]\n",
      "Mode: Test env_steps 200 total rewards -305.804304191377 total energy tensor([[89.2840]])\n",
      "[0.02778579]\n",
      "Mode: Test env_steps 200 total rewards -3.1038048248010455 total energy tensor([[40.4155]])\n",
      "[0.43975753]\n",
      "Mode: Test env_steps 200 total rewards -258.2782503491035 total energy tensor([[88.7557]])\n",
      "[-0.5787493]\n",
      "Mode: Test env_steps 200 total rewards -126.48209685087204 total energy tensor([[69.7784]])\n",
      "[0.00821242]\n",
      "Mode: Test env_steps 200 total rewards -390.0679525057785 total energy tensor([[121.4151]])\n",
      "[0.8478994]\n",
      "Mode: Test env_steps 200 total rewards -260.94006973668 total energy tensor([[93.3895]])\n",
      "325000 -235.40381170450564\n",
      "[-0.95179904]\n",
      "Mode: Train env_steps 200 total rewards -396.4471712890081 total energy tensor([[112.5434]])\n",
      "[-0.94846934]\n",
      "Mode: Train env_steps 200 total rewards -132.99933998571942 total energy tensor([[70.8066]])\n",
      "[0.9165049]\n",
      "Mode: Train env_steps 200 total rewards -124.85169725306332 total energy tensor([[71.3505]])\n",
      "[0.2722952]\n",
      "Mode: Train env_steps 200 total rewards -384.92895208112895 total energy tensor([[111.0383]])\n",
      "[0.10411022]\n",
      "Mode: Train env_steps 200 total rewards -262.1006259820424 total energy tensor([[105.3112]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56197596]\n",
      "Mode: Train env_steps 200 total rewards -125.68098945892416 total energy tensor([[70.8666]])\n",
      "[-0.7076059]\n",
      "Mode: Train env_steps 200 total rewards -514.1759008783847 total energy tensor([[98.2194]])\n",
      "[0.8273204]\n",
      "Mode: Train env_steps 200 total rewards -282.4723410140723 total energy tensor([[87.2096]])\n",
      "[-0.86722064]\n",
      "Mode: Train env_steps 200 total rewards -259.2259089949075 total energy tensor([[85.1873]])\n",
      "[0.78302187]\n",
      "Mode: Train env_steps 200 total rewards -258.1066327858716 total energy tensor([[101.4648]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9285236]\n",
      "Mode: Train env_steps 200 total rewards -371.1471506631933 total energy tensor([[98.8061]])\n",
      "[-0.551978]\n",
      "Mode: Train env_steps 200 total rewards -259.93396469578147 total energy tensor([[92.5111]])\n",
      "[0.6622561]\n",
      "Mode: Train env_steps 200 total rewards -256.626176469028 total energy tensor([[93.4444]])\n",
      "[-0.7903552]\n",
      "Mode: Train env_steps 200 total rewards -258.3877579984255 total energy tensor([[89.9209]])\n",
      "[-0.12914704]\n",
      "Mode: Train env_steps 200 total rewards -5.136100166710094 total energy tensor([[51.4904]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18369396]\n",
      "Mode: Train env_steps 200 total rewards -128.10096139460802 total energy tensor([[90.4644]])\n",
      "[0.11602388]\n",
      "Mode: Train env_steps 200 total rewards -259.96824004873633 total energy tensor([[99.4753]])\n",
      "[0.48117667]\n",
      "Mode: Train env_steps 200 total rewards -130.65904097259045 total energy tensor([[93.1723]])\n",
      "[0.3123262]\n",
      "Mode: Train env_steps 200 total rewards -256.38629481731914 total energy tensor([[91.1444]])\n",
      "[0.46140975]\n",
      "Mode: Train env_steps 200 total rewards -257.6619983287528 total energy tensor([[93.1587]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48610106]\n",
      "Mode: Train env_steps 200 total rewards -371.74310248345137 total energy tensor([[89.4085]])\n",
      "[-0.18448475]\n",
      "Mode: Train env_steps 200 total rewards -386.5963190961629 total energy tensor([[110.9912]])\n",
      "[0.02909283]\n",
      "Mode: Train env_steps 200 total rewards -381.4612088156864 total energy tensor([[105.1942]])\n",
      "[-0.8025774]\n",
      "Mode: Train env_steps 200 total rewards -128.54978909436613 total energy tensor([[94.5433]])\n",
      "[-0.32030165]\n",
      "Mode: Train env_steps 200 total rewards -132.55342383496463 total energy tensor([[98.6249]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57938826]\n",
      "Mode: Test env_steps 200 total rewards -404.5502632618882 total energy tensor([[82.1438]])\n",
      "[-0.58590233]\n",
      "Mode: Test env_steps 200 total rewards -375.18812255654484 total energy tensor([[87.4696]])\n",
      "[-0.23883276]\n",
      "Mode: Test env_steps 200 total rewards -374.25989165809005 total energy tensor([[87.2114]])\n",
      "[-0.83177894]\n",
      "Mode: Test env_steps 200 total rewards -7.4549099719151855 total energy tensor([[79.9203]])\n",
      "[0.48135284]\n",
      "Mode: Test env_steps 200 total rewards -256.4455419005826 total energy tensor([[92.1872]])\n",
      "[0.11406452]\n",
      "Mode: Test env_steps 200 total rewards -131.47465164773166 total energy tensor([[103.2176]])\n",
      "[-0.57876605]\n",
      "Mode: Test env_steps 200 total rewards -130.66596260853112 total energy tensor([[91.1169]])\n",
      "[-0.50332886]\n",
      "Mode: Test env_steps 200 total rewards -130.81958199781366 total energy tensor([[84.0258]])\n",
      "[-0.5096317]\n",
      "Mode: Test env_steps 200 total rewards -128.80341583769768 total energy tensor([[87.5594]])\n",
      "[0.09784367]\n",
      "Mode: Test env_steps 200 total rewards -257.29927088785917 total energy tensor([[90.7702]])\n",
      "330000 -219.69616123286542\n",
      "[-0.05449091]\n",
      "Mode: Train env_steps 200 total rewards -137.74453092366457 total energy tensor([[112.2895]])\n",
      "[-0.590016]\n",
      "Mode: Train env_steps 200 total rewards -371.93730505462736 total energy tensor([[91.9773]])\n",
      "[0.9950882]\n",
      "Mode: Train env_steps 200 total rewards -136.0591673888266 total energy tensor([[98.8517]])\n",
      "[-0.94627887]\n",
      "Mode: Train env_steps 200 total rewards -255.55915478616953 total energy tensor([[94.3320]])\n",
      "[-0.3983522]\n",
      "Mode: Train env_steps 200 total rewards -260.0174746019766 total energy tensor([[96.2659]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4151446]\n",
      "Mode: Train env_steps 200 total rewards -259.23061504680663 total energy tensor([[74.2677]])\n",
      "[0.5802281]\n",
      "Mode: Train env_steps 200 total rewards -132.34474314644467 total energy tensor([[61.0625]])\n",
      "[-0.24433482]\n",
      "Mode: Train env_steps 200 total rewards -327.16740920441225 total energy tensor([[86.8038]])\n",
      "[0.79585415]\n",
      "Mode: Train env_steps 200 total rewards -274.1845042791683 total energy tensor([[67.4177]])\n",
      "[-0.25847054]\n",
      "Mode: Train env_steps 200 total rewards -132.64556567650288 total energy tensor([[74.9497]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07936417]\n",
      "Mode: Train env_steps 200 total rewards -130.0779928425327 total energy tensor([[80.3945]])\n",
      "[0.16217494]\n",
      "Mode: Train env_steps 200 total rewards -128.2077082907781 total energy tensor([[88.0613]])\n",
      "[-0.15528771]\n",
      "Mode: Train env_steps 200 total rewards -252.2475855499506 total energy tensor([[85.4791]])\n",
      "[-0.6442186]\n",
      "Mode: Train env_steps 200 total rewards -259.09978820197284 total energy tensor([[84.6566]])\n",
      "[0.07540301]\n",
      "Mode: Train env_steps 200 total rewards -260.4699334548786 total energy tensor([[86.0241]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5752754]\n",
      "Mode: Train env_steps 200 total rewards -555.8389425203204 total energy tensor([[94.2287]])\n",
      "[0.36321807]\n",
      "Mode: Train env_steps 200 total rewards -248.10744650429115 total energy tensor([[84.4199]])\n",
      "[-0.8966618]\n",
      "Mode: Train env_steps 200 total rewards -131.0189837142825 total energy tensor([[78.6241]])\n",
      "[0.3344457]\n",
      "Mode: Train env_steps 200 total rewards -376.82459216192365 total energy tensor([[89.2296]])\n",
      "[0.15709746]\n",
      "Mode: Train env_steps 200 total rewards -252.5409865793772 total energy tensor([[96.0964]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42374295]\n",
      "Mode: Train env_steps 200 total rewards -260.9463106356561 total energy tensor([[101.6071]])\n",
      "[-0.64479625]\n",
      "Mode: Train env_steps 200 total rewards -130.99805681500584 total energy tensor([[84.1283]])\n",
      "[0.2950492]\n",
      "Mode: Train env_steps 200 total rewards -132.87200916092843 total energy tensor([[91.4755]])\n",
      "[-0.60612464]\n",
      "Mode: Train env_steps 200 total rewards -136.61296179890633 total energy tensor([[101.9349]])\n",
      "[0.93378705]\n",
      "Mode: Train env_steps 200 total rewards -10.680214203079231 total energy tensor([[99.6358]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11240756]\n",
      "Mode: Test env_steps 200 total rewards -134.4468331336975 total energy tensor([[101.8417]])\n",
      "[0.20118137]\n",
      "Mode: Test env_steps 200 total rewards -130.26862373016775 total energy tensor([[93.7328]])\n",
      "[0.4950387]\n",
      "Mode: Test env_steps 200 total rewards -379.95929221622646 total energy tensor([[102.8126]])\n",
      "[-0.212877]\n",
      "Mode: Test env_steps 200 total rewards -260.04585470817983 total energy tensor([[91.5347]])\n",
      "[0.58245176]\n",
      "Mode: Test env_steps 200 total rewards -375.4648239482194 total energy tensor([[102.8507]])\n",
      "[-0.6882893]\n",
      "Mode: Test env_steps 200 total rewards -284.69863518327475 total energy tensor([[115.0062]])\n",
      "[0.19419521]\n",
      "Mode: Test env_steps 200 total rewards -133.1030675820075 total energy tensor([[103.0616]])\n",
      "[0.38963702]\n",
      "Mode: Test env_steps 200 total rewards -132.1271221432835 total energy tensor([[104.1369]])\n",
      "[-0.6929689]\n",
      "Mode: Test env_steps 200 total rewards -256.8025534078479 total energy tensor([[114.9812]])\n",
      "[0.3989527]\n",
      "Mode: Test env_steps 200 total rewards -135.7880281638354 total energy tensor([[109.2267]])\n",
      "335000 -222.270483421674\n",
      "[-0.32341775]\n",
      "Mode: Train env_steps 200 total rewards -258.67451779637486 total energy tensor([[94.2579]])\n",
      "[-0.5535735]\n",
      "Mode: Train env_steps 200 total rewards -260.49373670108616 total energy tensor([[92.3346]])\n",
      "[-0.32634842]\n",
      "Mode: Train env_steps 200 total rewards -130.17628388199955 total energy tensor([[109.0656]])\n",
      "[0.6380529]\n",
      "Mode: Train env_steps 200 total rewards -132.33256246335804 total energy tensor([[106.7834]])\n",
      "[-0.39287087]\n",
      "Mode: Train env_steps 200 total rewards -259.09721215069294 total energy tensor([[93.9317]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5117076]\n",
      "Mode: Train env_steps 200 total rewards -128.0429410818033 total energy tensor([[59.1531]])\n",
      "[0.7114148]\n",
      "Mode: Train env_steps 200 total rewards -130.1942856319365 total energy tensor([[58.0577]])\n",
      "[-0.5786997]\n",
      "Mode: Train env_steps 200 total rewards -310.14956938195974 total energy tensor([[103.7324]])\n",
      "[0.9181724]\n",
      "Mode: Train env_steps 200 total rewards -256.8066575983539 total energy tensor([[74.3220]])\n",
      "[-0.64116204]\n",
      "Mode: Train env_steps 200 total rewards -381.11350857904836 total energy tensor([[87.3717]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9543237]\n",
      "Mode: Train env_steps 200 total rewards -133.76373283658177 total energy tensor([[107.4243]])\n",
      "[-0.82060516]\n",
      "Mode: Train env_steps 200 total rewards -262.28302818723023 total energy tensor([[100.1098]])\n",
      "[-0.38760257]\n",
      "Mode: Train env_steps 200 total rewards -379.87674286123365 total energy tensor([[94.5451]])\n",
      "[-0.09220378]\n",
      "Mode: Train env_steps 200 total rewards -379.2627440812066 total energy tensor([[109.9593]])\n",
      "[0.61030424]\n",
      "Mode: Train env_steps 200 total rewards -130.804189492148 total energy tensor([[88.7221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.14666727]\n",
      "Mode: Train env_steps 200 total rewards -249.97584644705057 total energy tensor([[94.3534]])\n",
      "[-0.5945032]\n",
      "Mode: Train env_steps 200 total rewards -126.4076142036356 total energy tensor([[85.0834]])\n",
      "[0.03130252]\n",
      "Mode: Train env_steps 200 total rewards -252.70029261382297 total energy tensor([[92.1074]])\n",
      "[0.34564105]\n",
      "Mode: Train env_steps 200 total rewards -376.47650289721787 total energy tensor([[98.5615]])\n",
      "[-0.81386817]\n",
      "Mode: Train env_steps 200 total rewards -259.39225466828793 total energy tensor([[91.2213]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40520406]\n",
      "Mode: Train env_steps 200 total rewards -132.93856472242624 total energy tensor([[94.8721]])\n",
      "[-0.30586612]\n",
      "Mode: Train env_steps 200 total rewards -132.33045668527484 total energy tensor([[95.5637]])\n",
      "[-0.18160628]\n",
      "Mode: Train env_steps 200 total rewards -257.2239248007536 total energy tensor([[123.6691]])\n",
      "[0.8021928]\n",
      "Mode: Train env_steps 200 total rewards -262.310416684486 total energy tensor([[93.8171]])\n",
      "[0.06347787]\n",
      "Mode: Train env_steps 200 total rewards -379.6700695063919 total energy tensor([[96.6486]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06989643]\n",
      "Mode: Test env_steps 200 total rewards -251.28972524951678 total energy tensor([[87.9428]])\n",
      "[0.7562646]\n",
      "Mode: Test env_steps 200 total rewards -354.4052111329511 total energy tensor([[100.5365]])\n",
      "[-0.5016457]\n",
      "Mode: Test env_steps 200 total rewards -7.7152570630423725 total energy tensor([[75.6599]])\n",
      "[-0.696405]\n",
      "Mode: Test env_steps 200 total rewards -366.15549634117633 total energy tensor([[100.4275]])\n",
      "[0.27045295]\n",
      "Mode: Test env_steps 200 total rewards -379.7849776032381 total energy tensor([[96.4006]])\n",
      "[-0.80635273]\n",
      "Mode: Test env_steps 200 total rewards -127.10701179364696 total energy tensor([[79.4416]])\n",
      "[0.52894586]\n",
      "Mode: Test env_steps 200 total rewards -401.127425679937 total energy tensor([[110.9746]])\n",
      "[0.07075826]\n",
      "Mode: Test env_steps 200 total rewards -257.21357100782916 total energy tensor([[81.7492]])\n",
      "[-0.7038212]\n",
      "Mode: Test env_steps 200 total rewards -364.4998497017659 total energy tensor([[98.1678]])\n",
      "[-0.06533872]\n",
      "Mode: Test env_steps 200 total rewards -9.136953815817833 total energy tensor([[83.6614]])\n",
      "340000 -251.84354793889216\n",
      "[-0.59059364]\n",
      "Mode: Train env_steps 200 total rewards -127.73108118411619 total energy tensor([[81.9244]])\n",
      "[-0.5331413]\n",
      "Mode: Train env_steps 200 total rewards -9.188026030082256 total energy tensor([[88.4457]])\n",
      "[-0.9622044]\n",
      "Mode: Train env_steps 200 total rewards -259.917059476953 total energy tensor([[83.7540]])\n",
      "[0.02762371]\n",
      "Mode: Train env_steps 200 total rewards -255.2494459892623 total energy tensor([[86.3971]])\n",
      "[-0.74189276]\n",
      "Mode: Train env_steps 200 total rewards -265.42716152220964 total energy tensor([[100.6753]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.297227]\n",
      "Mode: Train env_steps 200 total rewards -125.19251036539208 total energy tensor([[47.8962]])\n",
      "[0.14078571]\n",
      "Mode: Train env_steps 200 total rewards -124.48609972049599 total energy tensor([[54.8963]])\n",
      "[-0.5909542]\n",
      "Mode: Train env_steps 200 total rewards -124.872857860988 total energy tensor([[51.4482]])\n",
      "[-0.34981686]\n",
      "Mode: Train env_steps 200 total rewards -4.982633404433727 total energy tensor([[53.8066]])\n",
      "[0.33801988]\n",
      "Mode: Train env_steps 200 total rewards -244.3976392764598 total energy tensor([[102.6703]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.24278097]\n",
      "Mode: Train env_steps 200 total rewards -259.47336038481444 total energy tensor([[82.5226]])\n",
      "[0.14630395]\n",
      "Mode: Train env_steps 200 total rewards -126.6767147956416 total energy tensor([[70.3368]])\n",
      "[0.50955963]\n",
      "Mode: Train env_steps 200 total rewards -126.93814492197998 total energy tensor([[77.1998]])\n",
      "[-0.43679824]\n",
      "Mode: Train env_steps 200 total rewards -128.63007625564933 total energy tensor([[67.9334]])\n",
      "[-0.4773954]\n",
      "Mode: Train env_steps 200 total rewards -258.74447395978495 total energy tensor([[84.4189]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6190795]\n",
      "Mode: Train env_steps 200 total rewards -263.0420114835724 total energy tensor([[100.3482]])\n",
      "[0.13803843]\n",
      "Mode: Train env_steps 200 total rewards -127.63740821927786 total energy tensor([[84.1518]])\n",
      "[0.37991637]\n",
      "Mode: Train env_steps 200 total rewards -134.66480104252696 total energy tensor([[92.3212]])\n",
      "[0.4806241]\n",
      "Mode: Train env_steps 200 total rewards -264.52669563610107 total energy tensor([[99.3452]])\n",
      "[0.11512181]\n",
      "Mode: Train env_steps 200 total rewards -367.64185657864437 total energy tensor([[108.4869]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9819762]\n",
      "Mode: Train env_steps 200 total rewards -7.095378875732422 total energy tensor([[68.3897]])\n",
      "[-0.8713127]\n",
      "Mode: Train env_steps 200 total rewards -379.87714395625517 total energy tensor([[98.1350]])\n",
      "[0.92898315]\n",
      "Mode: Train env_steps 200 total rewards -376.1677818931639 total energy tensor([[97.3147]])\n",
      "[-0.81018525]\n",
      "Mode: Train env_steps 200 total rewards -133.79761644359678 total energy tensor([[73.6719]])\n",
      "[-0.35020804]\n",
      "Mode: Train env_steps 200 total rewards -131.756979865022 total energy tensor([[68.1448]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.58337784]\n",
      "Mode: Test env_steps 200 total rewards -135.59326354786754 total energy tensor([[85.6331]])\n",
      "[-0.73500925]\n",
      "Mode: Test env_steps 200 total rewards -125.7740030027926 total energy tensor([[78.5002]])\n",
      "[0.35866296]\n",
      "Mode: Test env_steps 200 total rewards -375.3965679798275 total energy tensor([[98.4475]])\n",
      "[0.8371457]\n",
      "Mode: Test env_steps 200 total rewards -387.39780524466187 total energy tensor([[98.3720]])\n",
      "[0.01112101]\n",
      "Mode: Test env_steps 200 total rewards -130.79779195412993 total energy tensor([[78.9207]])\n",
      "[0.5037528]\n",
      "Mode: Test env_steps 200 total rewards -126.64438053616323 total energy tensor([[70.9685]])\n",
      "[-0.33424848]\n",
      "Mode: Test env_steps 200 total rewards -134.04121290892363 total energy tensor([[88.6893]])\n",
      "[-0.29543558]\n",
      "Mode: Test env_steps 200 total rewards -122.26996905857231 total energy tensor([[73.0759]])\n",
      "[0.93176657]\n",
      "Mode: Test env_steps 200 total rewards -131.12078751809895 total energy tensor([[73.2294]])\n",
      "[0.9529026]\n",
      "Mode: Test env_steps 200 total rewards -133.26410324126482 total energy tensor([[87.1201]])\n",
      "345000 -180.22998849923025\n",
      "[0.81521785]\n",
      "Mode: Train env_steps 200 total rewards -124.3978151336778 total energy tensor([[72.4340]])\n",
      "[-0.4974848]\n",
      "Mode: Train env_steps 200 total rewards -388.3789156489074 total energy tensor([[105.7050]])\n",
      "[-0.12306555]\n",
      "Mode: Train env_steps 200 total rewards -127.40590200014412 total energy tensor([[94.6840]])\n",
      "[0.47087207]\n",
      "Mode: Train env_steps 200 total rewards -273.4299813769758 total energy tensor([[89.8331]])\n",
      "[0.39695364]\n",
      "Mode: Train env_steps 200 total rewards -130.40299285016954 total energy tensor([[73.6541]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.61572176]\n",
      "Mode: Train env_steps 200 total rewards -130.8403015434742 total energy tensor([[74.6184]])\n",
      "[0.48707038]\n",
      "Mode: Train env_steps 200 total rewards -9.597594637423754 total energy tensor([[78.4760]])\n",
      "[0.63129467]\n",
      "Mode: Train env_steps 200 total rewards -376.11877081077546 total energy tensor([[89.5435]])\n",
      "[-0.32530317]\n",
      "Mode: Train env_steps 200 total rewards -135.17815853469074 total energy tensor([[84.6645]])\n",
      "[0.9758442]\n",
      "Mode: Train env_steps 200 total rewards -262.48370665870607 total energy tensor([[93.7221]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85560423]\n",
      "Mode: Train env_steps 200 total rewards -267.5328958649188 total energy tensor([[90.7431]])\n",
      "[0.23735793]\n",
      "Mode: Train env_steps 200 total rewards -254.4201170746237 total energy tensor([[78.2358]])\n",
      "[-0.74146974]\n",
      "Mode: Train env_steps 200 total rewards -260.66527388524264 total energy tensor([[91.4388]])\n",
      "[0.9985982]\n",
      "Mode: Train env_steps 200 total rewards -280.56148121133447 total energy tensor([[89.9993]])\n",
      "[0.8587738]\n",
      "Mode: Train env_steps 200 total rewards -133.10530550591648 total energy tensor([[74.5651]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3391515]\n",
      "Mode: Train env_steps 200 total rewards -265.8375895144418 total energy tensor([[77.9984]])\n",
      "[-0.3655403]\n",
      "Mode: Train env_steps 200 total rewards -251.60181613638997 total energy tensor([[75.6524]])\n",
      "[-0.28799555]\n",
      "Mode: Train env_steps 200 total rewards -509.2774494779296 total energy tensor([[87.7065]])\n",
      "[-0.8118759]\n",
      "Mode: Train env_steps 200 total rewards -366.95030806260183 total energy tensor([[82.4810]])\n",
      "[0.4511055]\n",
      "Mode: Train env_steps 200 total rewards -131.68371909530833 total energy tensor([[70.7265]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76366466]\n",
      "Mode: Train env_steps 200 total rewards -252.58480307180434 total energy tensor([[92.0498]])\n",
      "[-0.20735279]\n",
      "Mode: Train env_steps 200 total rewards -367.3631191700697 total energy tensor([[90.6743]])\n",
      "[-0.2756679]\n",
      "Mode: Train env_steps 200 total rewards -129.94782079942524 total energy tensor([[79.0083]])\n",
      "[0.75230694]\n",
      "Mode: Train env_steps 200 total rewards -258.81368917785585 total energy tensor([[86.6979]])\n",
      "[-0.6567355]\n",
      "Mode: Train env_steps 200 total rewards -125.77405947586522 total energy tensor([[76.9677]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30088717]\n",
      "Mode: Test env_steps 200 total rewards -139.2250472055748 total energy tensor([[109.9305]])\n",
      "[0.842674]\n",
      "Mode: Test env_steps 200 total rewards -382.9711907459423 total energy tensor([[99.3506]])\n",
      "[-0.11939571]\n",
      "Mode: Test env_steps 200 total rewards -260.17322999890894 total energy tensor([[95.0985]])\n",
      "[-0.9424048]\n",
      "Mode: Test env_steps 200 total rewards -256.3420278215781 total energy tensor([[91.2840]])\n",
      "[0.44816244]\n",
      "Mode: Test env_steps 200 total rewards -260.3818854424171 total energy tensor([[99.5261]])\n",
      "[0.97128123]\n",
      "Mode: Test env_steps 200 total rewards -254.89642193098553 total energy tensor([[94.7616]])\n",
      "[-0.38154355]\n",
      "Mode: Test env_steps 200 total rewards -253.19008120056242 total energy tensor([[95.6883]])\n",
      "[0.84096324]\n",
      "Mode: Test env_steps 200 total rewards -263.05847081169486 total energy tensor([[100.7029]])\n",
      "[0.41833866]\n",
      "Mode: Test env_steps 200 total rewards -264.7505653128028 total energy tensor([[108.0444]])\n",
      "[-0.3615855]\n",
      "Mode: Test env_steps 200 total rewards -259.0723608569242 total energy tensor([[96.3207]])\n",
      "350000 -259.4061281327391\n",
      "[0.9086916]\n",
      "Mode: Train env_steps 200 total rewards -266.6037041177042 total energy tensor([[100.2943]])\n",
      "[0.52587014]\n",
      "Mode: Train env_steps 200 total rewards -512.4731929795817 total energy tensor([[103.7570]])\n",
      "[0.3336585]\n",
      "Mode: Train env_steps 200 total rewards -260.1298294402659 total energy tensor([[114.9469]])\n",
      "[-0.4509678]\n",
      "Mode: Train env_steps 200 total rewards -140.88418834190816 total energy tensor([[117.7732]])\n",
      "[-0.59387136]\n",
      "Mode: Train env_steps 200 total rewards -255.4455226205755 total energy tensor([[93.4340]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97024816]\n",
      "Mode: Train env_steps 200 total rewards -266.29834419488907 total energy tensor([[110.4807]])\n",
      "[-0.513172]\n",
      "Mode: Train env_steps 200 total rewards -400.92727157101035 total energy tensor([[132.9338]])\n",
      "[-0.5265051]\n",
      "Mode: Train env_steps 200 total rewards -381.30778997950256 total energy tensor([[118.2431]])\n",
      "[-0.00364054]\n",
      "Mode: Train env_steps 200 total rewards -391.7402293421328 total energy tensor([[110.5051]])\n",
      "[-0.20001361]\n",
      "Mode: Train env_steps 200 total rewards -375.08521462604403 total energy tensor([[114.8530]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.99729526]\n",
      "Mode: Train env_steps 200 total rewards -134.88002280332148 total energy tensor([[78.8658]])\n",
      "[0.5813372]\n",
      "Mode: Train env_steps 200 total rewards -133.58488714601845 total energy tensor([[77.6904]])\n",
      "[0.08515234]\n",
      "Mode: Train env_steps 200 total rewards -136.71791731193662 total energy tensor([[90.2764]])\n",
      "[-0.39157993]\n",
      "Mode: Train env_steps 200 total rewards -249.49855978693813 total energy tensor([[90.4644]])\n",
      "[0.04904249]\n",
      "Mode: Train env_steps 200 total rewards -384.5393673889339 total energy tensor([[98.6193]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4018405]\n",
      "Mode: Train env_steps 200 total rewards -140.27370085939765 total energy tensor([[113.7456]])\n",
      "[-0.48416004]\n",
      "Mode: Train env_steps 200 total rewards -138.46363975014538 total energy tensor([[100.7203]])\n",
      "[0.48747864]\n",
      "Mode: Train env_steps 200 total rewards -387.5905319736339 total energy tensor([[104.1002]])\n",
      "[-0.13582864]\n",
      "Mode: Train env_steps 200 total rewards -140.53069976717234 total energy tensor([[116.5821]])\n",
      "[0.84954554]\n",
      "Mode: Train env_steps 200 total rewards -500.8547133700922 total energy tensor([[114.8746]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.89929956]\n",
      "Mode: Train env_steps 200 total rewards -132.51123825088143 total energy tensor([[77.5958]])\n",
      "[-0.05379794]\n",
      "Mode: Train env_steps 200 total rewards -135.1674505006522 total energy tensor([[84.3459]])\n",
      "[-0.687733]\n",
      "Mode: Train env_steps 200 total rewards -263.48770342580974 total energy tensor([[100.4301]])\n",
      "[-0.21346089]\n",
      "Mode: Train env_steps 200 total rewards -133.92618518750533 total energy tensor([[87.1413]])\n",
      "[0.66833997]\n",
      "Mode: Train env_steps 200 total rewards -251.36102511141507 total energy tensor([[87.4886]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5632821]\n",
      "Mode: Test env_steps 200 total rewards -264.0262904157862 total energy tensor([[99.4138]])\n",
      "[-0.9256327]\n",
      "Mode: Test env_steps 200 total rewards -599.836712449789 total energy tensor([[122.2554]])\n",
      "[-0.5719029]\n",
      "Mode: Test env_steps 200 total rewards -130.8097718078643 total energy tensor([[87.1366]])\n",
      "[0.94399637]\n",
      "Mode: Test env_steps 200 total rewards -131.26019904762506 total energy tensor([[87.6782]])\n",
      "[0.00205479]\n",
      "Mode: Test env_steps 200 total rewards -256.84786251652986 total energy tensor([[99.8285]])\n",
      "[0.2998982]\n",
      "Mode: Test env_steps 200 total rewards -399.1246695481241 total energy tensor([[124.9642]])\n",
      "[0.9650642]\n",
      "Mode: Test env_steps 200 total rewards -128.671825889498 total energy tensor([[87.3950]])\n",
      "[-0.09230714]\n",
      "Mode: Test env_steps 200 total rewards -270.94280568882823 total energy tensor([[102.1892]])\n",
      "[0.25758195]\n",
      "Mode: Test env_steps 200 total rewards -264.83303931728005 total energy tensor([[101.9115]])\n",
      "[0.7484793]\n",
      "Mode: Test env_steps 200 total rewards -402.5894997622818 total energy tensor([[114.7248]])\n",
      "355000 -284.89426764436064\n",
      "[0.74975526]\n",
      "Mode: Train env_steps 200 total rewards -381.3651717044413 total energy tensor([[121.1551]])\n",
      "[0.5767306]\n",
      "Mode: Train env_steps 200 total rewards -379.646867049858 total energy tensor([[111.9099]])\n",
      "[-0.40651023]\n",
      "Mode: Train env_steps 200 total rewards -262.8872869666666 total energy tensor([[101.4057]])\n",
      "[-0.91673446]\n",
      "Mode: Train env_steps 200 total rewards -135.87526017986238 total energy tensor([[87.9306]])\n",
      "[-0.5809866]\n",
      "Mode: Train env_steps 200 total rewards -254.62231657281518 total energy tensor([[108.8512]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92334044]\n",
      "Mode: Train env_steps 200 total rewards -374.1713549904525 total energy tensor([[105.0932]])\n",
      "[-0.08540723]\n",
      "Mode: Train env_steps 200 total rewards -131.40399910882115 total energy tensor([[81.2577]])\n",
      "[0.23696414]\n",
      "Mode: Train env_steps 200 total rewards -256.4317118432373 total energy tensor([[102.0838]])\n",
      "[0.70714545]\n",
      "Mode: Train env_steps 200 total rewards -260.44241796061397 total energy tensor([[108.6339]])\n",
      "[0.2013777]\n",
      "Mode: Train env_steps 200 total rewards -256.9575094617903 total energy tensor([[91.3392]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.73561823]\n",
      "Mode: Train env_steps 200 total rewards -263.5489957034588 total energy tensor([[96.6009]])\n",
      "[-0.40555802]\n",
      "Mode: Train env_steps 200 total rewards -128.67097286321223 total energy tensor([[97.5333]])\n",
      "[0.66951305]\n",
      "Mode: Train env_steps 200 total rewards -253.6692442856729 total energy tensor([[93.1132]])\n",
      "[0.3128657]\n",
      "Mode: Train env_steps 200 total rewards -372.4998411331326 total energy tensor([[104.5617]])\n",
      "[0.545413]\n",
      "Mode: Train env_steps 200 total rewards -263.5120699321851 total energy tensor([[92.6516]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9692755]\n",
      "Mode: Train env_steps 200 total rewards -9.24116779997712 total energy tensor([[81.3001]])\n",
      "[0.95648533]\n",
      "Mode: Train env_steps 200 total rewards -255.95064190239646 total energy tensor([[90.0698]])\n",
      "[-0.5047888]\n",
      "Mode: Train env_steps 200 total rewards -132.89026563614607 total energy tensor([[80.4015]])\n",
      "[0.11025398]\n",
      "Mode: Train env_steps 200 total rewards -129.3709414685145 total energy tensor([[69.8243]])\n",
      "[-0.5092145]\n",
      "Mode: Train env_steps 200 total rewards -374.4616446029395 total energy tensor([[91.0917]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19134621]\n",
      "Mode: Train env_steps 200 total rewards -128.43261938355863 total energy tensor([[70.7304]])\n",
      "[-0.6455869]\n",
      "Mode: Train env_steps 200 total rewards -256.1416697045788 total energy tensor([[94.8089]])\n",
      "[-0.12368585]\n",
      "Mode: Train env_steps 200 total rewards -124.15489825396799 total energy tensor([[78.4618]])\n",
      "[0.17636532]\n",
      "Mode: Train env_steps 200 total rewards -129.1646501114592 total energy tensor([[71.9884]])\n",
      "[-0.37935394]\n",
      "Mode: Train env_steps 200 total rewards -8.431156255304813 total energy tensor([[76.1444]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1320803]\n",
      "Mode: Test env_steps 200 total rewards -257.29882783442736 total energy tensor([[94.6583]])\n",
      "[0.24308236]\n",
      "Mode: Test env_steps 200 total rewards -387.51647542975843 total energy tensor([[101.4629]])\n",
      "[0.09555586]\n",
      "Mode: Test env_steps 200 total rewards -371.636337261647 total energy tensor([[115.6066]])\n",
      "[-0.6858343]\n",
      "Mode: Test env_steps 200 total rewards -136.82591861486435 total energy tensor([[96.4550]])\n",
      "[0.42811835]\n",
      "Mode: Test env_steps 200 total rewards -258.7334863105789 total energy tensor([[92.4168]])\n",
      "[0.67343634]\n",
      "Mode: Test env_steps 200 total rewards -267.24065705016255 total energy tensor([[144.7400]])\n",
      "[0.10771979]\n",
      "Mode: Test env_steps 200 total rewards -11.36664956714958 total energy tensor([[93.0918]])\n",
      "[0.8006343]\n",
      "Mode: Test env_steps 200 total rewards -269.6212017610669 total energy tensor([[111.9646]])\n",
      "[0.73345506]\n",
      "Mode: Test env_steps 200 total rewards -260.846924174577 total energy tensor([[94.7463]])\n",
      "[-0.94677603]\n",
      "Mode: Test env_steps 200 total rewards -253.63238090998493 total energy tensor([[99.6654]])\n",
      "360000 -247.4718858914217\n",
      "[0.42028093]\n",
      "Mode: Train env_steps 200 total rewards -262.89902834873646 total energy tensor([[92.8011]])\n",
      "[-0.9771876]\n",
      "Mode: Train env_steps 200 total rewards -514.355256728828 total energy tensor([[118.5213]])\n",
      "[-0.0199882]\n",
      "Mode: Train env_steps 200 total rewards -257.365506852977 total energy tensor([[92.1254]])\n",
      "[0.37975004]\n",
      "Mode: Train env_steps 200 total rewards -373.0663445815444 total energy tensor([[103.7587]])\n",
      "[0.5791612]\n",
      "Mode: Train env_steps 200 total rewards -259.4915644582361 total energy tensor([[94.9192]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07975271]\n",
      "Mode: Train env_steps 200 total rewards -130.49116297904402 total energy tensor([[113.7824]])\n",
      "[0.42015558]\n",
      "Mode: Train env_steps 200 total rewards -385.3201839774847 total energy tensor([[106.1927]])\n",
      "[0.6813832]\n",
      "Mode: Train env_steps 200 total rewards -131.65568894706666 total energy tensor([[102.4985]])\n",
      "[0.91169375]\n",
      "Mode: Train env_steps 200 total rewards -143.8900165632367 total energy tensor([[137.3193]])\n",
      "[0.04627257]\n",
      "Mode: Train env_steps 200 total rewards -136.36546044796705 total energy tensor([[94.8788]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0523647]\n",
      "Mode: Train env_steps 200 total rewards -384.92126342491247 total energy tensor([[105.8374]])\n",
      "[0.7717119]\n",
      "Mode: Train env_steps 200 total rewards -129.14648082712665 total energy tensor([[53.0121]])\n",
      "[0.70514864]\n",
      "Mode: Train env_steps 200 total rewards -134.59966012719087 total energy tensor([[81.4956]])\n",
      "[0.13589874]\n",
      "Mode: Train env_steps 200 total rewards -129.1716081481427 total energy tensor([[57.8090]])\n",
      "[-0.19024089]\n",
      "Mode: Train env_steps 200 total rewards -130.23028931068256 total energy tensor([[62.0212]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24078918]\n",
      "Mode: Train env_steps 200 total rewards -132.61849349737167 total energy tensor([[75.0173]])\n",
      "[-0.5567169]\n",
      "Mode: Train env_steps 200 total rewards -6.726384351044544 total energy tensor([[65.4370]])\n",
      "[-0.17954974]\n",
      "Mode: Train env_steps 200 total rewards -7.544437936972827 total energy tensor([[67.9697]])\n",
      "[-0.6065634]\n",
      "Mode: Train env_steps 200 total rewards -256.03943404741585 total energy tensor([[98.4895]])\n",
      "[-0.590018]\n",
      "Mode: Train env_steps 200 total rewards -127.68607547134161 total energy tensor([[84.2778]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6707778]\n",
      "Mode: Train env_steps 200 total rewards -133.82623574510217 total energy tensor([[95.0638]])\n",
      "[0.5583919]\n",
      "Mode: Train env_steps 200 total rewards -131.01234441064298 total energy tensor([[76.5092]])\n",
      "[-0.8022562]\n",
      "Mode: Train env_steps 200 total rewards -133.52790064923465 total energy tensor([[91.7252]])\n",
      "[-0.3446184]\n",
      "Mode: Train env_steps 200 total rewards -6.072735492023639 total energy tensor([[78.7457]])\n",
      "[0.8536565]\n",
      "Mode: Train env_steps 200 total rewards -133.7042010370642 total energy tensor([[93.1262]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.63065314]\n",
      "Mode: Test env_steps 200 total rewards -270.1420640833676 total energy tensor([[102.3964]])\n",
      "[-0.70680004]\n",
      "Mode: Test env_steps 200 total rewards -324.4403284760192 total energy tensor([[103.3689]])\n",
      "[-0.14726694]\n",
      "Mode: Test env_steps 200 total rewards -131.99354790337384 total energy tensor([[91.1392]])\n",
      "[0.35285637]\n",
      "Mode: Test env_steps 200 total rewards -130.7423798656091 total energy tensor([[105.9576]])\n",
      "[0.8267604]\n",
      "Mode: Test env_steps 200 total rewards -377.90939281787723 total energy tensor([[120.9166]])\n",
      "[0.86099505]\n",
      "Mode: Test env_steps 200 total rewards -482.1280744802207 total energy tensor([[127.9093]])\n",
      "[0.09347016]\n",
      "Mode: Test env_steps 200 total rewards -261.66793871764094 total energy tensor([[102.5520]])\n",
      "[-0.35257545]\n",
      "Mode: Test env_steps 200 total rewards -282.34895819891244 total energy tensor([[102.7320]])\n",
      "[0.4208429]\n",
      "Mode: Test env_steps 200 total rewards -132.33526785299182 total energy tensor([[89.0373]])\n",
      "[0.03414846]\n",
      "Mode: Test env_steps 200 total rewards -857.0176631957293 total energy tensor([[129.3270]])\n",
      "365000 -325.07256155917423\n",
      "[0.40588295]\n",
      "Mode: Train env_steps 200 total rewards -9.320049526169896 total energy tensor([[88.3050]])\n",
      "[0.11575689]\n",
      "Mode: Train env_steps 200 total rewards -136.31172299198806 total energy tensor([[95.2039]])\n",
      "[0.84426653]\n",
      "Mode: Train env_steps 200 total rewards -140.1071290653199 total energy tensor([[116.3543]])\n",
      "[0.97702646]\n",
      "Mode: Train env_steps 200 total rewards -385.19190819747746 total energy tensor([[126.4832]])\n",
      "[0.6540941]\n",
      "Mode: Train env_steps 200 total rewards -264.91085310745984 total energy tensor([[139.1478]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5518274]\n",
      "Mode: Train env_steps 200 total rewards -135.20047131367028 total energy tensor([[109.3593]])\n",
      "[-0.8547425]\n",
      "Mode: Train env_steps 200 total rewards -519.0905103012919 total energy tensor([[113.6511]])\n",
      "[-0.28615308]\n",
      "Mode: Train env_steps 200 total rewards -131.3537628557533 total energy tensor([[89.4964]])\n",
      "[0.21742432]\n",
      "Mode: Train env_steps 200 total rewards -483.9838789086789 total energy tensor([[110.4097]])\n",
      "[-0.9556109]\n",
      "Mode: Train env_steps 200 total rewards -497.6826119264588 total energy tensor([[102.0680]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5787436]\n",
      "Mode: Train env_steps 200 total rewards -592.3338035306515 total energy tensor([[83.0308]])\n",
      "[-0.64414954]\n",
      "Mode: Train env_steps 200 total rewards -130.2845149775967 total energy tensor([[66.2246]])\n",
      "[0.10186851]\n",
      "Mode: Train env_steps 200 total rewards -360.6885801423341 total energy tensor([[95.7064]])\n",
      "[-0.3023424]\n",
      "Mode: Train env_steps 200 total rewards -123.19986051460728 total energy tensor([[57.6521]])\n",
      "[0.68686813]\n",
      "Mode: Train env_steps 200 total rewards -130.3614087831229 total energy tensor([[67.6195]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00015554]\n",
      "Mode: Train env_steps 200 total rewards -500.828346664086 total energy tensor([[106.2977]])\n",
      "[-0.6913244]\n",
      "Mode: Train env_steps 200 total rewards -500.0760282166302 total energy tensor([[107.6771]])\n",
      "[0.03269178]\n",
      "Mode: Train env_steps 200 total rewards -519.0185649194755 total energy tensor([[103.8628]])\n",
      "[0.18293786]\n",
      "Mode: Train env_steps 200 total rewards -376.83089910354465 total energy tensor([[94.2396]])\n",
      "[-0.45969146]\n",
      "Mode: Train env_steps 200 total rewards -251.66619557328522 total energy tensor([[88.2611]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.43931282]\n",
      "Mode: Train env_steps 200 total rewards -128.1718663945794 total energy tensor([[82.3135]])\n",
      "[-0.13826263]\n",
      "Mode: Train env_steps 200 total rewards -378.04263319447637 total energy tensor([[104.3999]])\n",
      "[0.2644959]\n",
      "Mode: Train env_steps 200 total rewards -257.009716713801 total energy tensor([[95.6014]])\n",
      "[-0.95016146]\n",
      "Mode: Train env_steps 200 total rewards -414.04484786093235 total energy tensor([[112.8164]])\n",
      "[-0.05747367]\n",
      "Mode: Train env_steps 200 total rewards -5.951129362452775 total energy tensor([[67.3500]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18561506]\n",
      "Mode: Test env_steps 200 total rewards -131.0287338430062 total energy tensor([[85.4039]])\n",
      "[-0.55212164]\n",
      "Mode: Test env_steps 200 total rewards -383.4334128499031 total energy tensor([[108.4057]])\n",
      "[-0.39361602]\n",
      "Mode: Test env_steps 200 total rewards -393.77405304275453 total energy tensor([[104.4427]])\n",
      "[0.22922651]\n",
      "Mode: Test env_steps 200 total rewards -125.13320002704859 total energy tensor([[71.9627]])\n",
      "[0.77533776]\n",
      "Mode: Test env_steps 200 total rewards -130.94032694771886 total energy tensor([[69.0067]])\n",
      "[0.8630809]\n",
      "Mode: Test env_steps 200 total rewards -498.4769257362932 total energy tensor([[115.3406]])\n",
      "[0.20928445]\n",
      "Mode: Test env_steps 200 total rewards -133.0187003314495 total energy tensor([[74.5291]])\n",
      "[-0.7607418]\n",
      "Mode: Test env_steps 200 total rewards -306.9281320795417 total energy tensor([[96.5611]])\n",
      "[-0.978843]\n",
      "Mode: Test env_steps 200 total rewards -383.67935439758 total energy tensor([[107.2612]])\n",
      "[-0.66585755]\n",
      "Mode: Test env_steps 200 total rewards -126.85233711823821 total energy tensor([[85.0128]])\n",
      "370000 -261.3265176373534\n",
      "[0.9197964]\n",
      "Mode: Train env_steps 200 total rewards -122.8690498219803 total energy tensor([[69.6623]])\n",
      "[-0.01247578]\n",
      "Mode: Train env_steps 200 total rewards -130.03437889553607 total energy tensor([[68.1646]])\n",
      "[0.96240175]\n",
      "Mode: Train env_steps 200 total rewards -503.58870672620833 total energy tensor([[119.8496]])\n",
      "[0.19642422]\n",
      "Mode: Train env_steps 200 total rewards -384.50052315555513 total energy tensor([[107.7891]])\n",
      "[0.25488293]\n",
      "Mode: Train env_steps 200 total rewards -510.4233074821532 total energy tensor([[116.1557]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83792573]\n",
      "Mode: Train env_steps 200 total rewards -496.34063090384007 total energy tensor([[108.6797]])\n",
      "[-0.5353722]\n",
      "Mode: Train env_steps 200 total rewards -498.852583212778 total energy tensor([[103.1490]])\n",
      "[0.5719763]\n",
      "Mode: Train env_steps 200 total rewards -127.43028268404305 total energy tensor([[82.9107]])\n",
      "[-0.43496683]\n",
      "Mode: Train env_steps 200 total rewards -524.6446337811649 total energy tensor([[113.6666]])\n",
      "[0.5691466]\n",
      "Mode: Train env_steps 200 total rewards -387.36222089640796 total energy tensor([[103.4836]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4754319]\n",
      "Mode: Train env_steps 200 total rewards -373.3016210994683 total energy tensor([[89.7530]])\n",
      "[0.46163103]\n",
      "Mode: Train env_steps 200 total rewards -131.4268069481477 total energy tensor([[71.5229]])\n",
      "[-0.24152073]\n",
      "Mode: Train env_steps 200 total rewards -481.2444893592037 total energy tensor([[85.4223]])\n",
      "[-0.05478643]\n",
      "Mode: Train env_steps 200 total rewards -262.2682188823819 total energy tensor([[91.0309]])\n",
      "[0.6159564]\n",
      "Mode: Train env_steps 200 total rewards -279.3717014566064 total energy tensor([[114.2722]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773584]\n",
      "Mode: Train env_steps 200 total rewards -128.0873770257458 total energy tensor([[62.8376]])\n",
      "[0.7769176]\n",
      "Mode: Train env_steps 200 total rewards -6.858979467302561 total energy tensor([[64.4370]])\n",
      "[0.7583358]\n",
      "Mode: Train env_steps 200 total rewards -250.6404450116679 total energy tensor([[82.6115]])\n",
      "[-0.66959745]\n",
      "Mode: Train env_steps 200 total rewards -374.3180509088561 total energy tensor([[96.1289]])\n",
      "[-0.64761513]\n",
      "Mode: Train env_steps 200 total rewards -130.48791969567537 total energy tensor([[73.6847]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:54<00:00,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4530173]\n",
      "Mode: Train env_steps 200 total rewards -126.48606133996509 total energy tensor([[82.5282]])\n",
      "[0.1420551]\n",
      "Mode: Train env_steps 200 total rewards -130.55697378050536 total energy tensor([[71.5856]])\n",
      "[-0.5181115]\n",
      "Mode: Train env_steps 200 total rewards -260.4496432263404 total energy tensor([[88.3334]])\n",
      "[-0.701325]\n",
      "Mode: Train env_steps 200 total rewards -271.2327365707606 total energy tensor([[94.8346]])\n",
      "[0.06759423]\n",
      "Mode: Train env_steps 200 total rewards -378.6124172769487 total energy tensor([[104.0148]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07184645]\n",
      "Mode: Test env_steps 200 total rewards -257.3325675930828 total energy tensor([[91.2383]])\n",
      "[0.8864339]\n",
      "Mode: Test env_steps 200 total rewards -6.4289485844783485 total energy tensor([[76.3030]])\n",
      "[-0.0341417]\n",
      "Mode: Test env_steps 200 total rewards -249.93568814732134 total energy tensor([[99.6793]])\n",
      "[0.3002264]\n",
      "Mode: Test env_steps 200 total rewards -380.88179543893784 total energy tensor([[108.4937]])\n",
      "[-0.76127154]\n",
      "Mode: Test env_steps 200 total rewards -373.5985479429364 total energy tensor([[103.9460]])\n",
      "[0.253961]\n",
      "Mode: Test env_steps 200 total rewards -123.35234755696729 total energy tensor([[79.8108]])\n",
      "[-0.8449085]\n",
      "Mode: Test env_steps 200 total rewards -255.61916491948068 total energy tensor([[100.9193]])\n",
      "[0.94186264]\n",
      "Mode: Test env_steps 200 total rewards -252.8761398885399 total energy tensor([[96.3738]])\n",
      "[-0.24465129]\n",
      "Mode: Test env_steps 200 total rewards -361.8514939791057 total energy tensor([[101.0606]])\n",
      "[0.4465114]\n",
      "Mode: Test env_steps 200 total rewards -264.0833974489942 total energy tensor([[101.6647]])\n",
      "375000 -252.59600914998447\n",
      "[-0.56983286]\n",
      "Mode: Train env_steps 200 total rewards -127.30226219724864 total energy tensor([[77.7292]])\n",
      "[-0.2260538]\n",
      "Mode: Train env_steps 200 total rewards -356.14905746281147 total energy tensor([[111.1365]])\n",
      "[0.75226235]\n",
      "Mode: Train env_steps 200 total rewards -261.8679296551272 total energy tensor([[94.2097]])\n",
      "[-0.2714037]\n",
      "Mode: Train env_steps 200 total rewards -133.8243005797267 total energy tensor([[84.7983]])\n",
      "[0.66830254]\n",
      "Mode: Train env_steps 200 total rewards -129.43785454984754 total energy tensor([[97.2337]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9563634]\n",
      "Mode: Train env_steps 200 total rewards -247.0540231615305 total energy tensor([[96.8031]])\n",
      "[0.5749626]\n",
      "Mode: Train env_steps 200 total rewards -265.74029541853815 total energy tensor([[106.3292]])\n",
      "[0.4508535]\n",
      "Mode: Train env_steps 200 total rewards -342.68603051733226 total energy tensor([[95.4501]])\n",
      "[-0.9971608]\n",
      "Mode: Train env_steps 200 total rewards -619.531865555793 total energy tensor([[119.9544]])\n",
      "[-0.6651905]\n",
      "Mode: Train env_steps 200 total rewards -130.69729467108846 total energy tensor([[70.3818]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37388667]\n",
      "Mode: Train env_steps 200 total rewards -131.04853469785303 total energy tensor([[81.2416]])\n",
      "[-0.99445385]\n",
      "Mode: Train env_steps 200 total rewards -253.11270051915199 total energy tensor([[81.0567]])\n",
      "[-0.07772799]\n",
      "Mode: Train env_steps 200 total rewards -132.79421602748334 total energy tensor([[79.7805]])\n",
      "[-0.7884488]\n",
      "Mode: Train env_steps 200 total rewards -134.7662104293704 total energy tensor([[80.3076]])\n",
      "[0.48892465]\n",
      "Mode: Train env_steps 200 total rewards -647.979832097888 total energy tensor([[138.9991]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.69591355]\n",
      "Mode: Train env_steps 200 total rewards -126.99305343208835 total energy tensor([[66.0566]])\n",
      "[-0.2238701]\n",
      "Mode: Train env_steps 200 total rewards -134.94633263070136 total energy tensor([[81.4680]])\n",
      "[0.28365356]\n",
      "Mode: Train env_steps 200 total rewards -8.432710418477654 total energy tensor([[77.5294]])\n",
      "[0.07391413]\n",
      "Mode: Train env_steps 200 total rewards -132.49646371696144 total energy tensor([[80.3645]])\n",
      "[0.87099534]\n",
      "Mode: Train env_steps 200 total rewards -6.204279257915914 total energy tensor([[68.8362]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9859627]\n",
      "Mode: Train env_steps 200 total rewards -256.4365238454193 total energy tensor([[92.2248]])\n",
      "[0.3116487]\n",
      "Mode: Train env_steps 200 total rewards -127.0307598207146 total energy tensor([[70.1236]])\n",
      "[-0.80053276]\n",
      "Mode: Train env_steps 200 total rewards -7.893785908818245 total energy tensor([[72.1660]])\n",
      "[0.42814103]\n",
      "Mode: Train env_steps 200 total rewards -6.189437527093105 total energy tensor([[62.1647]])\n",
      "[-0.52309847]\n",
      "Mode: Train env_steps 200 total rewards -400.83260742016137 total energy tensor([[110.1838]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5460109]\n",
      "Mode: Test env_steps 200 total rewards -378.32375842751935 total energy tensor([[94.6807]])\n",
      "[-0.28601667]\n",
      "Mode: Test env_steps 200 total rewards -6.346348143182695 total energy tensor([[68.0748]])\n",
      "[0.6427838]\n",
      "Mode: Test env_steps 200 total rewards -134.3330907393247 total energy tensor([[74.5422]])\n",
      "[-0.5130481]\n",
      "Mode: Test env_steps 200 total rewards -249.8510027769953 total energy tensor([[99.7513]])\n",
      "[-0.37206846]\n",
      "Mode: Test env_steps 200 total rewards -6.994952470064163 total energy tensor([[71.3535]])\n",
      "[-0.23082177]\n",
      "Mode: Test env_steps 200 total rewards -126.19540606997907 total energy tensor([[72.3980]])\n",
      "[0.2769539]\n",
      "Mode: Test env_steps 200 total rewards -134.1839660485275 total energy tensor([[81.6622]])\n",
      "[-0.9089448]\n",
      "Mode: Test env_steps 200 total rewards -511.1232050731778 total energy tensor([[109.8693]])\n",
      "[-0.85160697]\n",
      "Mode: Test env_steps 200 total rewards -126.88885702099651 total energy tensor([[71.5786]])\n",
      "[-0.63364667]\n",
      "Mode: Test env_steps 200 total rewards -264.3348350953311 total energy tensor([[91.6544]])\n",
      "380000 -193.85754218650982\n",
      "[0.74423856]\n",
      "Mode: Train env_steps 200 total rewards -134.16221551597118 total energy tensor([[79.6101]])\n",
      "[0.74705863]\n",
      "Mode: Train env_steps 200 total rewards -376.9136579707265 total energy tensor([[113.8069]])\n",
      "[0.21167548]\n",
      "Mode: Train env_steps 200 total rewards -375.4930471815169 total energy tensor([[94.5342]])\n",
      "[0.8021768]\n",
      "Mode: Train env_steps 200 total rewards -133.20107067818753 total energy tensor([[76.7869]])\n",
      "[0.31227797]\n",
      "Mode: Train env_steps 200 total rewards -371.5270603541285 total energy tensor([[92.8912]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32580143]\n",
      "Mode: Train env_steps 200 total rewards -129.72788961138576 total energy tensor([[62.0453]])\n",
      "[0.5260346]\n",
      "Mode: Train env_steps 200 total rewards -265.1141284084879 total energy tensor([[97.7703]])\n",
      "[-0.22353373]\n",
      "Mode: Train env_steps 200 total rewards -126.78363940201234 total energy tensor([[57.8051]])\n",
      "[0.35108972]\n",
      "Mode: Train env_steps 200 total rewards -126.43644916708581 total energy tensor([[56.0183]])\n",
      "[0.9132324]\n",
      "Mode: Train env_steps 200 total rewards -252.47161432914436 total energy tensor([[87.3258]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2244919]\n",
      "Mode: Train env_steps 200 total rewards -254.5205185492523 total energy tensor([[70.8474]])\n",
      "[0.7273635]\n",
      "Mode: Train env_steps 200 total rewards -128.86198561964557 total energy tensor([[74.3500]])\n",
      "[-0.6040003]\n",
      "Mode: Train env_steps 200 total rewards -634.728418149054 total energy tensor([[132.2300]])\n",
      "[-0.46076494]\n",
      "Mode: Train env_steps 200 total rewards -298.7713880338706 total energy tensor([[78.3347]])\n",
      "[0.23551533]\n",
      "Mode: Train env_steps 200 total rewards -256.7763868854381 total energy tensor([[69.1199]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42928553]\n",
      "Mode: Train env_steps 200 total rewards -244.39299109298736 total energy tensor([[107.9481]])\n",
      "[-0.6034361]\n",
      "Mode: Train env_steps 200 total rewards -252.8947893488221 total energy tensor([[81.5464]])\n",
      "[0.9097077]\n",
      "Mode: Train env_steps 200 total rewards -124.85657015163451 total energy tensor([[76.6775]])\n",
      "[-0.47125933]\n",
      "Mode: Train env_steps 200 total rewards -124.97086286311969 total energy tensor([[61.5396]])\n",
      "[-0.11979691]\n",
      "Mode: Train env_steps 200 total rewards -131.5477710799314 total energy tensor([[70.6972]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4149313]\n",
      "Mode: Train env_steps 200 total rewards -376.72078565042466 total energy tensor([[106.1509]])\n",
      "[-0.64527416]\n",
      "Mode: Train env_steps 200 total rewards -132.75399235868827 total energy tensor([[67.2547]])\n",
      "[-0.95333713]\n",
      "Mode: Train env_steps 200 total rewards -262.5206566983834 total energy tensor([[75.8112]])\n",
      "[-0.04341469]\n",
      "Mode: Train env_steps 200 total rewards -271.1517985993996 total energy tensor([[72.5427]])\n",
      "[-0.7727537]\n",
      "Mode: Train env_steps 200 total rewards -127.36105264630169 total energy tensor([[44.8626]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.75191724]\n",
      "Mode: Test env_steps 200 total rewards -3.7830711147980765 total energy tensor([[64.7512]])\n",
      "[-0.3501386]\n",
      "Mode: Test env_steps 200 total rewards -378.63081255555153 total energy tensor([[115.3160]])\n",
      "[0.90535027]\n",
      "Mode: Test env_steps 200 total rewards -135.6583183016628 total energy tensor([[102.8727]])\n",
      "[-0.6359509]\n",
      "Mode: Test env_steps 200 total rewards -263.16019204445183 total energy tensor([[115.1185]])\n",
      "[0.05946139]\n",
      "Mode: Test env_steps 200 total rewards -263.6606419309974 total energy tensor([[117.3379]])\n",
      "[-0.17403819]\n",
      "Mode: Test env_steps 200 total rewards -388.7140661329031 total energy tensor([[120.9952]])\n",
      "[0.85879934]\n",
      "Mode: Test env_steps 200 total rewards -135.4183980319649 total energy tensor([[90.6957]])\n",
      "[-0.26513377]\n",
      "Mode: Test env_steps 200 total rewards -380.9978006314486 total energy tensor([[118.4396]])\n",
      "[-0.68189305]\n",
      "Mode: Test env_steps 200 total rewards -255.3390788352117 total energy tensor([[99.0612]])\n",
      "[-0.02879815]\n",
      "Mode: Test env_steps 200 total rewards -250.19625243730843 total energy tensor([[96.9964]])\n",
      "385000 -245.55586320162985\n",
      "[0.3960603]\n",
      "Mode: Train env_steps 200 total rewards -130.45344899315387 total energy tensor([[94.0594]])\n",
      "[0.9375126]\n",
      "Mode: Train env_steps 200 total rewards -267.85013582743704 total energy tensor([[121.0354]])\n",
      "[-0.29507783]\n",
      "Mode: Train env_steps 200 total rewards -547.509034216404 total energy tensor([[129.5148]])\n",
      "[-0.9244449]\n",
      "Mode: Train env_steps 200 total rewards -270.81112059857696 total energy tensor([[126.7944]])\n",
      "[-0.31510502]\n",
      "Mode: Train env_steps 200 total rewards -378.19114150479436 total energy tensor([[129.1848]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07063625]\n",
      "Mode: Train env_steps 200 total rewards -261.109458969906 total energy tensor([[95.3326]])\n",
      "[-0.5479371]\n",
      "Mode: Train env_steps 200 total rewards -6.296175144147128 total energy tensor([[71.3603]])\n",
      "[0.8391538]\n",
      "Mode: Train env_steps 200 total rewards -131.0548716140911 total energy tensor([[70.6475]])\n",
      "[0.84384656]\n",
      "Mode: Train env_steps 200 total rewards -349.9259656574577 total energy tensor([[98.6577]])\n",
      "[0.00437048]\n",
      "Mode: Train env_steps 200 total rewards -8.037442992441356 total energy tensor([[75.5095]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25953305]\n",
      "Mode: Train env_steps 200 total rewards -132.1256679734215 total energy tensor([[66.4972]])\n",
      "[-0.9073009]\n",
      "Mode: Train env_steps 200 total rewards -127.94283515913412 total energy tensor([[64.3458]])\n",
      "[-0.34231687]\n",
      "Mode: Train env_steps 200 total rewards -124.15900834300555 total energy tensor([[69.0072]])\n",
      "[0.52858865]\n",
      "Mode: Train env_steps 200 total rewards -8.032013492425904 total energy tensor([[79.4207]])\n",
      "[-0.7852035]\n",
      "Mode: Train env_steps 200 total rewards -279.2222603461705 total energy tensor([[82.2552]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.94432956]\n",
      "Mode: Train env_steps 200 total rewards -133.92256522458047 total energy tensor([[95.4724]])\n",
      "[0.6028952]\n",
      "Mode: Train env_steps 200 total rewards -132.96269567869604 total energy tensor([[79.6918]])\n",
      "[0.29672834]\n",
      "Mode: Train env_steps 200 total rewards -255.60182615322992 total energy tensor([[101.7754]])\n",
      "[0.6278383]\n",
      "Mode: Train env_steps 200 total rewards -257.1831600461155 total energy tensor([[120.0024]])\n",
      "[-0.7753132]\n",
      "Mode: Train env_steps 200 total rewards -130.1071180095896 total energy tensor([[94.0275]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15277795]\n",
      "Mode: Train env_steps 200 total rewards -241.40780132077634 total energy tensor([[102.2637]])\n",
      "[-0.4074682]\n",
      "Mode: Train env_steps 200 total rewards -133.20413154922426 total energy tensor([[80.8929]])\n",
      "[0.44537205]\n",
      "Mode: Train env_steps 200 total rewards -281.60512896068394 total energy tensor([[98.4957]])\n",
      "[0.335843]\n",
      "Mode: Train env_steps 200 total rewards -377.0298956297338 total energy tensor([[110.3005]])\n",
      "[-0.01587563]\n",
      "Mode: Train env_steps 200 total rewards -314.12163489870727 total energy tensor([[100.6079]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.87136704]\n",
      "Mode: Test env_steps 200 total rewards -261.7859420860186 total energy tensor([[102.1744]])\n",
      "[-0.18180454]\n",
      "Mode: Test env_steps 200 total rewards -252.43209804221988 total energy tensor([[97.0647]])\n",
      "[0.08015302]\n",
      "Mode: Test env_steps 200 total rewards -125.57662318530492 total energy tensor([[70.2399]])\n",
      "[0.46582112]\n",
      "Mode: Test env_steps 200 total rewards -273.62300700112246 total energy tensor([[86.5003]])\n",
      "[0.16156967]\n",
      "Mode: Test env_steps 200 total rewards -248.5289835021831 total energy tensor([[100.6740]])\n",
      "[-0.774695]\n",
      "Mode: Test env_steps 200 total rewards -253.90748537424952 total energy tensor([[94.2349]])\n",
      "[0.02533076]\n",
      "Mode: Test env_steps 200 total rewards -261.38839751668274 total energy tensor([[89.0328]])\n",
      "[-0.59568465]\n",
      "Mode: Test env_steps 200 total rewards -389.39498546440154 total energy tensor([[108.2185]])\n",
      "[0.69535077]\n",
      "Mode: Test env_steps 200 total rewards -508.9275429882109 total energy tensor([[125.0221]])\n",
      "[-0.35256177]\n",
      "Mode: Test env_steps 200 total rewards -507.2740177884698 total energy tensor([[109.3452]])\n",
      "390000 -308.2839082948864\n",
      "[0.09218746]\n",
      "Mode: Train env_steps 200 total rewards -122.98683979536872 total energy tensor([[60.7936]])\n",
      "[0.691289]\n",
      "Mode: Train env_steps 200 total rewards -246.95089611038566 total energy tensor([[96.7181]])\n",
      "[0.7436578]\n",
      "Mode: Train env_steps 200 total rewards -131.6440302459523 total energy tensor([[74.4803]])\n",
      "[0.41048092]\n",
      "Mode: Train env_steps 200 total rewards -276.15266990161035 total energy tensor([[82.7642]])\n",
      "[0.6568503]\n",
      "Mode: Train env_steps 200 total rewards -124.96794504858553 total energy tensor([[65.5218]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:29<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52446795]\n",
      "Mode: Train env_steps 200 total rewards -132.75922987656668 total energy tensor([[79.0508]])\n",
      "[-0.5317428]\n",
      "Mode: Train env_steps 200 total rewards -272.05417110712733 total energy tensor([[82.5955]])\n",
      "[-0.57383204]\n",
      "Mode: Train env_steps 200 total rewards -128.86886560590938 total energy tensor([[69.6168]])\n",
      "[0.8919884]\n",
      "Mode: Train env_steps 200 total rewards -130.706323931925 total energy tensor([[68.2637]])\n",
      "[-0.727031]\n",
      "Mode: Train env_steps 200 total rewards -130.15568574517965 total energy tensor([[73.9020]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60457194]\n",
      "Mode: Train env_steps 200 total rewards -126.76129164523445 total energy tensor([[87.1658]])\n",
      "[-0.5183379]\n",
      "Mode: Train env_steps 200 total rewards -374.80960279982537 total energy tensor([[102.6354]])\n",
      "[-0.30018252]\n",
      "Mode: Train env_steps 200 total rewards -4.683292672270909 total energy tensor([[63.7907]])\n",
      "[0.40674135]\n",
      "Mode: Train env_steps 200 total rewards -121.89396021771245 total energy tensor([[80.1128]])\n",
      "[-0.36096025]\n",
      "Mode: Train env_steps 200 total rewards -259.57522765081376 total energy tensor([[96.2874]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45161197]\n",
      "Mode: Train env_steps 200 total rewards -357.4544113408774 total energy tensor([[125.5479]])\n",
      "[-0.44320363]\n",
      "Mode: Train env_steps 200 total rewards -5.995749833993614 total energy tensor([[83.9480]])\n",
      "[-0.14495488]\n",
      "Mode: Train env_steps 200 total rewards -380.2735011000186 total energy tensor([[121.3336]])\n",
      "[0.00288202]\n",
      "Mode: Train env_steps 200 total rewards -257.5897716274485 total energy tensor([[92.5282]])\n",
      "[-0.92426264]\n",
      "Mode: Train env_steps 200 total rewards -514.3434349521995 total energy tensor([[133.4508]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5855204]\n",
      "Mode: Train env_steps 200 total rewards -426.84067128039896 total energy tensor([[111.0530]])\n",
      "[0.07968094]\n",
      "Mode: Train env_steps 200 total rewards -236.6831240421161 total energy tensor([[121.5013]])\n",
      "[0.06727659]\n",
      "Mode: Train env_steps 200 total rewards -130.90049708355218 total energy tensor([[88.9436]])\n",
      "[0.5763603]\n",
      "Mode: Train env_steps 200 total rewards -123.73227935936302 total energy tensor([[85.9457]])\n",
      "[0.15331642]\n",
      "Mode: Train env_steps 200 total rewards -126.94411492533982 total energy tensor([[95.9905]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86188453]\n",
      "Mode: Test env_steps 200 total rewards -133.05524637550116 total energy tensor([[97.7848]])\n",
      "[0.44119477]\n",
      "Mode: Test env_steps 200 total rewards -138.00417661480606 total energy tensor([[101.7768]])\n",
      "[-0.16434957]\n",
      "Mode: Test env_steps 200 total rewards -133.2300299955532 total energy tensor([[100.0696]])\n",
      "[0.49536675]\n",
      "Mode: Test env_steps 200 total rewards -133.67364353407174 total energy tensor([[97.1364]])\n",
      "[0.5399458]\n",
      "Mode: Test env_steps 200 total rewards -134.0546357324347 total energy tensor([[96.1744]])\n",
      "[-0.08496605]\n",
      "Mode: Test env_steps 200 total rewards -132.26649820804596 total energy tensor([[92.2130]])\n",
      "[0.5941201]\n",
      "Mode: Test env_steps 200 total rewards -136.24894420336932 total energy tensor([[98.4757]])\n",
      "[0.5390654]\n",
      "Mode: Test env_steps 200 total rewards -389.73766780644655 total energy tensor([[133.6817]])\n",
      "[-0.5044895]\n",
      "Mode: Test env_steps 200 total rewards -134.2313934257254 total energy tensor([[96.6048]])\n",
      "[0.00154828]\n",
      "Mode: Test env_steps 200 total rewards -387.05158676346764 total energy tensor([[118.9870]])\n",
      "395000 -185.15538226594217\n",
      "[0.8113073]\n",
      "Mode: Train env_steps 200 total rewards -579.1153136398643 total energy tensor([[121.1780]])\n",
      "[0.9204573]\n",
      "Mode: Train env_steps 200 total rewards -253.29759342875332 total energy tensor([[121.5045]])\n",
      "[0.7558556]\n",
      "Mode: Train env_steps 200 total rewards -129.08080002479255 total energy tensor([[82.7771]])\n",
      "[-0.7249663]\n",
      "Mode: Train env_steps 200 total rewards -245.62825170811266 total energy tensor([[119.9407]])\n",
      "[0.88293004]\n",
      "Mode: Train env_steps 200 total rewards -258.9311334900558 total energy tensor([[122.7959]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9774723]\n",
      "Mode: Train env_steps 200 total rewards -125.12436643615365 total energy tensor([[70.2388]])\n",
      "[-0.11171784]\n",
      "Mode: Train env_steps 200 total rewards -3.5450778040103614 total energy tensor([[61.6270]])\n",
      "[0.03481805]\n",
      "Mode: Train env_steps 200 total rewards -263.01121722115204 total energy tensor([[91.2145]])\n",
      "[-0.7358936]\n",
      "Mode: Train env_steps 200 total rewards -135.19160139933228 total energy tensor([[83.1698]])\n",
      "[0.22323738]\n",
      "Mode: Train env_steps 200 total rewards -264.2457426963374 total energy tensor([[108.0985]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.2642048]\n",
      "Mode: Train env_steps 200 total rewards -2.9413858391344547 total energy tensor([[64.4702]])\n",
      "[-0.14980944]\n",
      "Mode: Train env_steps 200 total rewards -265.72715951828286 total energy tensor([[115.9424]])\n",
      "[0.33043855]\n",
      "Mode: Train env_steps 200 total rewards -247.65503195207566 total energy tensor([[93.7013]])\n",
      "[-0.9197985]\n",
      "Mode: Train env_steps 200 total rewards -254.0225545084104 total energy tensor([[112.8697]])\n",
      "[0.59917694]\n",
      "Mode: Train env_steps 200 total rewards -131.84537577512674 total energy tensor([[78.3215]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.42946798]\n",
      "Mode: Train env_steps 200 total rewards -505.30810707621276 total energy tensor([[119.1841]])\n",
      "[-0.8922113]\n",
      "Mode: Train env_steps 200 total rewards -264.3526847118046 total energy tensor([[100.8649]])\n",
      "[-0.38795742]\n",
      "Mode: Train env_steps 200 total rewards -133.75798690505326 total energy tensor([[82.6752]])\n",
      "[0.1059301]\n",
      "Mode: Train env_steps 200 total rewards -238.90586095955223 total energy tensor([[106.6093]])\n",
      "[-0.2107451]\n",
      "Mode: Train env_steps 200 total rewards -126.54597786458908 total energy tensor([[74.9596]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9895905]\n",
      "Mode: Train env_steps 200 total rewards -134.46857404708862 total energy tensor([[89.4367]])\n",
      "[0.295367]\n",
      "Mode: Train env_steps 200 total rewards -404.0599941127002 total energy tensor([[125.0726]])\n",
      "[-0.6128839]\n",
      "Mode: Train env_steps 200 total rewards -129.87002528831363 total energy tensor([[75.3168]])\n",
      "[0.4451832]\n",
      "Mode: Train env_steps 200 total rewards -128.60981694888324 total energy tensor([[77.2932]])\n",
      "[-0.15782692]\n",
      "Mode: Train env_steps 200 total rewards -4.8828506474383175 total energy tensor([[75.6809]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1757025]\n",
      "Mode: Test env_steps 200 total rewards -2.823575493588578 total energy tensor([[58.2457]])\n",
      "[0.5980894]\n",
      "Mode: Test env_steps 200 total rewards -132.99990404187702 total energy tensor([[80.5903]])\n",
      "[-0.01055077]\n",
      "Mode: Test env_steps 200 total rewards -232.84320762753487 total energy tensor([[104.5288]])\n",
      "[0.5989895]\n",
      "Mode: Test env_steps 200 total rewards -131.1512600139249 total energy tensor([[78.4329]])\n",
      "[-0.37529367]\n",
      "Mode: Test env_steps 200 total rewards -376.3820355013013 total energy tensor([[119.5789]])\n",
      "[-0.28015572]\n",
      "Mode: Test env_steps 200 total rewards -257.4146556011401 total energy tensor([[109.8770]])\n",
      "[0.94434494]\n",
      "Mode: Test env_steps 200 total rewards -246.0841778484173 total energy tensor([[96.4027]])\n",
      "[-0.85203207]\n",
      "Mode: Test env_steps 200 total rewards -285.71496245265007 total energy tensor([[92.8476]])\n",
      "[0.739228]\n",
      "Mode: Test env_steps 200 total rewards -272.0421062831301 total energy tensor([[88.6190]])\n",
      "[0.85052127]\n",
      "Mode: Test env_steps 200 total rewards -327.20628991769627 total energy tensor([[91.5239]])\n",
      "400000 -226.46621747812605\n",
      "[0.44925955]\n",
      "Mode: Train env_steps 200 total rewards -357.37909424025565 total energy tensor([[103.2013]])\n",
      "[-0.9011067]\n",
      "Mode: Train env_steps 200 total rewards -135.57892063469626 total energy tensor([[96.5193]])\n",
      "[-0.44154054]\n",
      "Mode: Train env_steps 200 total rewards -123.69473169883713 total energy tensor([[66.9420]])\n",
      "[-0.5832702]\n",
      "Mode: Train env_steps 200 total rewards -133.95752774225548 total energy tensor([[89.9374]])\n",
      "[0.21480815]\n",
      "Mode: Train env_steps 200 total rewards -378.0937159443274 total energy tensor([[123.2893]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6045759]\n",
      "Mode: Train env_steps 200 total rewards -253.44892381783575 total energy tensor([[91.6751]])\n",
      "[-0.54593676]\n",
      "Mode: Train env_steps 200 total rewards -127.79274157527834 total energy tensor([[73.4730]])\n",
      "[-0.54468024]\n",
      "Mode: Train env_steps 200 total rewards -260.7421689131297 total energy tensor([[95.5127]])\n",
      "[0.01870722]\n",
      "Mode: Train env_steps 200 total rewards -505.5915277111344 total energy tensor([[107.7457]])\n",
      "[-0.8187979]\n",
      "Mode: Train env_steps 200 total rewards -505.02847889252007 total energy tensor([[103.9653]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3684694]\n",
      "Mode: Train env_steps 200 total rewards -312.1024969005957 total energy tensor([[93.9797]])\n",
      "[0.8328634]\n",
      "Mode: Train env_steps 200 total rewards -131.44884561467916 total energy tensor([[88.3792]])\n",
      "[-0.28130153]\n",
      "Mode: Train env_steps 200 total rewards -519.1750292181969 total energy tensor([[134.0992]])\n",
      "[0.40950772]\n",
      "Mode: Train env_steps 200 total rewards -135.39375940803438 total energy tensor([[88.0220]])\n",
      "[-0.95860857]\n",
      "Mode: Train env_steps 200 total rewards -132.99899392807856 total energy tensor([[89.4396]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5082514]\n",
      "Mode: Train env_steps 200 total rewards -132.89475113106892 total energy tensor([[105.3856]])\n",
      "[-0.07658666]\n",
      "Mode: Train env_steps 200 total rewards -130.66777069307864 total energy tensor([[93.3217]])\n",
      "[-0.8348187]\n",
      "Mode: Train env_steps 200 total rewards -124.20843113493174 total energy tensor([[89.6023]])\n",
      "[0.88763714]\n",
      "Mode: Train env_steps 200 total rewards -123.76845866534859 total energy tensor([[76.0492]])\n",
      "[0.08949307]\n",
      "Mode: Train env_steps 200 total rewards -126.4863159111701 total energy tensor([[86.0740]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.77957547]\n",
      "Mode: Train env_steps 200 total rewards -11.33533895201981 total energy tensor([[114.0443]])\n",
      "[0.25828195]\n",
      "Mode: Train env_steps 200 total rewards -127.29506314173341 total energy tensor([[114.3466]])\n",
      "[0.03430737]\n",
      "Mode: Train env_steps 200 total rewards -125.85713141411543 total energy tensor([[113.1139]])\n",
      "[0.8471752]\n",
      "Mode: Train env_steps 200 total rewards -265.2427871823311 total energy tensor([[115.4237]])\n",
      "[-0.84350115]\n",
      "Mode: Train env_steps 200 total rewards -8.589588765054941 total energy tensor([[109.3862]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10357594]\n",
      "Mode: Test env_steps 200 total rewards -129.58875820972025 total energy tensor([[104.9394]])\n",
      "[0.42813003]\n",
      "Mode: Test env_steps 200 total rewards -132.46889135241508 total energy tensor([[108.0153]])\n",
      "[0.42093468]\n",
      "Mode: Test env_steps 200 total rewards -121.57934735156596 total energy tensor([[107.8867]])\n",
      "[-0.5154633]\n",
      "Mode: Test env_steps 200 total rewards -140.88550103642046 total energy tensor([[123.2785]])\n",
      "[-0.6242603]\n",
      "Mode: Test env_steps 200 total rewards -6.695881597697735 total energy tensor([[101.0999]])\n",
      "[-0.15989801]\n",
      "Mode: Test env_steps 200 total rewards -137.18450320884585 total energy tensor([[108.2413]])\n",
      "[0.8444811]\n",
      "Mode: Test env_steps 200 total rewards -120.49271633476019 total energy tensor([[99.9221]])\n",
      "[0.99582106]\n",
      "Mode: Test env_steps 200 total rewards -9.402954265475273 total energy tensor([[111.1623]])\n",
      "[0.82739127]\n",
      "Mode: Test env_steps 200 total rewards -511.531136918813 total energy tensor([[124.7650]])\n",
      "[0.34772572]\n",
      "Mode: Test env_steps 200 total rewards -635.8674233034253 total energy tensor([[149.1557]])\n",
      "405000 -194.56971135791392\n",
      "[0.9022509]\n",
      "Mode: Train env_steps 200 total rewards -257.63233050331473 total energy tensor([[139.8284]])\n",
      "[-0.42334434]\n",
      "Mode: Train env_steps 200 total rewards -128.94714746903628 total energy tensor([[108.1931]])\n",
      "[0.6694793]\n",
      "Mode: Train env_steps 200 total rewards -518.5538590848446 total energy tensor([[120.3858]])\n",
      "[0.29093882]\n",
      "Mode: Train env_steps 200 total rewards -128.79712281934917 total energy tensor([[106.2275]])\n",
      "[-0.82252103]\n",
      "Mode: Train env_steps 200 total rewards -244.47905897907913 total energy tensor([[121.1530]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7664633]\n",
      "Mode: Train env_steps 200 total rewards -123.10420066863298 total energy tensor([[104.6329]])\n",
      "[0.8327655]\n",
      "Mode: Train env_steps 200 total rewards -126.7218876844272 total energy tensor([[110.5229]])\n",
      "[-0.13048644]\n",
      "Mode: Train env_steps 200 total rewards -261.7806737581268 total energy tensor([[108.2456]])\n",
      "[-0.4362494]\n",
      "Mode: Train env_steps 200 total rewards -254.18219517171383 total energy tensor([[122.5229]])\n",
      "[0.17541887]\n",
      "Mode: Train env_steps 200 total rewards -376.3424288984388 total energy tensor([[122.3637]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70506346]\n",
      "Mode: Train env_steps 200 total rewards -127.56521775014699 total energy tensor([[99.0782]])\n",
      "[-0.10556433]\n",
      "Mode: Train env_steps 200 total rewards -136.51334758289158 total energy tensor([[119.7606]])\n",
      "[0.4993404]\n",
      "Mode: Train env_steps 200 total rewards -293.0246316222474 total energy tensor([[114.6738]])\n",
      "[-0.2953391]\n",
      "Mode: Train env_steps 200 total rewards -129.22429089713842 total energy tensor([[99.6303]])\n",
      "[-0.34732637]\n",
      "Mode: Train env_steps 200 total rewards -131.98761553503573 total energy tensor([[105.2810]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41532677]\n",
      "Mode: Train env_steps 200 total rewards -256.42852046189364 total energy tensor([[84.8886]])\n",
      "[-0.04871292]\n",
      "Mode: Train env_steps 200 total rewards -384.44577422505245 total energy tensor([[120.5216]])\n",
      "[-0.08171798]\n",
      "Mode: Train env_steps 200 total rewards -131.27579506940674 total energy tensor([[70.4328]])\n",
      "[0.6193056]\n",
      "Mode: Train env_steps 200 total rewards -232.772186225513 total energy tensor([[95.4266]])\n",
      "[0.16807465]\n",
      "Mode: Train env_steps 200 total rewards -126.14213320866111 total energy tensor([[66.3606]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07181735]\n",
      "Mode: Train env_steps 200 total rewards -127.47127347602509 total energy tensor([[64.6140]])\n",
      "[0.11933267]\n",
      "Mode: Train env_steps 200 total rewards -243.38721469650045 total energy tensor([[98.3799]])\n",
      "[-0.867126]\n",
      "Mode: Train env_steps 200 total rewards -249.08147091045976 total energy tensor([[114.5077]])\n",
      "[0.3203768]\n",
      "Mode: Train env_steps 200 total rewards -4.153889393201098 total energy tensor([[67.8215]])\n",
      "[-0.71465343]\n",
      "Mode: Train env_steps 200 total rewards -361.70042693801224 total energy tensor([[120.0753]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.65442306]\n",
      "Mode: Test env_steps 200 total rewards -131.32385339587927 total energy tensor([[68.4422]])\n",
      "[-0.06216547]\n",
      "Mode: Test env_steps 200 total rewards -132.14803693583235 total energy tensor([[79.0521]])\n",
      "[0.7733417]\n",
      "Mode: Test env_steps 200 total rewards -130.37456628121436 total energy tensor([[62.8122]])\n",
      "[0.96335155]\n",
      "Mode: Test env_steps 200 total rewards -131.44904443854466 total energy tensor([[72.2331]])\n",
      "[0.6591492]\n",
      "Mode: Test env_steps 200 total rewards -257.83246714482084 total energy tensor([[99.5625]])\n",
      "[-0.8280794]\n",
      "Mode: Test env_steps 200 total rewards -120.14800397260115 total energy tensor([[72.2177]])\n",
      "[0.20952757]\n",
      "Mode: Test env_steps 200 total rewards -256.001141410321 total energy tensor([[101.4209]])\n",
      "[-0.6993423]\n",
      "Mode: Test env_steps 200 total rewards -129.29263482801616 total energy tensor([[78.0083]])\n",
      "[0.49403346]\n",
      "Mode: Test env_steps 200 total rewards -254.57941517746076 total energy tensor([[86.6494]])\n",
      "[-0.20603812]\n",
      "Mode: Test env_steps 200 total rewards -131.856510351412 total energy tensor([[74.4662]])\n",
      "410000 -167.50056739361025\n",
      "[0.6215517]\n",
      "Mode: Train env_steps 200 total rewards -256.1379376752302 total energy tensor([[91.1625]])\n",
      "[0.4886101]\n",
      "Mode: Train env_steps 200 total rewards -125.04314806638286 total energy tensor([[63.8430]])\n",
      "[-0.13088034]\n",
      "Mode: Train env_steps 200 total rewards -127.98248120909557 total energy tensor([[64.0362]])\n",
      "[-0.7437088]\n",
      "Mode: Train env_steps 200 total rewards -133.57365587819368 total energy tensor([[81.2277]])\n",
      "[-0.88716984]\n",
      "Mode: Train env_steps 200 total rewards -133.0372624876909 total energy tensor([[75.2536]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2692116]\n",
      "Mode: Train env_steps 200 total rewards -407.31513555534184 total energy tensor([[124.1468]])\n",
      "[0.3093288]\n",
      "Mode: Train env_steps 200 total rewards -136.3842107206583 total energy tensor([[109.6869]])\n",
      "[0.19260442]\n",
      "Mode: Train env_steps 200 total rewards -125.21986669301987 total energy tensor([[104.9863]])\n",
      "[-0.05391455]\n",
      "Mode: Train env_steps 200 total rewards -136.07360343262553 total energy tensor([[107.3049]])\n",
      "[0.42689136]\n",
      "Mode: Train env_steps 200 total rewards -133.9945906214416 total energy tensor([[107.0952]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3930481]\n",
      "Mode: Train env_steps 200 total rewards -249.27449785079807 total energy tensor([[99.7514]])\n",
      "[0.955744]\n",
      "Mode: Train env_steps 200 total rewards -266.63041775487363 total energy tensor([[108.6535]])\n",
      "[-0.52007705]\n",
      "Mode: Train env_steps 200 total rewards -133.62948178499937 total energy tensor([[91.1720]])\n",
      "[-0.44471744]\n",
      "Mode: Train env_steps 200 total rewards -6.563594427891076 total energy tensor([[91.1879]])\n",
      "[0.3497335]\n",
      "Mode: Train env_steps 200 total rewards -138.31685292557813 total energy tensor([[105.0639]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2080693]\n",
      "Mode: Train env_steps 200 total rewards -128.64635780942626 total energy tensor([[65.9391]])\n",
      "[0.89646244]\n",
      "Mode: Train env_steps 200 total rewards -250.70518260644167 total energy tensor([[96.7438]])\n",
      "[-0.15008847]\n",
      "Mode: Train env_steps 200 total rewards -635.3772819638252 total energy tensor([[79.3956]])\n",
      "[-0.26775908]\n",
      "Mode: Train env_steps 200 total rewards -252.45410488173366 total energy tensor([[96.2131]])\n",
      "[0.19371863]\n",
      "Mode: Train env_steps 200 total rewards -3.5921561918221414 total energy tensor([[50.8423]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77788275]\n",
      "Mode: Train env_steps 200 total rewards -411.5665393099189 total energy tensor([[107.8371]])\n",
      "[0.18437195]\n",
      "Mode: Train env_steps 200 total rewards -4.96224226616323 total energy tensor([[73.8984]])\n",
      "[0.865183]\n",
      "Mode: Train env_steps 200 total rewards -395.61476205615327 total energy tensor([[112.1313]])\n",
      "[-0.06720499]\n",
      "Mode: Train env_steps 200 total rewards -385.8449622914195 total energy tensor([[104.6151]])\n",
      "[-0.58292407]\n",
      "Mode: Train env_steps 200 total rewards -304.4521328881383 total energy tensor([[102.6226]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.6492773]\n",
      "Mode: Test env_steps 200 total rewards -266.08562625572085 total energy tensor([[124.0290]])\n",
      "[-0.60987514]\n",
      "Mode: Test env_steps 200 total rewards -129.55253752879798 total energy tensor([[106.0873]])\n",
      "[0.29772618]\n",
      "Mode: Test env_steps 200 total rewards -134.22881651483476 total energy tensor([[130.6486]])\n",
      "[0.8041852]\n",
      "Mode: Test env_steps 200 total rewards -8.004021401517093 total energy tensor([[109.4201]])\n",
      "[0.0692024]\n",
      "Mode: Test env_steps 200 total rewards -131.05976055189967 total energy tensor([[123.9969]])\n",
      "[-0.00491407]\n",
      "Mode: Test env_steps 200 total rewards -9.638385869562626 total energy tensor([[114.4445]])\n",
      "[0.19625202]\n",
      "Mode: Test env_steps 200 total rewards -128.63624334149063 total energy tensor([[115.3690]])\n",
      "[0.78710526]\n",
      "Mode: Test env_steps 200 total rewards -654.4525948660448 total energy tensor([[113.2914]])\n",
      "[0.7145403]\n",
      "Mode: Test env_steps 200 total rewards -127.16336990520358 total energy tensor([[114.1724]])\n",
      "[0.1307814]\n",
      "Mode: Test env_steps 200 total rewards -129.94452757388353 total energy tensor([[108.5692]])\n",
      "415000 -171.87658838089556\n",
      "[-0.87284505]\n",
      "Mode: Train env_steps 200 total rewards -263.7378883268684 total energy tensor([[114.1941]])\n",
      "[-0.8359797]\n",
      "Mode: Train env_steps 200 total rewards -129.61024154536426 total energy tensor([[108.2555]])\n",
      "[0.85307765]\n",
      "Mode: Train env_steps 200 total rewards -253.84073409438133 total energy tensor([[117.3468]])\n",
      "[0.23419495]\n",
      "Mode: Train env_steps 200 total rewards -138.50086875259876 total energy tensor([[123.0224]])\n",
      "[-0.4695125]\n",
      "Mode: Train env_steps 200 total rewards -260.2002913195174 total energy tensor([[122.8373]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54417753]\n",
      "Mode: Train env_steps 200 total rewards -246.64066713489592 total energy tensor([[120.8575]])\n",
      "[0.38211071]\n",
      "Mode: Train env_steps 200 total rewards -126.82659686729312 total energy tensor([[100.3335]])\n",
      "[-0.00987436]\n",
      "Mode: Train env_steps 200 total rewards -127.8337620086968 total energy tensor([[96.5504]])\n",
      "[-0.33449775]\n",
      "Mode: Train env_steps 200 total rewards -138.25744411163032 total energy tensor([[111.3493]])\n",
      "[-0.09892291]\n",
      "Mode: Train env_steps 200 total rewards -513.5079808104783 total energy tensor([[125.0011]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.58965063]\n",
      "Mode: Train env_steps 200 total rewards -131.50322655402124 total energy tensor([[103.3530]])\n",
      "[-0.84919685]\n",
      "Mode: Train env_steps 200 total rewards -134.7557899383828 total energy tensor([[102.4265]])\n",
      "[0.8890147]\n",
      "Mode: Train env_steps 200 total rewards -127.28969570132904 total energy tensor([[113.0865]])\n",
      "[-0.06014033]\n",
      "Mode: Train env_steps 200 total rewards -264.39615417364985 total energy tensor([[115.7198]])\n",
      "[0.7148879]\n",
      "Mode: Train env_steps 200 total rewards -132.3602817170322 total energy tensor([[105.5625]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.771621]\n",
      "Mode: Train env_steps 200 total rewards -123.90128331119195 total energy tensor([[73.9279]])\n",
      "[-0.83195907]\n",
      "Mode: Train env_steps 200 total rewards -120.44958889414556 total energy tensor([[68.6778]])\n",
      "[-0.09281875]\n",
      "Mode: Train env_steps 200 total rewards -133.645862783771 total energy tensor([[78.4294]])\n",
      "[0.8884855]\n",
      "Mode: Train env_steps 200 total rewards -394.4103060560301 total energy tensor([[106.3164]])\n",
      "[0.47134167]\n",
      "Mode: Train env_steps 200 total rewards -619.2318308502436 total energy tensor([[125.0410]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08135227]\n",
      "Mode: Train env_steps 200 total rewards -3.2450912061613053 total energy tensor([[66.1315]])\n",
      "[0.91261274]\n",
      "Mode: Train env_steps 200 total rewards -129.48258967814036 total energy tensor([[73.1238]])\n",
      "[0.30646488]\n",
      "Mode: Train env_steps 200 total rewards -251.39176987297833 total energy tensor([[101.1913]])\n",
      "[-0.28888336]\n",
      "Mode: Train env_steps 200 total rewards -126.9468453892041 total energy tensor([[70.6517]])\n",
      "[-0.6676204]\n",
      "Mode: Train env_steps 200 total rewards -128.86168734473176 total energy tensor([[72.5521]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20564078]\n",
      "Mode: Test env_steps 200 total rewards -132.27314668428153 total energy tensor([[88.2023]])\n",
      "[-0.45909014]\n",
      "Mode: Test env_steps 200 total rewards -125.27851551864296 total energy tensor([[86.9910]])\n",
      "[-0.5838373]\n",
      "Mode: Test env_steps 200 total rewards -245.4652844723314 total energy tensor([[110.2639]])\n",
      "[0.99625254]\n",
      "Mode: Test env_steps 200 total rewards -4.3480151407420635 total energy tensor([[87.5209]])\n",
      "[-0.31978855]\n",
      "Mode: Test env_steps 200 total rewards -129.353558964096 total energy tensor([[89.4140]])\n",
      "[-0.32902682]\n",
      "Mode: Test env_steps 200 total rewards -243.32358399033546 total energy tensor([[102.8763]])\n",
      "[-0.4719692]\n",
      "Mode: Test env_steps 200 total rewards -121.85455899545923 total energy tensor([[97.4104]])\n",
      "[-0.16678227]\n",
      "Mode: Test env_steps 200 total rewards -130.57881307881325 total energy tensor([[88.9342]])\n",
      "[0.9230409]\n",
      "Mode: Test env_steps 200 total rewards -132.8346819486469 total energy tensor([[89.2704]])\n",
      "[0.9377841]\n",
      "Mode: Test env_steps 200 total rewards -261.3416503947228 total energy tensor([[120.0396]])\n",
      "420000 -152.66518091880715\n",
      "[0.39739555]\n",
      "Mode: Train env_steps 200 total rewards -131.29462058562785 total energy tensor([[98.7398]])\n",
      "[0.6112798]\n",
      "Mode: Train env_steps 200 total rewards -129.90363084385172 total energy tensor([[88.7388]])\n",
      "[0.576239]\n",
      "Mode: Train env_steps 200 total rewards -123.49273735890165 total energy tensor([[93.2550]])\n",
      "[-0.8155632]\n",
      "Mode: Train env_steps 200 total rewards -2.9669306511059403 total energy tensor([[81.8532]])\n",
      "[-0.19816478]\n",
      "Mode: Train env_steps 200 total rewards -257.5250807888806 total energy tensor([[110.4122]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8208042]\n",
      "Mode: Train env_steps 200 total rewards -121.35595079977065 total energy tensor([[76.3567]])\n",
      "[-0.6513287]\n",
      "Mode: Train env_steps 200 total rewards -133.37660824041814 total energy tensor([[87.9904]])\n",
      "[0.87038225]\n",
      "Mode: Train env_steps 200 total rewards -128.5176377943717 total energy tensor([[78.8100]])\n",
      "[0.1264204]\n",
      "Mode: Train env_steps 200 total rewards -385.6164037026465 total energy tensor([[124.5911]])\n",
      "[-0.2832867]\n",
      "Mode: Train env_steps 200 total rewards -123.98581496067345 total energy tensor([[91.7328]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9712022]\n",
      "Mode: Train env_steps 200 total rewards -131.70129360165447 total energy tensor([[86.8590]])\n",
      "[-0.0474818]\n",
      "Mode: Train env_steps 200 total rewards -128.6500205527991 total energy tensor([[84.1111]])\n",
      "[-0.38945547]\n",
      "Mode: Train env_steps 200 total rewards -354.47057158127427 total energy tensor([[117.8209]])\n",
      "[0.30532888]\n",
      "Mode: Train env_steps 200 total rewards -132.43276605010033 total energy tensor([[87.5490]])\n",
      "[0.12407919]\n",
      "Mode: Train env_steps 200 total rewards -131.72267409972847 total energy tensor([[88.9453]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.40725017]\n",
      "Mode: Train env_steps 200 total rewards -264.33555741701275 total energy tensor([[111.0703]])\n",
      "[-0.3439343]\n",
      "Mode: Train env_steps 200 total rewards -127.27065961482003 total energy tensor([[70.0129]])\n",
      "[0.86532336]\n",
      "Mode: Train env_steps 200 total rewards -128.371771894861 total energy tensor([[79.8488]])\n",
      "[0.62493]\n",
      "Mode: Train env_steps 200 total rewards -125.4616404864937 total energy tensor([[80.9075]])\n",
      "[0.07361115]\n",
      "Mode: Train env_steps 200 total rewards -129.58623471762985 total energy tensor([[83.7700]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.87650317]\n",
      "Mode: Train env_steps 200 total rewards -396.5054182820022 total energy tensor([[118.1453]])\n",
      "[-0.08275768]\n",
      "Mode: Train env_steps 200 total rewards -371.6507492978126 total energy tensor([[122.6237]])\n",
      "[-0.51454586]\n",
      "Mode: Train env_steps 200 total rewards -518.7207516375929 total energy tensor([[123.3343]])\n",
      "[0.2363221]\n",
      "Mode: Train env_steps 200 total rewards -387.46582286804914 total energy tensor([[108.5246]])\n",
      "[-0.7086866]\n",
      "Mode: Train env_steps 200 total rewards -373.3309856764972 total energy tensor([[123.7812]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9714694]\n",
      "Mode: Test env_steps 200 total rewards -378.9036791808903 total energy tensor([[112.5278]])\n",
      "[-0.6487191]\n",
      "Mode: Test env_steps 200 total rewards -303.36963482154533 total energy tensor([[103.5492]])\n",
      "[-0.5471673]\n",
      "Mode: Test env_steps 200 total rewards -126.7476163143292 total energy tensor([[80.0278]])\n",
      "[-0.6279056]\n",
      "Mode: Test env_steps 200 total rewards -258.85447240434587 total energy tensor([[99.0735]])\n",
      "[0.98951983]\n",
      "Mode: Test env_steps 200 total rewards -124.78116799145937 total energy tensor([[84.2081]])\n",
      "[0.19543515]\n",
      "Mode: Test env_steps 200 total rewards -133.3584673604346 total energy tensor([[90.8973]])\n",
      "[0.59570277]\n",
      "Mode: Test env_steps 200 total rewards -250.3824196299538 total energy tensor([[101.3255]])\n",
      "[-0.61435634]\n",
      "Mode: Test env_steps 200 total rewards -123.28017971012741 total energy tensor([[82.0888]])\n",
      "[-0.38815984]\n",
      "Mode: Test env_steps 200 total rewards -132.12308444362134 total energy tensor([[94.9613]])\n",
      "[-0.36034685]\n",
      "Mode: Test env_steps 200 total rewards -128.17282619327307 total energy tensor([[89.2428]])\n",
      "425000 -195.99735480499803\n",
      "[0.5513777]\n",
      "Mode: Train env_steps 200 total rewards -132.5335914203897 total energy tensor([[92.2918]])\n",
      "[-0.1677125]\n",
      "Mode: Train env_steps 200 total rewards -126.52474948111922 total energy tensor([[103.0969]])\n",
      "[-0.3608337]\n",
      "Mode: Train env_steps 200 total rewards -131.88576994743198 total energy tensor([[92.2465]])\n",
      "[-0.14138739]\n",
      "Mode: Train env_steps 200 total rewards -132.4178757434711 total energy tensor([[94.5807]])\n",
      "[0.91886675]\n",
      "Mode: Train env_steps 200 total rewards -258.5071890121326 total energy tensor([[99.1980]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6942573]\n",
      "Mode: Train env_steps 200 total rewards -263.1122537171468 total energy tensor([[112.7230]])\n",
      "[-0.6389417]\n",
      "Mode: Train env_steps 200 total rewards -127.77049024682492 total energy tensor([[97.0458]])\n",
      "[0.22294235]\n",
      "Mode: Train env_steps 200 total rewards -129.13404135778546 total energy tensor([[97.9161]])\n",
      "[-0.6862064]\n",
      "Mode: Train env_steps 200 total rewards -134.23531912546605 total energy tensor([[100.5530]])\n",
      "[-0.25309667]\n",
      "Mode: Train env_steps 200 total rewards -229.88800012599677 total energy tensor([[109.8467]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34945053]\n",
      "Mode: Train env_steps 200 total rewards -126.49095788458362 total energy tensor([[79.5715]])\n",
      "[-0.60368]\n",
      "Mode: Train env_steps 200 total rewards -127.13904276164249 total energy tensor([[77.8478]])\n",
      "[-0.24356987]\n",
      "Mode: Train env_steps 200 total rewards -119.35982221970335 total energy tensor([[75.8028]])\n",
      "[0.6923076]\n",
      "Mode: Train env_steps 200 total rewards -255.40265850396827 total energy tensor([[106.1422]])\n",
      "[-0.28950232]\n",
      "Mode: Train env_steps 200 total rewards -131.7758221141994 total energy tensor([[84.2778]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8105914]\n",
      "Mode: Train env_steps 200 total rewards -384.2242071805522 total energy tensor([[111.3955]])\n",
      "[-0.1454963]\n",
      "Mode: Train env_steps 200 total rewards -128.47668267437257 total energy tensor([[83.9675]])\n",
      "[0.00375348]\n",
      "Mode: Train env_steps 200 total rewards -277.887822591234 total energy tensor([[94.9927]])\n",
      "[0.7714181]\n",
      "Mode: Train env_steps 200 total rewards -248.08051342330873 total energy tensor([[99.3641]])\n",
      "[-0.986275]\n",
      "Mode: Train env_steps 200 total rewards -249.86436064261943 total energy tensor([[96.7332]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.940646]\n",
      "Mode: Train env_steps 200 total rewards -128.38276681862772 total energy tensor([[84.5557]])\n",
      "[0.80783033]\n",
      "Mode: Train env_steps 200 total rewards -124.34088264591992 total energy tensor([[85.7380]])\n",
      "[-0.6661638]\n",
      "Mode: Train env_steps 200 total rewards -258.53884868323803 total energy tensor([[103.8913]])\n",
      "[-0.6593645]\n",
      "Mode: Train env_steps 200 total rewards -247.82083315728232 total energy tensor([[95.2250]])\n",
      "[0.8180185]\n",
      "Mode: Train env_steps 200 total rewards -370.5159229747951 total energy tensor([[129.8212]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8362954]\n",
      "Mode: Test env_steps 200 total rewards -118.77155611221679 total energy tensor([[76.8884]])\n",
      "[-0.3825229]\n",
      "Mode: Test env_steps 200 total rewards -3.706940034404397 total energy tensor([[74.9132]])\n",
      "[0.6687843]\n",
      "Mode: Test env_steps 200 total rewards -255.7089059301652 total energy tensor([[99.8611]])\n",
      "[0.36461827]\n",
      "Mode: Test env_steps 200 total rewards -251.49583027185872 total energy tensor([[97.9306]])\n",
      "[0.06490245]\n",
      "Mode: Test env_steps 200 total rewards -2.556413392769173 total energy tensor([[67.6807]])\n",
      "[0.29597875]\n",
      "Mode: Test env_steps 200 total rewards -2.8443418703973293 total energy tensor([[73.4974]])\n",
      "[-0.4833438]\n",
      "Mode: Test env_steps 200 total rewards -3.138554784003645 total energy tensor([[74.1367]])\n",
      "[-0.80545413]\n",
      "Mode: Test env_steps 200 total rewards -256.7522795959376 total energy tensor([[108.4000]])\n",
      "[-0.88860404]\n",
      "Mode: Test env_steps 200 total rewards -131.3020767425187 total energy tensor([[85.0204]])\n",
      "[-0.9039587]\n",
      "Mode: Test env_steps 200 total rewards -298.46379832783714 total energy tensor([[102.1064]])\n",
      "430000 -132.47406970621086\n",
      "[0.02510479]\n",
      "Mode: Train env_steps 200 total rewards -123.22628540545702 total energy tensor([[82.5319]])\n",
      "[0.9526223]\n",
      "Mode: Train env_steps 200 total rewards -249.00140788732097 total energy tensor([[102.9299]])\n",
      "[0.8162582]\n",
      "Mode: Train env_steps 200 total rewards -4.283976756501943 total energy tensor([[80.9243]])\n",
      "[0.0113992]\n",
      "Mode: Train env_steps 200 total rewards -237.1872599599883 total energy tensor([[102.4348]])\n",
      "[0.9256037]\n",
      "Mode: Train env_steps 200 total rewards -125.76139809936285 total energy tensor([[75.8766]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.60139763]\n",
      "Mode: Train env_steps 200 total rewards -498.78767334111035 total energy tensor([[122.2552]])\n",
      "[0.9207532]\n",
      "Mode: Train env_steps 200 total rewards -296.9714049305767 total energy tensor([[114.3596]])\n",
      "[0.36108395]\n",
      "Mode: Train env_steps 200 total rewards -133.24100263882428 total energy tensor([[100.7293]])\n",
      "[0.7261206]\n",
      "Mode: Train env_steps 200 total rewards -126.61820558551699 total energy tensor([[101.9675]])\n",
      "[-0.84753215]\n",
      "Mode: Train env_steps 200 total rewards -134.75271281972528 total energy tensor([[110.1517]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02760634]\n",
      "Mode: Train env_steps 200 total rewards -246.52520833397284 total energy tensor([[100.2601]])\n",
      "[-0.19850878]\n",
      "Mode: Train env_steps 200 total rewards -394.5366592220962 total energy tensor([[106.4717]])\n",
      "[0.28510728]\n",
      "Mode: Train env_steps 200 total rewards -132.0317263591569 total energy tensor([[79.1547]])\n",
      "[0.8046641]\n",
      "Mode: Train env_steps 200 total rewards -272.3350221172441 total energy tensor([[95.2353]])\n",
      "[0.83582425]\n",
      "Mode: Train env_steps 200 total rewards -127.41325596603565 total energy tensor([[95.4650]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.80053985]\n",
      "Mode: Train env_steps 200 total rewards -133.5884255496785 total energy tensor([[99.0373]])\n",
      "[0.90631443]\n",
      "Mode: Train env_steps 200 total rewards -120.4461187561974 total energy tensor([[97.9423]])\n",
      "[-0.68558675]\n",
      "Mode: Train env_steps 200 total rewards -130.29428028315306 total energy tensor([[94.1306]])\n",
      "[-0.82893366]\n",
      "Mode: Train env_steps 200 total rewards -5.493731178808957 total energy tensor([[98.4144]])\n",
      "[-0.3948408]\n",
      "Mode: Train env_steps 200 total rewards -121.53030887804925 total energy tensor([[102.6013]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86583865]\n",
      "Mode: Train env_steps 200 total rewards -134.59797018021345 total energy tensor([[90.6420]])\n",
      "[0.42004895]\n",
      "Mode: Train env_steps 200 total rewards -4.800259552896023 total energy tensor([[79.6070]])\n",
      "[-0.6006868]\n",
      "Mode: Train env_steps 200 total rewards -131.9430777868256 total energy tensor([[84.6951]])\n",
      "[0.02308009]\n",
      "Mode: Train env_steps 200 total rewards -247.1615251423791 total energy tensor([[103.5195]])\n",
      "[-0.6352458]\n",
      "Mode: Train env_steps 200 total rewards -388.97169106453657 total energy tensor([[105.2823]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52334595]\n",
      "Mode: Test env_steps 200 total rewards -136.2429376207292 total energy tensor([[105.5571]])\n",
      "[0.834944]\n",
      "Mode: Test env_steps 200 total rewards -256.17104287073016 total energy tensor([[113.7404]])\n",
      "[-0.34833434]\n",
      "Mode: Test env_steps 200 total rewards -387.668270688504 total energy tensor([[125.0989]])\n",
      "[0.49127057]\n",
      "Mode: Test env_steps 200 total rewards -126.7104835328646 total energy tensor([[95.8307]])\n",
      "[-0.1832098]\n",
      "Mode: Test env_steps 200 total rewards -134.35692076198757 total energy tensor([[108.8220]])\n",
      "[0.5169171]\n",
      "Mode: Test env_steps 200 total rewards -350.41406390443444 total energy tensor([[116.8170]])\n",
      "[-0.7815603]\n",
      "Mode: Test env_steps 200 total rewards -130.24560959264636 total energy tensor([[97.0822]])\n",
      "[-0.66991705]\n",
      "Mode: Test env_steps 200 total rewards -232.34052201732993 total energy tensor([[110.1725]])\n",
      "[-0.5125405]\n",
      "Mode: Test env_steps 200 total rewards -128.08560160081834 total energy tensor([[98.7796]])\n",
      "[-0.40316728]\n",
      "Mode: Test env_steps 200 total rewards -6.595947050722316 total energy tensor([[89.7618]])\n",
      "435000 -188.8831399640767\n",
      "[-0.9791356]\n",
      "Mode: Train env_steps 200 total rewards -134.1207155631855 total energy tensor([[97.4372]])\n",
      "[0.50398976]\n",
      "Mode: Train env_steps 200 total rewards -246.76009557954967 total energy tensor([[108.1130]])\n",
      "[0.18956198]\n",
      "Mode: Train env_steps 200 total rewards -136.53898712061346 total energy tensor([[97.3259]])\n",
      "[0.4698767]\n",
      "Mode: Train env_steps 200 total rewards -133.16070006694645 total energy tensor([[96.1870]])\n",
      "[0.6484068]\n",
      "Mode: Train env_steps 200 total rewards -132.49533196352422 total energy tensor([[99.5177]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7649771]\n",
      "Mode: Train env_steps 200 total rewards -251.3392418883741 total energy tensor([[112.9830]])\n",
      "[0.61934614]\n",
      "Mode: Train env_steps 200 total rewards -135.1232595294714 total energy tensor([[106.4681]])\n",
      "[-0.44111076]\n",
      "Mode: Train env_steps 200 total rewards -127.51866283640265 total energy tensor([[107.1730]])\n",
      "[-0.7020057]\n",
      "Mode: Train env_steps 200 total rewards -136.11290354467928 total energy tensor([[116.0235]])\n",
      "[-0.7031559]\n",
      "Mode: Train env_steps 200 total rewards -129.96046424284577 total energy tensor([[101.5592]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.25235718]\n",
      "Mode: Train env_steps 200 total rewards -137.17808063700795 total energy tensor([[110.1575]])\n",
      "[0.48584455]\n",
      "Mode: Train env_steps 200 total rewards -130.66133098304272 total energy tensor([[103.2765]])\n",
      "[0.09153416]\n",
      "Mode: Train env_steps 200 total rewards -7.999177474528551 total energy tensor([[106.6329]])\n",
      "[0.97817034]\n",
      "Mode: Train env_steps 200 total rewards -135.71730642206967 total energy tensor([[108.1797]])\n",
      "[-0.664834]\n",
      "Mode: Train env_steps 200 total rewards -130.77644775435328 total energy tensor([[104.4707]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9586237]\n",
      "Mode: Train env_steps 200 total rewards -285.5042390692979 total energy tensor([[117.6555]])\n",
      "[-0.12971534]\n",
      "Mode: Train env_steps 200 total rewards -255.57755588553846 total energy tensor([[124.0220]])\n",
      "[-0.31164423]\n",
      "Mode: Train env_steps 200 total rewards -136.50322651024908 total energy tensor([[115.4163]])\n",
      "[0.72734594]\n",
      "Mode: Train env_steps 200 total rewards -7.766586416750215 total energy tensor([[105.5911]])\n",
      "[-0.82032484]\n",
      "Mode: Train env_steps 200 total rewards -132.71541915088892 total energy tensor([[107.6937]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0335201]\n",
      "Mode: Train env_steps 200 total rewards -241.0090979989618 total energy tensor([[128.6131]])\n",
      "[0.93421805]\n",
      "Mode: Train env_steps 200 total rewards -255.31407116912305 total energy tensor([[115.8943]])\n",
      "[-0.24754174]\n",
      "Mode: Train env_steps 200 total rewards -289.97686668505776 total energy tensor([[119.3188]])\n",
      "[0.44895872]\n",
      "Mode: Train env_steps 200 total rewards -255.3575003463775 total energy tensor([[119.5190]])\n",
      "[0.8250534]\n",
      "Mode: Train env_steps 200 total rewards -7.335465457290411 total energy tensor([[107.4155]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45383963]\n",
      "Mode: Test env_steps 200 total rewards -8.023485938087106 total energy tensor([[113.3800]])\n",
      "[0.5826818]\n",
      "Mode: Test env_steps 200 total rewards -120.95890864357352 total energy tensor([[111.2385]])\n",
      "[0.4322711]\n",
      "Mode: Test env_steps 200 total rewards -134.81670640874654 total energy tensor([[113.8000]])\n",
      "[-0.304161]\n",
      "Mode: Test env_steps 200 total rewards -128.10970521345735 total energy tensor([[118.2900]])\n",
      "[0.60038424]\n",
      "Mode: Test env_steps 200 total rewards -9.008685897104442 total energy tensor([[115.5055]])\n",
      "[0.54502624]\n",
      "Mode: Test env_steps 200 total rewards -263.6651569791138 total energy tensor([[117.5730]])\n",
      "[-0.06957762]\n",
      "Mode: Test env_steps 200 total rewards -134.3841254711151 total energy tensor([[110.4086]])\n",
      "[-0.34225842]\n",
      "Mode: Test env_steps 200 total rewards -134.4262009486556 total energy tensor([[104.0846]])\n",
      "[0.19213797]\n",
      "Mode: Test env_steps 200 total rewards -135.10317251086235 total energy tensor([[115.7084]])\n",
      "[0.87345684]\n",
      "Mode: Test env_steps 200 total rewards -256.30424197763205 total energy tensor([[120.7095]])\n",
      "440000 -132.4800389988348\n",
      "[-0.5744954]\n",
      "Mode: Train env_steps 200 total rewards -365.2210386637598 total energy tensor([[131.5520]])\n",
      "[-0.7229621]\n",
      "Mode: Train env_steps 200 total rewards -129.90507963486016 total energy tensor([[108.2719]])\n",
      "[0.24646805]\n",
      "Mode: Train env_steps 200 total rewards -128.74411471839994 total energy tensor([[103.9575]])\n",
      "[0.19292328]\n",
      "Mode: Train env_steps 200 total rewards -132.82859838567674 total energy tensor([[106.1805]])\n",
      "[0.20238142]\n",
      "Mode: Train env_steps 200 total rewards -125.8964388249442 total energy tensor([[108.3532]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40527192]\n",
      "Mode: Train env_steps 200 total rewards -130.04328216426075 total energy tensor([[98.4129]])\n",
      "[-0.7454816]\n",
      "Mode: Train env_steps 200 total rewards -133.38102404866368 total energy tensor([[96.6819]])\n",
      "[0.19623916]\n",
      "Mode: Train env_steps 200 total rewards -262.63467966299504 total energy tensor([[113.5900]])\n",
      "[0.9220173]\n",
      "Mode: Train env_steps 200 total rewards -5.156336301937699 total energy tensor([[99.2093]])\n",
      "[-0.42431578]\n",
      "Mode: Train env_steps 200 total rewards -136.77683843672276 total energy tensor([[115.7359]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.34141684]\n",
      "Mode: Train env_steps 200 total rewards -265.51327966107056 total energy tensor([[75.7411]])\n",
      "[0.65657264]\n",
      "Mode: Train env_steps 200 total rewards -2.519221712835133 total energy tensor([[65.2975]])\n",
      "[0.73993987]\n",
      "Mode: Train env_steps 200 total rewards -121.5239740225079 total energy tensor([[62.9012]])\n",
      "[-0.9436193]\n",
      "Mode: Train env_steps 200 total rewards -126.29468926717527 total energy tensor([[58.5414]])\n",
      "[-0.57994515]\n",
      "Mode: Train env_steps 200 total rewards -121.3237007349453 total energy tensor([[49.8697]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3263236]\n",
      "Mode: Train env_steps 200 total rewards -132.97095719678327 total energy tensor([[92.0066]])\n",
      "[-0.6800468]\n",
      "Mode: Train env_steps 200 total rewards -129.13909083162434 total energy tensor([[81.3667]])\n",
      "[0.67198044]\n",
      "Mode: Train env_steps 200 total rewards -131.8480101127643 total energy tensor([[84.9053]])\n",
      "[0.40996227]\n",
      "Mode: Train env_steps 200 total rewards -244.25856159767136 total energy tensor([[105.2718]])\n",
      "[-0.02607935]\n",
      "Mode: Train env_steps 200 total rewards -129.90254195523448 total energy tensor([[80.3631]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85171217]\n",
      "Mode: Train env_steps 200 total rewards -250.3744422774762 total energy tensor([[119.5520]])\n",
      "[0.6141939]\n",
      "Mode: Train env_steps 200 total rewards -251.71852980740368 total energy tensor([[120.4456]])\n",
      "[-0.84960735]\n",
      "Mode: Train env_steps 200 total rewards -140.00317929591984 total energy tensor([[122.4226]])\n",
      "[-0.37206075]\n",
      "Mode: Train env_steps 200 total rewards -133.1833173353225 total energy tensor([[115.5099]])\n",
      "[0.01081515]\n",
      "Mode: Train env_steps 200 total rewards -140.04567277245224 total energy tensor([[119.4640]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9733747]\n",
      "Mode: Test env_steps 200 total rewards -635.2715855590068 total energy tensor([[123.4954]])\n",
      "[-0.45432717]\n",
      "Mode: Test env_steps 200 total rewards -256.3557687886059 total energy tensor([[104.7353]])\n",
      "[0.819277]\n",
      "Mode: Test env_steps 200 total rewards -132.915760975593 total energy tensor([[79.5009]])\n",
      "[0.17718281]\n",
      "Mode: Test env_steps 200 total rewards -4.5104403188452125 total energy tensor([[75.9894]])\n",
      "[-0.47975096]\n",
      "Mode: Test env_steps 200 total rewards -250.93667965126224 total energy tensor([[89.5688]])\n",
      "[0.95356923]\n",
      "Mode: Test env_steps 200 total rewards -131.48647822858766 total energy tensor([[75.0752]])\n",
      "[-0.91191727]\n",
      "Mode: Test env_steps 200 total rewards -124.50597341218963 total energy tensor([[70.5068]])\n",
      "[0.13218969]\n",
      "Mode: Test env_steps 200 total rewards -122.48791706538759 total energy tensor([[85.1626]])\n",
      "[0.59331995]\n",
      "Mode: Test env_steps 200 total rewards -262.82126073841937 total energy tensor([[98.2200]])\n",
      "[0.18725973]\n",
      "Mode: Test env_steps 200 total rewards -120.19510356220417 total energy tensor([[78.0896]])\n",
      "445000 -204.14869683001015\n",
      "[0.36433277]\n",
      "Mode: Train env_steps 200 total rewards -246.09822424966842 total energy tensor([[96.5231]])\n",
      "[-0.03679512]\n",
      "Mode: Train env_steps 200 total rewards -267.54736290033907 total energy tensor([[95.6922]])\n",
      "[-0.29659837]\n",
      "Mode: Train env_steps 200 total rewards -122.31735785584897 total energy tensor([[81.1589]])\n",
      "[-0.58166856]\n",
      "Mode: Train env_steps 200 total rewards -248.08761870628223 total energy tensor([[90.6276]])\n",
      "[0.37230027]\n",
      "Mode: Train env_steps 200 total rewards -287.7956059977878 total energy tensor([[95.7273]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3103795]\n",
      "Mode: Train env_steps 200 total rewards -128.64092652592808 total energy tensor([[115.2049]])\n",
      "[-0.1407167]\n",
      "Mode: Train env_steps 200 total rewards -128.4890580899082 total energy tensor([[100.5431]])\n",
      "[-0.05727695]\n",
      "Mode: Train env_steps 200 total rewards -132.39953577145934 total energy tensor([[96.5888]])\n",
      "[0.00734515]\n",
      "Mode: Train env_steps 200 total rewards -134.75480555649847 total energy tensor([[100.4256]])\n",
      "[0.17412193]\n",
      "Mode: Train env_steps 200 total rewards -265.51134930737317 total energy tensor([[120.8449]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.55109]\n",
      "Mode: Train env_steps 200 total rewards -129.64671940729022 total energy tensor([[100.8697]])\n",
      "[0.6006337]\n",
      "Mode: Train env_steps 200 total rewards -124.82568215206265 total energy tensor([[102.1824]])\n",
      "[-0.6677419]\n",
      "Mode: Train env_steps 200 total rewards -274.89807331282645 total energy tensor([[114.2120]])\n",
      "[-0.720055]\n",
      "Mode: Train env_steps 200 total rewards -364.91340865567327 total energy tensor([[125.1556]])\n",
      "[0.38378608]\n",
      "Mode: Train env_steps 200 total rewards -263.04838011041284 total energy tensor([[115.7467]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10198621]\n",
      "Mode: Train env_steps 200 total rewards -5.304648163146339 total energy tensor([[98.2890]])\n",
      "[-0.45510256]\n",
      "Mode: Train env_steps 200 total rewards -5.604667384410277 total energy tensor([[100.3160]])\n",
      "[0.57892907]\n",
      "Mode: Train env_steps 200 total rewards -132.59799230191857 total energy tensor([[95.4120]])\n",
      "[0.48119467]\n",
      "Mode: Train env_steps 200 total rewards -292.46376936773595 total energy tensor([[111.8496]])\n",
      "[0.22776157]\n",
      "Mode: Train env_steps 200 total rewards -254.31109152175486 total energy tensor([[116.6071]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07630536]\n",
      "Mode: Train env_steps 200 total rewards -133.38375558890402 total energy tensor([[94.5626]])\n",
      "[-0.91918576]\n",
      "Mode: Train env_steps 200 total rewards -251.3328442275524 total energy tensor([[111.0277]])\n",
      "[-0.5160418]\n",
      "Mode: Train env_steps 200 total rewards -122.3096694322303 total energy tensor([[75.7886]])\n",
      "[0.4821917]\n",
      "Mode: Train env_steps 200 total rewards -305.1845851484686 total energy tensor([[111.8364]])\n",
      "[-0.46042705]\n",
      "Mode: Train env_steps 200 total rewards -129.4744093986228 total energy tensor([[93.8143]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10056206]\n",
      "Mode: Test env_steps 200 total rewards -130.79545252863318 total energy tensor([[92.0738]])\n",
      "[0.72766626]\n",
      "Mode: Test env_steps 200 total rewards -369.54363769106567 total energy tensor([[127.7353]])\n",
      "[-0.9721535]\n",
      "Mode: Test env_steps 200 total rewards -249.50906748883426 total energy tensor([[109.6225]])\n",
      "[0.952785]\n",
      "Mode: Test env_steps 200 total rewards -388.2683322057128 total energy tensor([[106.2898]])\n",
      "[-0.27461457]\n",
      "Mode: Test env_steps 200 total rewards -385.44223456829786 total energy tensor([[98.8733]])\n",
      "[-0.3070635]\n",
      "Mode: Test env_steps 200 total rewards -129.58221592847258 total energy tensor([[86.4848]])\n",
      "[-0.7869236]\n",
      "Mode: Test env_steps 200 total rewards -131.770368472673 total energy tensor([[88.2633]])\n",
      "[-0.7513096]\n",
      "Mode: Test env_steps 200 total rewards -5.24715841235593 total energy tensor([[84.4667]])\n",
      "[0.3841758]\n",
      "Mode: Test env_steps 200 total rewards -254.33982778713107 total energy tensor([[101.9105]])\n",
      "[-0.3799594]\n",
      "Mode: Test env_steps 200 total rewards -125.27048601116985 total energy tensor([[96.7380]])\n",
      "450000 -216.9768781094346\n",
      "[0.33815813]\n",
      "Mode: Train env_steps 200 total rewards -4.029121581465006 total energy tensor([[79.8348]])\n",
      "[-0.71404666]\n",
      "Mode: Train env_steps 200 total rewards -342.2480175290257 total energy tensor([[110.8583]])\n",
      "[-0.6503963]\n",
      "Mode: Train env_steps 200 total rewards -251.6709869839251 total energy tensor([[98.8855]])\n",
      "[-0.95107925]\n",
      "Mode: Train env_steps 200 total rewards -132.7192842233926 total energy tensor([[86.0631]])\n",
      "[-0.36912882]\n",
      "Mode: Train env_steps 200 total rewards -122.9772352669388 total energy tensor([[97.4905]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:10<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92549103]\n",
      "Mode: Train env_steps 200 total rewards -266.7725995667279 total energy tensor([[114.4433]])\n",
      "[0.5060967]\n",
      "Mode: Train env_steps 200 total rewards -125.40736495144665 total energy tensor([[96.1345]])\n",
      "[0.48678643]\n",
      "Mode: Train env_steps 200 total rewards -241.33093690872192 total energy tensor([[117.3924]])\n",
      "[0.34623954]\n",
      "Mode: Train env_steps 200 total rewards -135.17769900336862 total energy tensor([[97.3204]])\n",
      "[0.47661838]\n",
      "Mode: Train env_steps 200 total rewards -133.73875191714615 total energy tensor([[96.7880]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:05<00:00,  2.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20033379]\n",
      "Mode: Train env_steps 200 total rewards -260.44026751071215 total energy tensor([[109.4109]])\n",
      "[0.7965357]\n",
      "Mode: Train env_steps 200 total rewards -132.76485362276435 total energy tensor([[105.0957]])\n",
      "[0.8947072]\n",
      "Mode: Train env_steps 200 total rewards -278.6236305516213 total energy tensor([[116.4712]])\n",
      "[-0.4458339]\n",
      "Mode: Train env_steps 200 total rewards -134.73020118288696 total energy tensor([[99.8789]])\n",
      "[0.31647193]\n",
      "Mode: Train env_steps 200 total rewards -248.58196375519037 total energy tensor([[113.1862]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22462429]\n",
      "Mode: Train env_steps 200 total rewards -236.86833074036986 total energy tensor([[115.0042]])\n",
      "[0.4665418]\n",
      "Mode: Train env_steps 200 total rewards -296.578028537333 total energy tensor([[126.8188]])\n",
      "[0.06744453]\n",
      "Mode: Train env_steps 200 total rewards -260.3439374063164 total energy tensor([[128.2490]])\n",
      "[0.54556394]\n",
      "Mode: Train env_steps 200 total rewards -125.7543561104685 total energy tensor([[110.7614]])\n",
      "[0.22430024]\n",
      "Mode: Train env_steps 200 total rewards -132.89301673322916 total energy tensor([[100.3395]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41618374]\n",
      "Mode: Train env_steps 200 total rewards -250.57574122492224 total energy tensor([[107.1012]])\n",
      "[0.8378766]\n",
      "Mode: Train env_steps 200 total rewards -264.4095369707793 total energy tensor([[113.2407]])\n",
      "[-0.40522593]\n",
      "Mode: Train env_steps 200 total rewards -338.6421525646001 total energy tensor([[120.7580]])\n",
      "[-0.80182606]\n",
      "Mode: Train env_steps 200 total rewards -5.91361128538847 total energy tensor([[94.2811]])\n",
      "[0.9978197]\n",
      "Mode: Train env_steps 200 total rewards -251.22123149875551 total energy tensor([[99.5752]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:58<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7690154]\n",
      "Mode: Test env_steps 200 total rewards -128.22418040130287 total energy tensor([[96.5676]])\n",
      "[-0.2082084]\n",
      "Mode: Test env_steps 200 total rewards -402.58290214650333 total energy tensor([[127.0905]])\n",
      "[0.9294969]\n",
      "Mode: Test env_steps 200 total rewards -127.98545033298433 total energy tensor([[94.0592]])\n",
      "[0.3884611]\n",
      "Mode: Test env_steps 200 total rewards -131.69439005292952 total energy tensor([[95.5269]])\n",
      "[0.7822895]\n",
      "Mode: Test env_steps 200 total rewards -123.63959630485624 total energy tensor([[101.6566]])\n",
      "[-0.9782603]\n",
      "Mode: Test env_steps 200 total rewards -245.26181967370212 total energy tensor([[106.1353]])\n",
      "[-0.68647987]\n",
      "Mode: Test env_steps 200 total rewards -253.00411114282906 total energy tensor([[108.0751]])\n",
      "[0.8387196]\n",
      "Mode: Test env_steps 200 total rewards -4.9730743588879704 total energy tensor([[100.6518]])\n",
      "[0.95028913]\n",
      "Mode: Test env_steps 200 total rewards -129.19559876993299 total energy tensor([[97.0863]])\n",
      "[0.64643043]\n",
      "Mode: Test env_steps 200 total rewards -126.83078625705093 total energy tensor([[95.2684]])\n",
      "455000 -167.33919094409794\n",
      "[-0.36166877]\n",
      "Mode: Train env_steps 200 total rewards -129.61772713717073 total energy tensor([[96.8495]])\n",
      "[-0.45079416]\n",
      "Mode: Train env_steps 200 total rewards -255.47024953272194 total energy tensor([[112.9404]])\n",
      "[0.62825876]\n",
      "Mode: Train env_steps 200 total rewards -130.44773634895682 total energy tensor([[92.9894]])\n",
      "[-0.7465217]\n",
      "Mode: Train env_steps 200 total rewards -4.840868017286994 total energy tensor([[96.2395]])\n",
      "[-0.87795293]\n",
      "Mode: Train env_steps 200 total rewards -347.9043546319008 total energy tensor([[127.3569]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57772595]\n",
      "Mode: Train env_steps 200 total rewards -128.59617310669273 total energy tensor([[97.5652]])\n",
      "[0.46708918]\n",
      "Mode: Train env_steps 200 total rewards -117.99970696028322 total energy tensor([[98.6009]])\n",
      "[0.1777116]\n",
      "Mode: Train env_steps 200 total rewards -131.36338140349835 total energy tensor([[103.6322]])\n",
      "[-0.30396843]\n",
      "Mode: Train env_steps 200 total rewards -247.7967080269009 total energy tensor([[112.4530]])\n",
      "[0.5449725]\n",
      "Mode: Train env_steps 200 total rewards -135.19315098505467 total energy tensor([[95.4457]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4323032]\n",
      "Mode: Train env_steps 200 total rewards -132.28963596001267 total energy tensor([[88.1836]])\n",
      "[0.342203]\n",
      "Mode: Train env_steps 200 total rewards -133.8872472019866 total energy tensor([[91.0053]])\n",
      "[0.09889527]\n",
      "Mode: Train env_steps 200 total rewards -134.27771735889837 total energy tensor([[91.8494]])\n",
      "[-0.895948]\n",
      "Mode: Train env_steps 200 total rewards -134.28185205161572 total energy tensor([[98.2334]])\n",
      "[0.38614988]\n",
      "Mode: Train env_steps 200 total rewards -264.78383420733735 total energy tensor([[118.8292]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26137593]\n",
      "Mode: Train env_steps 200 total rewards -132.56019104458392 total energy tensor([[104.3423]])\n",
      "[-0.23820414]\n",
      "Mode: Train env_steps 200 total rewards -135.08398622646928 total energy tensor([[108.4511]])\n",
      "[-0.9297532]\n",
      "Mode: Train env_steps 200 total rewards -127.73111995309591 total energy tensor([[97.9870]])\n",
      "[0.44633648]\n",
      "Mode: Train env_steps 200 total rewards -7.150878103449941 total energy tensor([[105.8977]])\n",
      "[0.41773906]\n",
      "Mode: Train env_steps 200 total rewards -6.995528610888869 total energy tensor([[103.6187]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12318631]\n",
      "Mode: Train env_steps 200 total rewards -255.15803246479481 total energy tensor([[109.5738]])\n",
      "[0.75603056]\n",
      "Mode: Train env_steps 200 total rewards -259.59563946165144 total energy tensor([[100.8080]])\n",
      "[0.31737018]\n",
      "Mode: Train env_steps 200 total rewards -119.84709122218192 total energy tensor([[109.8337]])\n",
      "[-0.22385682]\n",
      "Mode: Train env_steps 200 total rewards -259.1614349298179 total energy tensor([[120.2193]])\n",
      "[0.02264736]\n",
      "Mode: Train env_steps 200 total rewards -246.95785899087787 total energy tensor([[118.2795]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:01<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.30571997]\n",
      "Mode: Test env_steps 200 total rewards -130.22711432512733 total energy tensor([[78.1002]])\n",
      "[-0.13638355]\n",
      "Mode: Test env_steps 200 total rewards -122.56192859663861 total energy tensor([[80.7374]])\n",
      "[0.6111101]\n",
      "Mode: Test env_steps 200 total rewards -250.17279787530424 total energy tensor([[103.1945]])\n",
      "[0.23772836]\n",
      "Mode: Test env_steps 200 total rewards -242.4036600307736 total energy tensor([[95.9784]])\n",
      "[-0.433078]\n",
      "Mode: Test env_steps 200 total rewards -123.59575156238861 total energy tensor([[81.1764]])\n",
      "[-0.70558673]\n",
      "Mode: Test env_steps 200 total rewards -125.92155964666745 total energy tensor([[79.2782]])\n",
      "[-0.7776515]\n",
      "Mode: Test env_steps 200 total rewards -132.9756430309717 total energy tensor([[85.1294]])\n",
      "[-0.8210939]\n",
      "Mode: Test env_steps 200 total rewards -123.75159262234229 total energy tensor([[81.2787]])\n",
      "[-0.00320633]\n",
      "Mode: Test env_steps 200 total rewards -390.9354762751609 total energy tensor([[119.4860]])\n",
      "[0.90546006]\n",
      "Mode: Test env_steps 200 total rewards -128.3240005940388 total energy tensor([[83.2533]])\n",
      "460000 -177.08695245594134\n",
      "[-0.08432357]\n",
      "Mode: Train env_steps 200 total rewards -132.8510744573723 total energy tensor([[88.5547]])\n",
      "[0.92899483]\n",
      "Mode: Train env_steps 200 total rewards -264.5685501643602 total energy tensor([[89.8492]])\n",
      "[-0.915189]\n",
      "Mode: Train env_steps 200 total rewards -257.5958409602754 total energy tensor([[108.5947]])\n",
      "[0.7071763]\n",
      "Mode: Train env_steps 200 total rewards -128.86555709451204 total energy tensor([[81.1170]])\n",
      "[0.42706773]\n",
      "Mode: Train env_steps 200 total rewards -122.82650111726252 total energy tensor([[78.2400]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7833605]\n",
      "Mode: Train env_steps 200 total rewards -3.5948924524709582 total energy tensor([[73.6906]])\n",
      "[-0.7489716]\n",
      "Mode: Train env_steps 200 total rewards -128.56197642942425 total energy tensor([[75.9521]])\n",
      "[-0.42450443]\n",
      "Mode: Train env_steps 200 total rewards -251.49196866009152 total energy tensor([[95.6294]])\n",
      "[0.22923523]\n",
      "Mode: Train env_steps 200 total rewards -251.62643042067066 total energy tensor([[97.7571]])\n",
      "[0.9776109]\n",
      "Mode: Train env_steps 200 total rewards -133.5985625104513 total energy tensor([[94.6067]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:11<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06403014]\n",
      "Mode: Train env_steps 200 total rewards -123.30558277852833 total energy tensor([[107.1357]])\n",
      "[0.82625383]\n",
      "Mode: Train env_steps 200 total rewards -241.83828386012465 total energy tensor([[120.6231]])\n",
      "[0.6769694]\n",
      "Mode: Train env_steps 200 total rewards -133.36216575372964 total energy tensor([[107.9301]])\n",
      "[0.46009782]\n",
      "Mode: Train env_steps 200 total rewards -133.57791788876057 total energy tensor([[97.3840]])\n",
      "[-0.9028839]\n",
      "Mode: Train env_steps 200 total rewards -129.91754931397736 total energy tensor([[101.2022]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57169616]\n",
      "Mode: Train env_steps 200 total rewards -129.2487581684254 total energy tensor([[104.6220]])\n",
      "[-0.4038847]\n",
      "Mode: Train env_steps 200 total rewards -258.6452485672198 total energy tensor([[105.5800]])\n",
      "[0.8857743]\n",
      "Mode: Train env_steps 200 total rewards -132.6067256424576 total energy tensor([[99.7694]])\n",
      "[0.5792042]\n",
      "Mode: Train env_steps 200 total rewards -124.89887118898332 total energy tensor([[105.2652]])\n",
      "[-0.24757256]\n",
      "Mode: Train env_steps 200 total rewards -131.95783219393343 total energy tensor([[97.8262]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4419897]\n",
      "Mode: Train env_steps 200 total rewards -435.52613554149866 total energy tensor([[123.8051]])\n",
      "[0.09093813]\n",
      "Mode: Train env_steps 200 total rewards -245.9645926868543 total energy tensor([[114.1477]])\n",
      "[-0.06758998]\n",
      "Mode: Train env_steps 200 total rewards -261.9848958645016 total energy tensor([[111.5941]])\n",
      "[-0.3530512]\n",
      "Mode: Train env_steps 200 total rewards -300.03730409312993 total energy tensor([[122.2989]])\n",
      "[-0.254714]\n",
      "Mode: Train env_steps 200 total rewards -356.0506859868765 total energy tensor([[123.3776]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93336254]\n",
      "Mode: Test env_steps 200 total rewards -132.5540145151317 total energy tensor([[95.1864]])\n",
      "[-0.1488544]\n",
      "Mode: Test env_steps 200 total rewards -259.6544886738993 total energy tensor([[98.1470]])\n",
      "[0.03811683]\n",
      "Mode: Test env_steps 200 total rewards -244.21022817119956 total energy tensor([[96.2286]])\n",
      "[0.72574145]\n",
      "Mode: Test env_steps 200 total rewards -357.852786898613 total energy tensor([[112.6026]])\n",
      "[-0.8893181]\n",
      "Mode: Test env_steps 200 total rewards -130.10578035749495 total energy tensor([[84.9015]])\n",
      "[0.43928295]\n",
      "Mode: Test env_steps 200 total rewards -122.49233397096395 total energy tensor([[93.7144]])\n",
      "[-0.5616479]\n",
      "Mode: Test env_steps 200 total rewards -129.5866275196895 total energy tensor([[80.7995]])\n",
      "[-0.13829356]\n",
      "Mode: Test env_steps 200 total rewards -134.0852078795433 total energy tensor([[87.3707]])\n",
      "[-0.8847222]\n",
      "Mode: Test env_steps 200 total rewards -259.18700963724405 total energy tensor([[113.8297]])\n",
      "[0.5150565]\n",
      "Mode: Test env_steps 200 total rewards -3.9243663637898862 total energy tensor([[82.6072]])\n",
      "465000 -177.36528439875693\n",
      "[-0.5827681]\n",
      "Mode: Train env_steps 200 total rewards -132.34386812895536 total energy tensor([[82.4789]])\n",
      "[-0.72888994]\n",
      "Mode: Train env_steps 200 total rewards -121.32836503535509 total energy tensor([[82.8365]])\n",
      "[-0.2175579]\n",
      "Mode: Train env_steps 200 total rewards -5.158845195546746 total energy tensor([[88.9648]])\n",
      "[0.68312067]\n",
      "Mode: Train env_steps 200 total rewards -129.43955485057086 total energy tensor([[91.7341]])\n",
      "[0.53864664]\n",
      "Mode: Train env_steps 200 total rewards -239.4043316412717 total energy tensor([[97.6169]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:07<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13903977]\n",
      "Mode: Train env_steps 200 total rewards -254.30706789437681 total energy tensor([[115.9340]])\n",
      "[0.3769466]\n",
      "Mode: Train env_steps 200 total rewards -4.182600045576692 total energy tensor([[87.9464]])\n",
      "[-0.68529576]\n",
      "Mode: Train env_steps 200 total rewards -256.2136761294678 total energy tensor([[107.6548]])\n",
      "[0.03210825]\n",
      "Mode: Train env_steps 200 total rewards -127.41198204737157 total energy tensor([[92.6944]])\n",
      "[-0.48686308]\n",
      "Mode: Train env_steps 200 total rewards -132.0841447915882 total energy tensor([[97.7499]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.44738922]\n",
      "Mode: Train env_steps 200 total rewards -4.120580009184778 total energy tensor([[83.1357]])\n",
      "[0.51648575]\n",
      "Mode: Train env_steps 200 total rewards -406.69927438907325 total energy tensor([[118.0594]])\n",
      "[-0.4503845]\n",
      "Mode: Train env_steps 200 total rewards -127.78514518402517 total energy tensor([[83.2596]])\n",
      "[0.16878939]\n",
      "Mode: Train env_steps 200 total rewards -127.18823192222044 total energy tensor([[87.3865]])\n",
      "[0.82844776]\n",
      "Mode: Train env_steps 200 total rewards -131.28030300419778 total energy tensor([[89.3886]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5768296]\n",
      "Mode: Train env_steps 200 total rewards -3.467278244672343 total energy tensor([[43.7172]])\n",
      "[-0.0591124]\n",
      "Mode: Train env_steps 200 total rewards -256.0514837121591 total energy tensor([[92.9955]])\n",
      "[-0.6315477]\n",
      "Mode: Train env_steps 200 total rewards -256.0338904146338 total energy tensor([[64.2481]])\n",
      "[-0.04400034]\n",
      "Mode: Train env_steps 200 total rewards -131.8609937733272 total energy tensor([[59.7949]])\n",
      "[0.9854258]\n",
      "Mode: Train env_steps 200 total rewards -261.8391390107572 total energy tensor([[82.5777]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31716567]\n",
      "Mode: Train env_steps 200 total rewards -129.08488183934242 total energy tensor([[65.9304]])\n",
      "[0.6014861]\n",
      "Mode: Train env_steps 200 total rewards -131.60098295053467 total energy tensor([[65.1842]])\n",
      "[-0.79818016]\n",
      "Mode: Train env_steps 200 total rewards -2.890405272737553 total energy tensor([[45.0145]])\n",
      "[-0.98995894]\n",
      "Mode: Train env_steps 200 total rewards -255.25520974211395 total energy tensor([[81.6668]])\n",
      "[0.81662947]\n",
      "Mode: Train env_steps 200 total rewards -129.8698201654479 total energy tensor([[61.8605]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76677513]\n",
      "Mode: Test env_steps 200 total rewards -280.1995544144884 total energy tensor([[93.0359]])\n",
      "[0.26344404]\n",
      "Mode: Test env_steps 200 total rewards -127.28331845253706 total energy tensor([[72.9613]])\n",
      "[-0.15903156]\n",
      "Mode: Test env_steps 200 total rewards -132.3987669814378 total energy tensor([[78.6110]])\n",
      "[-0.94255495]\n",
      "Mode: Test env_steps 200 total rewards -505.2497683316469 total energy tensor([[114.3532]])\n",
      "[0.67268807]\n",
      "Mode: Test env_steps 200 total rewards -258.51706601539627 total energy tensor([[100.3940]])\n",
      "[-0.64111024]\n",
      "Mode: Test env_steps 200 total rewards -251.2232411429286 total energy tensor([[92.9991]])\n",
      "[-0.61095846]\n",
      "Mode: Test env_steps 200 total rewards -3.7629281899426132 total energy tensor([[63.6670]])\n",
      "[0.32801428]\n",
      "Mode: Test env_steps 200 total rewards -263.52532239817083 total energy tensor([[109.3543]])\n",
      "[0.04137099]\n",
      "Mode: Test env_steps 200 total rewards -133.71057115262374 total energy tensor([[86.1432]])\n",
      "[0.9500196]\n",
      "Mode: Test env_steps 200 total rewards -241.1445598853752 total energy tensor([[104.3142]])\n",
      "470000 -219.70150969645474\n",
      "[-0.35325223]\n",
      "Mode: Train env_steps 200 total rewards -135.46654457226396 total energy tensor([[83.0388]])\n",
      "[0.5796811]\n",
      "Mode: Train env_steps 200 total rewards -244.37677794136107 total energy tensor([[91.7044]])\n",
      "[-0.12809315]\n",
      "Mode: Train env_steps 200 total rewards -129.73090262617916 total energy tensor([[80.5034]])\n",
      "[-0.6429274]\n",
      "Mode: Train env_steps 200 total rewards -132.23881103191525 total energy tensor([[76.9015]])\n",
      "[0.14736839]\n",
      "Mode: Train env_steps 200 total rewards -122.33367243502289 total energy tensor([[80.0165]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.36712146]\n",
      "Mode: Train env_steps 200 total rewards -128.71127680083737 total energy tensor([[63.7252]])\n",
      "[0.48281738]\n",
      "Mode: Train env_steps 200 total rewards -246.67777063371614 total energy tensor([[81.5586]])\n",
      "[0.9493112]\n",
      "Mode: Train env_steps 200 total rewards -129.57452016416937 total energy tensor([[61.6907]])\n",
      "[0.9776032]\n",
      "Mode: Train env_steps 200 total rewards -130.59346496942453 total energy tensor([[63.3573]])\n",
      "[-0.4395984]\n",
      "Mode: Train env_steps 200 total rewards -3.7436094023287296 total energy tensor([[57.5422]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:08<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07352331]\n",
      "Mode: Train env_steps 200 total rewards -130.94092308403924 total energy tensor([[71.8257]])\n",
      "[0.654334]\n",
      "Mode: Train env_steps 200 total rewards -264.4479497773573 total energy tensor([[99.5173]])\n",
      "[0.0519382]\n",
      "Mode: Train env_steps 200 total rewards -134.7741439314559 total energy tensor([[77.7097]])\n",
      "[0.24128285]\n",
      "Mode: Train env_steps 200 total rewards -606.051562609151 total energy tensor([[127.9393]])\n",
      "[-0.10969388]\n",
      "Mode: Train env_steps 200 total rewards -252.42258359864354 total energy tensor([[85.0649]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4643055]\n",
      "Mode: Train env_steps 200 total rewards -252.7155219768174 total energy tensor([[97.7384]])\n",
      "[0.98279047]\n",
      "Mode: Train env_steps 200 total rewards -258.47023390675895 total energy tensor([[89.9655]])\n",
      "[0.20432295]\n",
      "Mode: Train env_steps 200 total rewards -131.05839569494128 total energy tensor([[91.6664]])\n",
      "[0.73977304]\n",
      "Mode: Train env_steps 200 total rewards -124.67005406622775 total energy tensor([[90.4807]])\n",
      "[-0.30142143]\n",
      "Mode: Train env_steps 200 total rewards -133.4005623352714 total energy tensor([[89.9748]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5832234]\n",
      "Mode: Train env_steps 200 total rewards -127.99478333769366 total energy tensor([[76.4721]])\n",
      "[0.24122176]\n",
      "Mode: Train env_steps 200 total rewards -260.9873964479193 total energy tensor([[108.7990]])\n",
      "[0.38167074]\n",
      "Mode: Train env_steps 200 total rewards -261.617673413828 total energy tensor([[101.6266]])\n",
      "[0.401047]\n",
      "Mode: Train env_steps 200 total rewards -135.20268486673012 total energy tensor([[90.5457]])\n",
      "[-0.01960087]\n",
      "Mode: Train env_steps 200 total rewards -257.5920564471744 total energy tensor([[105.0659]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7396393]\n",
      "Mode: Test env_steps 200 total rewards -252.35444080177695 total energy tensor([[102.4962]])\n",
      "[-0.603707]\n",
      "Mode: Test env_steps 200 total rewards -248.16202034475282 total energy tensor([[113.2536]])\n",
      "[-0.29681915]\n",
      "Mode: Test env_steps 200 total rewards -368.26036376785487 total energy tensor([[119.4646]])\n",
      "[-0.7739633]\n",
      "Mode: Test env_steps 200 total rewards -124.73830537172034 total energy tensor([[89.2474]])\n",
      "[0.09703378]\n",
      "Mode: Test env_steps 200 total rewards -276.53202553652227 total energy tensor([[107.6240]])\n",
      "[-0.8066493]\n",
      "Mode: Test env_steps 200 total rewards -130.35795160662383 total energy tensor([[85.2691]])\n",
      "[0.17781334]\n",
      "Mode: Test env_steps 200 total rewards -133.59496876597404 total energy tensor([[83.6965]])\n",
      "[-0.9754607]\n",
      "Mode: Test env_steps 200 total rewards -4.586455317214131 total energy tensor([[79.7294]])\n",
      "[-0.3577422]\n",
      "Mode: Test env_steps 200 total rewards -132.40218824986368 total energy tensor([[88.4081]])\n",
      "[0.2638392]\n",
      "Mode: Test env_steps 200 total rewards -129.1777917360887 total energy tensor([[82.1522]])\n",
      "475000 -180.01665114983916\n",
      "[-0.5911851]\n",
      "Mode: Train env_steps 200 total rewards -269.3547431854531 total energy tensor([[103.4126]])\n",
      "[-0.00663584]\n",
      "Mode: Train env_steps 200 total rewards -127.63422472495586 total energy tensor([[92.5056]])\n",
      "[-0.11472023]\n",
      "Mode: Train env_steps 200 total rewards -248.45650938572362 total energy tensor([[100.9853]])\n",
      "[0.5233339]\n",
      "Mode: Train env_steps 200 total rewards -271.18112845160067 total energy tensor([[101.4137]])\n",
      "[0.6044459]\n",
      "Mode: Train env_steps 200 total rewards -263.8672892842442 total energy tensor([[107.8693]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37380585]\n",
      "Mode: Train env_steps 200 total rewards -3.521247650438454 total energy tensor([[72.6158]])\n",
      "[0.61482173]\n",
      "Mode: Train env_steps 200 total rewards -134.6470694781019 total energy tensor([[89.5662]])\n",
      "[-0.05294228]\n",
      "Mode: Train env_steps 200 total rewards -261.68375680968165 total energy tensor([[102.8005]])\n",
      "[-0.38209528]\n",
      "Mode: Train env_steps 200 total rewards -243.4763692835695 total energy tensor([[93.8526]])\n",
      "[0.5559843]\n",
      "Mode: Train env_steps 200 total rewards -125.9422240377462 total energy tensor([[79.0175]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:12<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5248424]\n",
      "Mode: Train env_steps 200 total rewards -133.46525872685015 total energy tensor([[93.9504]])\n",
      "[-0.01523225]\n",
      "Mode: Train env_steps 200 total rewards -301.54830916412175 total energy tensor([[115.1268]])\n",
      "[-0.24561222]\n",
      "Mode: Train env_steps 200 total rewards -5.122552601620555 total energy tensor([[90.8014]])\n",
      "[-0.42612568]\n",
      "Mode: Train env_steps 200 total rewards -132.03000620566308 total energy tensor([[98.7301]])\n",
      "[0.98803544]\n",
      "Mode: Train env_steps 200 total rewards -126.39564696978778 total energy tensor([[98.5004]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:20<00:00,  3.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97136444]\n",
      "Mode: Train env_steps 200 total rewards -124.52225141372764 total energy tensor([[79.9126]])\n",
      "[0.8374714]\n",
      "Mode: Train env_steps 200 total rewards -128.13479595951503 total energy tensor([[76.7051]])\n",
      "[0.45783806]\n",
      "Mode: Train env_steps 200 total rewards -131.17480984749272 total energy tensor([[86.2359]])\n",
      "[0.08376033]\n",
      "Mode: Train env_steps 200 total rewards -127.88542323675938 total energy tensor([[74.9676]])\n",
      "[0.7377296]\n",
      "Mode: Train env_steps 200 total rewards -483.42083589185495 total energy tensor([[105.5297]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6549474]\n",
      "Mode: Train env_steps 200 total rewards -249.8815097513725 total energy tensor([[84.5687]])\n",
      "[-0.25836864]\n",
      "Mode: Train env_steps 200 total rewards -241.36776636587456 total energy tensor([[96.1603]])\n",
      "[-0.12426005]\n",
      "Mode: Train env_steps 200 total rewards -2.4151448438933585 total energy tensor([[59.1924]])\n",
      "[-0.69606864]\n",
      "Mode: Train env_steps 200 total rewards -130.91105022939155 total energy tensor([[78.6753]])\n",
      "[0.39481854]\n",
      "Mode: Train env_steps 200 total rewards -259.49978906218894 total energy tensor([[88.9264]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.87417734]\n",
      "Mode: Test env_steps 200 total rewards -513.334707908798 total energy tensor([[115.2435]])\n",
      "[0.17294699]\n",
      "Mode: Test env_steps 200 total rewards -1.9730445828172378 total energy tensor([[57.2802]])\n",
      "[-0.8144225]\n",
      "Mode: Test env_steps 200 total rewards -133.62573452852666 total energy tensor([[92.3940]])\n",
      "[0.25087723]\n",
      "Mode: Test env_steps 200 total rewards -126.18431554781273 total energy tensor([[74.9402]])\n",
      "[-0.05087547]\n",
      "Mode: Test env_steps 200 total rewards -132.29141245689243 total energy tensor([[86.6924]])\n",
      "[-0.65111756]\n",
      "Mode: Test env_steps 200 total rewards -4.871717137750238 total energy tensor([[77.8086]])\n",
      "[-0.75113636]\n",
      "Mode: Test env_steps 200 total rewards -260.0815745461732 total energy tensor([[111.1270]])\n",
      "[-0.9289759]\n",
      "Mode: Test env_steps 200 total rewards -398.09172666538507 total energy tensor([[108.7959]])\n",
      "[-0.03714598]\n",
      "Mode: Test env_steps 200 total rewards -134.79065879061818 total energy tensor([[97.5608]])\n",
      "[0.00452281]\n",
      "Mode: Test env_steps 200 total rewards -264.71244263043627 total energy tensor([[95.2481]])\n",
      "480000 -196.995733479521\n",
      "[0.79345316]\n",
      "Mode: Train env_steps 200 total rewards -125.9949639281258 total energy tensor([[85.4671]])\n",
      "[0.3359028]\n",
      "Mode: Train env_steps 200 total rewards -124.893949104473 total energy tensor([[86.9226]])\n",
      "[-0.9393694]\n",
      "Mode: Train env_steps 200 total rewards -250.25817488972098 total energy tensor([[103.2129]])\n",
      "[0.21688378]\n",
      "Mode: Train env_steps 200 total rewards -133.7112377109006 total energy tensor([[95.3149]])\n",
      "[0.03953914]\n",
      "Mode: Train env_steps 200 total rewards -128.99117013346404 total energy tensor([[79.1664]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:17<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0008517]\n",
      "Mode: Train env_steps 200 total rewards -129.867925129598 total energy tensor([[86.2696]])\n",
      "[0.7856148]\n",
      "Mode: Train env_steps 200 total rewards -243.5551445579622 total energy tensor([[93.0816]])\n",
      "[-0.03875805]\n",
      "Mode: Train env_steps 200 total rewards -131.42803360143444 total energy tensor([[80.1447]])\n",
      "[0.49375054]\n",
      "Mode: Train env_steps 200 total rewards -123.16236991074402 total energy tensor([[75.7405]])\n",
      "[-0.9953305]\n",
      "Mode: Train env_steps 200 total rewards -243.99021160346456 total energy tensor([[104.2365]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:14<00:00,  2.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.8535952]\n",
      "Mode: Train env_steps 200 total rewards -2.7371728295911453 total energy tensor([[71.0346]])\n",
      "[0.7437564]\n",
      "Mode: Train env_steps 200 total rewards -127.01819264760707 total energy tensor([[80.2425]])\n",
      "[-0.3491841]\n",
      "Mode: Train env_steps 200 total rewards -122.65757326810854 total energy tensor([[85.7657]])\n",
      "[0.22830245]\n",
      "Mode: Train env_steps 200 total rewards -126.7815950709628 total energy tensor([[81.2149]])\n",
      "[-0.9371177]\n",
      "Mode: Train env_steps 200 total rewards -131.50435359147377 total energy tensor([[86.9047]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65489244]\n",
      "Mode: Train env_steps 200 total rewards -249.68441506288946 total energy tensor([[119.6917]])\n",
      "[-0.6579275]\n",
      "Mode: Train env_steps 200 total rewards -134.29029233101755 total energy tensor([[107.2038]])\n",
      "[0.2809316]\n",
      "Mode: Train env_steps 200 total rewards -132.73874684190378 total energy tensor([[101.5141]])\n",
      "[0.9295965]\n",
      "Mode: Train env_steps 200 total rewards -252.25560629088432 total energy tensor([[109.4262]])\n",
      "[0.41395062]\n",
      "Mode: Train env_steps 200 total rewards -253.49035326298326 total energy tensor([[104.2700]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:57<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.29461253]\n",
      "Mode: Train env_steps 200 total rewards -130.4864598158747 total energy tensor([[92.6252]])\n",
      "[-0.0155475]\n",
      "Mode: Train env_steps 200 total rewards -243.44200342567638 total energy tensor([[98.7991]])\n",
      "[0.23032366]\n",
      "Mode: Train env_steps 200 total rewards -248.8640845650807 total energy tensor([[101.0981]])\n",
      "[-0.8839636]\n",
      "Mode: Train env_steps 200 total rewards -132.2330608293414 total energy tensor([[95.4470]])\n",
      "[-0.8103218]\n",
      "Mode: Train env_steps 200 total rewards -128.64155241288245 total energy tensor([[88.8449]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:56<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80310136]\n",
      "Mode: Test env_steps 200 total rewards -131.35838801506907 total energy tensor([[96.8889]])\n",
      "[-0.6154116]\n",
      "Mode: Test env_steps 200 total rewards -125.901616377756 total energy tensor([[97.9844]])\n",
      "[0.20758408]\n",
      "Mode: Test env_steps 200 total rewards -133.7194849923253 total energy tensor([[100.2466]])\n",
      "[-0.6286198]\n",
      "Mode: Test env_steps 200 total rewards -131.06384158413857 total energy tensor([[100.5551]])\n",
      "[0.5279493]\n",
      "Mode: Test env_steps 200 total rewards -612.7608074825257 total energy tensor([[124.0693]])\n",
      "[-0.05569864]\n",
      "Mode: Test env_steps 200 total rewards -133.0762545177713 total energy tensor([[103.9007]])\n",
      "[-0.8583667]\n",
      "Mode: Test env_steps 200 total rewards -249.6127993343398 total energy tensor([[113.1551]])\n",
      "[0.09262865]\n",
      "Mode: Test env_steps 200 total rewards -252.77408873476088 total energy tensor([[112.4201]])\n",
      "[-0.63491917]\n",
      "Mode: Test env_steps 200 total rewards -249.85205665510148 total energy tensor([[110.8904]])\n",
      "[-0.81824917]\n",
      "Mode: Test env_steps 200 total rewards -268.1142739197239 total energy tensor([[116.9658]])\n",
      "485000 -228.82336116135122\n",
      "[0.17724405]\n",
      "Mode: Train env_steps 200 total rewards -122.5296029811725 total energy tensor([[106.6385]])\n",
      "[-0.99426365]\n",
      "Mode: Train env_steps 200 total rewards -126.92937647085637 total energy tensor([[108.8756]])\n",
      "[0.17238826]\n",
      "Mode: Train env_steps 200 total rewards -243.12287442293018 total energy tensor([[109.2149]])\n",
      "[-0.4531345]\n",
      "Mode: Train env_steps 200 total rewards -386.10806326847523 total energy tensor([[127.1768]])\n",
      "[-0.38560438]\n",
      "Mode: Train env_steps 200 total rewards -133.01140529103577 total energy tensor([[107.1178]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:06<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28443003]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode: Train env_steps 200 total rewards -137.33993499912322 total energy tensor([[112.4578]])\n",
      "[-0.5241203]\n",
      "Mode: Train env_steps 200 total rewards -134.2436507102102 total energy tensor([[121.7020]])\n",
      "[0.67742383]\n",
      "Mode: Train env_steps 200 total rewards -138.20834214240313 total energy tensor([[126.3244]])\n",
      "[-0.76269025]\n",
      "Mode: Train env_steps 200 total rewards -138.01029145810753 total energy tensor([[116.6371]])\n",
      "[0.6854138]\n",
      "Mode: Train env_steps 200 total rewards -258.9337580977008 total energy tensor([[130.7779]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.407591]\n",
      "Mode: Train env_steps 200 total rewards -125.44009750615805 total energy tensor([[89.2171]])\n",
      "[0.7406143]\n",
      "Mode: Train env_steps 200 total rewards -132.701890735887 total energy tensor([[86.6569]])\n",
      "[-0.8672872]\n",
      "Mode: Train env_steps 200 total rewards -130.36407751962543 total energy tensor([[91.9349]])\n",
      "[0.32409576]\n",
      "Mode: Train env_steps 200 total rewards -128.78935676813126 total energy tensor([[89.6432]])\n",
      "[0.71445477]\n",
      "Mode: Train env_steps 200 total rewards -135.09487295430154 total energy tensor([[98.5716]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:13<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7540392]\n",
      "Mode: Train env_steps 200 total rewards -387.3841680120677 total energy tensor([[108.8634]])\n",
      "[0.97301537]\n",
      "Mode: Train env_steps 200 total rewards -272.1804550550878 total energy tensor([[118.6687]])\n",
      "[0.4385881]\n",
      "Mode: Train env_steps 200 total rewards -250.4051579264924 total energy tensor([[99.3808]])\n",
      "[-0.17037249]\n",
      "Mode: Train env_steps 200 total rewards -123.07173234780203 total energy tensor([[86.6634]])\n",
      "[0.55713254]\n",
      "Mode: Train env_steps 200 total rewards -2.1955849500081968 total energy tensor([[70.1708]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8868964]\n",
      "Mode: Train env_steps 200 total rewards -3.39353067392949 total energy tensor([[78.8317]])\n",
      "[-0.79125506]\n",
      "Mode: Train env_steps 200 total rewards -6.081567406654358 total energy tensor([[88.5652]])\n",
      "[-0.66594476]\n",
      "Mode: Train env_steps 200 total rewards -117.16121005191235 total energy tensor([[70.2591]])\n",
      "[-0.49726573]\n",
      "Mode: Train env_steps 200 total rewards -132.65188047569245 total energy tensor([[91.2617]])\n",
      "[0.7964062]\n",
      "Mode: Train env_steps 200 total rewards -252.63672951655462 total energy tensor([[111.4757]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03006093]\n",
      "Mode: Test env_steps 200 total rewards -131.96842581024976 total energy tensor([[86.1156]])\n",
      "[0.17442235]\n",
      "Mode: Test env_steps 200 total rewards -131.4971911147004 total energy tensor([[85.7740]])\n",
      "[0.39907268]\n",
      "Mode: Test env_steps 200 total rewards -259.53187916686875 total energy tensor([[98.4776]])\n",
      "[-0.5972635]\n",
      "Mode: Test env_steps 200 total rewards -121.8025941598462 total energy tensor([[90.9472]])\n",
      "[0.38339403]\n",
      "Mode: Test env_steps 200 total rewards -127.90747466863832 total energy tensor([[83.5843]])\n",
      "[0.9940689]\n",
      "Mode: Test env_steps 200 total rewards -125.80513024691027 total energy tensor([[82.3817]])\n",
      "[0.84294355]\n",
      "Mode: Test env_steps 200 total rewards -117.76048352959333 total energy tensor([[94.7195]])\n",
      "[-0.1689129]\n",
      "Mode: Test env_steps 200 total rewards -258.7435128974612 total energy tensor([[102.7975]])\n",
      "[0.02352538]\n",
      "Mode: Test env_steps 200 total rewards -254.13699150056345 total energy tensor([[97.3344]])\n",
      "[-0.97329897]\n",
      "Mode: Test env_steps 200 total rewards -3.6313321085181087 total energy tensor([[82.0423]])\n",
      "490000 -153.27850152033497\n",
      "[-0.8418452]\n",
      "Mode: Train env_steps 200 total rewards -397.2394340382889 total energy tensor([[122.2605]])\n",
      "[0.99140775]\n",
      "Mode: Train env_steps 200 total rewards -254.68158718582708 total energy tensor([[96.2175]])\n",
      "[-0.63683045]\n",
      "Mode: Train env_steps 200 total rewards -131.02962975486298 total energy tensor([[81.0921]])\n",
      "[0.96925867]\n",
      "Mode: Train env_steps 200 total rewards -131.04660166506073 total energy tensor([[89.4927]])\n",
      "[0.8526299]\n",
      "Mode: Train env_steps 200 total rewards -131.31763119701645 total energy tensor([[86.0526]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:55<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19759795]\n",
      "Mode: Train env_steps 200 total rewards -127.06490135639615 total energy tensor([[70.0388]])\n",
      "[0.3119044]\n",
      "Mode: Train env_steps 200 total rewards -132.06834178241115 total energy tensor([[71.9215]])\n",
      "[-0.69468415]\n",
      "Mode: Train env_steps 200 total rewards -131.95383646071423 total energy tensor([[75.4714]])\n",
      "[-0.98693633]\n",
      "Mode: Train env_steps 200 total rewards -245.69400694326032 total energy tensor([[91.5137]])\n",
      "[0.30714148]\n",
      "Mode: Train env_steps 200 total rewards -268.4785388807941 total energy tensor([[84.0923]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06878009]\n",
      "Mode: Train env_steps 200 total rewards -124.02556264205123 total energy tensor([[44.5119]])\n",
      "[0.22916275]\n",
      "Mode: Train env_steps 200 total rewards -135.30028307740577 total energy tensor([[74.6886]])\n",
      "[-0.4662969]\n",
      "Mode: Train env_steps 200 total rewards -132.2653689473982 total energy tensor([[68.4776]])\n",
      "[0.3939272]\n",
      "Mode: Train env_steps 200 total rewards -3.0678249594475346 total energy tensor([[39.0618]])\n",
      "[0.8031894]\n",
      "Mode: Train env_steps 200 total rewards -2.6685531837465533 total energy tensor([[38.7477]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:09<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48353282]\n",
      "Mode: Train env_steps 200 total rewards -248.548219565826 total energy tensor([[95.6283]])\n",
      "[-0.74020535]\n",
      "Mode: Train env_steps 200 total rewards -258.077797001577 total energy tensor([[98.0699]])\n",
      "[0.9937032]\n",
      "Mode: Train env_steps 200 total rewards -2.917320696738898 total energy tensor([[65.8429]])\n",
      "[-0.98682785]\n",
      "Mode: Train env_steps 200 total rewards -131.34091123059625 total energy tensor([[81.8719]])\n",
      "[0.24331433]\n",
      "Mode: Train env_steps 200 total rewards -124.27913508270285 total energy tensor([[78.3525]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.08399935]\n",
      "Mode: Train env_steps 200 total rewards -131.03129956610792 total energy tensor([[80.6716]])\n",
      "[-0.2036776]\n",
      "Mode: Train env_steps 200 total rewards -4.038139963566209 total energy tensor([[80.1435]])\n",
      "[0.9658718]\n",
      "Mode: Train env_steps 200 total rewards -121.694013890301 total energy tensor([[73.5228]])\n",
      "[0.42464694]\n",
      "Mode: Train env_steps 200 total rewards -126.94689379144256 total energy tensor([[81.5973]])\n",
      "[-0.22307149]\n",
      "Mode: Train env_steps 200 total rewards -387.11129237152636 total energy tensor([[106.8696]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4902099]\n",
      "Mode: Test env_steps 200 total rewards -256.4135865736753 total energy tensor([[103.8593]])\n",
      "[-0.04221676]\n",
      "Mode: Test env_steps 200 total rewards -125.7036449557636 total energy tensor([[82.7343]])\n",
      "[0.5274422]\n",
      "Mode: Test env_steps 200 total rewards -248.41823502955958 total energy tensor([[105.1150]])\n",
      "[0.68078804]\n",
      "Mode: Test env_steps 200 total rewards -132.70465861621778 total energy tensor([[83.1208]])\n",
      "[0.5598523]\n",
      "Mode: Test env_steps 200 total rewards -292.5606405127328 total energy tensor([[103.6965]])\n",
      "[0.19868726]\n",
      "Mode: Test env_steps 200 total rewards -259.0112415314652 total energy tensor([[114.3518]])\n",
      "[0.4641393]\n",
      "Mode: Test env_steps 200 total rewards -132.64615868672263 total energy tensor([[92.6575]])\n",
      "[0.21920373]\n",
      "Mode: Test env_steps 200 total rewards -251.02631700690836 total energy tensor([[103.5859]])\n",
      "[0.43732074]\n",
      "Mode: Test env_steps 200 total rewards -246.3524998719804 total energy tensor([[105.8012]])\n",
      "[0.6682334]\n",
      "Mode: Test env_steps 200 total rewards -126.75269406754524 total energy tensor([[91.3106]])\n",
      "495000 -207.1589676852571\n",
      "[-0.6860553]\n",
      "Mode: Train env_steps 200 total rewards -133.68617585813627 total energy tensor([[98.3202]])\n",
      "[0.49088156]\n",
      "Mode: Train env_steps 200 total rewards -125.52908565069083 total energy tensor([[83.5324]])\n",
      "[-0.14783524]\n",
      "Mode: Train env_steps 200 total rewards -123.90875766181853 total energy tensor([[89.3825]])\n",
      "[-0.57427263]\n",
      "Mode: Train env_steps 200 total rewards -124.59180960804224 total energy tensor([[87.7723]])\n",
      "[-0.07521755]\n",
      "Mode: Train env_steps 200 total rewards -129.32438090175856 total energy tensor([[80.1821]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.7794881]\n",
      "Mode: Train env_steps 200 total rewards -254.86754664349428 total energy tensor([[81.7866]])\n",
      "[-0.04121658]\n",
      "Mode: Train env_steps 200 total rewards -130.92226055594801 total energy tensor([[63.3452]])\n",
      "[0.47963962]\n",
      "Mode: Train env_steps 200 total rewards -131.37320149403422 total energy tensor([[70.8534]])\n",
      "[-0.4100632]\n",
      "Mode: Train env_steps 200 total rewards -130.90919349693286 total energy tensor([[67.8781]])\n",
      "[0.24477299]\n",
      "Mode: Train env_steps 200 total rewards -121.66213500726735 total energy tensor([[58.7865]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:04<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19676776]\n",
      "Mode: Train env_steps 200 total rewards -134.76720312424004 total energy tensor([[91.5323]])\n",
      "[-0.45472863]\n",
      "Mode: Train env_steps 200 total rewards -123.02899661101401 total energy tensor([[101.5614]])\n",
      "[-0.71062905]\n",
      "Mode: Train env_steps 200 total rewards -130.8275718446821 total energy tensor([[99.4107]])\n",
      "[-0.24890901]\n",
      "Mode: Train env_steps 200 total rewards -134.1108194924891 total energy tensor([[91.0435]])\n",
      "[-0.13397667]\n",
      "Mode: Train env_steps 200 total rewards -353.97884229943156 total energy tensor([[120.5560]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:59<00:00,  2.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.48478326]\n",
      "Mode: Train env_steps 200 total rewards -267.62108016898856 total energy tensor([[77.0357]])\n",
      "[0.44821787]\n",
      "Mode: Train env_steps 200 total rewards -126.72529591732018 total energy tensor([[46.2552]])\n",
      "[0.53346115]\n",
      "Mode: Train env_steps 200 total rewards -251.63636798829248 total energy tensor([[70.5384]])\n",
      "[0.00373527]\n",
      "Mode: Train env_steps 200 total rewards -130.11674220702116 total energy tensor([[49.3783]])\n",
      "[0.20486441]\n",
      "Mode: Train env_steps 200 total rewards -128.96466162950492 total energy tensor([[50.0044]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:02<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7817782]\n",
      "Mode: Train env_steps 200 total rewards -125.58146928576753 total energy tensor([[80.3985]])\n",
      "[0.11162623]\n",
      "Mode: Train env_steps 200 total rewards -133.63699871581048 total energy tensor([[86.3158]])\n",
      "[-0.22647287]\n",
      "Mode: Train env_steps 200 total rewards -129.03542649792507 total energy tensor([[79.4410]])\n",
      "[0.32514578]\n",
      "Mode: Train env_steps 200 total rewards -122.35592419886962 total energy tensor([[74.5827]])\n",
      "[-0.8992841]\n",
      "Mode: Train env_steps 200 total rewards -2.91182582359761 total energy tensor([[60.8664]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:00<00:00,  2.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3986993]\n",
      "Mode: Test env_steps 200 total rewards -129.89036101847887 total energy tensor([[86.6904]])\n",
      "[0.6673573]\n",
      "Mode: Test env_steps 200 total rewards -264.504752301611 total energy tensor([[117.2539]])\n",
      "[0.39476943]\n",
      "Mode: Test env_steps 200 total rewards -237.99032243527472 total energy tensor([[108.0499]])\n",
      "[0.449213]\n",
      "Mode: Test env_steps 200 total rewards -132.60539234383032 total energy tensor([[92.8979]])\n",
      "[0.89525515]\n",
      "Mode: Test env_steps 200 total rewards -460.30446324590594 total energy tensor([[119.5671]])\n",
      "[0.4970267]\n",
      "Mode: Test env_steps 200 total rewards -255.53987970482558 total energy tensor([[112.3562]])\n",
      "[0.20842469]\n",
      "Mode: Test env_steps 200 total rewards -123.9520032228902 total energy tensor([[89.6720]])\n",
      "[-0.66413945]\n",
      "Mode: Test env_steps 200 total rewards -118.67722654156387 total energy tensor([[101.7269]])\n",
      "[0.77201396]\n",
      "Mode: Test env_steps 200 total rewards -133.50972650479525 total energy tensor([[102.0232]])\n",
      "[0.29919115]\n",
      "Mode: Test env_steps 200 total rewards -251.6337338797748 total energy tensor([[106.5902]])\n",
      "500000 -210.86078611989507\n",
      "[0.7710325]\n",
      "Mode: Train env_steps 200 total rewards -246.87634313385934 total energy tensor([[115.0218]])\n",
      "[-0.7896334]\n",
      "Mode: Train env_steps 200 total rewards -133.11335922032595 total energy tensor([[102.4336]])\n",
      "[0.08204713]\n",
      "Mode: Train env_steps 200 total rewards -288.424168238882 total energy tensor([[107.6941]])\n",
      "[0.806871]\n",
      "Mode: Train env_steps 200 total rewards -244.9705325514078 total energy tensor([[105.7354]])\n",
      "[-0.4921799]\n",
      "Mode: Train env_steps 200 total rewards -136.4426039615646 total energy tensor([[98.0822]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [01:03<00:00,  2.55s/it]\n"
     ]
    }
   ],
   "source": [
    "policy_storage = SeqReplayBuffer(\n",
    "    max_replay_buffer_size=int(buffer_size),\n",
    "    observation_dim=obs_dim,\n",
    "    action_dim=act_dim,\n",
    "    sampled_seq_len=sampled_seq_len,\n",
    "    sample_weight_baseline=0.0,\n",
    ")\n",
    "\n",
    "env_steps = collect_rollouts(\n",
    "    num_rollouts=num_init_rollouts_pool, random_actions=False, train_mode=True\n",
    ")\n",
    "_n_env_steps_total += env_steps\n",
    "\n",
    "# evaluation parameters\n",
    "last_eval_num_iters = 10\n",
    "log_interval = 5\n",
    "eval_num_rollouts = 10\n",
    "learning_curve = {\n",
    "    \"x\": [],\n",
    "    \"y\": [],\n",
    "    \"z\": [],\n",
    "}\n",
    "epoch=0\n",
    "lambda_pat = 0.65\n",
    "\n",
    "while _n_env_steps_total < n_env_steps_total:\n",
    "\n",
    "    env_steps = collect_rollouts(num_rollouts=num_rollouts_per_iter, train_mode=True)\n",
    "    _n_env_steps_total += env_steps\n",
    "\n",
    "    #train_stats = update(int(num_updates_per_iter * env_steps))\n",
    "    factor= lambda_pat **(epoch )\n",
    "    #train_stats = update(int(num_updates_per_iter * env_steps))\n",
    "    train_stats = update(25, lr)\n",
    "    \n",
    "    epoch += 1\n",
    "    current_num_iters = _n_env_steps_total // (\n",
    "        num_rollouts_per_iter * max_trajectory_len\n",
    "    )\n",
    "    if (\n",
    "        current_num_iters != last_eval_num_iters\n",
    "        and current_num_iters % log_interval == 0\n",
    "    ):\n",
    "        last_eval_num_iters = current_num_iters\n",
    "        average_returns, std_returns = collect_rollouts(\n",
    "            num_rollouts=eval_num_rollouts,\n",
    "            train_mode=False,\n",
    "            random_actions=False,\n",
    "            deterministic=True,\n",
    "        )\n",
    "        learning_curve[\"x\"].append(_n_env_steps_total)\n",
    "        learning_curve[\"y\"].append(average_returns)\n",
    "        learning_curve[\"z\"].append(std_returns)\n",
    "        print(_n_env_steps_total, average_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000, 80000, 85000, 90000, 95000, 100000, 105000, 110000, 115000, 120000, 125000, 130000, 135000, 140000, 145000, 150000, 155000, 160000, 165000, 170000, 175000, 180000, 185000, 190000, 195000, 200000, 205000, 210000, 215000, 220000, 225000, 230000, 235000, 240000, 245000, 250000, 255000, 260000, 265000, 270000, 275000, 280000, 285000, 290000, 295000, 300000, 305000, 310000, 315000, 320000, 325000, 330000, 335000, 340000, 345000, 350000, 355000, 360000, 365000, 370000, 375000, 380000, 385000, 390000, 395000, 400000, 405000, 410000, 415000, 420000, 425000, 430000, 435000, 440000, 445000, 450000, 455000, 460000, 465000, 470000, 475000, 480000, 485000, 490000, 495000, 500000], 'y': [-1605.5890913292765, -1546.404285749793, -1563.8056536437944, -1410.3137237869203, -1369.2470292168728, -1437.0939343184232, -1401.9649479907007, -1513.5825214140118, -1557.005600644648, -1600.7387911051512, -1684.4408224910499, -1648.1100856330245, -1604.9766858205198, -1725.607207417488, -1764.442258496862, -1817.6762919813395, -1744.0563324511052, -1692.5429591393563, -1665.959056238411, -1689.4137621449306, -1698.5820810670498, -1770.1456763193012, -1670.102483735769, -1622.1631514001172, -1715.1475187532137, -1240.941596505046, -790.8538477457129, -780.4173276998102, -992.6746461760486, -953.3522028461099, -889.713728663139, -811.7315181134269, -1022.7245036236942, -758.3015984174024, -608.7466604893795, -538.0154279640323, -770.6695072909818, -611.4488924360834, -630.249949205853, -577.2913061339641, -640.5939843523083, -586.696713083866, -592.586226739164, -600.1487356006576, -637.1523199431133, -604.8197095833718, -612.6479075731011, -602.7239692499861, -1020.3058172870427, -544.8664353555534, -638.9444693105994, -627.8432691174094, -530.5046863144264, -412.76951709365824, -376.8002258625755, -285.48171982909554, -380.6772183057619, -287.9350707642734, -434.63958893002416, -313.31788809415303, -294.8710861566622, -429.9030177567154, -231.74851059587672, -203.76782851258758, -235.40381170450564, -219.69616123286542, -222.270483421674, -251.84354793889216, -180.22998849923025, -259.4061281327391, -284.89426764436064, -247.4718858914217, -325.07256155917423, -261.3265176373534, -252.59600914998447, -193.85754218650982, -245.55586320162985, -308.2839082948864, -185.15538226594217, -226.46621747812605, -194.56971135791392, -167.50056739361025, -171.87658838089556, -152.66518091880715, -195.99735480499803, -132.47406970621086, -188.8831399640767, -132.4800389988348, -204.14869683001015, -216.9768781094346, -167.33919094409794, -177.08695245594134, -177.36528439875693, -219.70150969645474, -180.01665114983916, -196.995733479521, -228.82336116135122, -153.27850152033497, -207.1589676852571, -210.86078611989507], 'z': [37.32408207749372, 158.94655103099004, 150.53264467560786, 197.3406656212154, 246.423772249853, 172.6080575705848, 178.2179528150892, 88.40724142121694, 33.22077854154973, 33.96100112469904, 45.56566851796649, 82.28313604720296, 151.4123035154392, 46.237157649856776, 114.4040541091485, 52.23908225961099, 94.67860536647635, 185.32031687312207, 156.08954106817305, 126.38295300155308, 213.51934863658585, 73.84289670066802, 159.70819330500262, 166.7698668817629, 169.88843915396492, 187.50495323307084, 231.8560636558732, 189.17136019930672, 166.80692868963143, 72.97905965195626, 85.60794598231928, 58.285732448120704, 320.11676010052764, 124.34606013007026, 70.0136864335577, 90.98128634983635, 127.41428603411481, 143.11799575541346, 92.51645571438212, 70.48536979456972, 87.99643000231511, 63.140480607909666, 172.2929775237101, 70.19383872878184, 78.27107189231027, 82.79913266891604, 120.72221010319315, 72.19334702735793, 234.1512462064994, 96.11657438290845, 99.13406473703142, 60.11021842376438, 198.82694919269852, 213.27819587568086, 233.82292366871556, 166.02289403828172, 99.66823332069373, 72.7553472882529, 92.92015972715782, 169.4083626460734, 112.39972000325498, 128.6420451130273, 104.640711184317, 137.61441322150412, 136.89301435575328, 127.24761055939952, 97.25440220794934, 144.5772128529037, 100.6934078732091, 54.61111322399819, 141.30094677953392, 102.14653348198225, 207.7205712493073, 138.85797622462394, 109.77634281596593, 151.33827771544455, 118.30658737219264, 116.20042585002028, 101.63359366343393, 103.64899926309445, 197.44888118240596, 58.1241326237538, 174.76624042563563, 73.60639165616442, 89.24744306506625, 118.12320395237374, 110.4521767775131, 79.654357857598, 162.63244554321898, 126.10195834678028, 102.20936646038017, 85.5308871587656, 95.91692310159044, 126.59590151509774, 98.96039351624933, 155.27618692255595, 140.8052799218434, 77.17424537284766, 64.62713612099579, 102.08268099929545]}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(learning_curve)\n",
    "plt.plot(learning_curve[\"x\"], learning_curve[\"y\"])\n",
    "plt.fill_between(np.array(learning_curve[\"x\"]), np.array(learning_curve[\"y\"])-np.array(learning_curve[\"z\"]), np.array(learning_curve[\"y\"])+np.array(learning_curve[\"z\"]))\n",
    "plt.xlabel(\"env steps\")\n",
    "plt.ylabel(\"return\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learning_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21516\\2942410656.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mleaning_curve_ncde_48_rk4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'learning_curve' is not defined"
     ]
    }
   ],
   "source": [
    "leaning_curve_ncde_48_rk4 = learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_curve_ncde_64= learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "timess=torch.linspace(0, 65-1, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [], 'y': []}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.LSTM(10, 20, 2)\n",
    "input = torch.randn(5, 3, 10)\n",
    "h0 = torch.randn(2, 3, 20)\n",
    "c0 = torch.randn(2, 3, 20)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection (x, y):\n",
    "    \n",
    "    proj= y*torch.sum(x*y)/(torch.norm(y)**2)\n",
    "    \n",
    "    return proj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0,1.0])\n",
    "y = torch.tensor([1.0,-1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = projection(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., -0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b5f49fb63f78fde0f27b95a7c8e14eeaa9af6d816174ff450f7bbbcd21c7c97c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
